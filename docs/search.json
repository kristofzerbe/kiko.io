[{"title":"Discoveries #2","url":"/categories/Discoveries/Discoveries-2/","content":"New month, new discoveries. We will deal with key bindings, downloads on the fly, a lot of animations and contrasting images. Have fun, trying out these stunning solutions.\n\n* tinykeys - Modern library for keybindings\n* Creating files in JavaScript in your browser\n* CSS Animated Google Fonts\n* Skeleton Screen CSS\n* More Control Over CSS Borders With background-image\n* A CSS-only, animated, wrapping underline\n* Nailing the Perfect Contrast Between Light Text and a Background Image\n* Contrast.js\n\n<!-- more -->\n\n---\n\n## tinykeys - Modern library for keybindings\nby Jamie kyle : [https://jamiebuilds.github.io/tinykeys/](https://jamiebuilds.github.io/tinykeys/)\n\n![tinykey](Discoveries-2/tinykeys.png)\n\nVery easy to use key binding library for JavaScript. Supports key sequences and modifier keys.\n\n---\n\n## Creating files in JavaScript in your browser\nby Kilian Valkhof : [https://kilianvalkhof.com/2020/javascript/creating-files-in-javascript-in-your-browser/](https://kilianvalkhof.com/2020/javascript/creating-files-in-javascript-in-your-browser/)\n\n![Creating Files In Javascript](Discoveries-2/creating-files-in-javascript.png)\n\nKilian shows how to prepare data in JavaScript and offer them to download on the fly, without the use of storing a file.\n\n---\n\n## CSS Animated Google Fonts\nby Jhey Tompkins : [https://dev.to/jh3y/animated-google-fonts-193d](https://dev.to/jh3y/animated-google-fonts-193d)\n\n![CSS Animated Fonts](Discoveries-2/css-animated-fonts.png)\n\nAs Google Fonts now supports variable fonts, Jhey shows a solution how to create neat font animations with them.\n\n---\n\n## Skeleton Screen CSS\nby Dmitriy Kuznetsov : [https://github.com/nullilac/skeleton-screen-css](https://github.com/nullilac/skeleton-screen-css)\n\n![Skeleton Screen CSS](Discoveries-2/skeleton-screen-css.png)\n\nWhen loading data on demand, it is sometimes advisable to show placeholders, where the data will be filled in. Dimitriy has founded a CSS framework for these skeletons.\n\n---\n\n## More Control Over CSS Borders With background-image\nby Chris Coyier : [https://css-tricks.com/more-control-over-css-borders-with-background-image/](https://css-tricks.com/more-control-over-css-borders-with-background-image/)\n\n![More Control Over CSS Borders](Discoveries-2/more-control-over-css-borders.png)\n\nBorders are used to seperate things in a layout, but the build-in possibilities of CSS are restricted. Chris found a way by pimping borders up, using background images.\n\n---\n\n## A CSS-only, animated, wrapping underline\nby Nicky Meuleman : [https://nickymeuleman.netlify.app/blog/css-animated-wrapping-underline](https://nickymeuleman.netlify.app/blog/css-animated-wrapping-underline)\n\n![CSS-only, animated, wrapping underline](Discoveries-2/css-only-animated-wrapping-underline.png)\n\nAs Chris did for the borders, Nick's doing on underlined links. An end to boring rigid unterlines, let's animate them.\n\n---\n\n## Nailing the Perfect Contrast Between Light Text and a Background Image\nby Yaphi Berhanu : [https://css-tricks.com/nailing-the-perfect-contrast-between-light-text-and-a-background-image/](https://css-tricks.com/nailing-the-perfect-contrast-between-light-text-and-a-background-image/)\n\n![Nailing the Perfect Contrast](Discoveries-2/nailing-the-perfect-contrast.png)\n\nShowing text on background images can be challenging due to contrast and readability. Yaphi has developed a solution to find always the right transparent overlay to show the most of the picture, but keep the text readable. Stunning...\n\n---\n\n## Contrast.js\nby Misha Petrov : [https://github.com/MishaPetrov/Contrast.js](https://github.com/MishaPetrov/Contrast.js)\n\n![Contrast.js](Discoveries-2/contrast-js.png)\n\nMisha addresses the same problem as Yaphi, showing text on background images, but goes a different way with his library, which is trying to find the best constrasting text color, even if the page is responsive.","tags":["Great Finds"],"categories":["Discoveries"]},{"title":"Add website to Trello card the better way","url":"/categories/Tools/Add-website-to-Trello-card-the-better-way/","content":"I was looking for a new way to store interesting website articles for reading later, as Pocket, my favourite tool until here, gets worse and worse. As I am a big [Trello](https://trello.com) fan, I wanted to give it a chance to be Pockets successor on my smartphone, where I'm reading mostly.\n\nOn installing the Trello Android app, you will find a new SHARE target **Add new Trello card**, which is comfortable to use:\n\n(Sry, for the German screenshots ;)\n\n![Android's default share with New Trello Card](android-share-website.png)\n\nThe result, website's title and Url set, is nice at best:\n\n![Trello card via Android Share](card-via-share.png)\n\n... but Trello has a **[Bookmarklet](https://trello.com/add-card)**, which does the job much better.\n\n<!-- more -->\n\n***HINT: The following approach works best in the Google Chrome browser.***\n\nFirst, a Bookmarklet is a small piece of JavaScript, which is stored as a bookmark in your browser. As you can't actually create such a Bookmarklet in your Android Chrome, you have to create it in your desktop Chrome and switch on the bookmark sync of chrome. You should right away choose a short, concise name for the bookmark, so you find it easier in Android Chrome afterwards. I called it **2TrelloCard**, because few websites start with an number.\n\nAfter Chrome's sync is done, go to any website do you want to store as a Trello card. Now enter the Url box and type the name of the bookmarklet and select it.\n\nInstead of requesting a different page, Chrome executes the JavaScript of the Bookmarklet against the currently open website. This script shows a Trello dialog, where you can choose, which board and list the new card should be created on.\n\n![Open Bookmarklet on Website in Android Chrome](open-bookmarklet.gif)\n\nThis card creation method not only sets the title of the card, but fills the description with the [meta description](https://en.wikipedia.org/wiki/Meta_element) of the page, adds the first found meta image as cover and adds the Url as an attachment:\n\n![Trello card via Bookmarklet](card-via-bookmarklet.png)\n","tags":["Trello","Browser"],"categories":["Tools"]},{"title":"Horizontal navigation menu above an image","url":"/categories/UI-Design/Horizontal-navigation-menu-above-an-image/","content":"\nI changed the main menu of my blog, because I wanted to get rid of the hamburger menu on the upper left, which was shown only for smartphones, but was not really reachable conveniently. Beside that it made no sense to have different navigations for different devices.\n\nMy choice was to implement a horizontal scrolling menu, which can grow over the time, without any need of customizing. As I have quite big header images and I wanted to place the new navigation in a more accessible zone, I decided to place it at the bottom, but above the header image.\n\n<!-- more -->\n\nProblem was, not to cover a big part of the image with a full-colored or even semitransparent bar, by using a RGBA background color. I wanted it more translucent, but with enough contrast on bright images for the menu items to read.\n\nThe recently introduced W3C feature ``backdrop-filter`` was just the right thing for that. It is [supported by most modern browsers](https://caniuse.com/#feat=css-backdrop-filter), but it has to have a backup strategy for the rest of the bunch.\n\nThe HTML is simple: \n\n```html\n<nav id=\"header-nav\" role=\"navigation\">\n  <ul class=\"menu\">        \n  \n    <li class=\"menu-item\">\n      <a href=\"/first\" title=\"First\">\n        <span>First Item</span>\n      </a>\n    </li>\n            \n    <li class=\"menu-item\">\n      <a href=\"/second\" title=\"Second\">\n        <span>Second Item</span>\n      </a>\n    </li>\n    \n  </ul>\n</nav>\n```\nAnd here's the [Stylus](https://stylus-lang.com/docs) code for my approach:\n\n```styl\n#header-nav\n  position: absolute\n  bottom: 0\n  width: 100%\n  height: auto\n  box-sizing: content-box\n  overflow-x: scroll\n  overflow-y: hidden\n  \n  // BACKDROP-FILTER\n  backdrop-filter: blur(5px) brightness(90%)\n  @supports not (backdrop-filter: none)\n    background: rgba(0,0,0,0.25)\n  \n  // SCROLLBAR\n  &::-webkit-scrollbar\n    display: none\n  @supports not (webkit-scrollbar)  \n    scrollbar-width: none\n  \n  .menu\n    display: flex\n    list-style: none\n    margin: 0\n    padding: 0\n    \n    .menu-item\n      flex-basis: 80px \n      flex-shrink: 0\n      flex-grow: 1\n      max-width: 100px\n      margin: 0 2px\n      text-overflow: ellipsis;\n      \n      a\n        display: inline-block\n        width: 100%\n        padding: 10px 0\n        color: #ffffff\n        font-weight: bold\n        text-decoration: none\n        text-align: center        \n```\n\nThe navigation box is ``absolute`` positioned on the image, is as wide as the screen and scrolls exclusively horizontal. The items are a unordered list, with default width and arranged by ``flex``.\n\nIn case a browser doesn't understand ``backdrop-filter``, the navigation bar is shown with a classic alpha channel opacity.\n\nWhen having a horizontal scroll feature, the scrollbar shown by the browser is beyond beautiful. To prevent this, I used the CSS pseudo element ``::-webkit-scrollbar``, which is supported by WebKit and Blink bowsers, with a fallback for all other browsers. Both strategies allows to be still able to scroll. If you want to have a scrollbar, but not the built-in, I can only recommend to read something about styling scrollbars, like [here](https://css-tricks.com/custom-scrollbars-in-webkit/) and [here](https://css-tricks.com/the-current-state-of-styling-scrollbars/).","tags":["CSS","Stylus"],"categories":["UI-Design"]},{"title":"Change CSS class when element scrolls into viewport","url":"/categories/JavaScript/Change-CSS-class-when-element-scrolls-into-viewport/","content":"I had a neat visual gimmick on the start page of this blog, that the gray-scaled header image of a post in the list scaled up to 100% and became colored, when the user hovered over it:\n\n```css\n.article-inner .article-photo {\n  height: 150px;\n  width: 100%;\n  object-fit: cover;\n  transform: scale(1);\n  transform-style: preserve-3d;\n  transition: all ease-out 0.6s;\n  opacity: 0.3;\n  filter: grayscale(1) contrast(0.5);\n}\n.article-inner:hover .article-photo {\n  transform: scale(1.1);\n  opacity: 1;\n  filter: grayscale(0) contrast(1);\n}\n```\n\nNice, but a little bit useless on smartphones or tablets, where HOVER  doesn't really work.\n\n<!-- more -->\n\nA better idea was to transform the header image automatically, when it becomes visible to the user. So I changed the HOVER selector into a class...\n\n```css\n.article-photo.in-view {\n    transform: scale(1.1);\n    opacity: 1;\n    filter: grayscale(0) contrast(1);\n}\n```\n\n... and wrote a little JS function to determine the point, where the images is fully visible in the viewport:\n\n```js\nfunction isVisibleInViewPort(e) {\n  var viewTop = $(window).scrollTop();\n  var viewBottom = viewTop + $(window).height();\n  var eTop = $(e).offset().top;\n  var eBottom = eTop + $(e).height();\n  return ((eBottom <= viewBottom) && (eTop >= viewTop));\n}\n```\n\nThis function I had to bind to the windows scroll event to all header images only:\n\n```js\n$(window).on('scroll', function() {\n  $(\".article-photo\").each(function() {\n    if (isVisibleInViewPort($(this))) {\n      $(this).addClass(\"in-view\");\n    } else {\n      $(this).removeClass(\"in-view\");\n    }\n  });\n});\n```\n","tags":["jQuery","CSS"],"categories":["JavaScript"]},{"title":"Discoveries #1","url":"/categories/Discoveries/Discoveries-1/","content":"Due to my daily routine, I'm reading a lot of articles on the web regarding software development. \n\nThe most interesting stuff ends up on my Pocket list, which grows from day to day. Hard to find the pearls, when I need them. This recurring posts will throw a stroke of light on them.\n\nThey are maybe not the newest finds, not the fanciest ones, but remarkable for me and maybe for you also.\n\n* Pure CSS halftone portrait from .jpg source\n* ScrollTrigger - Highlight Text\n* Tiny long-press event handler\n* Show More/Less\n* 3D banners with ScrollTrigger\n* Image Compare Viewer\n* Add Read or Scroll Progress Bar To A Website To Indicate Read Progress\n* How to Get a Progressive Web App into the Google Play Store\n\n<!-- more -->\n\n--- \n\n## Pure CSS halftone portrait from .jpg source\nby Ana Tudor : [https://codepen.io/thebabydino/pen/LYGGwrm](https://codepen.io/thebabydino/pen/LYGGwrm)\n\n![Pure CSS Halftone](Discoveries-1/pure-css-halftone.jpg)\n\nAna, author at [CSS Tricks](https://css-tricks.com/author/thebabydino/), shows a CSS-only technique to convert an image into a halftone one.\n\n---\n\n## ScrollTrigger - Highlight Text\nby Ryan Mulligan : [https://codepen.io/hexagoncircle/details/gOPMwvd](https://codepen.io/hexagoncircle/details/gOPMwvd)\n\n![ScrollTrigger Highlight Text](Discoveries-1/scrolltrigger-highlight-text.jpg)\n\nWe all highlight important text passages for our readers. Ryan does the in an unusual, butt cool way by using GSAP ScrollTrigger.\n\n--- \n\n## Tiny long-press event handler\nby MudOnTire : [https://github.com/MudOnTire/web-long-press](https://github.com/MudOnTire/web-long-press)\n\n![Long-Press Event Handler](Discoveries-1/long-press-event-handler.jpg)\n\nVanilla JS multi-instance handling of long press event the easy way.\n\n---\n\n## Show More/Less\nby Grzegorz Tomicki : (https://github.com/tomik23/show-more)[https://github.com/tomik23/show-more]\n\n![Show More](Discoveries-1/show-more.jpg)\n\nGrzegorz's little JS helper to cut texts, lists and even tables and show a MORE link.\n\n---\n\n## 3D banners with ScrollTrigger\nby supamike : [https://codepen.io/supamike/full/KKVqXmR](https://codepen.io/supamike/full/KKVqXmR)\n\n![3d Banners with SrollTrigger](Discoveries-1/3d-banners-scrolltrigger.jpg)\n\nAwesome 3D effect on scrolling made with [ScrollTrigger](https://greensock.com/scrolltrigger/).\n\n---\n\n## Image Compare Viewer\nby Kyle Wetton : [https://image-compare-viewer.netlify.app/](https://image-compare-viewer.netlify.app/)\n\n![Image Compare Viewer](Discoveries-1/image-compare-viewer.jpg)\n\nComparison slider in Vanilla JS to compare BEFORE and AFTER images, which works responsively on every device.\n\n---\n\n## Add Read or Scroll Progress Bar To A Website To Indicate Read Progress\nby Jun711 : [https://jun711.github.io/web/add-scroll-progress-bar-to-a-website-to-indicate-read-progress/](https://jun711.github.io/web/add-scroll-progress-bar-to-a-website-to-indicate-read-progress/)\n\n![Read Progress Bar](Discoveries-1/read-progress-bar.jpg)\n\nA classic, simply explained...\n\nHere another approach: [CSS Tricks: Reading Position Indicator](https://css-tricks.com/reading-position-indicator/)\n\n---\n\n## How to Get a Progressive Web App into the Google Play Store\nby Mateusz Rybczonek : [https://css-tricks.com/how-to-get-a-progressive-web-app-into-the-google-play-store/](https://css-tricks.com/how-to-get-a-progressive-web-app-into-the-google-play-store/)\n\n![Get PWA Into Play Store](Discoveries-1/get-pwa-into-play-store.jpg)\n\nMateusz describes very detailed how offer your PWA as an App via Google Play Store.\n","tags":["Great Finds"],"categories":["Discoveries"]},{"title":"Dopamine: How Software should be...","url":"/categories/Tools/Dopamine-How-Software-should-be/","content":"\nNot very often, when I'm looking for a new tool to replace some annoying or outdated piece of software, I have to blog about it ... but from time to time, I'm discovering pearls, worth to lose a word about.\n\nThe Windows 10 built-in media player Groove is (to be kind) ... nice, but it is more or less a leftover from Microsoft's attempt to create a competitor to iTunes, years ago. The crippeled UI is not the most modern and I was more than once annoyed about its usability.\n\nDoing a research for a good alternative, you stumble always over the usual suspects: MediaMonkey, Foobar2000, Winamp, VLC or even Media Player Classic!? Not modern enough, not user friendly enough, not lean enough.\n\nI really don't remember where, but there was a screenshot of a player, which seems to be the complete opposite of the others: **Dopamine** from [Digimezzo](https://www.digimezzo.com/software/), a project by the Belgian developer [Raphaël Godart](https://twitter.com/RaphaelGodart)...\n\n![Screenshot Dopamine 2.0.2.](Dopamine-How-Software-should-be/screenshot_dopamine_202.png)\n<!-- more -->\n\nBut that wasn't the best, especially for me. **Dopamine** is written in C# as a WPF application and it is OpenSource, [hosted on GitHub](https://github.com/digimezzo/dopamine-windows).\n\nThe software is so wonderful lean and its integrating in Windows 10 like a charm. It has several categories to find the right music to play, a context-sensitive search, a folder view, is able to import and manage playlists, a light and dark mode and translations into currently 28 languages. It can update your collection automatically from several folders, has two player modes and is incredibly fast.\n\nThe keep long story short ... I fell in love on **Dopamine**'s simple beauty and it is now my favourite player on Windows 10! \n\nThanks Raphaël...\n","tags":["Great Finds"],"categories":["Tools"]},{"title":"Using GitHub as Commenting Platform","url":"/categories/Tools/Using-GitHub-as-Commenting-Platform/","content":"\nIf you run a blog, it is always advisable to integrate a commenting system, in order to get feedback on your posts from your readers.\n\nSo did I, when I start this blog and I decided to use the [Disqus platform](https://disqus.com), as it was very easy to integrate ... but I always had a bad feeling about a third-party platform collecting data from my readers. Disqus is probably not without reason under criticism by many people in the community.\n\nAs I host this blog at GitHub (see [A New Blog (Part One): VS Code, Hexo and GitHub Pages](/categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/)) I was looking for a solution to host the comments also on my prefered platform. There were some solutions, which uses GitHub Issues for this and wanted to implement something like that someday.\n\n<!-- more -->\n\nAs I read a post from on [Thomas Lavesques' blog](https://thomaslevesque.com), to solve another problem, his commenting section came to my attention: **[utteranc.es](https://utteranc.es/)** ... exactly the solution I needed! Thanx guys...\n\nOn their website is a small configurator for a script to implement in each post, which needs only few information:\n\n* Name of the Repo\n* How the mapping of the post to the Issues should work\n* Name of the Theme, in order to fit to the colors of the blog\n\nThe script had to be included to my Hexo ``article.js``:\n\n```ejs\n<% if (!index && post.comments){ %>\n  <script src=\"https://utteranc.es/client.js\"\n    repo=\"kristofzerbe/kiko.io\"\n    issue-term=\"pathname\"\n    theme=\"github-light\"\n    crossorigin=\"anonymous\"\n    async>\n  </script>\n<% } %>\n```\n\nThat's pretty much it. On entering the first comment, Utterances told me to install the needed GitHub App to my repo, in order to make it work ... and done.\n\n![Utterances GitHub App](Using-GitHub-as-Commenting-Platform/utteranc-github-app.png)\n\nThe result you see below ...\n\n### UPDATE...\n\nThe utterances script tag has the attribute ``theme``, to tell utterances  which style should be delivered. There are several themes available, but if users are able to switch between light or dark mode on the page (see [Hexo and the Dark Mode](/categories/Tools/Hexo-and-the-Dark-Mode)), the comment block should change to an suitable theme also.\n\nOn order to respond on a mode change, it is necessary to write a more dynamic script loading.\n\nFirst we define a function in a global script file to load the utterances script via JS:\n\n```js\nfunction insertUtterancesCommentBlock() {\n    var commentTheme = \"github-light\";\n    if(localStorage.getItem(\"theme\") === \"dark\"){\n      commentTheme = \"github-dark\";\n    }\n    const scriptId = \"comment-theme-script\";\n    const existingScript = document.getElementById(scriptId);\n    if (!existingScript) {\n      const commentScript = document.createElement(\"script\");\n      commentScript.id = scriptId;\n      commentScript.src = \"https://utteranc.es/client.js\";\n      commentScript.setAttribute(\"repo\", \"kristofzerbe/kiko.io\");\n      commentScript.setAttribute(\"issue-term\", \"pathname\");\n      commentScript.setAttribute(\"theme\", commentTheme);\n      commentScript.setAttribute(\"crossorigin\", \"anonymous\");\n      const placeholder = document.getElementById(\"comment-placeholder\");\n      placeholder.innerHTML = \"\";\n      placeholder.appendChild(commentScript);\n    }\n}\n```\n\nThen we change the placement in the EJS file, by defining a placeholder  and ensuring that the script above is loaded, before we call it:\n\n```ejs\n<div id=\"comment-placeholder\"></div>\n<script>\n  window.addEventListener('load', function () {\n    insertUtterancesCommentBlock();\n  })\n</script>\n```\n\nOn my blog, everytime the user switches between light/dark mode the ``body`` tag will be decorated with the data tag ``data-theme`` and the value of the mode. To keep the loading of the utterances script independent from this functionality, we just have to listen to this change via ``MutationObserver``:\n\n```js\n//observe theme change, to adjust comment block theme\nvar target = document.documentElement,\n    observer = new MutationObserver(function(mutations) {\n        mutations.forEach(function(mutation) {\n            if (mutation.attributionName === \"data-theme\" );\n                insertUtterancesCommentBlock();\n            });        \n    }),\n    config = { attributes: true };\nobserver.observe(target, config);\n```","tags":["Hexo","Blogging","GitHub"],"categories":["Tools"]},{"title":"Meaningful automatic versioning with T4","url":"/categories/C/Meaningful-automatic-versioning-with-T4/","content":"\nEvery developer has to have an idea of versioning his products. If you work with Visual Studio you have the ``Assembly Information`` in the project properties dialog, to enter it manually everytime you want to release a new version:\n\n![Assembly Information Dialog](Meaningful-automatic-versioning-with-T4/AssemblyInformationDialog.png)\n\nThe four fields are: MAJOR, MINOR, BUILD, REVISION.\n\nBut seriously ... who does that? I guess 99% of all C# developers are entering the ``AssemblyInfo.cs`` and enter the famous 2 asterisks into the version declaration of BUILD and REVISION, to let Visual Studio do the incrementation job:\n\n```c#\n[assembly: AssemblyVersion(\"1.0.*.*\")]\n[assembly: AssemblyFileVersion(\"1.0.*.*\")]\n```\n\nBut this is not the end of the possibilities ... Let's do it more meaningful, with some goodies and still automatic...\n<!-- more -->\n\n### More informative versioning\n\nA build with an increased MAJOR version number means, that there are significant changes in the product, even breaking changes. This always should be set manually.\n\nAlso the MINOR. It stands for significant functional extensions of the product.\n\nHow does Visual Studio calculate BUILD and REVISION?\n\n{% blockquote %}\nWhen specifying a version, you have to at least specify major. If you specify major and minor, you can specify an asterisk for build. This will cause **build** to be equal to the **number of days since January 1, 2000 local time**, and for **revision** to be equal to the **number of seconds since midnight local time, divided by 2**.\n{% endblockquote %}\n\nBut, the BUILD number should explain, how often a software with a particular MAJOR.MINOR has been build, due to minor changes and bug fixes.\n\nThe \"Asterisk\" REVISION number is a little weird, but at least with the BUILD number unique. But it says nothing. Better to pick up the idea of a date calculated, unique number, but not an arbitrary date ... let's take the date the project has started.\n\nFor example: **1.2.16.158** ... reads version 1.2 with 16 builds on the 158'th day after the project has started.\n\n### Start with T4\n\nT4 (Text Template Transformation Toolkit) is a templating system in Visual Studio for generating text files during design time. It is very suitable to even generate code. Read about it [here](https://docs.microsoft.com/en-us/visualstudio/modeling/code-generation-and-t4-text-templates) and [here](https://docs.microsoft.com/en-us/visualstudio/modeling/writing-a-t4-text-template).\n\nA Text Template (.tt) has **Directives** (how the template is processed), **Text blocks** (text copied to the output) and **Control blocks** (program code).\n\nFor our versioning template, we start with this in a new file named **``AssemblyVersion.tt``**:\n\n*Directives*:\n\n```xml\n<#@ template hostspecific=\"true\" language=\"C#\" #>\n<#@ output extension=\".cs\" #>\n```\n\n*Control block*:\n\n```c#\n<#\n  int major = 1;\n  int minor = 0;\n  int build = 0;\n  int revision = 0;\n#>\n```\n\n*Text block*:\n\n```c#\n// This code was generated by a tool. Any changes made manually will be lost\n// the next time this code is regenerated.\n\nusing System.Reflection;\n\n[assembly: AssemblyVersion(\"<#= $\"{major}.{minor}.{build}.{revision}\" #>\")]\n[assembly: AssemblyFileVersion(\"<#= $\"{major}.{minor}.{build}.{revision}\" #>\")]\n```\n\nOn saving the TT file, a new CS file with the same name will be created automatically and you got an error like this:\n\n![Duplicate Attributes Error](Meaningful-automatic-versioning-with-T4/DuplicateAttributes.png)\n\n#### A new place for version info\n\nTh error occurs, because we have now **two** ``AssemblyVersion`` and ``AssemblyFileVersion`` attributes in our project. We need to comment out the original in ``Properties\\AssemblyInfo.cs``:\n\n![Change AssemblyInfo.cs](Meaningful-automatic-versioning-with-T4/ChangeAssemblyInfo.png)\n\n#### Structural Considerations\n\nIt makes sense to store all needed files for the new versioning system in a new root folder of the project, named **AssemblyVersion**, starting with the ``AssemblyVersion.tt``, because there will be more files later on.\n\n### New app information file\n\nAs we replaced the original version attributes in the project with those from our generated  ``AssemblyVersion.cs``, we cannot control the MAJOR and MINOR version number via the project property dialog any longer. We need a new approach on that, which can be edited easily and processed automatically.\n\n#### AssemblyVersion.json\n\n```js\n{\n  \"initialDate\": \"2019-09-29\",\n  \"versions\": [\n    {\n      \"major\": 1,\n      \"minor\": 1,\n      \"releaseDate\": \"\",\n      \"remarks\": \"Some cool new features; New versioning system\"\n    },\n    {\n      \"major\": 1,\n      \"minor\": 0,\n      \"releaseDate\": \"2019-10-01\",\n      \"remarks\": \"Initial Release\"\n    }\n  ]\n}\n```\n\nThis new JSON file has two main items:\n* ``initialDate`` - the date the project has started, to calculate the REVISION later on\n* ``versions`` - a list with all different MAJOR/MINOR versions we have done so far, with at least one without a release date ... the one with the highest ``major`` and ``minor``.\n\nThe ``remarks`` attribute of a list item holds some information about the changes in a new version. Together with ``releaseDate``, useful for a possible release history, shown in the product itself.\n\n#### Library references in T4\n\nT4 runs in its own app domain, therefore it can use built-in libraries as ``System.IO``, but not third-party libraries like ``Newtonsoft.JSON``. \n\nWe could reference those libraries from the projects package folder via the absolute path (if we use it in our product), but when we are running a NuGet update, the reference will break. \n\nIt is advisable to store such libraries directly in a fixed folder, like **AssemblyVersion\\Libraries**. They won't have any impact to our product, because the are only used while design time.\n\n### The MAJOR and MINOR\n\nTo process the new ``AssemblyVersion.json`` in the template, we need some new directives for referencing the needed libraries and the import of the appropriate namepaces:\n\n```xml\n<#@ assembly name=\"System.Core\" #>\n<#@ assembly name=\"$(SolutionDir)\\AssemblyVersion\\Libraries\\Newtonsoft.Json.dll\" #>\n\n<#@ import namespace=\"System.IO\" #>\n<#@ import namespace=\"System.Linq\" #>\n<#@ import namespace=\"Newtonsoft.Json\" #>\n```\n\nVia the use of the T4 variable ``$(SolutionDir)``, we can point to our copy of Newtonsoft JSON.\n\nNow we can read and convert the JSON into an anonymous object and get the highest values of MAJOR and MINOR:\n\n```c#\n<#\n    string avPath = this.Host.ResolvePath(\"AssemblyVersion.json\");\n    string avJson = File.ReadAllText(avPath);\n\n    var avDefinition = new {\n        initialDate = \"\",\n        versions = new [] {\n            new {\n                major = 0,\n                minor = 0,\n                releaseDate = \"\",\n                remarks = \"\" }\n        }\n    };\n    var avObject = JsonConvert.DeserializeAnonymousType(avJson, avDefinition);\n\n    //Get highest Major/Minor from versions list\n    var maxVersion = avObject.versions\n      .OrderByDescending(i => i.major)\n      .ThenByDescending(j => j.minor)\n      .First();\n\n    //Set MAJOR\n    int major = maxVersion.major;\n\n    //Set MINOR\n    int minor = maxVersion.minor;\n#>\n```\n\n### The BuildLog\n\nIn order to get the version number for BUILD, we need a method to count and store every build that has been run, separated by the MAJOR/MINOR versions. This is a job for a **Post-build event**, which can be configured in the project properties dialog. The event uses shell commands as they are used on the command line.\n\nWhat the commands should do:&nbsp;&nbsp;&nbsp;Write a new line with the current date and time in a log file, named after the MAJOR/MINOR version and stored in the folder **AssemblyVersion\\BuildLogs**.\n\n![Build Log](Meaningful-automatic-versioning-with-T4/BuildLog.png)\n\n#### Extending build event macros\n\nShell commands for build events are supporting built-in variables, so called 'macros', like ``$(ProjectDir)`` (which returns the project directory path), but there is no such macro for the current version number. We have to introduce it via extending the project with a new build target.\n\nUnload the project in Visual Studio for editing the CSPROJ (or VBPROJ) file of your product manually and write the following definition just before the end-tag:\n\n```xml\n  <PropertyGroup>\n    <PostBuildEventDependsOn>\n      $(PostBuildEventDependsOn);\n      PostBuildMacros;\n    </PostBuildEventDependsOn>\n  </PropertyGroup>\n\n  <Target Name=\"PostBuildMacros\">\n    <GetAssemblyIdentity AssemblyFiles=\"$(TargetPath)\">\n      <Output TaskParameter=\"Assemblies\" ItemName=\"Targets\" />\n    </GetAssemblyIdentity>\n    <ItemGroup>\n      <VersionNumber Include=\"@(Targets->'%(Version)')\" />\n    </ItemGroup>\n  </Target>\n```\n\nAfter reloading the project in Visual Studio, we can use ``@(VersionNumber)`` in our commands.\n\n#### CreateBuildLog.bat\n\nThe event build editor is not very comfortable, so we create the batch file ``CreateBuildLog.bat`` in our **AssemblyVersion** folder and use this as the post build event command.\n\n**IMPORTANT: The BuildLog folder must exist, before running the following command the first time!**\n\n```bat\n@echo off\n\nREM --Get parameters\nset PROJECT_DIR=%1\nset VERSION_NUMBER=%2\n\nREM --Set what to log\nset LOG_LINE=%DATE% %TIME%\n\nREM --Inform the user\nset MSG=CreateBuildLog '%LOG_LINE%' for version %VERSION_NUMBER%\necho %MSG%\n\nREM --Get version parts\nFOR /f \"tokens=1,2,3,4 delims=.\" %%a IN (\"%VERSION_NUMBER%\") do (\n\tset MAJOR=%%a\n\tset MINOR=%%b\n\tset BUILD=%%c\n\tset REVISION=%%d\n)\n\nREM --Define BuildLog file and folder \nset BUILDLOG_FILE=%MAJOR%.%MINOR%.log\nset BUILDLOG_FOLDER=%PROJECT_DIR%\\AssemblyVersion\\BuildLogs\n\nREM --Write current date and time as new line in the file\necho %LOG_LINE% >> %BUILDLOG_FOLDER%\\%BUILDLOG_FILE%\"\n```\n\n![Post Build Event](Meaningful-automatic-versioning-with-T4/PostBuildEvent.png)\n\n```bat\n\"$(ProjectDir)\\AssemblyVersion\\CreateBuildLog.bat\" \"$(ProjectDir)\" @(VersionNumber)\n```\n\n### The BUILD\n\nAs we have now the BuildLogs, we can use them in the template:\n\n```c#\n<#\n    ...\n\n    //Get BuildLog of max version\n    string buildlogFolder = this.Host.ResolvePath(\"BuildLogs\");\n    string buildLog = \n      buildlogFolder + \"\\\\\" +\n      maxVersion.major + \".\" +\n      maxVersion.minor + \".log\";\n\n    //Get number of lines from BuildLog or create a new log (!)\n    var buildCount = 1;\n    if (File.Exists(buildLog)) {\n        buildCount = File.ReadLines(buildLog).Count() + 1;\n    } else {\n        File.Create(buildLog).Dispose();\n    }\n\n    //Set BUILD\n    int build = buildCount;\n#>\n```\n\nVery important is to create the log file, if it doesn't exists! Otherwise the build will always fail, because the version attributes can't be created.\n\n### The REVISION\n\nAt least we have to set the REVISION number, by calculating the difference between the current date and the ``initialDate``, which we have previously read from the ``AssemblyVersion.json``:\n\n```c#\n<#\n    ...\n\n    //Set REVISION\n    var dateCreated = DateTime.Parse(avObject.initialDate);\n    int revision = (DateTime.Now.Date - dateCreated.Date).Days;\n#>\n```\n\n### Transforming T4 template on build\n\nThe last hurdle is to run the text transformation every time you build your product. Until now it runs only on saving the ``AssemblyVersion.tt``.\n\nA great helper on that was Thomas Levesque's post [\"Transform T4 templates as part of the build, and pass variables from the project\"](https://thomaslevesque.com/2017/11/13/transform-t4-templates-as-part-of-the-build-and-pass-variables-from-the-project/), where he describes every difficulty to reach this goal.\n\nTo make it short: We have to edit the CSPROJ file again, to introduce TextTemplating to MSBuild.\n\nFirst we need following near the beginning of the projects XML:\n\n```xml\n<PropertyGroup>\n    <VisualStudioVersion Condition=\"'$(VisualStudioVersion)' == ''\">\n      16.0\n    </VisualStudioVersion>\n    <VSToolsPath Condition=\"'$(VSToolsPath)' == ''\">\n      $(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\n    </VSToolsPath>\n    <TransformOnBuild>true</TransformOnBuild>\n    <OverwriteReadOnlyOutputFiles>true</OverwriteReadOnlyOutputFiles>\n    <TransformOutOfDateOnly>false</TransformOutOfDateOnly>\n</PropertyGroup>\n```\n\nSecondly add the IMPORT of the TextTemplating target AFTER the CSharp target:\n\n```xml\n<Import Project=\"$(MSBuildToolsPath)\\Microsoft.CSharp.targets\" />\n...\n<Import Project=\"$(VSToolsPath)\\TextTemplating\\Microsoft.TextTemplating.targets\" />\n```\n\nIf you build your product now, a new build log is created and the version numbers BUILD and REVISION are automatically increased.\n\n### See it in action\n\nThe project where I implemented this versioning first is [HexoCommander](https://github.com/kristofzerbe/HexoCommander). Feel free to download the code and see how the new versioning mechanism works.\n\n![Screencast Build HexoCommander](Meaningful-automatic-versioning-with-T4/screencast-build-hexocommander.gif)\n\nEnjoy versioning...","tags":["Visual Studio","Versioning","T4"],"categories":["C#"]},{"title":"Automatic Header Images in Hexo","url":"/categories/Tools/Automatic-Header-Images-in-Hexo/","content":"\nEvery article in this blog has an individual header image, to bring a little bit color into it. In this post I will show you how I deal with the images in using and automatic provisioning.\n\nFor serving these pictures I use a static folder, as described in [A New Blog: Customizing Hexo](/categories/Tools/A-New-Blog-Customizing-Hexo/). The hard work is done by the plugin [Hexo Generator Copy](https://github.com/niahoo/hexo-generator-copy), which copies the static files into the ``public_dir`` while generating.\n\n<!-- more -->\n\n## Static File Structure\n\nIt is always advisable to provide one image for every device class, in order to save bandwidth and make the page loading as fast as possible:\n\n```txt\n| static/\n   | photos/\n      | mobile/\n         | my-lovely-picture.jpg\n         | ...\n      | tablet/\n         | my-lovely-picture.jpg\n         | ...\n      | normal/\n         | my-lovely-picture.jpg\n         | ...\n```\n\nThe ``mobile`` images are at least 480 pixels wide, the ``tablet`` variants 768 pixels and the standard or ``normal`` one 1280 pixels.\n\nWhile creating the JPG files, it is important to compress them with a tool like [JPEGMini](https://www.jpegmini.com/) to save data while loading.\n\n## Binding\n\nIn order to bind a picture with some additional information to an article, I have extended the Frontmatter of every post:\n\n```yaml\nphotograph:\n    file: 'my-lovely-image.jpg'\n    name: 'My Lovely Image'\n    link: 'https://500px.com/photo/123456789/My-Lovely-Image'\n```\n\n## Usage in Theme\n\nIt relies on your Hexo theme, how to use a header image. In my theme (derived from the standard theme) I just added following code in the ``article.js`` to show the individual header image as a background image at the top of the article: \n\n```html\n<% if (!index && post.photograph){ %>\n<style>\n  #banner {\n    background-size: cover;\n  }\n  @media screen and (max-width: 479px) {\n    #banner { background-image:\n      linear-gradient(to bottom, rgba(0,0,0,0.75) 0%, rgba(0,0,0,0) 75%),\n      url(\"/photos/mobile/<%= post.photograph.file %>\"); }\n  }\n  @media screen and (min-width: 480px) and (max-width: 767px) {\n    #banner { background-image: \n      linear-gradient(to bottom, rgba(0,0,0,0.75) 0%, rgba(0,0,0,0) 75%),\n      url(\"/photos/tablet/<%= post.photograph.file %>\"); }\n  }\n  @media screen and (min-width: 768px) {\n    #banner { background-image: \n      linear-gradient(to bottom, rgba(0,0,0,0.75) 0%, rgba(0,0,0,0) 75%),\n      url(\"/photos/normal/<%= post.photograph.file %>\"); }\n  }\n</style>\n<script>\n  var photoLink = document.getElementById(\"header-photo-link\");\n  photoLink.href = \"<%= post.photograph.link%>\";\n  photoLink.innerHTML = \"see <strong><%= post.photograph.name%></strong> at 500px\";\n</script>\n<% } %>\n```\n\nImportant part here is the use of the Frontmatter data ``post.photograph.file`` in the URL of the background CSS. The script fills the additional information into the absolute positioned element ``header-photo-link`` which is placed on top of the header.\n\n## Pooling Images\n\nAs it is time consuming to generate the necessary images, I have created another static folder ``pool`` to store prepared files and a text file with the additional information about the image. The structure of ``pool`` is different to ``photos``, because of my image workflow and some limitations of automating the provisioning.\n\n```txt\n| static/\n   | pool/\n      | my-lovely-picture/\n         | meta.txt\n         | mobile.jpg\n         | normal.jpg\n         | tablet.jpg\n      | ...\n```\nThe ``meta.txt`` is a simple text file with two lines of text: first the name of the image and second the Url to link to, which will be inserted in the appropriate Frontmatter fields on creating a new post:\n\n```txt\nMy Lovely Image\nhttps://500px.com/photo/123456789/My-Lovely-Image\n```\n\n## Automate binding and provisioning on new post\n\nDevelopers are lazy and I do not make an exception. Having all these pool images and the meta informations, it would be nice, if Hexo just picks and processes one of the pool folders automatically, when I'm creating a new post by calling ``hexo new \"My shiny new post\"`` ... and it was easier then I thought.\n\n### Where to place the code for the automatism\n\nHexo has a great [API](https://hexo.io/api/) to write [plugins](https://hexo.io/plugins/) and it is not very difficult to setup a new plugin for this, which can be published to the [NPM registry](https://www.npmjs.com/search?q=hexo). But it is also possible to extend Hexo's functionality by using a simple script. All you need is a **``script``** folder in the root of your Hexo project. Any JS files which is placed there, will be executed by Hexo.\n\nTherefore, lets use a script called ``\\scripts\\process-photo-on-new.js`` ...\n\n### Things an automatism should do - Step by Step\n\n1. Hook into the creation of a post\n2. Pick randomly one of the pool images\n3. Place the content of the meta.txt in the Frontmatter\n4. Move the 3 device-dependend images into the ``photos`` folder\n\n#### Step 1 - Hook into the creation of a post\n\nThe needed event, the automatism can hook on, is:\n\n```javascript\nhexo.on('new', function(data){\n  //\n});\n```\n\nIt will be executed every time you call the ``hexo new`` command. The parameter ``data`` is an object with two fields:\n\n* ``path``  \nFull path to the MD file of the new post\n\n* ``content``  \nComplete content of the scaffold (template), which Hexo has used to create the new post; default is ``/scaffolds/post.md``.\n\nBy preloading the Hexo Front matter library and parsing ``data.content`` we get access to the definition of the new post:\n\n```javascript\nconst front = require('hexo-front-matter');\n\nhexo.on('new', function(post){\n\n  // parse article content\n  var post = front.parse(data.content);\n});\n```\n\n#### Step 2 - Pick randomly one of the pool images\n\nThere are some build-in variables to get the full path, for example, of the ``source`` folder, we can use to define the needed paths to the ``pool`` and the ``photo`` folder.\n\n```javascript\nconst front = require('hexo-front-matter');\n\nhexo.on('new', function(post){\n  var post = front.parse(data.content);\n\n  // set the path variables\n  var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\";\n  var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\";\n});\n```\n\nNext, we need to preload the Hexo FS library for file access, to list the content of the ``poolDir``, including the subfolders, and filter out the meta files. Out of the resulting array we pick one randomly, to use for the new post:\n\n```javascript\nconst front = require('hexo-front-matter');\nconst fs = require('hexo-fs');\n\nhexo.on('new', function(post){\n  var post = front.parse(data.content);\n\n  var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\";\n  var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\";\n\n  // list all files\n  var files = fs.listDirSync(poolDir);\n\n  // filter the list to get meta files of each subfolder\n  var metaFiles = files.filter(file => file.match(/.*[\\\\]meta.txt/g));\n\n  // pick one randomly\n  var metaFile = metaFiles[Math.floor(Math.random() * metaFiles.length)];\n\n  // get the name of the picked photo (foldername)\n  var photoName = metaFile.split(\"\\\\\")[0];\n});\n```\n\n#### Step 3 - Place the content of the meta.txt in the Frontmatter\n\nNow we have to read the meta file, place the data in the Frontmatter and save the article file:\n\n```javascript\nconst front = require('hexo-front-matter');\nconst fs = require('hexo-fs');\n\nhexo.on('new', function(post){\n  var post = front.parse(data.content);\n\n  var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\";\n  var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\";\n  \n  var files = fs.listDirSync(poolDir);\n  var metaFiles = files.filter(file => file.match(/.*[\\\\]meta.txt/g));\n  var metaFile = metaFiles[Math.floor(Math.random() * metaFiles.length)];\n  var photoName = metaFile.split(\"\\\\\")[0];\n\n  // read meta file\n  var meta = fs.readFileSync(poolDir + \"\\\\\" + metaFile);\n  var metas = meta.split(\"\\n\");\n\n  // place file and additional info in the Frontmatter\n  post.photograph.file = photoName + \".jpg\";\n  post.photograph.name = metas[0];\n  post.photograph.link = metas[1];\n\n  // convert content back\n  postStr = front.stringify(post);\n  postStr = '---\\n' + postStr;\n\n  // store article\n  fs.writeFile(data.path, postStr, 'utf-8');\n});\n```\n\n#### Step 4 - Move the 3 device-dependend images into the photos folder\n\nLast but not least, we have to move the pool images into the ``photos`` folder and remove the pool folder with all its processed content:\n\n```javascript\nconst front = require('hexo-front-matter');\nconst fs = require('hexo-fs');\n\nhexo.on('new', function(post){\n  var post = front.parse(data.content);\n\n  var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\";\n  var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\";\n  \n  var files = fs.listDirSync(poolDir);\n  var metaFiles = files.filter(file => file.match(/.*[\\\\]meta.txt/g));\n  var metaFile = metaFiles[Math.floor(Math.random() * metaFiles.length)];\n  var photoName = metaFile.split(\"\\\\\")[0];\n\n  var meta = fs.readFileSync(poolDir + \"\\\\\" + metaFile);\n  var metas = meta.split(\"\\n\");\n\n  post.photograph.file = photoName + \".jpg\";\n  post.photograph.name = metas[0];\n  post.photograph.link = metas[1];\n\n  postStr = front.stringify(post);\n  postStr = '---\\n' + postStr;\n\n  fs.writeFile(data.path, postStr, 'utf-8');\n\n  //copy normal image\n  fs.copyFile(\n    poolDir + \"\\\\\" + photoName + \"\\\\normal.jpg\",\n    photosDir + \"\\\\normal\\\\\" + photoName + \".jpg\",\n    function() {\n\n      //copy tablet image\n      fs.copyFile(\n        poolDir + \"\\\\\" + photoName + \"\\\\tablet.jpg\",\n        photosDir + \"\\\\tablet\\\\\" + photoName + \".jpg\",\n        function() {\n\n          //copy mobile image\n          fs.copyFile(\n            poolDir + \"\\\\\" + photoName + \"\\\\mobile.jpg\",\n            photosDir + \"\\\\mobile\\\\\" + photoName + \".jpg\",\n            function() {\n\n              //remove processed pool folder\n              fs.rmdirSync(poolDir + \"\\\\\" + photoName);\n            });\n        });\n    });\n\n});\n```\n\nNow it so easy to write a new post, because almost everything is set and I can concentrate on the article. Also, it is a nice surprise to see, which photo the script has chosen. The only thing I have to do from time to time, is to refill the pool folder with new images.\n\n## Related\n\n* [A New Blog (Part Two): Customizing Hexo](/categories/Tools/A-New-Blog-Customizing-Hexo/)\n","tags":["Hexo","Blogging"],"categories":["Tools"]},{"title":"Localization with resource files in JavaScript web apps","url":"/categories/JavaScript/Localization-with-resource-files-in-JavaScript-web-apps/","content":"\nThere are plenty of editors out there to help you writing JavaScript web applications. As I'm working in my daily life with Visual Studio, it is a obvious choice for me. \n\nOne of the most time saving tools in VS is the plugin [ResXManager](https://marketplace.visualstudio.com/items?itemName=TomEnglert.ResXManager), which is an awesome assistant on managing the translations for a Desktop- or ASP.NET-App, which uses XML-based RESX files.\n\n<!-- more -->\n\nMostly very localization is based on key/value pairs, defined in separate files for every language provided.\n\nImplementing several languages in pure JavaScript apps is a little more difficult, because it makes no sense to deal with big XML files in JS. All localization libraries in the market uses JSON for storing the translations and it is a little bit of work to find the right one for your requirements.\n\n<!-- more -->\n\n## Localization in JavaScript\n\nFor a current project I use  [jquery-lang](https://github.com/Irrelon/jquery-lang-js), because it provides the switch of the apps UI language without reloading and it is easy to implement. Thanks Rob Evans for your work...\n\nThe definition of \"tokens\" in one JSON file for each language is quite easy:\n\n**.../languages/en.json**\n```js\n{\n    \"token\": {\n        \"my-test\": \"My Test in English\"\n    }\n}\n```\n\n**.../languages/de.json**\n```js\n{\n    \"token\": {\n        \"my-test\": \"Mein Test in Deutsch\"\n    }\n}\n```\n\nThe usage also:\n```html\n<div lang=\"en\" data-lang-token=\"my-test\">\n```\n\n## Using RESX and convert to JSON on build\n\nHaving this, the most time consuming work is to enter the translations to the localization files. If you have hundreds of them, it is hard to keep the 2, 3 or more language files in sync. You need a helper...\n\nAnd here comes ResXManager to the rescue, if you work with VS ... but it needs a conversation from RESX to the JSON format jquery-lang uses and this a task, which can be done on building the JS app, by using a task runner like [Grunt](https://gruntjs.com/).\n\nAs there was no Grunt plugin/task out there to fit my needs, I have created  **grunt-resource2json** ([GitHub](https://github.com/kristofzerbe/grunt-resource2json), [NPM](https://www.npmjs.com/package/grunt-resource2json)). The configuration in the **gruntfile.js** is like: \n\n```json\ngrunt.initConfig({\n    resource2json: {\n      convert: {\n        options: {\n          format: \"jquery-lang\"\n        },\n        files: [\n          {\n            input: \"resources/Resource.resx\",\n            output: \"build/langpacks/en.json\"\n          },\n          {\n            input: \"resources/Resource.de-DE.resx\",\n            output: \"build/langpacks/de.json\"\n          },\n          {\n            input: \"resources/Resource.es-ES.resx\",\n            output: \"build/langpacks/es.json\"\n          }\n        ]\n      }\n    });\n```\n\nIt takes one RESX file (input) and converts it to a JSON file (output) in an array of files.\n\nThe heavy work in the plugin is done by the library [xml2js](https://www.npmjs.com/package/xml2js), which transforms the complete XML of the RESX file into a JSON object in one call. All I had to do, was to write all DATA nodes in a loop into the jquery-lang given structure and save it as JSON.\n\nCurrently supported is the format for jquery-lang only, but it would be awesome, if you fork the code on [GitHub](https://github.com/kristofzerbe/grunt-resource2json) and send me a Pull Request with the implementation of your needed format.\n","tags":["GitHub","Visual Studio","Resource","Localization"],"categories":["JavaScript"]},{"title":"TFS/DevOps: Delete Remote Workspace","url":"/categories/Tools/TFS-DevOps-Delete-Remote-Workspace/","content":"\nIf you are working with freelance developers and Azure DevOps/TFS with TFVC (Team Foundation Version Control) in your company, maybe this will look familiar to you: You hire a new freelancer and you want to reuse the hardware, including the complete software setup, to bring him/her to work as fast and straightforward as possible. You set up a new Azure Devops account with all necessary permissions and you think you're done. No you are not...\n<!-- more -->\n\nEverytime a user connects to a Team Project on Azure DevOps via Visual Studio and gets the code, VS is creating a **remote workspace** on the server, with the **machine name** as default, therefor it is not enough to wipe the profile and any other legacies of the last user from the machine. You also have to remove the remote workspace. Otherwise you will get an error message like that, if you are using a unique file structure on the developers hard disc:\n\n```txt\nThe working folder c://xxx is already in use by the workspace yyy;zzz on computer yyy\n```\n\nThe variable xxx stands for the blocked folder, yyy for the workspace/machine name and zzz for the users id on Azure DevOps.\n\nUnfortunately, there is no visual management console on Azure DevOps to manage your server workspaces, but there is a command line tool called **[tf.exe](https://docs.microsoft.com/en-us/azure/devops/repos/tfvc/use-team-foundation-version-control-commands?view=azure-devops)**.\n\nThe easiest way to get rid of the unused server workspace in 3 steps:\n\n### Step 1\n\nRun **Developer Command Prompt** from Visual Studio 2019 and login with your Azure DevOps credentials. You need to have administration rights...!\n\n### Step 2\n\nGet a list of all remote workspaces available in your DevOps Collection by running the command:\n\n```txt\ntf.exe workspaces /computer:* /owner:* /format:xml > c:\\temp\\workspaces.xml\n```\n\nYou can get a list of all your workspaces by running ``tf workspaces``, but the list only shows you the ``owner``, but not the necessary ``ownerid`` and ... it is nicer to have a file to search in.\n\n### Step 3\n\nFind the abandoned workspace in the list and note its ``name`` and  ``ownerid`` for running the command:\n\n```txt\ntf workspace /delete {WORKSPACE.name};{WORKSPACE.ownerid}\n```\n\nNow your new colleague can create his own workspace on the same machine.\n\n## Related\n* [Use Team Foundation version control commands](https://docs.microsoft.com/en-us/azure/devops/repos/tfvc/use-team-foundation-version-control-commands?view=azure-devops)\n* [How to remove TFS workspace mapping for another user\n](https://stackoverflow.com/questions/28298771/how-to-remove-tfs-workspace-mapping-for-another-user/28299407)","tags":["Visual Studio","TFS/DevOps"],"categories":["Tools"]},{"title":"Better Input Change Event","url":"/categories/JavaScript/Better-Input-Change-Event/","content":"\nOften it is important to trigger an event, after the user of your website/web app has filled out an text input. You have to do something with the given value in JavaScript.\n\nThe intended event for this is ``change``, which will be triggered, when the user has ended changing by leaving the input with his cursor, mostly by using the TAB key. This works at some degree, if there is a physical keyboard, but not really on mobile devices ... and for me is leaving the field often too late to start the upcoming event.\n\n<!-- more -->\n\nA better way to show the user the result of his entered value, could be the event ``input`` which fires on every key stroke, but could be way to often, if the triggered event is for example an AJAX call.\n\nBest solution is, to observe the users key strokes and trigger the event, when he stops typing. Then there is no extra action needed by the user and the event isn't triggered multiple times. \n\nHere's an implementation with jQuery:\n\n```javascript\n$(\"#my-text-input\").keyup(function () {\n    var $this = $(this);\n    clearTimeout($.data(this, 'timer'));\n    var wait = setTimeout(function () {\n\n        //do something with the value...\n\n    }, 1000);\n    $(this).data('timer', wait);\n});\n```\n\nImportant is to wipe and set the timer on every key up, to achive that the event will be executed after 1 second after the last key stroke only.","tags":["jQuery"],"categories":["JavaScript"]},{"title":"Hexo and the Dark Mode ... revised","url":"/categories/Tools/Hexo-and-the-Dark-Mode-revised/","content":"\nWhile writing my post [Hexo and the Dark Mode](/categories/Tools/Hexo-and-the-Dark-Mode) a few days ago, I thought it would be nice, if I could switch between the normal (light) and the dark theme, I've created for the support of the OS-related Dark Mode, even manually. The only thing I needed was a toggle element and a little bit of JavaScript.\n\nOf course, I couldn't manipulate the [media query ``prefers-color-scheme``](https://drafts.csswg.org/mediaqueries-5/#descdef-media-prefers-color-scheme) itself, but introduce a different way by blog uses it. Instead of implementing the media query directly into my CSS (or Stylus) code, I used a root selector, which can be manipulated by JavaScript ... something like this:\n\n```css\nbody {\n    background-color: white;\n    color: black;\n}\n\n[data-theme=\"dark\"] body {\n    background-color: black;\n    color: white;\n  }\n}\n```\n<!-- more -->\n\nIn every Stylus file, where I used ``@media prefers-dark`` to achieve the automatic switch by the OS, I changed this line into ``/[data-theme=\"dark\"] &`` :\n\n```styl\n#mobile-nav-header\n  background-color: color-background\n  /[data-theme=\"dark\"] &\n    background-color: dark-color-background\n  img.avatar\n    ...\n    /[data-theme=\"dark\"] &\n      filter: brightness(85%)\n```\n\nSome explanations on the [Stylus syntax](http://stylus-lang.com/docs/selectors.html): ``/`` means the root of the DOM and ``&`` points to the parent selector. Therefore the example will be rendered into this:\n\n```css\n#mobile-nav-header {\n    background-color: #f1f1f1;\n}\n[data-theme=\"dark\"] #mobile-nav-header {\n    background-color: #111;\n}\n\n#mobile-nav-header img.avatar {\n...\n}\n[data-theme=\"dark\"] #mobile-nav-header img.avatar\n    filter: brightness(85%);\n}\n```\n\nOnly problem was: the \"Root + Parent\" Stylus selector doesn't work in the block variables in the ``_extend.styl``. So I had to copy all theme relevant styles directly to the elements, where such a block was used: ``@extend <block-name>``.\n\n### The Toggle Switch\n\nIn the ``footer.ejs`` I added a toggle checkbox, where I could bind my JavaScript...\n\n```html\n<div id=\"footer-theme\">\n    <input type=\"checkbox\" id=\"theme-switch\">\n    <label for=\"theme-switch\"></label>\n</div>\n```\n\n... and some CSS in the ``footer.styl``, to style it:\n\n```styl\ninput#theme-switch[type=checkbox] {\n  display:none;\n}\n\ninput#theme-switch[type=checkbox] + label\n  height: 16px\n  width: 16px\n  display: inline-block\n  padding: 12px\n  font-size: 22px\n  cursor: pointer\n  &:before\n    display: inline-block\n    font-size: inherit\n    text-rendering: auto\n    -webkit-font-smoothing: antialiased\n    font-family: fa-icon-solid\n    content: icon-moon\n\ninput#theme-switch[type=checkbox]:checked + label\n  &:before\n    content: icon-sun\n```\n\nThe ``icon`` variables are defined in the ``_variables.styl`` like this:\n\n```styl\nicon-moon = \"\\f186\"\nicon-sun = \"\\f185\"\n```\n\n### The JavaScript\n\nEverything was now prepared to implement the switching code in JavaScript, which should support a manual switch by clicking the toggle element as well as the automatic switch by the OS.\n\nI wrapped all necessary code into a seperate JS file and placed a reference in the ``after-footer.ejs``, which places it at the bottom of the HTML:\n\n```ejs\n<%- js('js/dark-mode-toggle.js') %>\n```\n\n```js\nfunction detectColorScheme() {\n    var theme = \"light\"; //default\n\n    // get last used theme from local cache\n    if(localStorage.getItem(\"theme\")){\n        if(localStorage.getItem(\"theme\") === \"dark\"){\n            theme = \"dark\";\n        }\n    } else if(!window.matchMedia) { \n        // matchMedia not supported  \n        return false;\n    } else if(window.matchMedia(\"(prefers-color-scheme: dark)\").matches) {\n        // OS has set Dark Mode\n        theme = \"dark\";\n    }\n\n    // set detected theme\n    if (theme === \"dark\") {\n        setThemeDark();\n    } else {\n        setThemeLight();\n    }\n}\n\nconst toggleTheme = document.querySelector('input#theme-switch[type=\"checkbox\"]');\n\nfunction setThemeDark() {\n    localStorage.setItem('theme', 'dark');\n    document.documentElement.setAttribute('data-theme', 'dark');\n    toggleTheme.checked = true;\n}\nfunction setThemeLight() {\n    localStorage.setItem('theme', 'light');\n    document.documentElement.setAttribute('data-theme', 'light');\n    toggleTheme.checked = false;\n}\n\n// Listener for theme change by toggle\ntoggleTheme.addEventListener('change', function(e) {\n    if (e.target.checked) {\n        setThemeDark();\n    } else {\n        setThemeLight();\n    }\n}, false);\n\n// Listener for theme change by OS\nvar toggleOS = window.matchMedia('(prefers-color-scheme: dark)');\ntoggleOS.addEventListener('change', function (e) {\n    if (e.matches) {\n        setThemeDark();\n    } else {\n        setThemeLight();\n    }\n});\n\n// call theme detection\ndetectColorScheme();\n```\n\nBy using the both ``addEventListener``'s, each switch will be recognized and this approach is capable to support even more themes, just by using different values in the ``data-theme`` attribute.\n\n## Related\n\n* [Hexo and the Dark Mode](/categories/Tools/Hexo-and-the-Dark-Mode)","tags":["Hexo","CSS","Stylus","Dark Mode"],"categories":["Tools"]},{"title":"Hexo and the Dark Mode","url":"/categories/Tools/Hexo-and-the-Dark-Mode/","content":"\nDue to the fact, that nowadays everybody is talking about Dark Modes for Browsers and Operating Systems, in order to save battery or for easier reading (uhh, really?), I decided my blog should support that.\n\n![Switching Dark Mode in Windows 10](Hexo-and-the-Dark-Mode/screen-recording-1.gif)\n<!-- more -->\n\nStarting point is the new media query ``prefers-color-scheme``, which is actually supported by all modern browsers.\n\n### Technique\n\nMy first read was Tom Brow's [Dark mode in a website with CSS](https://tombrow.com/dark-mode-website-css), where he shows how to use the media query. Simplified, this is it, assuming the light version is the default:\n\n```css\nbody {\n    background-color: white;\n    color: black;\n}\n\n@media (prefers-color-scheme: dark) {\n  body {\n    background-color: black;\n    color: white;\n  }\n}\n```\n\n### Pimping CSS for automatic switching\n\nTo support the automatic browser/OS-based automatic switch in Hexo, where [Stylus](http://stylus-lang.com/) is used, I had to change some template files. First the ``_variables.styl``:\n\n```styl\n// existing color variables\ncolor-background = #f1f1f1\ncolor-foreground = #111\ncolor-border = #ddd\n...\n\n// new dark color variables\ndark-color-background = #111\ndark-color-foreground = #eee\ndark-color-border = #000\n...\n\n// new media query variable\nprefers-dark = \"(prefers-color-scheme: dark)\"\n```\n\nNext step was to change the ``_extend.styl``, where some Stylus variables are defining complete blocks to extend. Here I had to supplement all lines, where something mode-dependend was defined, by adding the new ``prefers-dark`` media query and beneath the new 'dark' equivalence of the style:\n\n```styl\n$base-style\n  hr\n    ...\n    border: 1px dashed color-border-article\n    @media prefers-dark\n      border: 1px dashed dark-color-border-article\n    ...\n\n$block\n  ...\n  background: color-block\n  box-shadow: 1px 2px 3px color-border\n  border: 1px solid color-border\n  @media prefers-dark\n    background: dark-color-block\n    box-shadow: 1px 2px 3px dark-color-border\n    border-color: dark-color-border\n\n...\n```\n\nThe same changes I had to do in every template ``styl`` file, where one of the colors or other mode dependent style was used. For example:\n\n```styl\n#mobile-nav-header\n  background-color: color-background\n  @media prefers-dark\n    background-color: dark-color-background\n  img.avatar\n    ...\n    @media prefers-dark\n      filter: brightness(85%)\n```\n\nThis will be rendered as:\n\n```css\n  #mobile-nav-header {\n    background-color: #f1f1f1;\n  }\n  @media (prefers-color-scheme: dark) {\n      #mobile-nav-header {\n      background-color: #111;\n    }\n  }\n\n  #mobile-nav-header img.avatar {\n    ...\n  }\n  @media (prefers-color-scheme: dark) {\n    filter: brightness(85%);\n  }\n```\n\nPlease note the use of ``filter:brightness()`` in the example. It is always advisable to darken the images too, because they can really pop out on dark backgrounds.\n\n## Related\n\n* [Hexo and the Dark Mode ... revised](/categories/Tools/Hexo-and-the-Dark-Mode-revised)\n","tags":["Hexo","CSS","Stylus","Dark Mode"],"categories":["Tools"]},{"title":"A New Blog: Blogging and Synching en route","url":"/categories/Tools/A-New-Blog-Blogging-and-Synching-en-route/","content":"\nI work with several devices, some Windows, some Android, and sometimes I have time to write on my articles at home (Notebook, Tablet), in my spare time in the office (Desktop, Laptop) or on my way to somewhere (Smartphone). Right now I'm am in a barber shop, waiting for my haircut and write these lines. So, wherever I am, I need the Hexo project locally, but in sync on a digital device.\n\nThe blog is synced via Dropbox, but hosted on GitHub Pages, so on every device I need the  publishing functions of Git too.\n\n<!-- more -->\n\n## Sync Hexo Project\n\nBest option for me to achieve this was  [Dropbox](https://dropbox.com). Another benefit on that is: I can work on the structure of the blog wherever I am and commit when the new feature or improvement is done, because all Git related files are always in sync too.\n\n## Writing, Editing and Publishing on Windows\n\nMy preferred editor is [Visual Studio Code](https://code.visualstudio.com/). Good file handling, easy writing, full Git integration and tons of other plugins and helpers. Chapeau Microsoft, well done.\n\nSome of the following VS Code plugins makes working with Hexo on GitHub pages a breeze:\n\n---\n\n[![vscode-hexo](A-New-Blog-Blogging-and-Synching-en-route/icon-vscode-hexo.png)]((https://marketplace.visualstudio.com/items?itemName=codeyu.vscode-hexo){.lefty})  \nAdds Hexo commands like ``init``, ``new``, ``generate``, ``server`` and ``clean`` to the VS Code command palette.\n\n---\n\n[![Markdown All in One](A-New-Blog-Blogging-and-Synching-en-route/icon-markdown-all-in-one.png)](https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one)  \nKeyboard shortcuts for basic formatting, automatic list editing, autocomlete for images,  table formatter and much more for an easier handling of Markdown.\n\n---\n\n[![markdownlint](A-New-Blog-Blogging-and-Synching-en-route/icon-markdownlint.png)](https://marketplace.visualstudio.com/items?itemName=DavidAnson.vscode-markdownlint)  \nMarkdown linting and style checking\n\n---\n\n[![Language Stylus](A-New-Blog-Blogging-and-Synching-en-route/icon-stylus.png)](https://marketplace.visualstudio.com/items?itemName=sysoev.language-stylus)  \nAdds syntax highlighting and code completion to Stylus files\n\n---\n\n[![GitLens](A-New-Blog-Blogging-and-Synching-en-route/icon-gitlens.png)](https://marketplace.visualstudio.com/items?itemName=sysoev.language-stylus)  \nComplete visual management of your repositories in VS Code\n\n---\n\n[![Git Graph](A-New-Blog-Blogging-and-Synching-en-route/icon-gitgraph.png)](https://marketplace.visualstudio.com/items?itemName=mhutchie.git-graph)  \nView a Git Graph of your repository with all changes and manage commits.\n\n---\n\nWith this editor and its helpers, I'm just two clicks away from publishing a new article or even a new version of the Hexo blog itself.\n\n## Writing on Android\n\nThere are a lot of Markdown editors available on Google Play, but one is outstanding: [iA Writer for Android](https://ia.net/writer/support/android). I can open my posts or drafts directly from Dropbox, without the need of any sychronization. Open, write, close, done.\n\n![iA Writer Android](A-New-Blog-Blogging-and-Synching-en-route/ia-writer-1.png)\n\n## Publishing on Android\n\nThere are some Git related Android apps out there, but no solution was satisfying. Furthermore, I didn't really need Git here, because I didn't want to have all source files on my smartphone. I'm working directly on the Dropbox stored MD files via iA Writer. Finally and most important, Git won't be enough, because before publishing, I have to run ``hexo generate``! Therefore some sort of automatic transfer from Dropbox to GitHub is also out of the game.\n\nWhat I needed, was to tell a server at a certain point of time 'Hey, please publish for me', using the only connection I have: Dropbox.\n\n### Introducing a Demon\n\nI have a little media server, running on Windows, and he is synchronizing some folders with Dropbox. He could do the job! After I installed all necessary packages, like NodeJS, Hexo and Git, I included the project folder into the sync. \n\nNext step was to design a so called **Hexo Command File**, a simple TXT file, which holds commands in single lines, extended with execution times, when they were successfully running.\n\n```properties\npostdraft: A-New-Blog-Blogging-and-Synching-en-route\npublish\nnewdraft: \"A New Blog: Blogging and Synching en route\" @ 2019-09-30 21:15\nregenerate @ 2019-09-29 16:40:01\npublish @ 2019-09-29 16:40:10\n```\n\nThese commands are predefined, because they bundle several real commands and I didn't want to deal with real commands, due to security reasons.\n\nThe unprocessed commands are standing at the top of the file (in execution order!) and parameters are separated from the command by a colon and delimited by commas.\n\n    <command>: [<param1>, ...] @ <execution time>\n\nNext step was to create a program to work as an executing demon, who monitors the Hexo Command File (synced by Dropbox) on my server and executes commands without execution dates.\n\nI decided to create a simple Console Application in C# and use the built-in [Windows Task Scheduler](https://en.wikipedia.org/wiki/Windows_Task_Scheduler) for running it every 2 minutes. The application is called **HexoCommander** and is [available at GitHub](https://github.com/kristofzerbe/HexoCommander).\n\nIt expects the Hexo Command File to be named ``hexo-commands.txt``, located in the same folder, and provides the following commands:\n\n**newdraft: \"&lt;title&gt;\"** ... runs\n\n1. ``hexo new draft \"<title>\"``\n\nCreates a new draft.\n\n**postdraft: \"&lt;filename without extension&gt;\"** ... runs\n\n1. ``hexo publish \"<filename without extension>\"``\n\nMakes a post out of a draft.\n\n**regenerate** ... runs\n\n1. ``hexo clean``\n2. ``hexo generate``\n\nWipes all Hexo static pages and generates them new.\n\n**publish** ... runs\n\n1. ``hexo generate``\n2. ``git add \"source/*\" \"docs/*\"``\n3. ``git commit -m \"Remote publication via HexoCommander\"``\n4. ``git push origin master``\n\nGenerates Hexo static pages, stage changes on drafts, posts and static pages, commits the changes with a generic message and pushes them to the server.\n\n### Running the demon\n\nI would have never expected, that the trickiest part was to get HexoCommander running via Windows Task Scheduler. What a mess! I finally find the solution [here](https://social.msdn.microsoft.com/Forums/SqlServer/en-US/29446adf-8304-4b9f-bbc4-95daf2941d53/program-runs-fine-but-task-scheduler-wont-run-it?forum=winserver2008appcompatabilityandcertification):\n\n1. Compile HexoCommander in a **x86** configuration\n\n2. Create a new task in Task Scheduler with\n   * **Trigger**\n     * Dialy\n     * Recur every 1 days\n     * Repeat task every 2 minutes for a duration of 1 day\n   * **Action**\n     * Program/Script: **%systemroot%\\Syswow64\\cmd.exe**\n     * Add Arguments: **/C \"C:\\MyPath\\HexoCommander.exe /workdir=C:\\MyPath\"**\n     * Start In: **%systemroot%\\Syswow64\\\\**\n\nBecause some executing commands in the chain are NOT 64-bit, I had to force Task Scheduler to run the 32-bit Command Shell in its own path (see 'Start In' and don't forget the closing backslash) and take the 32-bit compiled HexoCommander as argument after the parameter ```/C``` (forcing command to terminate), including its own argument for defining the real working directory. Mind bending, but works...\n\n---\n\n## Related\n\n* [A New Blog (Part One): VS Code, Hexo and GitHub Pages](/categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/)\n* [A New Blog (Part Two): Customizing Hexo](/categories/Tools/A-New-Blog-Customizing-Hexo/)","tags":["VS Code","Hexo","Blogging","GitHub"],"categories":["Tools"]},{"title":"A New Blog: Customizing Hexo","url":"/categories/Tools/A-New-Blog-Customizing-Hexo/","content":"\nHexo is a great tool to get quick results (see [Part One of this series](/categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/)), when you decide to have a blog and its defaults are practical, but it's power lies in the possiblities of customization via plugins. On the [official plugin page](https://hexo.io/plugins/index.html), there are actually 302 plugins listed, but there are many more and no wish will be unsatisfied.\n\nI will show you which of these I found worth to work with...\n<!-- more -->\n\n### Relative Image Path\n\nThe build-in way to include images in your posts works fine, but it is a little aside the normal way to declare images in Markdown. The plugin [Hexo Asset Link] corrects that. After installing via ``npm install hexo-asset-link --save`` you can write this:\n\n    ![Test Image](hello-world/image-1.png)\n\nThe best is, that VS Code's Markdown can now show the image.\n\n---\n\n**UPDATE**:  \nActually the plugin [destroys external links](https://github.com/liolok/hexo-asset-link/issues/3), so don't use it until this is fixed ... or go to **node_modules** &gt; **hexo-asset-link** &gt; **index.js** in your project and change in line 22 ``protocal`` to ``protocol``.\n\n**UPDATE from Update**:  \n[liolok](https://github.com/liolok), the author of the plugin has merged my pull request and published a new new version without the typo. It works now as expected.\n\n---\n\n### Hide Posts\n\nA new Hexo project comes with a sample post called ``Hello World``. This is fine to play around with, but you don't want to publish it. Here comes a Hexo plugin to the rescue called [Hexo Hide Posts](https://github.com/printempw/hexo-hide-posts). After installing, you just have to write ``hidden: true`` to the Front Matter of you post and it won't be shown on the blog, but it is still available by URL.\n\n### Static Files\n\nHexo has the concept of [Assets Folders](https://hexo.io/docs/asset-folders), but for static files, beside article based files, I find it more useful to have a STATIC folder and copy the contents on every build into the publish folder. A good helper for this approach is the plugin [Hexo Generator Copy](https://github.com/niahoo/hexo-generator-copy). Install it by running ``npm install hexo-generator-copy --save`` and add ``static_dir: static`` to your ``_config.yml`` and you are done.\n\n    ![Hexo Static Files](A-New-Blog-Customizing-Hexo/vscode-1.png)\n\n### Feed\n\nThe default Hexo layout has an Atom Feed icon in the upper right corner, but strangely no feed file is generated on build. You need to install the plugin [Hexo Feed Generator](https://github.com/hexojs/hexo-generator-feed) to fix this, by running ``npm install hexo-generator-feed --save`` and copy following section into the ``_config.yml``:\n\n```yaml\nfeed:\n    type: atom\n    path: atom.xml\n    limit: 20\n    hub:\n    content:\n    content_limit: 140\n    content_limit_delim: ' '\n    order_by: -date\n```\n\n### Manifest for PWA\n\nIn these modern times it's always a good idea, that your blog feels like an App. For this you need a manifest file (JSON) an several icons (PNG). You can generate these files very fast with the [Web App Manifest Generator](https://app-manifest.firebaseapp.com) and store it in your static folder.\n\nTo bind this file into your blog, you can use the plugin [Hexo PWA](https://github.com/lavas-project/hexo-pwa). Run ``npm install --save hexo-pwa`` and copy following section to your ``_config.yml``, where you take the settings from your generated manifest file:\n\n```yaml\npwa:\n    manifest:\n        path: /manifest.json\n        body:\n        name: myblog.de\n        short_name: My Blog\n        icons:\n            - src: /images/icon-192x192.png\n            sizes: 192x192\n            type: image/png\n            - src: /images/icon-512x512.png\n            sizes: 512x512\n            type: image/png\n        start_url: /index.html\n        theme_color: '#025ab1'\n        background_color: '#dddddd'\n        display: standalone\n```\n\n### Sitemap File\n\nTo help [Google](https://support.google.com/webmasters/answer/183668) and others a bit to index your blog, it is advisable to provide a sitemap file. Here comes [Hexo Generator Sitemap](https://github.com/hexojs/hexo-generator-sitemap) to the rescue. Install it by running the command ``npm install hexo-generator-sitemap --save``. You can configure it via ``_config.yml``:\n\n```yaml\nsitemap:\n    path: sitemap.xml\n    template: ./sitemap-template.xml\n```\n\nThe plugin installation doesn't create the needed ``sitemap-template`` file, so be sure you grab a copy from the plugins repository: [https://github.com/hexojs/hexo-generator-sitemap/blob/master/sitemap.xml](https://github.com/hexojs/hexo-generator-sitemap/blob/master/sitemap.xml)\n\n### Commenting\n\nHexo doesn't have a commenting system, but it's prepared to stick [Disqus](https://disqus.com/) comments under each article. Just create a new Disqus account for your blog and note the given short name. By adding following section to the ``_config.yml`` Hexo shows the commenting section:\n\n```yaml\ndisqus_enabled: true\ndisqus_shortname: my-blog\n```\n\n### Inifinite Scroll\n\nHexo shows as much articles at the start page as configured in ``_config.yml`` under ``index_generator.per_page``, but it's nicer to load more articles as you scroll by using the Hexo script [Inifinite Scroll](https://github.com/FrontendSophie/hexo-infinite-scroll). Install by adding following little script in **themes** & gt; **layout** &gt; **_partial** &gt; **after-footer.ejs**\n\n```html\n<script src=\"//cdn.jsdelivr.net/gh/frontendsophie/hexo-infinite-scroll@2.0.0/dist/main.js\"></script> \n<script>\n    infiniteScroll({\n    showNum: 5,\n    style: 'line-scale',\n    color: '#025ab1'\n    })\n</script>\n```\n\n### Back To Top\n\nIts nice to support the reader on scolling by providing a Scroll-To-Top button. The easiest way to get this, is the script [Vanilla Back To Top](https://github.com/vfeskov/vanilla-back-to-top). Just add follwing to **themes** &gt;**layout** &gt; **_partial** &gt; **after-footer.ejs**:\n\n```html\n<script>addBackToTop({\n    diameter: 30,\n    backgroundColor: 'rgb(0, 90, 180)',\n    textColor: '#fff'\n})\n</script>\n<style>\n#back-to-top {\n    border-radius: 0;\n    opacity: 0.6;\n}\n#back-to-top:hover {\n    opacity: 1;\n}\n</style>\n```\n\n## Related\n\n* [A New Blog (Part One): VS Code, Hexo and GitHub Pages](/categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/)\n* [A New Blog (Part Three): Blogging and Synching en route](/categories/Tools/A-New-Blog-Blogging-and-Synching-en-route/)\n","tags":["VS Code","Hexo","Blogging"],"categories":["Tools"]},{"title":"A New Blog: VS Code, Hexo and GitHub Pages","url":"/categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/","content":"\nA few days ago I puzzled over a technical problem regarding SQL Server, Active Directory and Visual Studio Database Projects. With tips, hints and snippets from several websites I got it running and the solution was absolutely memorable. For myself and for others. Nothing is harder than to know 'you did this before...', but not to remember how.\n\nBecause of this strong leaning towards oblivion, I started over 20 years ago my very first website **zerbit.de**, manually crafted with Classic ASP and a SQL Server database as backend, with an editor, tagging, categories and so on. It was really exciting to build this blog from scratch and writing articles for it, but it was so time consuming to expand the features of the website and keep it running, that some day I quit it silently.\n\nSo, to document the solution mentioned above, I could use tools like OneNote or others, like in the past years, but this would be just for me and not for all developers, who have a similar problem. I felt it would be unfair to participate from the knowledge of others to get my solution and dont give something back.\n\nI decided to write an article just in HTML and publish it on my personal GitHub Page that I didn't used so far. Ok, just Text ... ugly. Just a little CSS and a little more structure and maybe I should do something with Vue JS ... STOP ... It would be better to pick one of the cool new static website generators based on Node.js, to detain myself from inventing the wheel again and save my time to write articles. So I did a little research and found [HEXO](https://hexo.io) ... Bingo! I can work with my favorite editor [Visual Studio Code](https://code.visualstudio.com/), its all HTML, JavaScript and CSS, I can write my articles in Markdown and Hexo has a lot of helpers for stuff Markdown doesn't provide, it produces static files and works only with files, therefore no need for a database ... and it is well documented.\n<!-- more -->\n\n## Installation\n\n.. is quite easy, as described here: [https://hexo.io/docs/setup](https://hexo.io/docs/setup)\n\n1. Create folder and open in VS Code\n2. Open VS Code Terminal window\n3. Install Hexo with ``$ npm install -g hexo-cli``\n4. Init Hexo project with ``$ hexo init``\n5. Install dependencies with ``npm install``\n6. Done\n\n![New Hexo Project](A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/vscode-1.png)\n\n## Writing\n\n### Create new post/draft\n\nHexo has posts and drafts, whereat drafts has to published via a Hexo command to become a post. To create an article use the command ``hexo new post|draft \"My Title\"``. The title will be converted in a URL-encoded string and will be used as file name and url.\n\n### Meta data\nEvery post/draft starts with its header (so called [Front Matter](https://hexo.io/docs/front-matter)) to store some meta data, which describes the post, like ``title``, ``date``, ``tags`` or ``categories``. This is used by Hexo to classify and arrange your post during the build.\n\n### Markdown\nHexo posts/drafts are written in [Markdown](https://en.wikipedia.org/wiki/Markdown). Good syntax reference are the [Markdown Guide](https://www.markdownguide.org/basic-syntax/) and the more detailed [Markdown Syntax Guide](https://sourceforge.net/p/hexo/wiki/markdown_syntax/).\n\n### Excerpt\nIs is usual to show a short excerpt an the start page of a blog, to keep it compact and teasering the user to click on a READ MORE button. To achieve this, you just have to add following comment to your article. Everything above is the excerpt and everything below is only shown, when you enter the article:\n\n    <!-- more -->\n\n### Images\n\nSome articles will contain images to illustrate something and the question is, where should they be stored? Answer: In a folder beside the post/draft, which has the same name as the article MD file. To get this, you have to activate the setting ``post_asset_folder`` in your ``_config.yml``. Now this folder will be created automatically, when you add a new post/draft.\n\nIn your Markdown you reference your image with:\n\n    {% asset_img image-1.png \"Test Image\" %}\n\n![Reference Image](A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/vscode-2.png)\n\n## Build\n\nHexo is a website generator, so a build will generate the whole website in a special folder, which has to be published. This output folder can be configured in the ``_config.yml``:\n\n    public_dir: public\n\nTo wipe the output folder, run the command:\n\n    hexo clean\n\nTo start the build, run:\n\n    hexo generate\n\nTo view the website via the build-in local Hexo server, run:\n\n    hexo server\n\n## Publishing\n\nMost \"complex\" task was to publish the new blog on [GitHub Pages](https://pages.github.com/). My first approach was to use my personal page, as I did with my single HTML file, but this didn't work, because I wanted to store the whole project on GitHub and it is not possible to point a personal page to the subdirectory **docs** or use a different branch as **master**.\n\nThe simple solution was to create a new repository, named after my my blog **kiko.io**, to store teh whole project and point the GitHub Page to the subdirectory **docs** in the settings of the repository.\n\n![GitHub Settings](A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/github-1.png)\n\nBy overriding the default publish folder of Hexo in ``_config.yml`` ...\n\n    public_dir: docs\n\n... everything was set up. Commit and Push via git and done.\n\nHexo has its own deploying mechanism and it is advisable to disable it, by commenting out the Deployment section ``_config.yml``.\n\nNext step was to use my own custom domain for the blog. To achieve this, the most easiest way is to create a text file named ``CNAME`` (without extension!) with the content of the domain in a single line and publish this file in the root of the docs folder. Github will recognize this file and do the setup automatically.\n\nTo point the domain to GitHub, I had to create following ``A`` records in my domain providers DNS settings:\n\n* 185.199.108.153\n* 185.199.109.153\n* 185.199.110.153\n* 185.199.111.153\n\nLast step was to enable **Enforce HTTPS** in the repositories settings.\n\n---\n\n## Related\n\n* [A New Blog (Part Two): Customizing Hexo](/categories/Tools/A-New-Blog-Customizing-Hexo/)\n* [A New Blog (Part Three): Blogging and Synching en route](/categories/Tools/A-New-Blog-Blogging-and-Synching-en-route/)\n","tags":["VS Code","Hexo","Blogging","GitHub"],"categories":["Tools"]},{"title":"How-To: Visual Studio Database Project and ADSI","url":"/categories/SQL/How-To-Visual-Studio-Database-Project-and-ADSI/","content":"If you are working with a Visual Studio Database Project and have to deal with data from the Active Directory via a Linked Server, you have to announce the data structure of the AD data in order to get the project compiled.\n<!-- more -->\n## Step 1 - Linking to the Active Directory\n\nFirst of all you have to connect your SQL Server to the AD permanently, by running  following SQL script once on your SQL Server:\n\n    USE [master]\n    GO\n    EXEC master.dbo.sp_addlinkedserver @server = N'ADSI', \n        @srvproduct=N'Active Directory Service Interfaces', \n        @provider=N'ADSDSOObject', \n        @datasrc=N'adsdatasource'\n    \n    EXEC master.dbo.sp_addlinkedsrvlogin @rmtsrvname=N'ADSI',\n        @useself=N'False',\n        @locallogin=NULL,\n        @rmtuser=N'mydomain\\myadminuser',\n        @rmtpassword='mypassword'\n    GO\n    \n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'collation compatible', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'data access', @optvalue=N'true'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'dist', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'pub', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'rpc', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'rpc out', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'sub', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'connect timeout', @optvalue=N'0'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'collation name', @optvalue=null\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'lazy schema validation', @optvalue=N'false'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'query timeout', @optvalue=N'0'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'use remote collation', @optvalue=N'true'\n    GO\n    EXEC master.dbo.sp_serveroption @server=N'ADSI', \n        @optname=N'remote proc transaction promotion', @optvalue=N'true'\n    GO\n\n## Step 2 - Fetching ADSI data  \n\nTo get data, use ``OpenQuery`` against the Linked Server. In order to get only persons and no system accounts, you should filter out all users, which has no firstname (``givenName``) or lastname (``sn``):\n\n    SELECT \n        UserPrincipalName, \n        DisplayName, \n        sAMAccountName AS [SamAccountName], \n        sn AS [LastName], \n        givenName AS [FirstName], \n        title AS [Title], \n        Mail as [MailAddress],\n        department AS [Department],\n        l AS [Location], \n        postalCode AS [PostCode], \n        streetAddress AS [Street],\n        st AS [State]\n    FROM OpenQuery(ADSI, '\n        SELECT \n            UserPrincipalName, \n            DisplayName, \n            sAMAccountName, \n            sn, \n            givenName, \n            department,\n            title, \n            Mail, \n            l, \n            postalCode, \n            streetAddress, \n            st\n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' \n        WHERE objectClass =  ''User'' \n        AND objectCategory = ''Person'' \n        AND sn=''*'' \n        AND givenName = ''*'' \n    ')    \n\nIn most cases you're done with that ... except your organisation has more the 900 users! Then you have to split the fetch in several requests, because SQL Server quits with an error, when trying to read more than 900 records via ADSI.  \n\nBest option is, to filter the ADSI statement by something like *'get all user starting with a to j'*, when you are sure, that in this case less than 900 records will be given back and repeat the statement several times and glue the data together via a ``UNION`` statement:\n\n<pre>\n<code>SELECT  \n    UserPrincipalName,  \n    DisplayName,  \n    sAMAccountName AS [SamAccountName],  \n    sn AS [LastName],  \n    givenName AS [FirstName],  \n    title AS [Title],  \n    Mail as [MailAddress],  \n    department AS [Department],  \n    l AS [Location],  \n    postalCode AS [PostCode],  \n    streetAddress AS [Street],  \n    st AS [State]  \nFROM (  \n    SELECT *  \n    FROM OpenQuery(ADSI, '  \n        SELECT  \n            UserPrincipalName,  \n            DisplayName,  \n            sAMAccountName,  \n            sn,  \n            givenName,  \n            department,  \n            title,  \n            Mail,  \n            l,  \n            postalCode,  \n            streetAddress,  \n            st  \n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de''  \n        WHERE objectClass =  ''User''  \n        AND objectCategory = ''Person''  \n        AND sn=''*''  \n        AND givenName = ''*''  \n        <strong>AND sAMAccountName &lt;= ''j''</strong>\n    ')  \n\n    <strong>UNION ALL</strong>  \n\n    SELECT *  \n    FROM OpenQuery(ADSI, '  \n        SELECT <em>[...same as above]</em>  \n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de''  \n        WHERE objectClass =  ''User''  \n        AND objectCategory = ''Person''  \n        AND sn=''*''  \n        AND givenName = ''*''  \n        <strong>AND sAMAccountName &gt; ''j''</strong>  \n        <strong>AND sAMAccountName &lt; ''p''</strong>  \n    ')\n\n    <strong>UNION ALL</strong>  \n\n    SELECT *  \n    FROM OpenQuery(ADSI,  '  \n        SELECT <em>[...same as above]</em>  \n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de''  \n        WHERE objectClass =  ''User''  \n        AND objectCategory = ''Person''  \n        AND sn=''*'' AND givenName = ''*''  \n        <strong>AND sAMAccountName &gt;= ''p''</strong>  \n    ')  \n) AD</code>\n</pre>\n\nWhen you store this as a VIEW, you can join it wherever you want on SQL Server:\n\n<pre>\n<code>CREATE VIEW [dbo].[vADUsers]\nAS\n    <em>[...SQL code from above]</em>\n\nGO</code>\n</pre>\n\n## Step 3 - SQL Server Database Project\n\nIf you work with a SQL Server Database Project, to have the complete structure of your database available in a version control system, you will get some reference errors on compiling and publishing your newly added SQL View ``vADUsers`` and on some objects, which rely on this View, because of following problems:\n\n1. Project doesn't know the Linked Server `ADSI`\n2. The structure (fields) of the data source is unknown\n\n### Declare the Linked Server\n\nTo show the Project that there is a Linked Server called ``ADSI``, just add following lines at the start of your view:\n\n<pre>\n<code><strong>sp_addlinkedserver 'ADSI'</strong>\n<strong>GO</strong>\n\nCREATE VIEW [dbo].[vADUsers]\nAS\n    <em>[...SQL code from above]</em></code>\n</pre>\n\nThis mimics the adding of a Linked Server, but will be ignored by SQL Server on publish, because you already have a Linked Server with this name. The project is happy with it.\n\n### Declare the data structure\n\nWhen you use the SQL-View ``vADUsers`` in a Stored Procedure for example, this object won't compile, because the project knows nothing about the fields of the ADSI data source. The SELECT in the view is not enough. You have to add an empty ``SELECT`` to the View ``vADUsers``, just for the declaration of the fields and without returning any records and join this via ``UNION`` with the other statements:\n\n<pre>\n<code>sp_addlinkedserver 'ADSI'\nGO\n\nCREATE VIEW [dbo].[vtADAllUsers]\nAS\n\nSELECT\n    UserPrincipalName,\n    DisplayName,\n    sAMAccountName AS [SamAccountName],\n    sn AS [LastName],\n    givenName AS [FirstName],\n    title AS [Title],\n    Mail as [MailAddress],\n    department AS [Department],\n    l AS [Location],\n    postalCode AS [PostCode],\n    streetAddress AS [Street],\n    st AS [State]\nFROM (\n\n    -- Fake SELECT to declare the structure of the view<strong>\n    SELECT TOP 0\n        '' UserPrincipalName,\n        '' DisplayName,\n        '' sAMAccountName,\n        '' sn,\n        '' givenName,\n        '' department,\n        '' title,\n        '' Mail,\n        '' l,\n        '' postalCode,\n        '' streetAddress,\n        '' st\n\n    UNION ALL</strong>\n\n    SELECT *\n    FROM OpenQuery(ADSI, '\n        SELECT\n            UserPrincipalName,\n            DisplayName,\n            sAMAccountName,\n            sn,\n            givenName,\n            department,\n            title,\n            Mail,\n            l,\n            postalCode,\n            streetAddress,\n            st\n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de''\n        WHERE objectClass =  ''User''\n        AND objectCategory = ''Person''\n        AND sn=''*''\n        AND givenName = ''*''\n        AND sAMAccountName &gt;= ''j''  \n    ')\n\n    UNION ALL  \n\n    SELECT *  \n    FROM OpenQuery(ADSI, '  \n        SELECT <em>[...same as above]</em>  \n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de''  \n        WHERE objectClass =  ''User''  \n        AND objectCategory = ''Person''  \n        AND sn=''*''  \n        AND givenName = ''*''  \n        AND sAMAccountName &lt; ''j''  \n        AND sAMAccountName &gt; ''p''  \n    ')\n\n    UNION ALL  \n\n    SELECT *  \n    FROM OpenQuery(ADSI,  '  \n        SELECT <em>[...same as above]</em>  \n        FROM ''LDAP://mydomain.de/DC=mydomain,DC=de''  \n        WHERE objectClass =  ''User''  \n        AND objectCategory = ''Person''  \n        AND sn=''*''  \n        AND givenName = ''*''  \n        AND sAMAccountName &lt;= ''p''  \n    ')\n) AD</code>\n</pre>\n\nNow, you can fetch data from Active Directory and store the code in a Database Project properly.\n\nHAPPY CODING :)\n","tags":["Visual Studio","ADSI","Database Project"],"categories":["SQL"]}]