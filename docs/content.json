{"meta":{"title":"kiko.io","subtitle":"Memorable Tech Stuff","description":"Blog about Development & Photography","author":"Kristof Zerbe","url":"https://kiko.io","root":"/"},"pages":[{"title":"404","date":"2020-09-23","updated":"2020-09-23","path":"/404.html","permalink":"https://kiko.io//404.html","excerpt":"","text":"I don’t know how you ended up here, but you have jumped over the edge of this blog. Maybe it’s the end of the internet and you can power off your machine now… /@@ @@@@@@@@@ @@@@@@@@@ @@@@@@@@@ @@@@@ @@@@@@@@@ ,@@@@@ @@@@@@@@@@ @@@@@@@@@ @@@@@@@@@@ ,@@@@@@@@@@@@ @@@@@@@@@ @@@@@@@@@@@@ @@@@@@@@@@@@ @@@@@@@@@ (@@@@@@@@@@@@ #@@@@@@@@@@@ @@@@@@@@@ @@@@@@@@@@@ @@@@@@@@@@@ @@@@@@@@@ @@@@@@@@@@, @@@@@@@@@. @@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@ @@@@@@@@@@ @@@@@@@@@ @@@@@@@@ @@@@@@@@@ @@@@@@@@@ @@@@@@@@@ @@@@@@@@@ @@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@ @@@@@@@@@@@ @@@@@@@@@@@ @@@@@@@@@@@@@ /@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@ &@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@. *@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@ … or you climb back and read one of my recent posts :)"},{"title":"About","date":"2020-09-05","updated":"2020-10-02","path":"about/index.html","permalink":"https://kiko.io/about/index.html","excerpt":"","text":"Hi there!I’m Kristof from the lovely snoring Wiesbaden, in sometimes too hot and most times to cold Germany.I love three things: Software Development, Photography and first and foremost the brightest star in my sky: Leni. tl;dr The Photo EnthusiastAs I was around 14 years old, I catched from wherever a Praktika TL 1000, a fully mechanic SLR build in the former GDR. It was a revelation. I pointed my camera on everything and spend all my little money in developing the negatives and getting the prints. My first big purchase was a Nikon F301 with some additional lenses and some equipment for my own black/white darkroom at home in the bathroom, for the joy of my family. Since then, I’m addicted to photography. I have even tried to become a photographer and started an apprenticeship in Frankfurt/Main after leaving school, but due to lack of support, I have given it up in favor of a “decent” profession, as my father would say ;) Today a have a lot of equipment, knowing that a good picture is done by the photographer and not by the camera, but it’s part of the fun, carrying 3 ore more kilos around my shoulder, to grab the right lens for the right shot. Find some of my photographs on 500px — https://500px.com/p/kikon The DeveloperI’m a creative person and most people are shaking their heads in disbelief, when I’m telling them, that IT has a lot to do with creativity and not with math. While learning a lot of stuff about business as an industrial clerk trainee at the German headquarter of Prime Computer around 1990 (the decent profession), there was a guy in the warehouse, Colin Urquhart, who was working with a new type of computer, a x68 machine from IBM and he taught me something about it and ignited my fascination about the possibilities of a computer. A little later I got in touch with a i386DX computer from Escom and started to fiddle around on how to achieve this or that under MS-DOS, installing Windows 3.x from a dozen of 3.5 discs, connecting via a 14.4k modem to the FidoNet (greets to all the guys from the 45er Infosystems) and talk shop with my fellow students at the University of Applied Aciences, Wiesbaden, department of economics. One of our teachers gave me a copy of Microsoft Access 1.1 and I started to explore the possibilities of this new relational database system. A short time later, our professor for computer science wanted to switch teaching DBase towards Access and so I became his assistant and held some class hours, where one of my students, having a little company on selling hardware, was asking me someday, if I was interested building Access-based software for his clients. I said yes. My starting point into a career as a freelance software developer. Years later, after dozens of clients, authoring a book about Access, coming and going technologies, building (and leaving) my own company Division by Zero with my good friend Marcus Michaels, I’m now Head of Software Development at Allgeier Experts SE (formerly Goetzfried AG), developing internal software by using almost the complete Microsoft technology stack … and my creativity is demanded day by day. I’m still first and foremost fascinated by the technology on building software, in particular in creating pleasing, but functional UI’s, a user wants to works with, even if I spend a large part of my daily working time on management stuff. So it is not surprising that I sit at my laptop in my spare time, working on my private projects or trying out new technologies. I made by hobby a profession… If you want to talk about the old, recent or new times in IT, you can find me at: Xinghttps://www.xing.com/profile/Kristof_Zerbe LinkedInhttps://www.linkedin.com/in/kristof-zerbe-91012510/ GitHubhttps://github.com/kristofzerbe The Tool GuyMy colleagues always start to giggle, when I’m telling them that I’ve found a new tool, which is doing this or that. I’m the Tool Guy. I love to look for those little helpers, which saves my time. Every machine, I work with, has a folder called TOOLS on the primary disc, with dozens of these little programs and the first thing I do, on setting up a new machine, is to install the foundation of my indespensable tools: KeePassThe one and only password store CropperIndividual screenshots with ease PaintDotNetThe bitmap imaging programm for in between PapercutTiny SMTP trap for debugging mail sending Process ExplorerThe one and only task manager AutorunsKnow whats happening on startup PNGGauntletNo PNG leaves my machine without compressing JPEGMini… and so do JPG’s FileZillaFTP’ing since 2007 SourceTreeGit management at it’s best for the window guys SyncBackProAutomating almost all file related stuff Visual Studio CodeBest IDE for almost everything VeryCryptSuccessor of TrueCrypt for creating encrypted containers 7ZipFile packing the Open Source way DeepLBest translator ever seen USBDLMStop looking, start knowing USB Drive Letters Sizer 4.0Predefined resizing windows FileMenu ToolsHelper for the Windows Explorer context menu"},{"title":"","date":"2020-09-26","updated":"2020-09-26","path":"downloads/code/test.js","permalink":"https://kiko.io/downloads/code/test.js","excerpt":"","text":"alert('This is a test...'); console.log('This is a test...');"}],"posts":[{"title":"Show related posts in Hexo","subtitle":null,"series":"A New Blog","part":12,"date":"2020-10-03","updated":"2020-10-03","path":"categories/Tools/Show-related-posts-in-Hexo/","permalink":"https://kiko.io/categories/Tools/Show-related-posts-in-Hexo/","excerpt":"It is always nice to point the readers of your blog’s articles to related posts, they might be interested in. They stay a little longer to understand what you have to offer and increases the likelihood that they become loyal readers, followers or subscribers. Related posts has become a standard on delivering news and posts. In the default Hexo theme Landscape, on which this blog is based, there is no such function built in, but as the Hexo community is very busy, there are some plugins you can use.","keywords":"nice point readers blogs articles related posts interested stay longer understand offer increases likelihood loyal followers subscribers standard delivering news default hexo theme landscape blog based function built community busy plugins","text":"It is always nice to point the readers of your blog’s articles to related posts, they might be interested in. They stay a little longer to understand what you have to offer and increases the likelihood that they become loyal readers, followers or subscribers. Related posts has become a standard on delivering news and posts. In the default Hexo theme Landscape, on which this blog is based, there is no such function built in, but as the Hexo community is very busy, there are some plugins you can use. Plugin: hexo-list-related-postsThis plugin, available at GitHub is pretty lean and generates a list of links to related posts based on tags. It just counts how often a tag is occuring and shows a list of related posts either by count descending or randomly. Advantage: Easy and fast Disadvantage: Necessity of a sophisticated tag system Technical approach Plugin: hexo-related-postsSergey Zwezdin made much more effort in his solution. The plugins depends on statistic methodologies like Stemming and TF/IDF, provided by the Node library Natural. It has plenty setting, options like weighting and reserved words in order to optimize results. Advantages: Much better results Disadvantages: Huge installation, because of many dependent Node modules Necessity of maintaining reserved words Technical approach Manually CuratedOne point, that no technical solution can achieve is: you can guide the reader through your blog, by pointing out posts, which doesn’t really belong to the topic, but tries to give him a wider perspective on your thoughts or work. This is only possible, if you link the related posts manually. Here is a way to implement the requirements… The right place to store related posts is in the Frontmatter of your article. Create a list below the keyword related and take the slug (name of the post file) of the posts you want to show below the article as entries: 12345title: My New fancy Postrelated: - my-other-post - one-of-my-first-posts - yet-another-post In your article.ejs add a new partial called related to the place where it should be shown under the content of the actual article: 123456789101112131415161718192021&lt;article id=\"&lt;%= post.layout %&gt;-&lt;%= post.slug %&gt;\" class=\"article article-type-&lt;%= post.layout %&gt;\" itemscope itemprop=\"blogPost\"&gt; ... &lt;div class=\"article-inner\"&gt; &lt;%- post.content %&gt; &lt;/div&gt; &lt;% if (!index)&#123; %&gt; &lt;!-- NEW RELATED PARTIAL --&gt; &lt;%- partial('post/related') %&gt; &lt;%- partial('post/comments') %&gt; &lt;%- partial('post/nav') %&gt; &lt;% &#125; %&gt;&lt;/article&gt; In the folder themes/landscape/layout/_partial/post, where all partials are stored which belongs to posts, create the new partial file: related.ejs \"remove the comments, because they doesn't belong to EJS\"12345678910111213141516171819202122232425&lt;% if (post.related &amp;&amp; post.related.length)&#123; %&gt; &lt;div class=\"article-related\"&gt; &lt;h2&gt;Related&lt;/h2&gt; &lt;div class=\"archives\"&gt; &lt;!-- Loop through the Frontmatter list of RELATED posts --&gt; &lt;% post.related.forEach(function(item) &#123; %&gt; &lt;!--Determine the post(s) with the given slug --&gt; &lt;% var posts = site.posts.filter(function(post) &#123; return post.slug.toLowerCase() === item.toLowerCase(); &#125;); %&gt; &lt;!-- Loop through the post(s) and render the archive panel --&gt; &lt;% posts.each(function(post) &#123; %&gt; &lt;%- partial('../archive-post', &#123; post: post, show_link: true &#125;) %&gt; &lt;% &#125;); %&gt; &lt;% &#125;); %&gt; &lt;/div&gt; &lt;/div&gt;&lt;% &#125; %&gt; (Remove the comments, because they doesn’t belong to EJS) In this partial we loop through the Frontmatter list of related posts, determine the post by the given slug and render an archive panel for each post. In the site.posts list should always contain a slug once, therefore getting an array of posts and looping is just a precuation. What you are getting you can see below…","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"}]},{"title":"Discoveries #3 - Tutorials","subtitle":null,"series":"Discoveries","part":3,"date":"2020-09-29","updated":"2020-10-03","path":"categories/Discoveries/Discoveries-3-Tutorials/","permalink":"https://kiko.io/categories/Discoveries/Discoveries-3-Tutorials/","excerpt":"Some articles I stumble upon in my daily routine of reading news and blogs are diving very deep in a certain topic, especially if they are describing the basics of techniques I use every day. All of the following reading tips are of the type “ahh, that’s why this works like that” or “uuh, I just scatch on the surface on that”. Take your time and read the articles in detail. We all never stop learning and it’s a pleasure to do so… CSS CSS Viewport Units Grid for layout, Flexbox for components How CSS Perspective Works Linearly Scale font-size with CSS clamp() Based on the Viewport Learn CSS Centering JavaScript The Flavors of Object-Oriented Programming (in JavaScript) Understanding the Event Loop, Callbacks, Promises, and Async/Await in JavaScript","keywords":"articles stumble daily routine reading news blogs diving deep topic describing basics techniques day tips type ahh works uuh scatch surface time read detail stop learning pleasure so… css viewport units grid layout flexbox components perspective linearly scale font-size clamp based learn centering javascript flavors object-oriented programming understanding event loop callbacks promises async/await","text":"Some articles I stumble upon in my daily routine of reading news and blogs are diving very deep in a certain topic, especially if they are describing the basics of techniques I use every day. All of the following reading tips are of the type “ahh, that’s why this works like that” or “uuh, I just scatch on the surface on that”. Take your time and read the articles in detail. We all never stop learning and it’s a pleasure to do so… CSS CSS Viewport Units Grid for layout, Flexbox for components How CSS Perspective Works Linearly Scale font-size with CSS clamp() Based on the Viewport Learn CSS Centering JavaScript The Flavors of Object-Oriented Programming (in JavaScript) Understanding the Event Loop, Callbacks, Promises, and Async/Await in JavaScript CSS Viewport Units by Ahmad Shadeed&nbsp;:&nbsp;https://ishadeed.com/article/viewport-units Ahmad is a true master of CSS and describes complex topics in an understandable way. Here he deals with the different Viewport Units: how they are calculated and how to use them properly. Grid for layout, Flexbox for components by Ahmad Shadeed&nbsp;:&nbsp;https://ishadeed.com/article/grid-layout-flexbox-components Another one from Ahmad. Here he talks about the usage of Grid and/or Flexbox. Both techniques have their purpose and he shows when to use this or that. How CSS Perspective Works by Amit Sheen&nbsp;:&nbsp;https://css-tricks.com/how-css-perspective-works Amit shows in this tutorial how to deal with perspective on using transform and animation in CSS. A true eye opener… Linearly Scale font-size with CSS clamp() Based on the Viewport by Pedro Rodriguez&nbsp;:&nbsp;https://css-tricks.com/linearly-scale-font-size-with-css-clamp-based-on-the-viewport Few of us really deal with repsonsive typography. We fiddle arounf with line-height and font-size to achieve an B+ effect. Pedro shows how do it right with clamp() … and it is amazing. Centering in CSS by Ahmad Shadeed&nbsp;:&nbsp;https://ishadeed.com/article/learn-css-centering Ahmad again (I told you, he is amazing). In this tutorial he goes through every technique to center stuff in CSS. Never again google ‘center text flexbox’… The Flavors of Object-Oriented Programming (in JavaScript) by Zell Liew&nbsp;:&nbsp;https://css-tricks.com/the-flavors-of-object-oriented-programming-in-javascript There are different methods to ‘organize’ your JavaScript code. Zell shows the possibilities and pitfalls of techniques like Constructor Functions, Classes, Factory Functions and OLOO. Huge post, but couldn’t stop reading… Understanding the Event Loop, Callbacks, Promises, and Async/Await in JavaScript by Tania Rascia&nbsp;:&nbsp;https://www-digitalocean-com.cdn.ampproject.org/v/s/www.digitalocean.com/community/tutorials/understanding-the-event-loop-callbacks-promises-and-async-await-in-javascript.amp?usqp=mq331AQFKAGwASA%3D&amp_js_v=0.1 Tanias deep knowledge of asynchronous JavaScript techniques and its basics is as long as this tutorials title and its Url. A must-read.","categories":[{"name":"Discoveries","slug":"Discoveries","permalink":"https://kiko.io/categories/Discoveries/"}],"tags":[{"name":"Great Finds","slug":"Great-Finds","permalink":"https://kiko.io/tags/Great-Finds/"}]},{"title":"Device Class Detection in JavaScript","subtitle":"The unusual way by using CSS Media Queries","date":"2020-09-28","updated":"2020-10-02","path":"categories/JavaScript/Device-Class-Detection-in-JavaScript/","permalink":"https://kiko.io/categories/JavaScript/Device-Class-Detection-in-JavaScript/","excerpt":"In some occasions it is necessary to know which device a user is using while writing JavaScript Web Apps. Should be nothing regarding layout, because for this we have CSS Media Queries. Somewhere around 2011 W3C introduced matchMedia(), which returns a MediaQueryList object that can be used to detemnine if the document matches the media query string. The using is pretty straightforward and feels a bit like RegEx matching in JS: 1234const mediaQuery = window.matchMedia('(min-width: 1025px)')if (mediaQuery.matches) &#123; // do something... &#125; If you are interested in this API, you will find good introductions to the topic here, here and here (German). One point of criticism on this pure JS approach can be, that you have to maintain the breakpoints in addition to CSS … but why not use these existing breakpoints in JS?","keywords":"occasions device user writing javascript web apps layout css media queries w3c introduced matchmedia returns mediaquerylist object detemnine document matches query string pretty straightforward feels bit regex matching js 1234const mediaquery = windowmatchmedia'min-width 1025px'if mediaquerymatches &#123 // &#125 interested api find good introductions topic german point criticism pure approach maintain breakpoints addition … existing","text":"In some occasions it is necessary to know which device a user is using while writing JavaScript Web Apps. Should be nothing regarding layout, because for this we have CSS Media Queries. Somewhere around 2011 W3C introduced matchMedia(), which returns a MediaQueryList object that can be used to detemnine if the document matches the media query string. The using is pretty straightforward and feels a bit like RegEx matching in JS: 1234const mediaQuery = window.matchMedia('(min-width: 1025px)')if (mediaQuery.matches) &#123; // do something... &#125; If you are interested in this API, you will find good introductions to the topic here, here and here (German). One point of criticism on this pure JS approach can be, that you have to maintain the breakpoints in addition to CSS … but why not use these existing breakpoints in JS? If you implement a feature that is based on the different device classes, you don’t have to determine the current class with dozens of lines of JavaScript code, if you just can ask the DOM. The CSS/JS Breakpoint HackFor this approach, we take advantage of the fact, that CSS can be used to define not only styles, but also content. We always use it, when showing an icon by using a symbol font like FontAwesome: 1234my-fancy-icon::before &#123; font-family: FontAwesome5Solid; content: \"\\f186\";&#125; Mixed with a @media rule, we can “inject” the needed device value into the DOM, for example into the BODY tag, but you can take whatever you want: 12345@media (min-width: 1025px) &#123; body:before &#123; content: \"DESKTOP\"; &#125;&#125; Just one line more in the masses of CSS code to make a Web App responsive, but with this one you can do without many lines of JS. Now you can read out this value via JavaScript by getting the styles of the tag and get the injected content: 12var style = window.getComputedStyle(document.querySelector(\"body\"), \":before\");var breakpoint = style.getPropertyValue(\"content\").replace(/\\\"/g, \"\"); It is advisable to embed this request into an event listener of DOMContentLoaded, because the rule has to be set, before you can access it. See a simple working pen:","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"}],"tags":[{"name":"Browser","slug":"Browser","permalink":"https://kiko.io/tags/Browser/"},{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/tags/JavaScript/"}]},{"title":"404 Page in Hexo for GitHub Pages","subtitle":"Provide an error page automatically when resource not found","series":"A New Blog","part":11,"date":"2020-09-23","updated":"2020-10-03","path":"categories/Tools/404-Page-in-Hexo-for-GitHub-Pages/","permalink":"https://kiko.io/categories/Tools/404-Page-in-Hexo-for-GitHub-Pages/","excerpt":"As this blog is a static one, generated by Hexo and hostet at GitHub, the page which was shown, when a user enters an Url which points to nowhere, was the default GitHub 404 page.","keywords":"blog static generated hexo hostet github page shown user enters url points default","text":"As this blog is a static one, generated by Hexo and hostet at GitHub, the page which was shown, when a user enters an Url which points to nowhere, was the default GitHub 404 page. Not optimal and should be solved by an own Hexo page, because GitHub Pages allows you to deliver a custom 404 page by creating simply a 404.html in the root of the website. As you can create separate pages in Hexo, this is done quickly by: 1hexo new page \"404\" It generates a new folder named 404 in your source folder, where a index.md is placed. In this file you can enter the text as Markdown you want to show to the user, in case of a 404 error (page not found) occurs. On generating the static files by hexo generate, a subfolder 404 with a index.html will be created, which doesn’t really work with GitHub Pages, because it needs a 404.htm in the root. You can fix this, by defining the permalink in the Frontmatter of your page: 1234---title: 404permalink: /404.html--- Example … click here: https://kiko.io/no-page-here","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kiko.io/tags/GitHub/"},{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"Error","slug":"Error","permalink":"https://kiko.io/tags/Error/"}]},{"title":"Pimping the Permalink","subtitle":"How to copy and share the permalink programatically","series":"A New Blog","part":10,"date":"2020-09-20","updated":"2020-10-03","path":"categories/JavaScript/Pimping-the-Permalink/","permalink":"https://kiko.io/categories/JavaScript/Pimping-the-Permalink/","excerpt":"Until now I did not show the permalink under my posts in this blog, but in the past I had sometimes the need to pass one of the links and it was not very user-friendly, on desktop as well as on mobile. Not the One-Click experience I prefer. My goal was to show the permalink and, even more important, provide a simple way to copy and to share. JavaScript to the rescue…","keywords":"show permalink posts blog past pass links user-friendly desktop mobile one-click experience prefer goal important provide simple copy share javascript rescue…","text":"Until now I did not show the permalink under my posts in this blog, but in the past I had sometimes the need to pass one of the links and it was not very user-friendly, on desktop as well as on mobile. Not the One-Click experience I prefer. My goal was to show the permalink and, even more important, provide a simple way to copy and to share. JavaScript to the rescue… DisplayAs I run my blog with Hexo, I deal with EJS files. To show the permalink in my article.ejs, was quite simple. First step was to create a new partial file named permalink.ejs, to be called every time when the complete article has to be rendered: 123&lt;% if (!index)&#123; %&gt; &lt;%- partial('post/permalink', &#123; class_name: 'article-permalink' &#125;) %&gt;&lt;% &#125; %&gt; The partial file looked like this in this step: 123&lt;div class=\"&lt;%= class_name %&gt;\"\"&gt; &lt;a id=\"article-permalink\" href=\"&lt;%- post.permalink %&gt;\"&gt;&lt;%- post.permalink %&gt;&lt;/a&gt;&lt;/div&gt; CopyAs I read a little bit about the possibilities to copy text into the clipboard via JavaScript on MDN, it became obvious that a link is not the best solution, because using the exeCommand needs to have something selected and this is difficult on anchors. Then … do it with an input: 123456789101112131415161718192021222324252627&lt;div class=\"&lt;%= class_name %&gt;\"\"&gt; &lt;input id=\"article-permalink\" value=\"&lt;%- post.permalink %&gt;\" /&gt; &lt;a id=\"action-copy\" class=\"article-action\" href=\"javascript:copyPermalink();\"&gt;&lt;/a&gt;&lt;/div&gt;&lt;script&gt; var copyText = document.querySelector(\"#article-permalink\"); //Disable Input by default copyText.disabled = true; function copyPermalink() &#123; //Enable Input copyText.disabled = false; //Select permalink text copyText.select(); //Copy to clipboard document.execCommand(\"copy\"); //Remove selection again copyText.blur(); //Disable Input again copyText.disabled = true; &#125;&lt;/script&gt; Nice, but a user feedback, that the text has been copied to the clipboard, was advisable, because nothing is more annoying, when you click somewhere and nothing seems to happen. As I hate default browser confirmations and other distracting messaging methods, I wanted to use the input itself, by fading out the link text, replace it with a message and fade in the text again: I extended my animation.styl (Hexo works with Stylus) with two keyframe animations … one for fading in, one for fading out… 12345678910111213141516171819202122232425@keyframes fadeIn &#123; 0% &#123; opacity:0; &#125; 100% &#123; opacity:1; &#125;&#125;.fade-in-500 animation: fadeIn ease 0.5s;.fade-in-1000 animation: fadeIn ease 1s;@keyframes fadeOut &#123; 0% &#123; opacity:1; &#125; 100% &#123; opacity:0; &#125;&#125;.fade-out-500 animation: fadeOut ease 0.5s;.fade-out-1000 animation: fadeOut ease 1s; … and wrote a setTimeout cascade to achive the effect: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;div class=\"&lt;%= class_name %&gt;\"\"&gt; &lt;input id=\"article-permalink\" value=\"&lt;%- post.permalink %&gt;\" /&gt; &lt;a class=\"article-action action-copy\" href=\"javascript:copyPermalink();\"&gt;&lt;/a&gt;&lt;/div&gt;&lt;script&gt; var copyText = document.querySelector(\"#article-permalink\"); copyText.disabled = true; function copyPermalink() &#123; copyText.disabled = false; copyText.select(); document.execCommand(\"copy\"); copyText.blur(); copyText.disabled = true; //Store original text var permalink = copyText.value; //Start fading out copyText.classList.add(\"fade-out-500\"); //Wait until animation is done setTimeout(function()&#123; //Set message, remove fadout class and add start fading in copyText.value = \"copied to clipboard\"; copyText.classList.remove(\"fade-out-500\"); copyText.classList.add(\"fade-in-1000\"); //Wait 2 seconds to show the message setTimeout(function() &#123; //Start to fade out message copyText.classList.add(\"fade-out-500\"); //Wait until animation is done setTimeout(function() &#123; //Set original text again and remove fadout class copyText.value = permalink; copyText.classList.remove(\"fade-out-500\"); //Wait until animation is done setTimeout(function() &#123; //Remove fadeout class copyText.classList.remove(\"fade-in-1000\"); &#125;, 500); &#125;, 500); &#125;, 2000); &#125;, 500); &#125;&lt;/script&gt; ShareThe second permalink feature was a little bit trickier, because I didn’t want to use one of the sharing libraries out there, whose business model is based on my readers data (always keep conservative on implementing third party stuff, because you never know what they are doing with the data). But a couple of months ago I read about a new native browser API for WebApps on the rise: Web Share API. Since 2019 W3C is working on this API, for sharing text, links and other content to an arbitrary destination of the user’s choice. On 27 August 2020 the published a Working Draft and on 16 September 2020 the latest Editors Draft. Brand new stuff. The browser support is not the best yet, but it will be getting better in the near feature, especially as Edge Chrome is one of the early adopters. web.dev lists important requirements on using this new feature in JavaScript: It can only be used on a site that supports HTTPS It must be invoked in response to a user action such as a click But it can share URL’s, text and even files! A raw implementation can be: 12345678910if (navigator.share === undefined) &#123; navigator.share(&#123; title: 'My Post', url: 'https://my-domain.com/my-url', &#125;) .then(() =&gt; console.log('Successful share')) .catch((error) =&gt; console.log('Error sharing', error));&#125; else &#123; // fallback&#125; I refrain to implement a fallback, rather I would like to show the appropriate button only to those users, whose browser supports it: 12345678910111213141516171819202122&lt;div class=\"&lt;%= class_name %&gt;\"\"&gt; &lt;input id=\"article-permalink\" value=\"&lt;%- post.permalink %&gt;\" data-id=\"&lt;%= post._id %&gt;\" /&gt; &lt;a id=\"action-copy\" class=\"article-action\" href=\"javascript:copyPermalink();\"&gt;&lt;/a&gt; &lt;a id=\"action-share\" class=\"article-action\" href=\"javascript:sharePermalink();\"&gt;&lt;/a&gt;&lt;/div&gt;&lt;script&gt; function copyPermalink() &#123; -- SEE ABOVE &#125; if (navigator.share === undefined) &#123; var shareLink = document.querySelector(\"#action-share\"); shareLink.style.display = \"none\"; &#125; function sharePermalink() &#123; navigator.share(&#123; title: \"&lt;%- post.title %&gt;\", url: \"&lt;%- post.permalink %&gt;\", &#125;) &#125;&lt;/script&gt; More information about Web Share API: W3C Web Share Test heise Developer: Features von übermorgen: Die Web Share API und die Web Share Target API (German) CSS-Tricks: How to Use the Web Share API","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/tags/JavaScript/"},{"name":"Stylus","slug":"Stylus","permalink":"https://kiko.io/tags/Stylus/"}]},{"title":"Discoveries #2","subtitle":null,"series":"Discoveries","part":2,"date":"2020-09-07","updated":"2020-10-02","path":"categories/Discoveries/Discoveries-2/","permalink":"https://kiko.io/categories/Discoveries/Discoveries-2/","excerpt":"New month, new discoveries. We will deal with key bindings, downloads on the fly, a lot of animations and contrasting images. Have fun, trying out these stunning solutions. tinykeys - Modern library for keybindings Creating files in JavaScript in your browser CSS Animated Google Fonts Skeleton Screen CSS More Control Over CSS Borders With background-image A CSS-only, animated, wrapping underline Nailing the Perfect Contrast Between Light Text and a Background Image Contrast.js","keywords":"month discoveries deal key bindings downloads fly lot animations contrasting images fun stunning solutions tinykeys modern library keybindings creating files javascript browser css animated google fonts skeleton screen control borders background-image css-only wrapping underline nailing perfect contrast light text background image contrastjs","text":"New month, new discoveries. We will deal with key bindings, downloads on the fly, a lot of animations and contrasting images. Have fun, trying out these stunning solutions. tinykeys - Modern library for keybindings Creating files in JavaScript in your browser CSS Animated Google Fonts Skeleton Screen CSS More Control Over CSS Borders With background-image A CSS-only, animated, wrapping underline Nailing the Perfect Contrast Between Light Text and a Background Image Contrast.js tinykeys - Modern library for keybindings by Jamie Kyle&nbsp;:&nbsp;https://jamiebuilds.github.io/tinykeys Very easy to use key binding library for JavaScript. Supports key sequences and modifier keys. Creating files in JavaScript in your browser by Kilian Valkhof&nbsp;:&nbsp;https://kilianvalkhof.com/2020/javascript/creating-files-in-javascript-in-your-browser Kilian shows how to prepare data in JavaScript and offer them to download on the fly, without the use of storing a file. CSS Animated Google Fonts by Jhey Tompkins&nbsp;:&nbsp;https://dev.to/jh3y/animated-google-fonts-193d As Google Fonts now supports variable fonts, Jhey shows a solution how to create neat font animations with them. Skeleton Screen CSS by Dmitriy Kuznetsov&nbsp;:&nbsp;https://github.com/nullilac/skeleton-screen-css When loading data on demand, it is sometimes advisable to show placeholders, where the data will be filled in. Dimitriy has founded a CSS framework for these skeletons. More Control Over CSS Borders With background-image by Chris Coyier&nbsp;:&nbsp;https://css-tricks.com/more-control-over-css-borders-with-background-image Borders are used to seperate things in a layout, but the build-in possibilities of CSS are restricted. Chris found a way by pimping borders up, using background images. A CSS-only, animated, wrapping underline by Nicky Meuleman&nbsp;:&nbsp;https://nickymeuleman.netlify.app/blog/css-animated-wrapping-underline As Chris did for the borders, Nick’s doing on underlined links. An end to boring rigid unterlines, let’s animate them. Nailing the Perfect Contrast Between Light Text and a Background Image by Yaphi Berhanu&nbsp;:&nbsp;https://css-tricks.com/nailing-the-perfect-contrast-between-light-text-and-a-background-image Showing text on background images can be challenging due to contrast and readability. Yaphi has developed a solution to find always the right transparent overlay to show the most of the picture, but keep the text readable. Stunning… Contrast.js by Misha Petrov&nbsp;:&nbsp;https://github.com/MishaPetrov/Contrast.js Misha addresses the same problem as Yaphi, showing text on background images, but goes a different way with his library, which is trying to find the best constrasting text color, even if the page is responsive.","categories":[{"name":"Discoveries","slug":"Discoveries","permalink":"https://kiko.io/categories/Discoveries/"}],"tags":[{"name":"Great Finds","slug":"Great-Finds","permalink":"https://kiko.io/tags/Great-Finds/"}]},{"title":"Add website to Trello card the better way","subtitle":"Avoid default share, use the Trello bookmarklet","date":"2020-09-07","updated":"2020-10-02","path":"categories/Tools/Add-website-to-Trello-card-the-better-way/","permalink":"https://kiko.io/categories/Tools/Add-website-to-Trello-card-the-better-way/","excerpt":"I was looking for a new way to store interesting website articles for reading later, as Pocket, my favourite tool until here, gets worse and worse. As I am a big Trello fan, I wanted to give it a chance to be Pockets successor on my smartphone, where I’m reading mostly. On installing the Trello Android app, you will find a new SHARE target Add new Trello card, which is comfortable to use: (Sry, for the German screenshots ;) The result, website’s title and Url set, is nice at best: … but Trello has a Bookmarklet, which does the job much better.","keywords":"store interesting website articles reading pocket favourite tool worse big trello fan wanted give chance pockets successor smartphone im installing android app find share target add card comfortable sry german screenshots result websites title url set nice … bookmarklet job","text":"I was looking for a new way to store interesting website articles for reading later, as Pocket, my favourite tool until here, gets worse and worse. As I am a big Trello fan, I wanted to give it a chance to be Pockets successor on my smartphone, where I’m reading mostly. On installing the Trello Android app, you will find a new SHARE target Add new Trello card, which is comfortable to use: (Sry, for the German screenshots ;) The result, website’s title and Url set, is nice at best: … but Trello has a Bookmarklet, which does the job much better. The following approach works best in the Google Chrome browser. First, a Bookmarklet is a small piece of JavaScript, which is stored as a bookmark in your browser. As you can’t actually create such a Bookmarklet in your Android Chrome, you have to create it in your desktop Chrome and switch on the bookmark sync of chrome. You should right away choose a short, concise name for the bookmark, so you find it easier in Android Chrome afterwards. I called it 2TrelloCard, because few websites start with an number. After Chrome’s sync is done, go to any website do you want to store as a Trello card. Now enter the Url box and type the name of the bookmarklet and select it. Instead of requesting a different page, Chrome executes the JavaScript of the Bookmarklet against the currently open website. This script shows a Trello dialog, where you can choose, which board and list the new card should be created on. This card creation method not only sets the title of the card, but fills the description with the meta description of the page, adds the first found meta image as cover and adds the Url as an attachment:","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Trello","slug":"Trello","permalink":"https://kiko.io/tags/Trello/"},{"name":"Browser","slug":"Browser","permalink":"https://kiko.io/tags/Browser/"}]},{"title":"Horizontal navigation menu above an image","subtitle":"How to deal with coverage, readability and scrollbars","series":"A New Blog","part":9,"date":"2020-07-20","updated":"2020-10-03","path":"categories/UI-Design/Horizontal-navigation-menu-above-an-image/","permalink":"https://kiko.io/categories/UI-Design/Horizontal-navigation-menu-above-an-image/","excerpt":"I changed the main menu of my blog, because I wanted to get rid of the hamburger menu on the upper left, which was shown only for smartphones, but was not really reachable conveniently. Beside that it made no sense to have different navigations for different devices. My choice was to implement a horizontal scrolling menu, which can grow over the time, without any need of customizing. As I have quite big header images and I wanted to place the new navigation in a more accessible zone, I decided to place it at the bottom, but above the header image.","keywords":"changed main menu blog wanted rid hamburger upper left shown smartphones reachable conveniently made sense navigations devices choice implement horizontal scrolling grow time customizing big header images place navigation accessible zone decided bottom image","text":"I changed the main menu of my blog, because I wanted to get rid of the hamburger menu on the upper left, which was shown only for smartphones, but was not really reachable conveniently. Beside that it made no sense to have different navigations for different devices. My choice was to implement a horizontal scrolling menu, which can grow over the time, without any need of customizing. As I have quite big header images and I wanted to place the new navigation in a more accessible zone, I decided to place it at the bottom, but above the header image. Problem was, not to cover a big part of the image with a full-colored or even semitransparent bar, by using a RGBA background color. I wanted it more translucent, but with enough contrast on bright images for the menu items to read. The recently introduced W3C feature backdrop-filter was just the right thing for that. It is supported by most modern browsers, but it has to have a backup strategy for the rest of the bunch. The HTML is simple: 1234567891011121314151617&lt;nav id=\"header-nav\" role=\"navigation\"&gt; &lt;ul class=\"menu\"&gt; &lt;li class=\"menu-item\"&gt; &lt;a href=\"/first\" title=\"First\"&gt; &lt;span&gt;First Item&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;li class=\"menu-item\"&gt; &lt;a href=\"/second\" title=\"Second\"&gt; &lt;span&gt;Second Item&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/nav&gt; And here’s the Stylus code for my approach: 123456789101112131415161718192021222324252627282930313233343536373839404142#header-nav position: absolute bottom: 0 width: 100% height: auto box-sizing: content-box overflow-x: scroll overflow-y: hidden // BACKDROP-FILTER backdrop-filter: blur(5px) brightness(90%) @supports not (backdrop-filter: none) background: rgba(0,0,0,0.25) // SCROLLBAR &amp;::-webkit-scrollbar display: none @supports not (webkit-scrollbar) scrollbar-width: none .menu display: flex list-style: none margin: 0 padding: 0 .menu-item flex-basis: 80px flex-shrink: 0 flex-grow: 1 max-width: 100px margin: 0 2px text-overflow: ellipsis; a display: inline-block width: 100% padding: 10px 0 color: #ffffff font-weight: bold text-decoration: none text-align: center The navigation box is absolute positioned on the image, is as wide as the screen and scrolls exclusively horizontal. The items are a unordered list, with default width and arranged by flex. In case a browser doesn’t understand backdrop-filter, the navigation bar is shown with a classic alpha channel opacity. When having a horizontal scroll feature, the scrollbar shown by the browser is beyond beautiful. To prevent this, I used the CSS pseudo element ::-webkit-scrollbar, which is supported by WebKit and Blink bowsers, with a fallback for all other browsers. Both strategies allows to be still able to scroll. If you want to have a scrollbar, but not the built-in, I can only recommend to read something about styling scrollbars, like here and here.","categories":[{"name":"UI-Design","slug":"UI-Design","permalink":"https://kiko.io/categories/UI-Design/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"},{"name":"Stylus","slug":"Stylus","permalink":"https://kiko.io/tags/Stylus/"}]},{"title":"Change CSS class when element scrolls into viewport","subtitle":null,"series":"A New Blog","part":8,"date":"2020-07-13","updated":"2020-10-02","path":"categories/JavaScript/Change-CSS-class-when-element-scrolls-into-viewport/","permalink":"https://kiko.io/categories/JavaScript/Change-CSS-class-when-element-scrolls-into-viewport/","excerpt":"I had a neat visual gimmick on the start page of this blog, that the gray-scaled header image of a post in the list scaled up to 100% and became colored, when the user hovered over it: 123456789101112131415.article-inner .article-photo &#123; height: 150px; width: 100%; object-fit: cover; transform: scale(1); transform-style: preserve-3d; transition: all ease-out 0.6s; opacity: 0.3; filter: grayscale(1) contrast(0.5);&#125;.article-inner:hover .article-photo &#123; transform: scale(1.1); opacity: 1; filter: grayscale(0) contrast(1);&#125; Nice, but a little bit useless on smartphones or tablets, where HOVER doesn’t really work.","keywords":"neat visual gimmick start page blog gray-scaled header image post list scaled 100% colored user hovered 123456789101112131415article-inner article-photo &#123 height 150px width object-fit cover transform scale1 transform-style preserve-3d transition ease-out 06s opacity filter grayscale1 contrast05&#125article-innerhover scale11 grayscale0 contrast1&#125 nice bit useless smartphones tablets hover doesnt work","text":"I had a neat visual gimmick on the start page of this blog, that the gray-scaled header image of a post in the list scaled up to 100% and became colored, when the user hovered over it: 123456789101112131415.article-inner .article-photo &#123; height: 150px; width: 100%; object-fit: cover; transform: scale(1); transform-style: preserve-3d; transition: all ease-out 0.6s; opacity: 0.3; filter: grayscale(1) contrast(0.5);&#125;.article-inner:hover .article-photo &#123; transform: scale(1.1); opacity: 1; filter: grayscale(0) contrast(1);&#125; Nice, but a little bit useless on smartphones or tablets, where HOVER doesn’t really work. A better idea was to transform the header image automatically, when it becomes visible to the user. So I changed the HOVER selector into a class… 12345.article-photo.in-view &#123; transform: scale(1.1); opacity: 1; filter: grayscale(0) contrast(1);&#125; … and wrote a little JS function to determine the point, where the images is fully visible in the viewport: 1234567function isVisibleInViewPort(e) &#123; var viewTop = $(window).scrollTop(); var viewBottom = viewTop + $(window).height(); var eTop = $(e).offset().top; var eBottom = eTop + $(e).height(); return ((eBottom &lt;= viewBottom) &amp;&amp; (eTop &gt;= viewTop));&#125; This function I had to bind to the windows scroll event to all header images only: 123456789$(window).on('scroll', function() &#123; $(\".article-photo\").each(function() &#123; if (isVisibleInViewPort($(this))) &#123; $(this).addClass(\"in-view\"); &#125; else &#123; $(this).removeClass(\"in-view\"); &#125; &#125;);&#125;);","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://kiko.io/tags/jQuery/"},{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"}]},{"title":"Discoveries #1","subtitle":null,"series":"Discoveries","part":1,"date":"2020-07-12","updated":"2020-10-02","path":"categories/Discoveries/Discoveries-1/","permalink":"https://kiko.io/categories/Discoveries/Discoveries-1/","excerpt":"Due to my daily routine, I’m reading a lot of articles on the web regarding software development. The most interesting stuff ends up on my Pocket list, which grows from day to day. Hard to find the pearls, when I need them. This recurring posts will throw a stroke of light on them. They are maybe not the newest finds, not the fanciest ones, but remarkable for me and maybe for you also. Pure CSS halftone portrait from .jpg source ScrollTrigger - Highlight Text Tiny long-press event handler Show More/Less 3D banners with ScrollTrigger Image Compare Viewer Add Read or Scroll Progress Bar To A Website To Indicate Read Progress How to Get a Progressive Web App into the Google Play Store","keywords":"due daily routine im reading lot articles web software development interesting stuff ends pocket list grows day hard find pearls recurring posts throw stroke light newest finds fanciest remarkable pure css halftone portrait jpg source scrolltrigger highlight text tiny long-press event handler show more/less 3d banners image compare viewer add read scroll progress bar website progressive app google play store","text":"Due to my daily routine, I’m reading a lot of articles on the web regarding software development. The most interesting stuff ends up on my Pocket list, which grows from day to day. Hard to find the pearls, when I need them. This recurring posts will throw a stroke of light on them. They are maybe not the newest finds, not the fanciest ones, but remarkable for me and maybe for you also. Pure CSS halftone portrait from .jpg source ScrollTrigger - Highlight Text Tiny long-press event handler Show More/Less 3D banners with ScrollTrigger Image Compare Viewer Add Read or Scroll Progress Bar To A Website To Indicate Read Progress How to Get a Progressive Web App into the Google Play Store Pure CSS halftone portrait from .jpg source by Ana Tudor&nbsp;:&nbsp;https://codepen.io/thebabydino/pen/LYGGwrm Ana, author at CSS Tricks, shows a CSS-only technique to convert an image into a halftone one. ScrollTrigger - Highlight Text by Ryan Mulligan&nbsp;:&nbsp;https://codepen.io/hexagoncircle/details/gOPMwvd We all highlight important text passages for our readers. Ryan does the in an unusual, butt cool way by using GSAP ScrollTrigger. Tiny long-press event handler by MudOnTire&nbsp;:&nbsp;https://github.com/MudOnTire/web-long-press Vanilla JS multi-instance handling of long press event the easy way. Show More/Less by Grzegorz Tomicki&nbsp;:&nbsp;https://github.com/tomik23/show-more Grzegorz’s little JS helper to cut texts, lists and even tables and show a MORE link. 3D banners with ScrollTrigger by supamike&nbsp;:&nbsp;https://codepen.io/supamike/full/KKVqXmR Awesome 3D effect on scrolling made with ScrollTrigger. Image Compare Viewer by Kyle Wetton&nbsp;:&nbsp;https://image-compare-viewer.netlify.app/ Comparison slider in Vanilla JS to compare BEFORE and AFTER images, which works responsively on every device. Add Read or Scroll Progress Bar To A Website To Indicate Read Progress by Jun711&nbsp;:&nbsp;https://jun711.github.io/web/add-scroll-progress-bar-to-a-website-to-indicate-read-progress/ A classic, simply explained… Here another approach: CSS Tricks: Reading Position Indicator How to Get a Progressive Web App into the Google Play Store by Mateusz Rybczonek&nbsp;:&nbsp;https://css-tricks.com/how-to-get-a-progressive-web-app-into-the-google-play-store/ Mateusz describes very detailed how offer your PWA as an App via Google Play Store.","categories":[{"name":"Discoveries","slug":"Discoveries","permalink":"https://kiko.io/categories/Discoveries/"}],"tags":[{"name":"Great Finds","slug":"Great-Finds","permalink":"https://kiko.io/tags/Great-Finds/"}]},{"title":"Dopamine: How Software should be...","subtitle":"A great media player for Windows 10","date":"2020-07-10","updated":"2020-10-03","path":"categories/Tools/Dopamine-How-Software-should-be/","permalink":"https://kiko.io/categories/Tools/Dopamine-How-Software-should-be/","excerpt":"Not very often, when I’m looking for a new tool to replace some annoying or outdated piece of software, I have to blog about it … but from time to time, I’m discovering pearls, worth to lose a word about. The Windows 10 built-in media player Groove is (to be kind) … nice, but it is more or less a leftover from Microsoft’s attempt to create a competitor to iTunes, years ago. The crippeled UI is not the most modern and I was more than once annoyed about its usability. Doing a research for a good alternative, you stumble always over the usual suspects: MediaMonkey, Foobar2000, Winamp, VLC or even Media Player Classic!? Not modern enough, not user friendly enough, not lean enough. I really don’t remember where, but there was a screenshot of a player, which seems to be the complete opposite of the others: Dopamine from Digimezzo, a project by the Belgian developer Raphaël Godart…","keywords":"im tool replace annoying outdated piece software blog … time discovering pearls worth lose word windows built-in media player groove kind nice leftover microsofts attempt create competitor itunes years ago crippeled ui modern annoyed usability research good alternative stumble usual suspects mediamonkey foobar2000 winamp vlc classic user friendly lean dont remember screenshot complete opposite dopamine digimezzo project belgian developer raphaël godart…","text":"Not very often, when I’m looking for a new tool to replace some annoying or outdated piece of software, I have to blog about it … but from time to time, I’m discovering pearls, worth to lose a word about. The Windows 10 built-in media player Groove is (to be kind) … nice, but it is more or less a leftover from Microsoft’s attempt to create a competitor to iTunes, years ago. The crippeled UI is not the most modern and I was more than once annoyed about its usability. Doing a research for a good alternative, you stumble always over the usual suspects: MediaMonkey, Foobar2000, Winamp, VLC or even Media Player Classic!? Not modern enough, not user friendly enough, not lean enough. I really don’t remember where, but there was a screenshot of a player, which seems to be the complete opposite of the others: Dopamine from Digimezzo, a project by the Belgian developer Raphaël Godart… But that wasn’t the best, especially for me. Dopamine is written in C# as a WPF application and it is OpenSource, hosted on GitHub. The software is so wonderful lean and its integrating in Windows 10 like a charm. It has several categories to find the right music to play, a context-sensitive search, a folder view, is able to import and manage playlists, a light and dark mode and translations into currently 28 languages. It can update your collection automatically from several folders, has two player modes and is incredibly fast. The keep long story short … I fell in love on Dopamine‘s simple beauty and it is now my favourite player on Windows 10! Thanks Raphaël…","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Great Finds","slug":"Great-Finds","permalink":"https://kiko.io/tags/Great-Finds/"}]},{"title":"Using GitHub as Commenting Platform","subtitle":"Integrate Utterances' GitHub Issue Commenting to Hexo","series":"A New Blog","part":7,"date":"2020-07-05","updated":"2020-10-03","path":"categories/Tools/Using-GitHub-as-Commenting-Platform/","permalink":"https://kiko.io/categories/Tools/Using-GitHub-as-Commenting-Platform/","excerpt":"If you run a blog, it is always advisable to integrate a commenting system, in order to get feedback on your posts from your readers. So did I, when I start this blog and I decided to use the Disqus platform, as it was very easy to integrate … but I always had a bad feeling about a third-party platform collecting data from my readers. Disqus is probably not without reason under criticism by many people in the community. As I host this blog at GitHub (see A New Blog (Part One): VS Code, Hexo and GitHub Pages) I was looking for a solution to host the comments also on my prefered platform. There were some solutions, which uses GitHub Issues for this and wanted to implement something like that someday.","keywords":"run blog advisable integrate commenting system order feedback posts readers start decided disqus platform easy … bad feeling third-party collecting data reason criticism people community host github part code hexo pages solution comments prefered solutions issues wanted implement someday","text":"If you run a blog, it is always advisable to integrate a commenting system, in order to get feedback on your posts from your readers. So did I, when I start this blog and I decided to use the Disqus platform, as it was very easy to integrate … but I always had a bad feeling about a third-party platform collecting data from my readers. Disqus is probably not without reason under criticism by many people in the community. As I host this blog at GitHub (see A New Blog (Part One): VS Code, Hexo and GitHub Pages) I was looking for a solution to host the comments also on my prefered platform. There were some solutions, which uses GitHub Issues for this and wanted to implement something like that someday. As I read a post from on Thomas Lavesques’ blog, to solve another problem, his commenting section came to my attention: utteranc.es … exactly the solution I needed! Thanx guys… On their website is a small configurator for a script to implement in each post, which needs only few information: Name of the Repo How the mapping of the post to the Issues should work Name of the Theme, in order to fit to the colors of the blog The script had to be included to my Hexo article.js: 123456789&lt;% if (!index &amp;&amp; post.comments)&#123; %&gt; &lt;script src=&quot;https://utteranc.es/client.js&quot; repo=&quot;kristofzerbe/kiko.io&quot; issue-term=&quot;pathname&quot; theme=&quot;github-light&quot; crossorigin=&quot;anonymous&quot; async&gt; &lt;/script&gt;&lt;% &#125; %&gt; That’s pretty much it. On entering the first comment, Utterances told me to install the needed GitHub App to my repo, in order to make it work … and done. The result you see below … UPDATE…The utterances script tag has the attribute theme, to tell utterances which style should be delivered. There are several themes available, but if users are able to switch between light or dark mode on the page (see Hexo and the Dark Mode), the comment block should change to an suitable theme also. On order to respond on a mode change, it is necessary to write a more dynamic script loading. First we define a function in a global script file to load the utterances script via JS: 1234567891011121314151617181920function insertUtterancesCommentBlock() &#123; var commentTheme = \"github-light\"; if(localStorage.getItem(\"theme\") === \"dark\")&#123; commentTheme = \"github-dark\"; &#125; const scriptId = \"comment-theme-script\"; const existingScript = document.getElementById(scriptId); if (!existingScript) &#123; const commentScript = document.createElement(\"script\"); commentScript.id = scriptId; commentScript.src = \"https://utteranc.es/client.js\"; commentScript.setAttribute(\"repo\", \"kristofzerbe/kiko.io\"); commentScript.setAttribute(\"issue-term\", \"pathname\"); commentScript.setAttribute(\"theme\", commentTheme); commentScript.setAttribute(\"crossorigin\", \"anonymous\"); const placeholder = document.getElementById(\"comment-placeholder\"); placeholder.innerHTML = \"\"; placeholder.appendChild(commentScript); &#125;&#125; Then we change the placement in the EJS file, by defining a placeholder and ensuring that the script above is loaded, before we call it: 123456&lt;div id=&quot;comment-placeholder&quot;&gt;&lt;/div&gt;&lt;script&gt; window.addEventListener(&apos;load&apos;, function () &#123; insertUtterancesCommentBlock(); &#125;)&lt;/script&gt; On my blog, everytime the user switches between light/dark mode the body tag will be decorated with the data tag data-theme and the value of the mode. To keep the loading of the utterances script independent from this functionality, we just have to listen to this change via MutationObserver: 12345678910//observe theme change, to adjust comment block themevar target = document.documentElement, observer = new MutationObserver(function(mutations) &#123; mutations.forEach(function(mutation) &#123; if (mutation.attributionName === \"data-theme\" ); insertUtterancesCommentBlock(); &#125;); &#125;), config = &#123; attributes: true &#125;;observer.observe(target, config);","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kiko.io/tags/GitHub/"},{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"}]},{"title":"Meaningful automatic versioning with T4","subtitle":"How to implement versioning in C# projects the better way","date":"2020-06-27","updated":"2020-10-02","path":"categories/C/Meaningful-automatic-versioning-with-T4/","permalink":"https://kiko.io/categories/C/Meaningful-automatic-versioning-with-T4/","excerpt":"Every developer has to have an idea of versioning his products. If you work with Visual Studio you have the Assembly Information in the project properties dialog, to enter it manually everytime you want to release a new version: The four fields are: MAJOR, MINOR, BUILD, REVISION. But seriously … who does that? I guess 99% of all C# developers are entering the AssemblyInfo.cs and enter the famous 2 asterisks into the version declaration of BUILD and REVISION, to let Visual Studio do the incrementation job: 12[assembly: AssemblyVersion(\"1.0.*.*\")][assembly: AssemblyFileVersion(\"1.0.*.*\")] But this is not the end of the possibilities … Let’s do it more meaningful, with some goodies and still automatic…","keywords":"developer idea versioning products work visual studio assembly information project properties dialog enter manually everytime release version fields major minor build revision … guess 99% c# developers entering assemblyinfocs famous asterisks declaration incrementation job 12[assembly assemblyversion10**][assembly assemblyfileversion10**] end possibilities lets meaningful goodies automatic…","text":"Every developer has to have an idea of versioning his products. If you work with Visual Studio you have the Assembly Information in the project properties dialog, to enter it manually everytime you want to release a new version: The four fields are: MAJOR, MINOR, BUILD, REVISION. But seriously … who does that? I guess 99% of all C# developers are entering the AssemblyInfo.cs and enter the famous 2 asterisks into the version declaration of BUILD and REVISION, to let Visual Studio do the incrementation job: 12[assembly: AssemblyVersion(\"1.0.*.*\")][assembly: AssemblyFileVersion(\"1.0.*.*\")] But this is not the end of the possibilities … Let’s do it more meaningful, with some goodies and still automatic… More informative versioningA build with an increased MAJOR version number means, that there are significant changes in the product, even breaking changes. This always should be set manually. Also the MINOR. It stands for significant functional extensions of the product. How does Visual Studio calculate BUILD and REVISION? When specifying a version, you have to at least specify major. If you specify major and minor, you can specify an asterisk for build. This will cause build to be equal to the number of days since January 1, 2000 local time, and for revision to be equal to the number of seconds since midnight local time, divided by 2. But, the BUILD number should explain, how often a software with a particular MAJOR.MINOR has been build, due to minor changes and bug fixes. The “Asterisk” REVISION number is a little weird, but at least with the BUILD number unique. But it says nothing. Better to pick up the idea of a date calculated, unique number, but not an arbitrary date … let’s take the date the project has started. For example: 1.2.16.158 … reads version 1.2 with 16 builds on the 158’th day after the project has started. Start with T4T4 (Text Template Transformation Toolkit) is a templating system in Visual Studio for generating text files during design time. It is very suitable to even generate code. Read about it here and here. A Text Template (.tt) has Directives (how the template is processed), Text blocks (text copied to the output) and Control blocks (program code). For our versioning template, we start with this in a new file named AssemblyVersion.tt: Directives: 12&lt;#@ template hostspecific=\"true\" language=\"C#\" #&gt;&lt;#@ output extension=\".cs\" #&gt; Control block: 123456&lt;# int major = 1; int minor = 0; int build = 0; int revision = 0;#&gt; Text block: 1234567// This code was generated by a tool. Any changes made manually will be lost// the next time this code is regenerated.using System.Reflection;[assembly: AssemblyVersion(\"&lt;#= $\"&#123;major&#125;.&#123;minor&#125;.&#123;build&#125;.&#123;revision&#125;\" #&gt;\")][assembly: AssemblyFileVersion(\"&lt;#= $\"&#123;major&#125;.&#123;minor&#125;.&#123;build&#125;.&#123;revision&#125;\" #&gt;\")] On saving the TT file, a new CS file with the same name will be created automatically and you got an error like this: A new place for version infoTh error occurs, because we have now two AssemblyVersion and AssemblyFileVersion attributes in our project. We need to comment out the original in Properties\\AssemblyInfo.cs: Structural ConsiderationsIt makes sense to store all needed files for the new versioning system in a new root folder of the project, named AssemblyVersion, starting with the AssemblyVersion.tt, because there will be more files later on. New app information fileAs we replaced the original version attributes in the project with those from our generated AssemblyVersion.cs, we cannot control the MAJOR and MINOR version number via the project property dialog any longer. We need a new approach on that, which can be edited easily and processed automatically. AssemblyVersion.json1234567891011121314151617&#123; \"initialDate\": \"2019-09-29\", \"versions\": [ &#123; \"major\": 1, \"minor\": 1, \"releaseDate\": \"\", \"remarks\": \"Some cool new features; New versioning system\" &#125;, &#123; \"major\": 1, \"minor\": 0, \"releaseDate\": \"2019-10-01\", \"remarks\": \"Initial Release\" &#125; ]&#125; This new JSON file has two main items: initialDate - the date the project has started, to calculate the REVISION later on versions - a list with all different MAJOR/MINOR versions we have done so far, with at least one without a release date … the one with the highest major and minor. The remarks attribute of a list item holds some information about the changes in a new version. Together with releaseDate, useful for a possible release history, shown in the product itself. Library references in T4T4 runs in its own app domain, therefore it can use built-in libraries as System.IO, but not third-party libraries like Newtonsoft.JSON. We could reference those libraries from the projects package folder via the absolute path (if we use it in our product), but when we are running a NuGet update, the reference will break. It is advisable to store such libraries directly in a fixed folder, like AssemblyVersion\\Libraries. They won’t have any impact to our product, because the are only used while design time. The MAJOR and MINORTo process the new AssemblyVersion.json in the template, we need some new directives for referencing the needed libraries and the import of the appropriate namepaces: 123456&lt;#@ assembly name=\"System.Core\" #&gt;&lt;#@ assembly name=\"$(SolutionDir)\\AssemblyVersion\\Libraries\\Newtonsoft.Json.dll\" #&gt;&lt;#@ import namespace=\"System.IO\" #&gt;&lt;#@ import namespace=\"System.Linq\" #&gt;&lt;#@ import namespace=\"Newtonsoft.Json\" #&gt; Via the use of the T4 variable $(SolutionDir), we can point to our copy of Newtonsoft JSON. Now we can read and convert the JSON into an anonymous object and get the highest values of MAJOR and MINOR: 12345678910111213141516171819202122232425262728&lt;# string avPath = this.Host.ResolvePath(\"AssemblyVersion.json\"); string avJson = File.ReadAllText(avPath); var avDefinition = new &#123; initialDate = \"\", versions = new [] &#123; new &#123; major = 0, minor = 0, releaseDate = \"\", remarks = \"\" &#125; &#125; &#125;; var avObject = JsonConvert.DeserializeAnonymousType(avJson, avDefinition); //Get highest Major/Minor from versions list var maxVersion = avObject.versions .OrderByDescending(i =&gt; i.major) .ThenByDescending(j =&gt; j.minor) .First(); //Set MAJOR int major = maxVersion.major; //Set MINOR int minor = maxVersion.minor;#&gt; The BuildLogIn order to get the version number for BUILD, we need a method to count and store every build that has been run, separated by the MAJOR/MINOR versions. This is a job for a Post-build event, which can be configured in the project properties dialog. The event uses shell commands as they are used on the command line. What the commands should do:&nbsp;&nbsp;&nbsp;Write a new line with the current date and time in a log file, named after the MAJOR/MINOR version and stored in the folder AssemblyVersion\\BuildLogs. Extending build event macrosShell commands for build events are supporting built-in variables, so called ‘macros’, like $(ProjectDir) (which returns the project directory path), but there is no such macro for the current version number. We have to introduce it via extending the project with a new build target. Unload the project in Visual Studio for editing the CSPROJ (or VBPROJ) file of your product manually and write the following definition just before the end-tag: 123456789101112131415&lt;PropertyGroup&gt; &lt;PostBuildEventDependsOn&gt; $(PostBuildEventDependsOn); PostBuildMacros; &lt;/PostBuildEventDependsOn&gt;&lt;/PropertyGroup&gt;&lt;Target Name=\"PostBuildMacros\"&gt; &lt;GetAssemblyIdentity AssemblyFiles=\"$(TargetPath)\"&gt; &lt;Output TaskParameter=\"Assemblies\" ItemName=\"Targets\" /&gt; &lt;/GetAssemblyIdentity&gt; &lt;ItemGroup&gt; &lt;VersionNumber Include=\"@(Targets-&gt;'%(Version)')\" /&gt; &lt;/ItemGroup&gt;&lt;/Target&gt; After reloading the project in Visual Studio, we can use @(VersionNumber) in our commands. CreateBuildLog.batThe event build editor is not very comfortable, so we create the batch file CreateBuildLog.bat in our AssemblyVersion folder and use this as the post build event command. The BuildLog folder must exist, before running the following command the first time! 123456789101112131415161718192021222324252627@echo offREM --Get parametersset PROJECT_DIR=%1set VERSION_NUMBER=%2REM --Set what to logset LOG_LINE=%DATE% %TIME%REM --Inform the userset MSG=CreateBuildLog '%LOG_LINE%' for version %VERSION_NUMBER%echo %MSG%REM --Get version partsFOR /f \"tokens=1,2,3,4 delims=.\" %%a IN (\"%VERSION_NUMBER%\") do ( set MAJOR=%%a set MINOR=%%b set BUILD=%%c set REVISION=%%d)REM --Define BuildLog file and folder set BUILDLOG_FILE=%MAJOR%.%MINOR%.logset BUILDLOG_FOLDER=%PROJECT_DIR%\\AssemblyVersion\\BuildLogsREM --Write current date and time as new line in the fileecho %LOG_LINE% &gt;&gt; %BUILDLOG_FOLDER%\\%BUILDLOG_FILE%\" 1\"$(ProjectDir)\\AssemblyVersion\\CreateBuildLog.bat\" \"$(ProjectDir)\" @(VersionNumber) The BUILDAs we have now the BuildLogs, we can use them in the template: 123456789101112131415161718192021&lt;# ... //Get BuildLog of max version string buildlogFolder = this.Host.ResolvePath(\"BuildLogs\"); string buildLog = buildlogFolder + \"\\\\\" + maxVersion.major + \".\" + maxVersion.minor + \".log\"; //Get number of lines from BuildLog or create a new log (!) var buildCount = 1; if (File.Exists(buildLog)) &#123; buildCount = File.ReadLines(buildLog).Count() + 1; &#125; else &#123; File.Create(buildLog).Dispose(); &#125; //Set BUILD int build = buildCount;#&gt; Very important is to create the log file, if it doesn’t exists! Otherwise the build will always fail, because the version attributes can’t be created. The REVISIONAt least we have to set the REVISION number, by calculating the difference between the current date and the initialDate, which we have previously read from the AssemblyVersion.json: 1234567&lt;# ... //Set REVISION var dateCreated = DateTime.Parse(avObject.initialDate); int revision = (DateTime.Now.Date - dateCreated.Date).Days;#&gt; Transforming T4 template on buildThe last hurdle is to run the text transformation every time you build your product. Until now it runs only on saving the AssemblyVersion.tt. A great helper on that was Thomas Levesque’s post “Transform T4 templates as part of the build, and pass variables from the project”, where he describes every difficulty to reach this goal. To make it short: We have to edit the CSPROJ file again, to introduce TextTemplating to MSBuild. First we need following near the beginning of the projects XML: 1234567891011&lt;PropertyGroup&gt; &lt;VisualStudioVersion Condition=\"'$(VisualStudioVersion)' == ''\"&gt; 16.0 &lt;/VisualStudioVersion&gt; &lt;VSToolsPath Condition=\"'$(VSToolsPath)' == ''\"&gt; $(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion) &lt;/VSToolsPath&gt; &lt;TransformOnBuild&gt;true&lt;/TransformOnBuild&gt; &lt;OverwriteReadOnlyOutputFiles&gt;true&lt;/OverwriteReadOnlyOutputFiles&gt; &lt;TransformOutOfDateOnly&gt;false&lt;/TransformOutOfDateOnly&gt;&lt;/PropertyGroup&gt; Secondly add the IMPORT of the TextTemplating target AFTER the CSharp target: 123&lt;Import Project=\"$(MSBuildToolsPath)\\Microsoft.CSharp.targets\" /&gt;...&lt;Import Project=\"$(VSToolsPath)\\TextTemplating\\Microsoft.TextTemplating.targets\" /&gt; If you build your product now, a new build log is created and the version numbers BUILD and REVISION are automatically increased. See it in actionThe project where I implemented this versioning first is HexoCommander. Feel free to download the code and see how the new versioning mechanism works. Enjoy versioning…","categories":[{"name":"C#","slug":"C","permalink":"https://kiko.io/categories/C/"}],"tags":[{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://kiko.io/tags/Visual-Studio/"},{"name":"Versioning","slug":"Versioning","permalink":"https://kiko.io/tags/Versioning/"},{"name":"T4","slug":"T4","permalink":"https://kiko.io/tags/T4/"}]},{"title":"Automatic Header Images in Hexo","subtitle":"Use static images randomly for posts via Hexo script","series":"A New Blog","part":6,"date":"2020-06-22","updated":"2020-10-03","path":"categories/Tools/Automatic-Header-Images-in-Hexo/","permalink":"https://kiko.io/categories/Tools/Automatic-Header-Images-in-Hexo/","excerpt":"Every article in this blog has an individual header image, to bring a little bit color into it. In this post I will show you how I deal with the images in using and automatic provisioning. For serving these pictures I use a static folder, as described in A New Blog: Customizing Hexo. The hard work is done by the plugin Hexo Generator Copy, which copies the static files into the public_dir while generating.","keywords":"article blog individual header image bring bit color post show deal images automatic provisioning serving pictures static folder customizing hexo hard work plugin generator copy copies files public_dir generating","text":"Every article in this blog has an individual header image, to bring a little bit color into it. In this post I will show you how I deal with the images in using and automatic provisioning. For serving these pictures I use a static folder, as described in A New Blog: Customizing Hexo. The hard work is done by the plugin Hexo Generator Copy, which copies the static files into the public_dir while generating. Static File StructureIt is always advisable to provide one image for every device class, in order to save bandwidth and make the page loading as fast as possible: 1234567891011| static/ | photos/ | mobile/ | my-lovely-picture.jpg | ... | tablet/ | my-lovely-picture.jpg | ... | normal/ | my-lovely-picture.jpg | ... The mobile images are at least 480 pixels wide, the tablet variants 768 pixels and the standard or normal one 1280 pixels. While creating the JPG files, it is important to compress them with a tool like JPEGMini to save data while loading. BindingIn order to bind a picture with some additional information to an article, I have extended the Frontmatter of every post: 1234photograph: file: 'my-lovely-image.jpg' name: 'My Lovely Image' link: 'https://500px.com/photo/123456789/My-Lovely-Image' Usage in ThemeIt relies on your Hexo theme, how to use a header image. In my theme (derived from the standard theme) I just added following code in the article.js to show the individual header image as a background image at the top of the article: 123456789101112131415161718192021222324252627&lt;% if (!index &amp;&amp; post.photograph)&#123; %&gt;&lt;style&gt; #banner &#123; background-size: cover; &#125; @media screen and (max-width: 479px) &#123; #banner &#123; background-image: linear-gradient(to bottom, rgba(0,0,0,0.75) 0%, rgba(0,0,0,0) 75%), url(\"/photos/mobile/&lt;%= post.photograph.file %&gt;\"); &#125; &#125; @media screen and (min-width: 480px) and (max-width: 767px) &#123; #banner &#123; background-image: linear-gradient(to bottom, rgba(0,0,0,0.75) 0%, rgba(0,0,0,0) 75%), url(\"/photos/tablet/&lt;%= post.photograph.file %&gt;\"); &#125; &#125; @media screen and (min-width: 768px) &#123; #banner &#123; background-image: linear-gradient(to bottom, rgba(0,0,0,0.75) 0%, rgba(0,0,0,0) 75%), url(\"/photos/normal/&lt;%= post.photograph.file %&gt;\"); &#125; &#125;&lt;/style&gt;&lt;script&gt; var photoLink = document.getElementById(\"header-photo-link\"); photoLink.href = \"&lt;%= post.photograph.link%&gt;\"; photoLink.innerHTML = \"see &lt;strong&gt;&lt;%= post.photograph.name%&gt;&lt;/strong&gt; at 500px\";&lt;/script&gt;&lt;% &#125; %&gt; Important part here is the use of the Frontmatter data post.photograph.file in the URL of the background CSS. The script fills the additional information into the absolute positioned element header-photo-link which is placed on top of the header. Pooling ImagesAs it is time consuming to generate the necessary images, I have created another static folder pool to store prepared files and a text file with the additional information about the image. The structure of pool is different to photos, because of my image workflow and some limitations of automating the provisioning. 12345678| static/ | pool/ | my-lovely-picture/ | meta.txt | mobile.jpg | normal.jpg | tablet.jpg | ... The meta.txt is a simple text file with two lines of text: first the name of the image and second the Url to link to, which will be inserted in the appropriate Frontmatter fields on creating a new post: 12My Lovely Imagehttps://500px.com/photo/123456789/My-Lovely-Image Automate binding and provisioning on new postDevelopers are lazy and I do not make an exception. Having all these pool images and the meta informations, it would be nice, if Hexo just picks and processes one of the pool folders automatically, when I’m creating a new post by calling hexo new &quot;My shiny new post&quot; … and it was easier then I thought. Where to place the code for the automatismHexo has a great API to write plugins and it is not very difficult to setup a new plugin for this, which can be published to the NPM registry. But it is also possible to extend Hexo’s functionality by using a simple script. All you need is a script folder in the root of your Hexo project. Any JS files which is placed there, will be executed by Hexo. Therefore, lets use a script called \\scripts\\process-photo-on-new.js … Things an automatism should do - Step by Step Hook into the creation of a post Pick randomly one of the pool images Place the content of the meta.txt in the Frontmatter Move the 3 device-dependend images into the photos folder Step 1 - Hook into the creation of a postThe needed event, the automatism can hook on, is: 123hexo.on('new', function(data)&#123; //&#125;); It will be executed every time you call the hexo new command. The parameter data is an object with two fields: pathFull path to the MD file of the new post contentComplete content of the scaffold (template), which Hexo has used to create the new post; default is /scaffolds/post.md. By preloading the Hexo Front matter library and parsing data.content we get access to the definition of the new post: 1234567const front = require('hexo-front-matter');hexo.on('new', function(post)&#123; // parse article content var post = front.parse(data.content);&#125;); Step 2 - Pick randomly one of the pool imagesThere are some build-in variables to get the full path, for example, of the source folder, we can use to define the needed paths to the pool and the photo folder. 123456789const front = require('hexo-front-matter');hexo.on('new', function(post)&#123; var post = front.parse(data.content); // set the path variables var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\"; var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\";&#125;); Next, we need to preload the Hexo FS library for file access, to list the content of the poolDir, including the subfolders, and filter out the meta files. Out of the resulting array we pick one randomly, to use for the new post: 123456789101112131415161718192021const front = require('hexo-front-matter');const fs = require('hexo-fs');hexo.on('new', function(post)&#123; var post = front.parse(data.content); var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\"; var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\"; // list all files var files = fs.listDirSync(poolDir); // filter the list to get meta files of each subfolder var metaFiles = files.filter(file =&gt; file.match(/.*[\\\\]meta.txt/g)); // pick one randomly var metaFile = metaFiles[Math.floor(Math.random() * metaFiles.length)]; // get the name of the picked photo (foldername) var photoName = metaFile.split(\"\\\\\")[0];&#125;); Step 3 - Place the content of the meta.txt in the FrontmatterNow we have to read the meta file, place the data in the Frontmatter and save the article file: 123456789101112131415161718192021222324252627282930const front = require('hexo-front-matter');const fs = require('hexo-fs');hexo.on('new', function(post)&#123; var post = front.parse(data.content); var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\"; var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\"; var files = fs.listDirSync(poolDir); var metaFiles = files.filter(file =&gt; file.match(/.*[\\\\]meta.txt/g)); var metaFile = metaFiles[Math.floor(Math.random() * metaFiles.length)]; var photoName = metaFile.split(\"\\\\\")[0]; // read meta file var meta = fs.readFileSync(poolDir + \"\\\\\" + metaFile); var metas = meta.split(\"\\n\"); // place file and additional info in the Frontmatter post.photograph.file = photoName + \".jpg\"; post.photograph.name = metas[0]; post.photograph.link = metas[1]; // convert content back postStr = front.stringify(post); postStr = '---\\n' + postStr; // store article fs.writeFile(data.path, postStr, 'utf-8');&#125;); Step 4 - Move the 3 device-dependend images into the photos folderLast but not least, we have to move the pool images into the photos folder and remove the pool folder with all its processed content: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051const front = require('hexo-front-matter');const fs = require('hexo-fs');hexo.on('new', function(post)&#123; var post = front.parse(data.content); var poolDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"pool\"; var photosDir = hexo.source_dir.replace(\"\\source\", hexo.config.static_dir) + \"photos\"; var files = fs.listDirSync(poolDir); var metaFiles = files.filter(file =&gt; file.match(/.*[\\\\]meta.txt/g)); var metaFile = metaFiles[Math.floor(Math.random() * metaFiles.length)]; var photoName = metaFile.split(\"\\\\\")[0]; var meta = fs.readFileSync(poolDir + \"\\\\\" + metaFile); var metas = meta.split(\"\\n\"); post.photograph.file = photoName + \".jpg\"; post.photograph.name = metas[0]; post.photograph.link = metas[1]; postStr = front.stringify(post); postStr = '---\\n' + postStr; fs.writeFile(data.path, postStr, 'utf-8'); //copy normal image fs.copyFile( poolDir + \"\\\\\" + photoName + \"\\\\normal.jpg\", photosDir + \"\\\\normal\\\\\" + photoName + \".jpg\", function() &#123; //copy tablet image fs.copyFile( poolDir + \"\\\\\" + photoName + \"\\\\tablet.jpg\", photosDir + \"\\\\tablet\\\\\" + photoName + \".jpg\", function() &#123; //copy mobile image fs.copyFile( poolDir + \"\\\\\" + photoName + \"\\\\mobile.jpg\", photosDir + \"\\\\mobile\\\\\" + photoName + \".jpg\", function() &#123; //remove processed pool folder fs.rmdirSync(poolDir + \"\\\\\" + photoName); &#125;); &#125;); &#125;);&#125;); Now it so easy to write a new post, because almost everything is set and I can concentrate on the article. Also, it is a nice surprise to see, which photo the script has chosen. The only thing I have to do from time to time, is to refill the pool folder with new images.","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"}]},{"title":"Localization with resource files in JavaScript web apps","subtitle":"How to work with Visual Studio resource files for localization in Single Page Applications","date":"2020-06-13","updated":"2020-10-03","path":"categories/JavaScript/Localization-with-resource-files-in-JavaScript-web-apps/","permalink":"https://kiko.io/categories/JavaScript/Localization-with-resource-files-in-JavaScript-web-apps/","excerpt":"There are plenty of editors out there to help you writing JavaScript web applications. As I’m working in my daily life with Visual Studio, it is a obvious choice for me. One of the most time saving tools in VS is the plugin ResXManager, which is an awesome assistant on managing the translations for a Desktop- or ASP.NET-App, which uses XML-based RESX files.","keywords":"plenty editors writing javascript web applications im working daily life visual studio obvious choice time saving tools plugin resxmanager awesome assistant managing translations desktop- aspnet-app xml-based resx files","text":"There are plenty of editors out there to help you writing JavaScript web applications. As I’m working in my daily life with Visual Studio, it is a obvious choice for me. One of the most time saving tools in VS is the plugin ResXManager, which is an awesome assistant on managing the translations for a Desktop- or ASP.NET-App, which uses XML-based RESX files. Mostly very localization is based on key/value pairs, defined in separate files for every language provided. Implementing several languages in pure JavaScript apps is a little more difficult, because it makes no sense to deal with big XML files in JS. All localization libraries in the market uses JSON for storing the translations and it is a little bit of work to find the right one for your requirements. Localization in JavaScriptFor a current project I use jquery-lang, because it provides the switch of the apps UI language without reloading and it is easy to implement. Thanks Rob Evans for your work… The definition of “tokens” in one JSON file for each language is quite easy: ../languages/en.json12345&#123; \"token\": &#123; \"my-test\": \"My Test in English\" &#125;&#125; ../languages/de.json12345&#123; \"token\": &#123; \"my-test\": \"Mein Test in Deutsch\" &#125;&#125; The usage also: 1&lt;div lang=\"en\" data-lang-token=\"my-test\"&gt; Using RESX and convert to JSON on buildHaving this, the most time consuming work is to enter the translations to the localization files. If you have hundreds of them, it is hard to keep the 2, 3 or more language files in sync. You need a helper… And here comes ResXManager to the rescue, if you work with VS … but it needs a conversation from RESX to the JSON format jquery-lang uses and this a task, which can be done on building the JS app, by using a task runner like Grunt. As there was no Grunt plugin/task out there to fit my needs, I have created grunt-resource2json (GitHub, NPM). The configuration in the gruntfile.js is like: gruntfile.js12345678910111213141516171819202122grunt.initConfig(&#123; resource2json: &#123; convert: &#123; options: &#123; format: \"jquery-lang\" &#125;, files: [ &#123; input: \"resources/Resource.resx\", output: \"build/langpacks/en.json\" &#125;, &#123; input: \"resources/Resource.de-DE.resx\", output: \"build/langpacks/de.json\" &#125;, &#123; input: \"resources/Resource.es-ES.resx\", output: \"build/langpacks/es.json\" &#125; ] &#125; &#125;); It takes one RESX file (input) and converts it to a JSON file (output) in an array of files. The heavy work in the plugin is done by the library xml2js, which transforms the complete XML of the RESX file into a JSON object in one call. All I had to do, was to write all DATA nodes in a loop into the jquery-lang given structure and save it as JSON. Currently supported is the format for jquery-lang only, but it would be awesome, if you fork the code on GitHub and send me a Pull Request with the implementation of your needed format.","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kiko.io/tags/GitHub/"},{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://kiko.io/tags/Visual-Studio/"},{"name":"Resource","slug":"Resource","permalink":"https://kiko.io/tags/Resource/"},{"name":"Localization","slug":"Localization","permalink":"https://kiko.io/tags/Localization/"}]},{"title":"TFS/DevOps: Delete Remote Workspace","subtitle":null,"date":"2020-02-28","updated":"2020-10-02","path":"categories/Tools/TFS-DevOps-Delete-Remote-Workspace/","permalink":"https://kiko.io/categories/Tools/TFS-DevOps-Delete-Remote-Workspace/","excerpt":"If you are working with freelance developers and Azure DevOps/TFS with TFVC (Team Foundation Version Control) in your company, maybe this will look familiar to you: You hire a new freelancer and you want to reuse the hardware, including the complete software setup, to bring him/her to work as fast and straightforward as possible. You set up a new Azure Devops account with all necessary permissions and you think you’re done. No you are not…","keywords":"working freelance developers azure devops/tfs tfvc team foundation version control company familiar hire freelancer reuse hardware including complete software setup bring him/her work fast straightforward set devops account permissions youre not…","text":"If you are working with freelance developers and Azure DevOps/TFS with TFVC (Team Foundation Version Control) in your company, maybe this will look familiar to you: You hire a new freelancer and you want to reuse the hardware, including the complete software setup, to bring him/her to work as fast and straightforward as possible. You set up a new Azure Devops account with all necessary permissions and you think you’re done. No you are not… Everytime a user connects to a Team Project on Azure DevOps via Visual Studio and gets the code, VS is creating a remote workspace on the server, with the machine name as default, therefor it is not enough to wipe the profile and any other legacies of the last user from the machine. You also have to remove the remote workspace. Otherwise you will get an error message like that, if you are using a unique file structure on the developers hard disc: 1The working folder c://xxx is already in use by the workspace yyy;zzz on computer yyy The variable xxx stands for the blocked folder, yyy for the workspace/machine name and zzz for the users id on Azure DevOps. Unfortunately, there is no visual management console on Azure DevOps to manage your server workspaces, but there is a command line tool called tf.exe. The easiest way to get rid of the unused server workspace in 3 steps: Step 1Run Developer Command Prompt with Administrator privileges from Visual Studio 2019 and login with your Azure DevOps credentials. If the Login dialog doesn’t show up, force it by executing: 1tf.exe workspace Step 2Get a list of all remote workspaces available in your DevOps Collection by running the command: 1tf.exe workspaces /computer:* /owner:* /format:xml &gt; c:\\temp\\workspaces.xml You can get a list of all your workspaces by running tf workspaces, but the list only shows you the owner, but not the necessary ownerid and … it is nicer to have a file to search in. Step 3Find the abandoned workspace in the list and note its name and ownerid for running the command: 1tf workspace /delete &#123;WORKSPACE.name&#125;;&#123;WORKSPACE.ownerid&#125; Now your new colleague can create his own workspace on the same machine. UpdateIn case you want to switch your own DevOps account to another and use the same folder as before, you can certainly delete the local workspace, but this wont help, because you are still logged in at TeamExplorer and the folder knows to whom it belongs. Solution is easy: Quit Visual Studio Rename folder in ***_OLD or something Create new folder with the same name Enter C:\\Users\\YOUR-NAME\\appdata\\Local\\Microsoft\\Team Foundation\\VS-VERSION\\Cache and emtpy the folder to let Visual Studio forget who you are Remove all your Remote Workspaces as described above Start Visual Studio, connect in TeamExplorer to your TFS server and map the code to your folder Related Use Team Foundation version control commands How to remove TFS workspace mapping for another user","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://kiko.io/tags/Visual-Studio/"},{"name":"TFS/DevOps","slug":"TFS-DevOps","permalink":"https://kiko.io/tags/TFS-DevOps/"}]},{"title":"Better Input Change Event","subtitle":null,"date":"2019-11-26","updated":"2020-10-03","path":"categories/JavaScript/Better-Input-Change-Event/","permalink":"https://kiko.io/categories/JavaScript/Better-Input-Change-Event/","excerpt":"Often it is important to trigger an event, after the user of your website/web app has filled out an text input. You have to do something with the given value in JavaScript. The intended event for this is change, which will be triggered, when the user has ended changing by leaving the input with his cursor, mostly by using the TAB key. This works at some degree, if there is a physical keyboard, but not really on mobile devices … and for me is leaving the field often too late to start the upcoming event.","keywords":"important trigger event user website/web app filled text input javascript intended change triggered ended changing leaving cursor tab key works degree physical keyboard mobile devices … field late start upcoming","text":"Often it is important to trigger an event, after the user of your website/web app has filled out an text input. You have to do something with the given value in JavaScript. The intended event for this is change, which will be triggered, when the user has ended changing by leaving the input with his cursor, mostly by using the TAB key. This works at some degree, if there is a physical keyboard, but not really on mobile devices … and for me is leaving the field often too late to start the upcoming event. A better way to show the user the result of his entered value, could be the event input which fires on every key stroke, but could be way to often, if the triggered event is for example an AJAX call. Best solution is, to observe the users key strokes and trigger the event, when he stops typing. Then there is no extra action needed by the user and the event isn’t triggered multiple times. Here’s an implementation with jQuery: 12345678910$(\"#my-text-input\").keyup(function () &#123; var $this = $(this); clearTimeout($.data(this, 'timer')); var wait = setTimeout(function () &#123; //do something with the value... &#125;, 1000); $(this).data('timer', wait);&#125;); Important is to wipe and set the timer on every key up, to achive that the event will be executed after 1 second after the last key stroke only.","categories":[{"name":"JavaScript#","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"}],"tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://kiko.io/tags/jQuery/"}]},{"title":"Hexo and the Dark Mode ... revised","subtitle":"Second approach to implement 'prefers-color-scheme'","series":"A New Blog","part":5,"date":"2019-10-26","updated":"2020-10-03","path":"categories/Tools/Hexo-and-the-Dark-Mode-revised/","permalink":"https://kiko.io/categories/Tools/Hexo-and-the-Dark-Mode-revised/","excerpt":"While writing my post Hexo and the Dark Mode a few days ago, I thought it would be nice, if I could switch between the normal (light) and the dark theme, I’ve created for the support of the OS-related Dark Mode, even manually. The only thing I needed was a toggle element and a little bit of JavaScript. Of course, I couldn’t manipulate the media query prefers-color-scheme itself, but introduce a different way by blog uses it. Instead of implementing the media query directly into my CSS (or Stylus) code, I used a root selector, which can be manipulated by JavaScript … something like this: 12345678910body &#123; background-color: white; color: black;&#125;[data-theme=\"dark\"] body &#123; background-color: black; color: white; &#125;&#125;","keywords":"writing post hexo dark mode days ago thought nice switch normal light theme ive created support os-related manually thing needed toggle element bit javascript couldnt manipulate media query prefers-color-scheme introduce blog implementing directly css stylus code root selector manipulated … 12345678910body &#123 background-color white color black&#125[data-theme=dark] body black &#125&#125","text":"While writing my post Hexo and the Dark Mode a few days ago, I thought it would be nice, if I could switch between the normal (light) and the dark theme, I’ve created for the support of the OS-related Dark Mode, even manually. The only thing I needed was a toggle element and a little bit of JavaScript. Of course, I couldn’t manipulate the media query prefers-color-scheme itself, but introduce a different way by blog uses it. Instead of implementing the media query directly into my CSS (or Stylus) code, I used a root selector, which can be manipulated by JavaScript … something like this: 12345678910body &#123; background-color: white; color: black;&#125;[data-theme=\"dark\"] body &#123; background-color: black; color: white; &#125;&#125; In every Stylus file, where I used @media prefers-dark to achieve the automatic switch by the OS, I changed this line into /[data-theme=&quot;dark&quot;] &amp; : 12345678#mobile-nav-header background-color: color-background /[data-theme=\"dark\"] &amp; background-color: dark-color-background img.avatar ... /[data-theme=\"dark\"] &amp; filter: brightness(85%) Some explanations on the Stylus syntax: / means the root of the DOM and &amp; points to the parent selector. Therefore the example will be rendered into this: 12345678910111213#mobile-nav-header &#123; background-color: #f1f1f1;&#125;[data-theme=\"dark\"] #mobile-nav-header &#123; background-color: #111;&#125;#mobile-nav-header img.avatar &#123;...&#125;[data-theme=\"dark\"] #mobile-nav-header img.avatar filter: brightness(85%);&#125; Only problem was: the “Root + Parent” Stylus selector doesn’t work in the block variables in the _extend.styl. So I had to copy all theme relevant styles directly to the elements, where such a block was used: @extend &lt;block-name&gt;. The Toggle SwitchIn the footer.ejs I added a toggle checkbox, where I could bind my JavaScript… 1234&lt;div id=\"footer-theme\"&gt; &lt;input type=\"checkbox\" id=\"theme-switch\"&gt; &lt;label for=\"theme-switch\"&gt;&lt;/label&gt;&lt;/div&gt; … and some CSS in the footer.styl, to style it: 12345678910111213141516171819202122input#theme-switch[type=checkbox] &#123; display:none;&#125;input#theme-switch[type=checkbox] + label height: 16px width: 16px display: inline-block padding: 12px font-size: 22px cursor: pointer &amp;:before display: inline-block font-size: inherit text-rendering: auto -webkit-font-smoothing: antialiased font-family: fa-icon-solid content: icon-mooninput#theme-switch[type=checkbox]:checked + label &amp;:before content: icon-sun The icon variables are defined in the _variables.styl like this: 12icon-moon = \"\\f186\"icon-sun = \"\\f185\" The JavaScriptEverything was now prepared to implement the switching code in JavaScript, which should support a manual switch by clicking the toggle element as well as the automatic switch by the OS. I wrapped all necessary code into a seperate JS file and placed a reference in the after-footer.ejs, which places it at the bottom of the HTML: 1&lt;%- js(&apos;js/dark-mode-toggle.js&apos;) %&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758function detectColorScheme() &#123; var theme = \"light\"; //default // get last used theme from local cache if(localStorage.getItem(\"theme\"))&#123; if(localStorage.getItem(\"theme\") === \"dark\")&#123; theme = \"dark\"; &#125; &#125; else if(!window.matchMedia) &#123; // matchMedia not supported return false; &#125; else if(window.matchMedia(\"(prefers-color-scheme: dark)\").matches) &#123; // OS has set Dark Mode theme = \"dark\"; &#125; // set detected theme if (theme === \"dark\") &#123; setThemeDark(); &#125; else &#123; setThemeLight(); &#125;&#125;const toggleTheme = document.querySelector('input#theme-switch[type=\"checkbox\"]');function setThemeDark() &#123; localStorage.setItem('theme', 'dark'); document.documentElement.setAttribute('data-theme', 'dark'); toggleTheme.checked = true;&#125;function setThemeLight() &#123; localStorage.setItem('theme', 'light'); document.documentElement.setAttribute('data-theme', 'light'); toggleTheme.checked = false;&#125;// Listener for theme change by toggletoggleTheme.addEventListener('change', function(e) &#123; if (e.target.checked) &#123; setThemeDark(); &#125; else &#123; setThemeLight(); &#125;&#125;, false);// Listener for theme change by OSvar toggleOS = window.matchMedia('(prefers-color-scheme: dark)');toggleOS.addEventListener('change', function (e) &#123; if (e.matches) &#123; setThemeDark(); &#125; else &#123; setThemeLight(); &#125;&#125;);// call theme detectiondetectColorScheme(); By using the both addEventListener‘s, each switch will be recognized and this approach is capable to support even more themes, just by using different values in the data-theme attribute.","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"},{"name":"Stylus","slug":"Stylus","permalink":"https://kiko.io/tags/Stylus/"},{"name":"Dark Mode","slug":"Dark-Mode","permalink":"https://kiko.io/tags/Dark-Mode/"}]},{"title":"Hexo and the Dark Mode","subtitle":"First approach to implement 'prefers-color-scheme'","series":"A New Blog","part":4,"date":"2019-10-23","updated":"2020-10-03","path":"categories/Tools/Hexo-and-the-Dark-Mode/","permalink":"https://kiko.io/categories/Tools/Hexo-and-the-Dark-Mode/","excerpt":"Due to the fact, that nowadays everybody is talking about Dark Modes for Browsers and Operating Systems, in order to save battery or for easier reading (uhh, really?), I decided my blog should support that.","keywords":"due fact nowadays talking dark modes browsers operating systems order save battery easier reading uhh decided blog support","text":"Due to the fact, that nowadays everybody is talking about Dark Modes for Browsers and Operating Systems, in order to save battery or for easier reading (uhh, really?), I decided my blog should support that. Starting point is the new media query prefers-color-scheme, which is actually supported by all modern browsers. TechniqueMy first read was Tom Brow’s Dark mode in a website with CSS, where he shows how to use the media query. Simplified, this is it, assuming the light version is the default: 1234567891011body &#123; background-color: white; color: black;&#125;@media (prefers-color-scheme: dark) &#123; body &#123; background-color: black; color: white; &#125;&#125; Pimping CSS for automatic switchingTo support the automatic browser/OS-based automatic switch in Hexo, where Stylus is used, I had to change some template files. First the _variables.styl: 1234567891011121314// existing color variablescolor-background = #f1f1f1color-foreground = #111color-border = #ddd...// new dark color variablesdark-color-background = #111dark-color-foreground = #eeedark-color-border = #000...// new media query variableprefers-dark = \"(prefers-color-scheme: dark)\" Next step was to change the _extend.styl, where some Stylus variables are defining complete blocks to extend. Here I had to supplement all lines, where something mode-dependend was defined, by adding the new prefers-dark media query and beneath the new ‘dark’ equivalence of the style: 12345678910111213141516171819$base-style hr ... border: 1px dashed color-border-article @media prefers-dark border: 1px dashed dark-color-border-article ...$block ... background: color-block box-shadow: 1px 2px 3px color-border border: 1px solid color-border @media prefers-dark background: dark-color-block box-shadow: 1px 2px 3px dark-color-border border-color: dark-color-border... The same changes I had to do in every template styl file, where one of the colors or other mode dependent style was used. For example: 12345678#mobile-nav-header background-color: color-background @media prefers-dark background-color: dark-color-background img.avatar ... @media prefers-dark filter: brightness(85%) This will be rendered as: 123456789101112131415#mobile-nav-header &#123; background-color: #f1f1f1;&#125;@media (prefers-color-scheme: dark) &#123; #mobile-nav-header &#123; background-color: #111; &#125;&#125;#mobile-nav-header img.avatar &#123; ...&#125;@media (prefers-color-scheme: dark) &#123; filter: brightness(85%);&#125; Please note the use of filter:brightness() in the example. It is always advisable to darken the images too, because they can really pop out on dark backgrounds.","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"},{"name":"Stylus","slug":"Stylus","permalink":"https://kiko.io/tags/Stylus/"},{"name":"Dark Mode","slug":"Dark-Mode","permalink":"https://kiko.io/tags/Dark-Mode/"}]},{"title":"A New Blog: Blogging and Synching en route","subtitle":"Part Three of having fun with Hexo and GitHub Pages","series":"A New Blog","part":3,"date":"2019-10-01","updated":"2020-10-03","path":"categories/Tools/A-New-Blog-Blogging-and-Synching-en-route/","permalink":"https://kiko.io/categories/Tools/A-New-Blog-Blogging-and-Synching-en-route/","excerpt":"I work with several devices, some Windows, some Android, and sometimes I have time to write on my articles at home (Notebook, Tablet), in my spare time in the office (Desktop, Laptop) or on my way to somewhere (Smartphone). Right now I’m am in a barber shop, waiting for my haircut and write these lines. So, wherever I am, I need the Hexo project locally, but in sync on a digital device. The blog is synced via Dropbox, but hosted on GitHub Pages, so on every device I need the publishing functions of Git too.","keywords":"work devices windows android time write articles home notebook tablet spare office desktop laptop smartphone im barber shop waiting haircut lines hexo project locally sync digital device blog synced dropbox hosted github pages publishing functions git","text":"I work with several devices, some Windows, some Android, and sometimes I have time to write on my articles at home (Notebook, Tablet), in my spare time in the office (Desktop, Laptop) or on my way to somewhere (Smartphone). Right now I’m am in a barber shop, waiting for my haircut and write these lines. So, wherever I am, I need the Hexo project locally, but in sync on a digital device. The blog is synced via Dropbox, but hosted on GitHub Pages, so on every device I need the publishing functions of Git too. Sync Hexo ProjectBest option for me to achieve this was Dropbox. Another benefit on that is: I can work on the structure of the blog wherever I am and commit when the new feature or improvement is done, because all Git related files are always in sync too. Writing, Editing and Publishing on WindowsMy preferred editor is Visual Studio Code. Good file handling, easy writing, full Git integration and tons of other plugins and helpers. Chapeau Microsoft, well done. Some of the following VS Code plugins makes working with Hexo on GitHub pages a breeze: Adds Hexo commands like init, new, generate, server and clean to the VS Code command palette. Keyboard shortcuts for basic formatting, automatic list editing, autocomlete for images, table formatter and much more for an easier handling of Markdown. Markdown linting and style checking Adds syntax highlighting and code completion to Stylus files Complete visual management of your repositories in VS Code View a Git Graph of your repository with all changes and manage commits. With this editor and its helpers, I’m just two clicks away from publishing a new article or even a new version of the Hexo blog itself. Writing on AndroidThere are a lot of Markdown editors available on Google Play, but one is outstanding: iA Writer for Android. I can open my posts or drafts directly from Dropbox, without the need of any sychronization. Open, write, close, done. Publishing on AndroidThere are some Git related Android apps out there, but no solution was satisfying. Furthermore, I didn’t really need Git here, because I didn’t want to have all source files on my smartphone. I’m working directly on the Dropbox stored MD files via iA Writer. Finally and most important, Git won’t be enough, because before publishing, I have to run hexo generate! Therefore some sort of automatic transfer from Dropbox to GitHub is also out of the game. What I needed, was to tell a server at a certain point of time ‘Hey, please publish for me’, using the only connection I have: Dropbox. Introducing a DemonI have a little media server, running on Windows, and he is synchronizing some folders with Dropbox. He could do the job! After I installed all necessary packages, like NodeJS, Hexo and Git, I included the project folder into the sync. Next step was to design a so called Hexo Command File, a simple TXT file, which holds commands in single lines, extended with execution times, when they were successfully running. 12345postdraft: A-New-Blog-Blogging-and-Synching-en-routepublishnewdraft: \"A New Blog: Blogging and Synching en route\" @ 2019-09-30 21:15regenerate @ 2019-09-29 16:40:01publish @ 2019-09-29 16:40:10 These commands are predefined, because they bundle several real commands and I didn’t want to deal with real commands, due to security reasons. The unprocessed commands are standing at the top of the file (in execution order!) and parameters are separated from the command by a colon and delimited by commas. &lt;command&gt;: [&lt;param1&gt;, ...] @ &lt;execution time&gt;Next step was to create a program to work as an executing demon, who monitors the Hexo Command File (synced by Dropbox) on my server and executes commands without execution dates. I decided to create a simple Console Application in C# and use the built-in Windows Task Scheduler for running it every 2 minutes. The application is called HexoCommander and is available at GitHub. It expects the Hexo Command File to be named hexo-commands.txt, located in the same folder, and provides the following commands: newdraft: “&lt;title&gt;” … runs hexo new draft &quot;&lt;title&gt;&quot; Creates a new draft. postdraft: “&lt;filename without extension&gt;” … runs hexo publish &quot;&lt;filename without extension&gt;&quot; Makes a post out of a draft. regenerate … runs hexo clean hexo generate Wipes all Hexo static pages and generates them new. publish … runs hexo generate git add &quot;source/*&quot; &quot;docs/*&quot; git commit -m &quot;Remote publication via HexoCommander&quot; git push origin master Generates Hexo static pages, stage changes on drafts, posts and static pages, commits the changes with a generic message and pushes them to the server. Running the demonI would have never expected, that the trickiest part was to get HexoCommander running via Windows Task Scheduler. What a mess! I finally find the solution here: Compile HexoCommander in a x86 configuration Create a new task in Task Scheduler with Trigger Dialy Recur every 1 days Repeat task every 2 minutes for a duration of 1 day Action Program/Script: %systemroot%\\Syswow64\\cmd.exe Add Arguments: /C “C:\\MyPath\\HexoCommander.exe /workdir=C:\\MyPath” Start In: %systemroot%\\Syswow64\\ Because some executing commands in the chain are NOT 64-bit, I had to force Task Scheduler to run the 32-bit Command Shell in its own path (see ‘Start In’ and don’t forget the closing backslash) and take the 32-bit compiled HexoCommander as argument after the parameter /C (forcing command to terminate), including its own argument for defining the real working directory. Mind bending, but works…","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kiko.io/tags/GitHub/"},{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://kiko.io/tags/VS-Code/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"}]},{"title":"A New Blog: Customizing Hexo","subtitle":"Part Two of having fun with Hexo and GitHub Pages","series":"A New Blog","part":2,"date":"2019-09-25","updated":"2019-09-26","path":"categories/Tools/A-New-Blog-Customizing-Hexo/","permalink":"https://kiko.io/categories/Tools/A-New-Blog-Customizing-Hexo/","excerpt":"Hexo is a great tool to get quick results (see Part One of this series), when you decide to have a blog and its defaults are practical, but it’s power lies in the possiblities of customization via plugins. On the official plugin page, there are actually 302 plugins listed, but there are many more and no wish will be unsatisfied. I will show you which of these I found worth to work with…","keywords":"hexo great tool quick results part series decide blog defaults practical power lies possiblities customization plugins official plugin page listed unsatisfied show found worth work with…","text":"Hexo is a great tool to get quick results (see Part One of this series), when you decide to have a blog and its defaults are practical, but it’s power lies in the possiblities of customization via plugins. On the official plugin page, there are actually 302 plugins listed, but there are many more and no wish will be unsatisfied. I will show you which of these I found worth to work with… Relative Image PathThe build-in way to include images in your posts works fine, but it is a little aside the normal way to declare images in Markdown. The plugin [Hexo Asset Link] corrects that. After installing via npm install hexo-asset-link --save you can write this: ![Test Image](hello-world/image-1.png)The best is, that VS Code’s Markdown can now show the image. UPDATE:Actually the plugin destroys external links, so don’t use it until this is fixed … or go to node_modules &gt; hexo-asset-link &gt; index.js in your project and change in line 22 protocal to protocol. UPDATE from Update:liolok, the author of the plugin has merged my pull request and published a new new version without the typo. It works now as expected. Hide PostsA new Hexo project comes with a sample post called Hello World. This is fine to play around with, but you don’t want to publish it. Here comes a Hexo plugin to the rescue called Hexo Hide Posts. After installing, you just have to write hidden: true to the Front Matter of you post and it won’t be shown on the blog, but it is still available by URL. Static FilesHexo has the concept of Assets Folders, but for static files, beside article based files, I find it more useful to have a STATIC folder and copy the contents on every build into the publish folder. A good helper for this approach is the plugin Hexo Generator Copy. Install it by running npm install hexo-generator-copy --save and add static_dir: static to your _config.yml and you are done. ![Hexo Static Files](A-New-Blog-Customizing-Hexo/vscode-1.png)FeedThe default Hexo layout has an Atom Feed icon in the upper right corner, but strangely no feed file is generated on build. You need to install the plugin Hexo Feed Generator to fix this, by running npm install hexo-generator-feed --save and copy following section into the _config.yml: 123456789feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' ' order_by: -date Manifest for PWAIn these modern times it’s always a good idea, that your blog feels like an App. For this you need a manifest file (JSON) an several icons (PNG). You can generate these files very fast with the Web App Manifest Generator and store it in your static folder. To bind this file into your blog, you can use the plugin Hexo PWA. Run npm install --save hexo-pwa and copy following section to your _config.yml, where you take the settings from your generated manifest file: 1234567891011121314151617pwa: manifest: path: /manifest.json body: name: myblog.de short_name: My Blog icons: - src: /images/icon-192x192.png sizes: 192x192 type: image/png - src: /images/icon-512x512.png sizes: 512x512 type: image/png start_url: /index.html theme_color: '#025ab1' background_color: '#dddddd' display: standalone Sitemap FileTo help Google and others a bit to index your blog, it is advisable to provide a sitemap file. Here comes Hexo Generator Sitemap to the rescue. Install it by running the command npm install hexo-generator-sitemap --save. You can configure it via _config.yml: 123sitemap: path: sitemap.xml template: ./sitemap-template.xml The plugin installation doesn’t create the needed sitemap-template file, so be sure you grab a copy from the plugins repository: https://github.com/hexojs/hexo-generator-sitemap/blob/master/sitemap.xml CommentingHexo doesn’t have a commenting system, but it’s prepared to stick Disqus comments under each article. Just create a new Disqus account for your blog and note the given short name. By adding following section to the _config.yml Hexo shows the commenting section: 12disqus_enabled: truedisqus_shortname: my-blog Inifinite ScrollHexo shows as much articles at the start page as configured in _config.yml under index_generator.per_page, but it’s nicer to load more articles as you scroll by using the Hexo script Inifinite Scroll. Install by adding following little script in themes &amp; gt; layout &gt; _partial &gt; after-footer.ejs 12345678&lt;script src=\"//cdn.jsdelivr.net/gh/frontendsophie/hexo-infinite-scroll@2.0.0/dist/main.js\"&gt;&lt;/script&gt; &lt;script&gt; infiniteScroll(&#123; showNum: 5, style: 'line-scale', color: '#025ab1' &#125;)&lt;/script&gt; Back To TopIts nice to support the reader on scolling by providing a Scroll-To-Top button. The easiest way to get this, is the script Vanilla Back To Top. Just add follwing to themes &gt;layout &gt; _partial &gt; after-footer.ejs: 123456789101112131415&lt;script&gt;addBackToTop(&#123; diameter: 30, backgroundColor: 'rgb(0, 90, 180)', textColor: '#fff'&#125;)&lt;/script&gt;&lt;style&gt;#back-to-top &#123; border-radius: 0; opacity: 0.6;&#125;#back-to-top:hover &#123; opacity: 1;&#125;&lt;/style&gt;","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://kiko.io/tags/VS-Code/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"}]},{"title":"A New Blog: VS Code, Hexo and GitHub Pages","subtitle":"Part One of having fun with Hexo and GitHub Pages","series":"A New Blog","part":1,"date":"2019-09-24","updated":"2020-10-03","path":"categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/","permalink":"https://kiko.io/categories/Tools/A-New-Blog-VS-Code-Hexo-and-GitHub-Pages/","excerpt":"A few days ago I puzzled over a technical problem regarding SQL Server, Active Directory and Visual Studio Database Projects. With tips, hints and snippets from several websites I got it running and the solution was absolutely memorable. For myself and for others. Nothing is harder than to know ‘you did this before…’, but not to remember how. Because of this strong leaning towards oblivion, I started over 20 years ago my very first website zerbit.de, manually crafted with Classic ASP and a SQL Server database as backend, with an editor, tagging, categories and so on. It was really exciting to build this blog from scratch and writing articles for it, but it was so time consuming to expand the features of the website and keep it running, that some day I quit it silently. So, to document the solution mentioned above, I could use tools like OneNote or others, like in the past years, but this would be just for me and not for all developers, who have a similar problem. I felt it would be unfair to participate from the knowledge of others to get my solution and dont give something back. I decided to write an article just in HTML and publish it on my personal GitHub Page that I didn’t used so far. Ok, just Text … ugly. Just a little CSS and a little more structure and maybe I should do something with Vue JS … STOP … It would be better to pick one of the cool new static website generators based on Node.js, to detain myself from inventing the wheel again and save my time to write articles. So I did a little research and found HEXO … Bingo! I can work with my favorite editor Visual Studio Code, its all HTML, JavaScript and CSS, I can write my articles in Markdown and Hexo has a lot of helpers for stuff Markdown doesn’t provide, it produces static files and works only with files, therefore no need for a database … and it is well documented.","keywords":"days ago puzzled technical problem sql server active directory visual studio database projects tips hints snippets websites running solution absolutely memorable harder before… remember strong leaning oblivion started years website zerbitde manually crafted classic asp backend editor tagging categories exciting build blog scratch writing articles time consuming expand features day quit silently document mentioned tools onenote past developers similar felt unfair participate knowledge dont give back decided write article html publish personal github page didnt text … ugly css structure vue js stop pick cool static generators based nodejs detain inventing wheel save research found hexo bingo work favorite code javascript markdown lot helpers stuff doesnt provide produces files works documented","text":"A few days ago I puzzled over a technical problem regarding SQL Server, Active Directory and Visual Studio Database Projects. With tips, hints and snippets from several websites I got it running and the solution was absolutely memorable. For myself and for others. Nothing is harder than to know ‘you did this before…’, but not to remember how. Because of this strong leaning towards oblivion, I started over 20 years ago my very first website zerbit.de, manually crafted with Classic ASP and a SQL Server database as backend, with an editor, tagging, categories and so on. It was really exciting to build this blog from scratch and writing articles for it, but it was so time consuming to expand the features of the website and keep it running, that some day I quit it silently. So, to document the solution mentioned above, I could use tools like OneNote or others, like in the past years, but this would be just for me and not for all developers, who have a similar problem. I felt it would be unfair to participate from the knowledge of others to get my solution and dont give something back. I decided to write an article just in HTML and publish it on my personal GitHub Page that I didn’t used so far. Ok, just Text … ugly. Just a little CSS and a little more structure and maybe I should do something with Vue JS … STOP … It would be better to pick one of the cool new static website generators based on Node.js, to detain myself from inventing the wheel again and save my time to write articles. So I did a little research and found HEXO … Bingo! I can work with my favorite editor Visual Studio Code, its all HTML, JavaScript and CSS, I can write my articles in Markdown and Hexo has a lot of helpers for stuff Markdown doesn’t provide, it produces static files and works only with files, therefore no need for a database … and it is well documented. Installation.. is quite easy, as described here: https://hexo.io/docs/setup Create folder and open in VS Code Open VS Code Terminal window Install Hexo with $ npm install -g hexo-cli Init Hexo project with $ hexo init Install dependencies with npm install Done WritingCreate new post/draftHexo has posts and drafts, whereat drafts has to published via a Hexo command to become a post. To create an article use the command hexo new post|draft &quot;My Title&quot;. The title will be converted in a URL-encoded string and will be used as file name and url. Meta dataEvery post/draft starts with its header (so called Front Matter) to store some meta data, which describes the post, like title, date, tags or categories. This is used by Hexo to classify and arrange your post during the build. MarkdownHexo posts/drafts are written in Markdown. Good syntax reference are the Markdown Guide and the more detailed Markdown Syntax Guide. ExcerptIs is usual to show a short excerpt an the start page of a blog, to keep it compact and teasering the user to click on a READ MORE button. To achieve this, you just have to add following comment to your article. Everything above is the excerpt and everything below is only shown, when you enter the article: &lt;!-- more --&gt;ImagesSome articles will contain images to illustrate something and the question is, where should they be stored? Answer: In a folder beside the post/draft, which has the same name as the article MD file. To get this, you have to activate the setting post_asset_folder in your _config.yml. Now this folder will be created automatically, when you add a new post/draft. In your Markdown you reference your image with: {% asset_img image-1.png \"Test Image\" %} BuildHexo is a website generator, so a build will generate the whole website in a special folder, which has to be published. This output folder can be configured in the _config.yml: public_dir: publicTo wipe the output folder, run the command: hexo cleanTo start the build, run: hexo generateTo view the website via the build-in local Hexo server, run: hexo serverPublishingMost “complex” task was to publish the new blog on GitHub Pages. My first approach was to use my personal page, as I did with my single HTML file, but this didn’t work, because I wanted to store the whole project on GitHub and it is not possible to point a personal page to the subdirectory docs or use a different branch as master. The simple solution was to create a new repository, named after my my blog kiko.io, to store teh whole project and point the GitHub Page to the subdirectory docs in the settings of the repository. By overriding the default publish folder of Hexo in _config.yml … public_dir: docs… everything was set up. Commit and Push via git and done. Hexo has its own deploying mechanism and it is advisable to disable it, by commenting out the Deployment section _config.yml. Next step was to use my own custom domain for the blog. To achieve this, the most easiest way is to create a text file named CNAME (without extension!) with the content of the domain in a single line and publish this file in the root of the docs folder. Github will recognize this file and do the setup automatically. To point the domain to GitHub, I had to create following A records in my domain providers DNS settings: 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 Last step was to enable Enforce HTTPS in the repositories settings.","categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://kiko.io/tags/GitHub/"},{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://kiko.io/tags/VS-Code/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"}]},{"title":"How-To: Visual Studio Database Project and ADSI","subtitle":null,"date":"2019-09-17","updated":"2020-10-02","path":"categories/SQL/How-To-Visual-Studio-Database-Project-and-ADSI/","permalink":"https://kiko.io/categories/SQL/How-To-Visual-Studio-Database-Project-and-ADSI/","excerpt":"If you are working with a Visual Studio Database Project and have to deal with data from the Active Directory via a Linked Server, you have to announce the data structure of the AD data in order to get the project compiled.","keywords":"working visual studio database project deal data active directory linked server announce structure ad order compiled","text":"If you are working with a Visual Studio Database Project and have to deal with data from the Active Directory via a Linked Server, you have to announce the data structure of the AD data in order to get the project compiled. Step 1 - Linking to the Active DirectoryFirst of all you have to connect your SQL Server to the AD permanently, by running following SQL script once on your SQL Server: USE [master] GO EXEC master.dbo.sp_addlinkedserver @server = N&apos;ADSI&apos;, @srvproduct=N&apos;Active Directory Service Interfaces&apos;, @provider=N&apos;ADSDSOObject&apos;, @datasrc=N&apos;adsdatasource&apos; EXEC master.dbo.sp_addlinkedsrvlogin @rmtsrvname=N&apos;ADSI&apos;, @useself=N&apos;False&apos;, @locallogin=NULL, @rmtuser=N&apos;mydomain\\myadminuser&apos;, @rmtpassword=&apos;mypassword&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;collation compatible&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;data access&apos;, @optvalue=N&apos;true&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;dist&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;pub&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;rpc&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;rpc out&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;sub&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;connect timeout&apos;, @optvalue=N&apos;0&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;collation name&apos;, @optvalue=null GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;lazy schema validation&apos;, @optvalue=N&apos;false&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;query timeout&apos;, @optvalue=N&apos;0&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;use remote collation&apos;, @optvalue=N&apos;true&apos; GO EXEC master.dbo.sp_serveroption @server=N&apos;ADSI&apos;, @optname=N&apos;remote proc transaction promotion&apos;, @optvalue=N&apos;true&apos; GOStep 2 - Fetching ADSI dataTo get data, use OpenQuery against the Linked Server. In order to get only persons and no system accounts, you should filter out all users, which has no firstname (givenName) or lastname (sn): SELECT UserPrincipalName, DisplayName, sAMAccountName AS [SamAccountName], sn AS [LastName], givenName AS [FirstName], title AS [Title], Mail as [MailAddress], department AS [Department], l AS [Location], postalCode AS [PostCode], streetAddress AS [Street], st AS [State] FROM OpenQuery(ADSI, &apos; SELECT UserPrincipalName, DisplayName, sAMAccountName, sn, givenName, department, title, Mail, l, postalCode, streetAddress, st FROM &apos;&apos;LDAP://mydomain.de/DC=mydomain,DC=de&apos;&apos; WHERE objectClass = &apos;&apos;User&apos;&apos; AND objectCategory = &apos;&apos;Person&apos;&apos; AND sn=&apos;&apos;*&apos;&apos; AND givenName = &apos;&apos;*&apos;&apos; &apos;) In most cases you’re done with that … except your organisation has more the 900 users! Then you have to split the fetch in several requests, because SQL Server quits with an error, when trying to read more than 900 records via ADSI. Best option is, to filter the ADSI statement by something like ‘get all user starting with a to j’, when you are sure, that in this case less than 900 records will be given back and repeat the statement several times and glue the data together via a UNION statement: SELECT UserPrincipalName, DisplayName, sAMAccountName AS [SamAccountName], sn AS [LastName], givenName AS [FirstName], title AS [Title], Mail as [MailAddress], department AS [Department], l AS [Location], postalCode AS [PostCode], streetAddress AS [Street], st AS [State] FROM ( SELECT * FROM OpenQuery(ADSI, ' SELECT UserPrincipalName, DisplayName, sAMAccountName, sn, givenName, department, title, Mail, l, postalCode, streetAddress, st FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' WHERE objectClass = ''User'' AND objectCategory = ''Person'' AND sn=''*'' AND givenName = ''*'' AND sAMAccountName &lt;= ''j'' ') UNION ALL SELECT * FROM OpenQuery(ADSI, ' SELECT [...same as above] FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' WHERE objectClass = ''User'' AND objectCategory = ''Person'' AND sn=''*'' AND givenName = ''*'' AND sAMAccountName &gt; ''j'' AND sAMAccountName &lt; ''p'' ') UNION ALL SELECT * FROM OpenQuery(ADSI, ' SELECT [...same as above] FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' WHERE objectClass = ''User'' AND objectCategory = ''Person'' AND sn=''*'' AND givenName = ''*'' AND sAMAccountName &gt;= ''p'' ') ) AD When you store this as a VIEW, you can join it wherever you want on SQL Server: CREATE VIEW [dbo].[vADUsers] AS [...SQL code from above] GO Step 3 - SQL Server Database ProjectIf you work with a SQL Server Database Project, to have the complete structure of your database available in a version control system, you will get some reference errors on compiling and publishing your newly added SQL View vADUsers and on some objects, which rely on this View, because of following problems: Project doesn’t know the Linked Server ADSI The structure (fields) of the data source is unknown Declare the Linked ServerTo show the Project that there is a Linked Server called ADSI, just add following lines at the start of your view: sp_addlinkedserver 'ADSI' GO CREATE VIEW [dbo].[vADUsers] AS [...SQL code from above] This mimics the adding of a Linked Server, but will be ignored by SQL Server on publish, because you already have a Linked Server with this name. The project is happy with it. Declare the data structureWhen you use the SQL-View vADUsers in a Stored Procedure for example, this object won’t compile, because the project knows nothing about the fields of the ADSI data source. The SELECT in the view is not enough. You have to add an empty SELECT to the View vADUsers, just for the declaration of the fields and without returning any records and join this via UNION with the other statements: sp_addlinkedserver 'ADSI' GO CREATE VIEW [dbo].[vtADAllUsers] AS SELECT UserPrincipalName, DisplayName, sAMAccountName AS [SamAccountName], sn AS [LastName], givenName AS [FirstName], title AS [Title], Mail as [MailAddress], department AS [Department], l AS [Location], postalCode AS [PostCode], streetAddress AS [Street], st AS [State] FROM ( -- Fake SELECT to declare the structure of the view SELECT TOP 0 '' UserPrincipalName, '' DisplayName, '' sAMAccountName, '' sn, '' givenName, '' department, '' title, '' Mail, '' l, '' postalCode, '' streetAddress, '' st UNION ALL SELECT * FROM OpenQuery(ADSI, ' SELECT UserPrincipalName, DisplayName, sAMAccountName, sn, givenName, department, title, Mail, l, postalCode, streetAddress, st FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' WHERE objectClass = ''User'' AND objectCategory = ''Person'' AND sn=''*'' AND givenName = ''*'' AND sAMAccountName &gt;= ''j'' ') UNION ALL SELECT * FROM OpenQuery(ADSI, ' SELECT [...same as above] FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' WHERE objectClass = ''User'' AND objectCategory = ''Person'' AND sn=''*'' AND givenName = ''*'' AND sAMAccountName &lt; ''j'' AND sAMAccountName &gt; ''p'' ') UNION ALL SELECT * FROM OpenQuery(ADSI, ' SELECT [...same as above] FROM ''LDAP://mydomain.de/DC=mydomain,DC=de'' WHERE objectClass = ''User'' AND objectCategory = ''Person'' AND sn=''*'' AND givenName = ''*'' AND sAMAccountName &lt;= ''p'' ') ) AD Now, you can fetch data from Active Directory and store the code in a Database Project properly. HAPPY CODING :)","categories":[{"name":"SQL","slug":"SQL","permalink":"https://kiko.io/categories/SQL/"}],"tags":[{"name":"ADSI","slug":"ADSI","permalink":"https://kiko.io/tags/ADSI/"},{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://kiko.io/tags/Visual-Studio/"},{"name":"Database Project","slug":"Database-Project","permalink":"https://kiko.io/tags/Database-Project/"}]}],"categories":[{"name":"Tools","slug":"Tools","permalink":"https://kiko.io/categories/Tools/"},{"name":"Discoveries","slug":"Discoveries","permalink":"https://kiko.io/categories/Discoveries/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"},{"name":"UI-Design","slug":"UI-Design","permalink":"https://kiko.io/categories/UI-Design/"},{"name":"C#","slug":"C","permalink":"https://kiko.io/categories/C/"},{"name":"JavaScript#","slug":"JavaScript","permalink":"https://kiko.io/categories/JavaScript/"},{"name":"SQL","slug":"SQL","permalink":"https://kiko.io/categories/SQL/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://kiko.io/tags/Hexo/"},{"name":"Blogging","slug":"Blogging","permalink":"https://kiko.io/tags/Blogging/"},{"name":"Great Finds","slug":"Great-Finds","permalink":"https://kiko.io/tags/Great-Finds/"},{"name":"Browser","slug":"Browser","permalink":"https://kiko.io/tags/Browser/"},{"name":"CSS","slug":"CSS","permalink":"https://kiko.io/tags/CSS/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://kiko.io/tags/JavaScript/"},{"name":"GitHub","slug":"GitHub","permalink":"https://kiko.io/tags/GitHub/"},{"name":"Error","slug":"Error","permalink":"https://kiko.io/tags/Error/"},{"name":"Stylus","slug":"Stylus","permalink":"https://kiko.io/tags/Stylus/"},{"name":"Trello","slug":"Trello","permalink":"https://kiko.io/tags/Trello/"},{"name":"jQuery","slug":"jQuery","permalink":"https://kiko.io/tags/jQuery/"},{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://kiko.io/tags/Visual-Studio/"},{"name":"Versioning","slug":"Versioning","permalink":"https://kiko.io/tags/Versioning/"},{"name":"T4","slug":"T4","permalink":"https://kiko.io/tags/T4/"},{"name":"Resource","slug":"Resource","permalink":"https://kiko.io/tags/Resource/"},{"name":"Localization","slug":"Localization","permalink":"https://kiko.io/tags/Localization/"},{"name":"TFS/DevOps","slug":"TFS-DevOps","permalink":"https://kiko.io/tags/TFS-DevOps/"},{"name":"Dark Mode","slug":"Dark-Mode","permalink":"https://kiko.io/tags/Dark-Mode/"},{"name":"VS Code","slug":"VS-Code","permalink":"https://kiko.io/tags/VS-Code/"},{"name":"ADSI","slug":"ADSI","permalink":"https://kiko.io/tags/ADSI/"},{"name":"Database Project","slug":"Database-Project","permalink":"https://kiko.io/tags/Database-Project/"}]}